{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arup3201/Summarization-Project-using-Pointer-Gen/blob/main/Get_To_The_Point_Summarization_with_Pointer_Generator_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the wraping the outputs of colab"
      ],
      "metadata": {
        "id": "aWWumM-N6C31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "J2_Q63jmdSp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports Libraries"
      ],
      "metadata": {
        "id": "A3eWiUNHDwjn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x6QucUCZ0q2V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "# For tokenizing and processing the examples for the model training\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Layers for the Encoder, Attention and Decoder\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM\n",
        "from tensorflow.keras.layers import RepeatVector, Concatenate, Activation, Dot\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# For model initialization\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "# For training the model\n",
        "from tensorflow.keras.optimizers.experimental import Adagrad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data"
      ],
      "metadata": {
        "id": "Z-SylnbUD2s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the CNN stories from the url into cnn_stories_tgz file\n",
        "cnn_stories_tgz = tf.keras.utils.get_file(\n",
        "    origin=\"https://huggingface.co/datasets/cnn_dailymail/resolve/main/data/cnn_stories.tgz\",\n",
        ")\n",
        "\n",
        "# Download the Dailymail stories from the url into dailymail_stories_tgz file\n",
        "dailymail_stories_tgz = tf.keras.utils.get_file(\n",
        "    origin=\"https://huggingface.co/datasets/cnn_dailymail/resolve/main/data/dailymail_stories.tgz\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_03wyoLlFhO",
        "outputId": "ad1d3d12-a264-45b5-8773-b5c923cf5fd9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://huggingface.co/datasets/cnn_dailymail/resolve/main/data/cnn_stories.tgz\n",
            "158577824/158577824 [==============================] - 2s 0us/step\n",
            "Downloading data from https://huggingface.co/datasets/cnn_dailymail/resolve/main/data/dailymail_stories.tgz\n",
            "375893739/375893739 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_stories_tgz, dailymail_stories_tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyid1XyFl1sp",
        "outputId": "fa9020ad-37f3-4249-f23b-c41499da48d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/root/.keras/datasets/cnn_stories.tgz',\n",
              " '/root/.keras/datasets/dailymail_stories.tgz')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf /root/.keras/datasets/cnn_stories.tgz\n",
        "!tar -xzf /root/.keras/datasets/dailymail_stories.tgz"
      ],
      "metadata": {
        "id": "EHJtYhZpls0i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_stories_dir = pathlib.Path('/content/cnn/stories')\n",
        "dailymail_stories_dir = pathlib.Path('/content/cnn/stories')"
      ],
      "metadata": {
        "id": "ag5ubSt7l88l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_stories_dir, dailymail_stories_dir"
      ],
      "metadata": {
        "id": "UmMCM--Yhm3B",
        "outputId": "8cb6a093-72f6-40df-a083-2d5c4e35f2e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('/content/cnn/stories'), PosixPath('/content/cnn/stories'))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print Stories"
      ],
      "metadata": {
        "id": "WqScGmO6D5XI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_filenames(dir_path, num_files=5):\n",
        "  '''Prints the name of the files that are present at `dir_path`.\n",
        "  Maximum `num_files` number of files are shown.\n",
        "\n",
        "  Arguments:\n",
        "    dir_path: PosixPath, pointing to the directory of which the user\n",
        "              wants to prints the file names.\n",
        "    num_files: int, number of files user wants to print.\n",
        "\n",
        "  returns:\n",
        "    nothing\n",
        "  '''\n",
        "\n",
        "  count = 0\n",
        "  for f in dir_path.glob('*.story'):\n",
        "    print(f.name)\n",
        "    count += 1\n",
        "\n",
        "    if count == num_files:\n",
        "      break\n",
        "  else:\n",
        "    print(f\"Less than {num_files} is present!\")"
      ],
      "metadata": {
        "id": "dZFFXG7Pg86H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_filenames(cnn_stories_dir)"
      ],
      "metadata": {
        "id": "nv3g7-M316yL",
        "outputId": "1cb2a81e-2da0-4875-ed50-778ef6351829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7b96da612c71da177853c056b656254b1e4e871f.story\n",
            "86873c04f431c7f5a093351bf60033268181dd25.story\n",
            "5990e753f34d1c62cc2a29e7519fbd4748ef6090.story\n",
            "4b4683d06ab2f0dd0044c756f5d9dc4bd253fe37.story\n",
            "1a413ac9d0bbb5e1ae178f6c8df0588a5c75c961.story\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_filenames(dailymail_stories_dir)"
      ],
      "metadata": {
        "id": "WcyW1wJa2EaN",
        "outputId": "a8c02393-6b34-4fd4-b013-edf41ebb38f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7b96da612c71da177853c056b656254b1e4e871f.story\n",
            "86873c04f431c7f5a093351bf60033268181dd25.story\n",
            "5990e753f34d1c62cc2a29e7519fbd4748ef6090.story\n",
            "4b4683d06ab2f0dd0044c756f5d9dc4bd253fe37.story\n",
            "1a413ac9d0bbb5e1ae178f6c8df0588a5c75c961.story\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking a sample .story file from cnn stories\n",
        "sample_filename = \"438411e10e1ef79b47cc48cd95296d85798c1e38.story\"\n",
        "sample_filedir = cnn_stories_dir\n",
        "\n",
        "sample_filepath = sample_filedir / sample_filename\n",
        "with open(sample_filepath, 'r') as f:\n",
        "  sample_story = f.read()\n",
        "\n",
        "print(f\"A sample story:\\n{sample_story}\")"
      ],
      "metadata": {
        "id": "Uw0kqchX3X7X",
        "outputId": "b8a73eb0-be8e-4c46-d84c-6b67080ca83f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample story:\n",
            "New York (CNN) -- The U.S. population is expected to top out at close to 312.8 million people just around the time crowds gather to watch the ball drop on New Year's Eve, according to new census data released Thursday.\n",
            "\n",
            "The figure represents a 0.7% increase from last year, adding 2,250,129 people to the U.S. population since the start of 2011, and a 1.3% increase since Census Day, April 1, 2010.\n",
            "\n",
            "The agency estimates that beginning in January, one American will be born every eight seconds and one will die every 12 seconds.\n",
            "\n",
            "U.S.-bound immigrants are also expected to add one person every 46 seconds.\n",
            "\n",
            "That combination of births, deaths and migration is expected to add a single person to the U.S. population every 17 seconds, the Census Bureau said.\n",
            "\n",
            "Meanwhile, millions are set to ring in the new year.\n",
            "\n",
            "In New York, authorities are preparing for large crowds in Manhattan's Times Square, where Lady Gaga is expected to join Mayor Michael Bloomberg to push the button that drops the Waterford Crystal ball at 11:59 p.m. ET on New Year's Eve.\n",
            "\n",
            "\"And I'm so looking forward to performing on NYE+dropping the Ball with Mayor Bloomberg!\" the pop star posted on Twitter. \"What an honor as a New Yorker.\"\n",
            "\n",
            "Past guests have included Muhammad Ali, Rudy Giuliani, Colin Powell and Bill and Hillary Clinton.\n",
            "\n",
            "On Thursday, officials conducted New York's annual \"airworthiness test\" -- a process in which confetti is tossed by handfuls above Times Square -- in preparation for the annual city tradition of dumping one ton of confetti over revelers in the iconic square.\n",
            "\n",
            "The Big Apple this year edged out Las Vegas for the first time in seven years as the top travel U.S. destination for those celebrating the new year, according to a December travel booking website poll.\n",
            "\n",
            "Seven New York neighborhoods made the top 10 list, with two districts in Las Vegas and one in New Orleans making up the other three, according to the Priceline poll.\n",
            "\n",
            "\"It appears that New York City will be helped this year by a weather forecast that calls for warmer than usual temperatures over the holiday weekend,\" said company spokesman Brian Ek.\n",
            "\n",
            "@highlight\n",
            "\n",
            "Census Bureau: U.S. population is expected to be 312.8 million on New Year's Day\n",
            "\n",
            "@highlight\n",
            "\n",
            "That figure represents a 0.7% increase from last year\n",
            "\n",
            "@highlight\n",
            "\n",
            "Lady Gaga, mayor to activate ball drop at Times Square on New Year's Eve\n",
            "\n",
            "@highlight\n",
            "\n",
            "NYC has supplanted Las Vegas as the top New Year's destination, Priceline poll says\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Global Variables"
      ],
      "metadata": {
        "id": "ihAsXBceD7ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the global variables\n",
        "dm_single_close_quote = u'\\u2019' # unicode for closing single quote\n",
        "dm_double_close_quote = u'\\u201d' # unicode for closing double quote\n",
        "END_TOKENS = ['.', '!', '?', '...', \"'\", \"`\", '\"',\n",
        "              dm_single_close_quote, dm_double_close_quote, \")\"]\n",
        "\n",
        "# Maximum stories to process from cnn and dailymail each\n",
        "MAX_STORIES = 310000\n",
        "\n",
        "# From the total data how to split into train, val and test\n",
        "TRAIN_SIZE = 0.8 # Fraction of the total dataset to use for training\n",
        "VAL_SIZE = 0.1 # Fraction of the total dataset to use for validation\n",
        "TEST_SIZE = 0.1 # Fraction of the total dataset to use for testing\n",
        "\n",
        "# For tokenization\n",
        "VOCAB_SIZE = 50000 # Vocabulary size or no of unique words\n",
        "OOV_TOKEN = \"<OOV>\" # Word token to represent the out-of-vocabulary words\n",
        "\n",
        "# For standardization\n",
        "START_TOKEN = '<START>' # Starting word of each sentence\n",
        "END_TOKEN = '<END>' # Ending word of each sentence\n",
        "\n",
        "# Total tokens to represent encoder input sentence and decoder input sentence(Values are taken from paper)\n",
        "MAX_ARTICLE_TOKENS = 400 # Maximum no of tokens to consider in article when processing them for model\n",
        "MAX_SUMMARY_TOKENS = 100 # Maximum no of tokens to consider in summary when processing them for model\n",
        "\n",
        "# For dataset creation hyperparameters\n",
        "BUFFER_SIZE = 5000 # Buffer size when using shuffle\n",
        "BATCH_SIZE = 16 # No of examples in each batch\n",
        "\n",
        "# Model Archietecture hyperparameters (Values are taken from the paper)\n",
        "EMB_OUT = 128 # Embedding output dimension\n",
        "ENCODER_STATE_DIM = 256 # Encoder hidden(also cell) state dimension\n",
        "DECODER_STATE_DIM = 2*ENCODER_STATE_DIM # Decoder hidden(also cell) state dimension\n",
        "DENSE1_UNITS = 128 # Attention first dense layer units(calculates partial energy)\n",
        "DENSE2_UNITS = 1 # Attention secodn dense layer units(calculated final energy)\n",
        "DENSE_UNITS = 512 # Units of the Dense layers before output layer, make sure it is same as decoder state dimension\n",
        "\n",
        "# Model Optimizer hyperparameters (Values are taken from the paper)\n",
        "LEARNING_RATE=0.15 # Learning rate\n",
        "INIT_ACC_VAL=0.1 # Initial accumulator value\n",
        "MAX_GRAD_NORM=2 # Gardient norm\n",
        "\n",
        "# Model Checkpoint hyperparameters\n",
        "BASELINE_MODEL_CHECKPOINT = \"baseline-model/cp-{epoch:04d}.ckpt\"\n",
        "POINTER_MODEL_CHECKPOINT = \"pointer-model/cp-{epoch:04d}.ckpt\"\n",
        "COVERAGE_MODEL_CHECKPOINT = \"coverage-model/cp-{epoch:04d}.ckpt\"\n",
        "PATIENCE = 5\n",
        "\n",
        "## Model Fit (All values are choosen closer to the ones in the paper)\n",
        "# Base model\n",
        "BASE_EPOCHS = 33\n",
        "STEPS_PER_EPOCHS_BASE = 18181\n",
        "# Pointer Model\n",
        "POINTER_EPOCHS = 13\n",
        "POINTER_STEPS_PER_EPOCHS = 18000\n",
        "# Coverage Model\n",
        "COVERAGE_EPOCHS = 1\n",
        "COVERAGE_STEPS_PER_EPOCHS = 3000\n",
        "\n",
        "# Coverage mechanism\n",
        "LAMBDA_VAL = 1"
      ],
      "metadata": {
        "id": "cubLAm1Q3SuG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixing periods of the stories"
      ],
      "metadata": {
        "id": "UXHUPXvlEDTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am creating a function `fix_missing_period` where I am taking 2 arguements, one for the `line` for which I am checking and fixing the period and other is `end_tokens` which is a list that has all the tokens that I should consider as ending of a sentence.\n",
        "\n",
        "These are the steps -\n",
        "1. Check if line contains `@highlight`, if True then just return the line.\n",
        "2. Check if line is empty, then return line as it is.\n",
        "3. Check is line ends with any of the `end_tokens`, if so then return line as it is.\n",
        "4. Only is none of the above conditions match then append `.` to the current line."
      ],
      "metadata": {
        "id": "iZPt8EVBzJ8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_missing_period(line, end_tokens=END_TOKENS):\n",
        "  '''function to fix the missing periods for some story lines which do not end with\n",
        "  any of the end_tokens mentioned.\n",
        "\n",
        "  Argument:\n",
        "    line: string, line of the story to fix the missing the period of.\n",
        "    end_tokens: list of strings, all the tokens that are considered as line end.\n",
        "\n",
        "  Returns:\n",
        "    new line with fixed the ending part by adding an ending token if not present.\n",
        "  '''\n",
        "  if \"@highlight\" in line:\n",
        "    return line\n",
        "  elif line == \"\":\n",
        "    return line\n",
        "  elif line[-1] in end_tokens:\n",
        "    return line\n",
        "\n",
        "  return line + '.'"
      ],
      "metadata": {
        "id": "i-S-Hss12TPk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"i have a bad habit of not giving full-stop after sentence\\nLike this setence\"\n",
        "print(f\"Fixing {fix_missing_period(sample_text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1hiNysxnmAO",
        "outputId": "1493cc4e-e13e-49d1-bb3d-907b44d3c67d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixing i have a bad habit of not giving full-stop after sentence\n",
            "Like this setence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the Stories into articles and summaries"
      ],
      "metadata": {
        "id": "fEoN3HDSEHjI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am creating a function `split_article_summary` which will split the story into article and summary parts.\n",
        "\n",
        "The function takes only 1 arguement and that is the `story` which will be splitted into article and summary.\n",
        "\n",
        "The steps to follow are -\n",
        "1. Split the story by new line `\\n`. I will get a list of lines.\n",
        "2. Strip the lines by using list comprehension.\n",
        "3. Use list comprehension to make lower case each line by using `.lower()`.\n",
        "4. Fix each line by adding period if there is none in that line using `fix_missing_period` function.\n",
        "5. Make 2 empty list for `article` and `summary`.\n",
        "6. Go through each line. In each line, I need to check 4 things,\n",
        "  * line contains `@highlight` or not, if True then set `next_highlight` to `True` because the next to next line is going to be a summary line.\n",
        "  * line is `\"\"` empty or not, if True then ignore.\n",
        "  * `next_highlight` is True or not, if True then append the line to `summary`.\n",
        "  * If non of the ebove then append to `article`.\n",
        "7. After done with filling the `article` and `summary` list with lines, join those sentences to make the whole article and summary. Here, I am using `.join()` method."
      ],
      "metadata": {
        "id": "5-tqWtoowXxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_article_summary(story):\n",
        "  '''Splits the story into 2 parts, one for article and other for summary of that\n",
        "  article. Returns the article and summary.\n",
        "\n",
        "  Argument:\n",
        "    story: string file that contains both article and summary combiningly.\n",
        "\n",
        "  Returns:\n",
        "    article, summary seperately from the story.\n",
        "\n",
        "  '''\n",
        "  lines = story.split('\\n')\n",
        "  lines = [line.strip() for line in lines]\n",
        "  lines = [line.lower() for line in lines]\n",
        "\n",
        "  # Fix the ending period\n",
        "  lines = [fix_missing_period(line) for line in lines]\n",
        "\n",
        "  # List to contain the article and summary lines\n",
        "  article = []\n",
        "  summary = []\n",
        "\n",
        "  # Indicator of whether the next line is the summary or not\n",
        "  next_highlight = False\n",
        "\n",
        "  for line in lines:\n",
        "    if \"@highlight\" in line:\n",
        "      next_highlight = True\n",
        "    elif line==\"\":\n",
        "      continue\n",
        "    elif next_highlight:\n",
        "      summary.append(line)\n",
        "    else:\n",
        "      article.append(line)\n",
        "\n",
        "  article = ' '.join(article)\n",
        "  summary = ' '.join(summary)\n",
        "\n",
        "  return article, summary"
      ],
      "metadata": {
        "id": "-X4eMltQnf10"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_article, sample_summary = split_article_summary(sample_story)\n",
        "\n",
        "print(f\"Sample Article after spliting:\\n{sample_article}\")\n",
        "print(f\"Sample Summary after spliting:\\n{sample_summary}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuUjOaN9orGU",
        "outputId": "e0133cca-84cd-4b01-e063-ec57f7244ae3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Article after spliting:\n",
            "new york (cnn) -- the u.s. population is expected to top out at close to 312.8 million people just around the time crowds gather to watch the ball drop on new year's eve, according to new census data released thursday. the figure represents a 0.7% increase from last year, adding 2,250,129 people to the u.s. population since the start of 2011, and a 1.3% increase since census day, april 1, 2010. the agency estimates that beginning in january, one american will be born every eight seconds and one will die every 12 seconds. u.s.-bound immigrants are also expected to add one person every 46 seconds. that combination of births, deaths and migration is expected to add a single person to the u.s. population every 17 seconds, the census bureau said. meanwhile, millions are set to ring in the new year. in new york, authorities are preparing for large crowds in manhattan's times square, where lady gaga is expected to join mayor michael bloomberg to push the button that drops the waterford crystal ball at 11:59 p.m. et on new year's eve. \"and i'm so looking forward to performing on nye+dropping the ball with mayor bloomberg!\" the pop star posted on twitter. \"what an honor as a new yorker.\" past guests have included muhammad ali, rudy giuliani, colin powell and bill and hillary clinton. on thursday, officials conducted new york's annual \"airworthiness test\" -- a process in which confetti is tossed by handfuls above times square -- in preparation for the annual city tradition of dumping one ton of confetti over revelers in the iconic square. the big apple this year edged out las vegas for the first time in seven years as the top travel u.s. destination for those celebrating the new year, according to a december travel booking website poll. seven new york neighborhoods made the top 10 list, with two districts in las vegas and one in new orleans making up the other three, according to the priceline poll. \"it appears that new york city will be helped this year by a weather forecast that calls for warmer than usual temperatures over the holiday weekend,\" said company spokesman brian ek.\n",
            "Sample Summary after spliting:\n",
            "census bureau: u.s. population is expected to be 312.8 million on new year's day. that figure represents a 0.7% increase from last year. lady gaga, mayor to activate ball drop at times square on new year's eve. nyc has supplanted las vegas as the top new year's destination, priceline poll says.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am creating a function `get_articles_summaries` which will process each of the stories present in the directory of cnn and dailymail and return the articles, summaries in the form of list.\n",
        "\n",
        "This function will take 2 arguements. One will be the `stories_dir` which is a Posix format string from `pathlib` library and another arguement is of `max_stories` which is the maximum number of stories that we will extract from those directories.\n",
        "\n",
        "The process is simple. We will follow this steps -\n",
        "1. Create 2 empty lists of `articles` and `summaries`.\n",
        "2. Loop through all the files present in the directory `stories_dir` using `.glob` generator method.\n",
        "3. Make a `count` variable which will count the number of processed strories and when it hits `max_stories`, break from the loop.\n",
        "4. Inside the loop, you will open the file in `r` reading format, then just use `.read()` method to read the story.\n",
        "5. Everytime after reading the story, split the article and summary part from it and then append them inside the `articles` and `summaries` list.\n",
        "6. Return the 2 lists."
      ],
      "metadata": {
        "id": "oTEa0m3Huxz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_articles_summaries(stories_dir, max_stories):\n",
        "  '''stores the stories from stories_dir folder into a list and returns the list\n",
        "\n",
        "  Arguments:\n",
        "    stories_dir: Posix string, the directory where the stories are stored\n",
        "    max_stories: maximum number of stories to store\n",
        "\n",
        "  Returns:\n",
        "    list of stories.\n",
        "\n",
        "  '''\n",
        "  articles = []\n",
        "  summaries = []\n",
        "\n",
        "  count = 0\n",
        "  for f in stories_dir.glob(\"*.story\"):\n",
        "    count += 1\n",
        "    with open(f, 'r') as reader:\n",
        "      story = reader.read()\n",
        "\n",
        "      article, summary = split_article_summary(story)\n",
        "\n",
        "      articles.append(article)\n",
        "      summaries.append(summary)\n",
        "\n",
        "    if count == max_stories:\n",
        "      break\n",
        "\n",
        "  return articles, summaries"
      ],
      "metadata": {
        "id": "4VUmbYSpnjAr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of all available .story files, we will only take `MAX_STORIES` number of files and then open them."
      ],
      "metadata": {
        "id": "Uk-BuCM4rIiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_articles, cnn_summaries = get_articles_summaries(cnn_stories_dir, MAX_STORIES)"
      ],
      "metadata": {
        "id": "aa9ZDQntpHQZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total no of cnn stories captured are {len(cnn_articles)}\\n\\n\")\n",
        "print(f\"One of the CNN articles: {cnn_articles[0]}\\n\\n\")\n",
        "print(f\"The summary of this article: {cnn_summaries[0]}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q_i-69YqJnj",
        "outputId": "6078cf9e-816e-49fd-a540-7fda9f3b03c1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no of cnn stories captured are 92579\n",
            "\n",
            "\n",
            "One of the CNN articles: (cnn) -- jerry yellin has spent most of his life trying to forget about the stench of death on the island of iwo jima 65 years ago. yellin was a p-51 fighter pilot who had turned 22 a few weeks before he touched down on the island march 7, 1945, amid some of the bloodiest fighting of world war ii's pacific campaign. \"to one side, there were mounds and mounds and mounds of bodies of japanese soldiers being pushed around by bulldozers into mass graves. and right behind our squadron area was the marine mortuary, where they'd lay out the bodies, check their dog tags and fingerprint them for identification,\" recalls yellin, an 87-year-old retiree who lives in vero beach, florida. \"i've lived with those memories all of my life and it was not something i ever wanted to go back to.\" nevertheless, yellin was back on the island last week for the first time since 1945 to attend a ceremony commemorating the battle's 65th anniversary. about 22,000 japanese soldiers died defending the island, along with more than 6,000 americans, in a battle that was memorialized in the iconic photograph of five u.s. marines and a navy corpsman raising the u.s. flag atop mount suribachi, the island's dormant volcano. the americans secured the island on march 26, 1945, marking the u.s. military's most significant advance in its island-hopping strategy to reach japan. but the battle proved to be longer and deadlier than planners had anticipated, depleting much of the u.s. military's resources. the u.s. abandoned its plan to invade the japanese mainland and turned to the atomic bomb to end the war. since 1995, the japanese and american associations of iwo jima have met on the 8-square-mile island, now known as iwo to, to commemorate the 35-day battle with a \"reunion of honor.\" yellin and several other veterans made the day-long trip to iwo jima from guam on march 3 with the tour company, military tours. each man had his own reason for going, but all left united through the shared experience of an event that only a few can understand, says cyril \"cy\" o'brien, a marine correspondent who covered the battle of iwo jima, who also made the trip. \"in a way, it's reliving something that happened so long ago that was probably what i would consider some of the most ennobling moments of our lives. i am a writer, too, so going there this time, looking at the terrain and seeing this hill, this cliff, this gorge, opens a whole new page to the memory,\" he says. o'brien, a retired newspaper reporter who is working on a book about his experiences as a war correspondent, has been back to iwo jima for the reunion of honor four times. but the sense of awe never diminishes as the first sight of the island from the plane, he says. \"when we approached iwo jima and saw suribachi, you would be amazed what happens. everything became as quiet and as solemn as if we'd entered a cathedral. you could tell the island had captivated everyone, the island had brought them back to their youth. the first moment was a very stirring moment. always is,\" he says. for yellin, it has been a longer journey back to the battlefield where, as a young airman, he left behind 11 comrades, sparking years of bitterness and racial prejudice. yellin recalls passing over the flag each time he and his brothers flew a mission to support the marines on the ground, who faced the formidable task of taking the island from a military force on its last stand. \"i never thought of the people on the ground as people. you can hate somebody so much that you don't see them as people,\" he says. \"i had no desire to go back to japan. why the hell would you want to visit the place where your enemy was? who wants to visit the people you fought against and hated?\" the healing began in 1988, when his son married a japanese woman whose father was a pilot in the japanese imperial army air service, who also flew missions in iwo jima. yellin's son's future in-laws opposed the marriage until the men met and shared their experiences in iwo jima. \"i hated him and he hated me. we met for the first time three days before the wedding. and he said, 'any man that could fly a p-51 against the japanese and live must be a brave man, and i want the blood of that man to flow through the veins of my grandchildren.'\" he says. \"then, my son got married and started having children and my whole life expanded. i saw that human beings were killed in the war, and they were kind people, they were bright people, and now they're my family.\" through the marriage, the two wartime enemies made peace, a process that yellin documented in a novel published last year, \"of war & weddings.\" but he still never considered visiting iwo jima until he was offered an opportunity to commemorate his fallen brothers -- 11 in combat and five in training -- from the 78th fighter squadron in a ceremony during the reunion of honor. upon learning of his plans, yellin's 18-year-old grandson expressed interest in seeing the place where his grandfathers had once fought each other. \"i just didn't want to relive all that, but because i have a japanese grandson and because he wanted to go, i had to go,\" says yellin. \"and i'm happy, delighted, thrilled that i went. i cried most of the day, from the moment we landed. many memories came back, and we did a memorial for the 16 guys. it was like closing the circle.\"\n",
            "\n",
            "\n",
            "The summary of this article: retired fighter pilot jerry yellin returns to iwo jima with son, grandson for \"reunion of honor\" reunion brings together veterans, officials from japan, the united states. return represents closure for yellin, whose son married the daughter of japanese pilot. \"it's reliving something that happened so long ago,\" marine correspondent cy o'brien says.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dailymail_articles, dailymail_summaries = get_articles_summaries(dailymail_stories_dir,\n",
        "                                                                 MAX_STORIES)"
      ],
      "metadata": {
        "id": "KT4Hrp6nqeKu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total no of dailymail stories captured are {len(dailymail_articles)}\\n\\n\")\n",
        "print(f\"One of the Dailymail articles: {dailymail_articles[0]}\\n\\n\")\n",
        "print(f\"The summary of this article: {dailymail_summaries[0]}\\n\\n\")"
      ],
      "metadata": {
        "id": "nkzwSP9kh4VK",
        "outputId": "0d3aaab8-5a41-46ae-95b9-d2949dc9e336",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no of dailymail stories captured are 92579\n",
            "\n",
            "\n",
            "One of the Dailymail articles: (cnn) -- jerry yellin has spent most of his life trying to forget about the stench of death on the island of iwo jima 65 years ago. yellin was a p-51 fighter pilot who had turned 22 a few weeks before he touched down on the island march 7, 1945, amid some of the bloodiest fighting of world war ii's pacific campaign. \"to one side, there were mounds and mounds and mounds of bodies of japanese soldiers being pushed around by bulldozers into mass graves. and right behind our squadron area was the marine mortuary, where they'd lay out the bodies, check their dog tags and fingerprint them for identification,\" recalls yellin, an 87-year-old retiree who lives in vero beach, florida. \"i've lived with those memories all of my life and it was not something i ever wanted to go back to.\" nevertheless, yellin was back on the island last week for the first time since 1945 to attend a ceremony commemorating the battle's 65th anniversary. about 22,000 japanese soldiers died defending the island, along with more than 6,000 americans, in a battle that was memorialized in the iconic photograph of five u.s. marines and a navy corpsman raising the u.s. flag atop mount suribachi, the island's dormant volcano. the americans secured the island on march 26, 1945, marking the u.s. military's most significant advance in its island-hopping strategy to reach japan. but the battle proved to be longer and deadlier than planners had anticipated, depleting much of the u.s. military's resources. the u.s. abandoned its plan to invade the japanese mainland and turned to the atomic bomb to end the war. since 1995, the japanese and american associations of iwo jima have met on the 8-square-mile island, now known as iwo to, to commemorate the 35-day battle with a \"reunion of honor.\" yellin and several other veterans made the day-long trip to iwo jima from guam on march 3 with the tour company, military tours. each man had his own reason for going, but all left united through the shared experience of an event that only a few can understand, says cyril \"cy\" o'brien, a marine correspondent who covered the battle of iwo jima, who also made the trip. \"in a way, it's reliving something that happened so long ago that was probably what i would consider some of the most ennobling moments of our lives. i am a writer, too, so going there this time, looking at the terrain and seeing this hill, this cliff, this gorge, opens a whole new page to the memory,\" he says. o'brien, a retired newspaper reporter who is working on a book about his experiences as a war correspondent, has been back to iwo jima for the reunion of honor four times. but the sense of awe never diminishes as the first sight of the island from the plane, he says. \"when we approached iwo jima and saw suribachi, you would be amazed what happens. everything became as quiet and as solemn as if we'd entered a cathedral. you could tell the island had captivated everyone, the island had brought them back to their youth. the first moment was a very stirring moment. always is,\" he says. for yellin, it has been a longer journey back to the battlefield where, as a young airman, he left behind 11 comrades, sparking years of bitterness and racial prejudice. yellin recalls passing over the flag each time he and his brothers flew a mission to support the marines on the ground, who faced the formidable task of taking the island from a military force on its last stand. \"i never thought of the people on the ground as people. you can hate somebody so much that you don't see them as people,\" he says. \"i had no desire to go back to japan. why the hell would you want to visit the place where your enemy was? who wants to visit the people you fought against and hated?\" the healing began in 1988, when his son married a japanese woman whose father was a pilot in the japanese imperial army air service, who also flew missions in iwo jima. yellin's son's future in-laws opposed the marriage until the men met and shared their experiences in iwo jima. \"i hated him and he hated me. we met for the first time three days before the wedding. and he said, 'any man that could fly a p-51 against the japanese and live must be a brave man, and i want the blood of that man to flow through the veins of my grandchildren.'\" he says. \"then, my son got married and started having children and my whole life expanded. i saw that human beings were killed in the war, and they were kind people, they were bright people, and now they're my family.\" through the marriage, the two wartime enemies made peace, a process that yellin documented in a novel published last year, \"of war & weddings.\" but he still never considered visiting iwo jima until he was offered an opportunity to commemorate his fallen brothers -- 11 in combat and five in training -- from the 78th fighter squadron in a ceremony during the reunion of honor. upon learning of his plans, yellin's 18-year-old grandson expressed interest in seeing the place where his grandfathers had once fought each other. \"i just didn't want to relive all that, but because i have a japanese grandson and because he wanted to go, i had to go,\" says yellin. \"and i'm happy, delighted, thrilled that i went. i cried most of the day, from the moment we landed. many memories came back, and we did a memorial for the 16 guys. it was like closing the circle.\"\n",
            "\n",
            "\n",
            "The summary of this article: retired fighter pilot jerry yellin returns to iwo jima with son, grandson for \"reunion of honor\" reunion brings together veterans, officials from japan, the united states. return represents closure for yellin, whose son married the daughter of japanese pilot. \"it's reliving something that happened so long ago,\" marine correspondent cy o'brien says.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting data into training, validation and testing set"
      ],
      "metadata": {
        "id": "nEaIcT3lEaez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am creating another function -\n",
        "`split_dataset(train_size, val_size, test_size)`: I am creating this function to split the original 1,00,000 examples into 80,000 training samples, 10,000 val samples and 10,000 test samples."
      ],
      "metadata": {
        "id": "8ea-PhS3iIJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataset, train_size, val_size, test_size):\n",
        "  first_split = train_size\n",
        "  second_split = train_size+val_size\n",
        "  third_split = train_size+val_size+test_size\n",
        "  return dataset[:first_split, :], dataset[first_split:second_split, :], dataset[second_split:third_split, :]"
      ],
      "metadata": {
        "id": "v-iZDbUCqkdC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us create a function `make_datasets`, that will be make training, validation and testing datasets. This function will -\n",
        "1. This functions will have many argumenets and among them 2 argumenets `cnn_stories` and `dailymail_stories` are lists which has list of articles and summaries at 0 and 1 index. It means `cnn_stories[0]` is articles of cnn news and `cnn_stories[1]` is summaries of cnn news. It applies to `dailymail_stories` as well.\n",
        "Objective of this step is to concatenate the cnn articles with dailymail articles and cnn summaries with dailymail summaries.\n",
        "```python\n",
        "[1, 2] + [3, 4] = [1, 2, 3, 4]\n",
        "```\n",
        "\n",
        "3. Convert the articles and summaries list into tensors and then concatenate them along a new axis. To create new axis I can use `tf.newaxis` in the indexing. E.g.\n",
        "```python\n",
        "  np.concatenate([articles[:, tf.newaxis], summaries[:, tf.newaxis]], axis=-1)\n",
        "```\n",
        "4. Shuffle the dataset using `random.sample` method.\n",
        "```python\n",
        "random.seed(seed_value) # To make sure that everytime it gives the same shuffle\n",
        "random.sample(list_to_shuffle, len(list_to_shuffle))\n",
        "```\n",
        "5. Split the dataset into 3 parts, one for training, other for validation and last one for testing. All the tensors are of shape `(num_samples, 2)`."
      ],
      "metadata": {
        "id": "FTB5eNzJrqyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_datasets(cnn_stories, dailymail_stories, train_fraction, val_fraction, test_fraction, seed_value=0):\n",
        "  '''Create 3 datasets each for training, validation and testing respectively.\n",
        "  This function concatenates the articles, summaries of cnn and dailymail news. After that it will tokenize\n",
        "  them one by one in a loop. After it is done with the tokenization, it will shuffle the articles and\n",
        "  summaries using random.sample method (although we have a helper function for it). Finally we do the\n",
        "  splitting of the whole dataset. Remember here the returned values become tensors.\n",
        "\n",
        "  Arguments:\n",
        "    cnn_stories: list of 2 values, one for cnn articles and other for cnn summaries.\n",
        "    dailymail_stories: list of 2 values, one for dailymail articles and other for dailymail summaries.\n",
        "    train_size: float, specifying how much fraction of the original dataset to take for training.\n",
        "    val_size: float, specifying how much fraction of the original dataset to take for validation.\n",
        "    test_size: float, specifying how much fraction of the original dataset to take for testing.\n",
        "\n",
        "  Returns:\n",
        "    returns a tuple with 3 values inside it, `training_data`, `validation_data` and `testing_data`\n",
        "    with the specified amount of data in it.\n",
        "    Each one of them are tensor with shape `(num_samples, 2)`. `shape[1]=2` for article and summary.\n",
        "  '''\n",
        "  articles = cnn_stories[0] + dailymail_stories[0]\n",
        "  summaries = cnn_stories[1] + dailymail_stories[1]\n",
        "\n",
        "  articles = np.array(articles, dtype=object)\n",
        "  summaries = np.array(summaries, dtype=object)\n",
        "\n",
        "  dataset = np.concatenate((articles[:, tf.newaxis], summaries[:, tf.newaxis]), axis=-1)\n",
        "\n",
        "  random.seed(seed_value)\n",
        "  shuffled_indices = random.sample(list(range(dataset.shape[0])), dataset.shape[0])\n",
        "\n",
        "  dataset = dataset[shuffled_indices, :]\n",
        "\n",
        "  train_size = int(train_fraction * dataset.shape[0])\n",
        "  val_size = int(val_fraction * dataset.shape[0])\n",
        "  test_size = dataset.shape[0] - (train_size + val_size)\n",
        "\n",
        "  training_samples, validation_samples, testing_samples = split_dataset(dataset,\n",
        "                                                                        train_size,\n",
        "                                                                        val_size,\n",
        "                                                                        test_size)\n",
        "\n",
        "  return (training_samples, validation_samples, testing_samples)"
      ],
      "metadata": {
        "id": "QDB0_32RrnHk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset, test_dataset = make_datasets([cnn_articles, cnn_summaries], [dailymail_articles, dailymail_summaries], TRAIN_SIZE, VAL_SIZE, TEST_SIZE)"
      ],
      "metadata": {
        "id": "GTnXBwd6Sa-U"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Type of the datasets: {type(train_dataset)}\\n\")\n",
        "\n",
        "print(f\"Training dataset shape: {train_dataset.shape}\")\n",
        "print(f\"Validation dataset shape: {val_dataset.shape}\")\n",
        "print(f\"Testing dataset shape: {test_dataset.shape}\\n\")\n",
        "\n",
        "print(f\"First example in the training dataset looks like: \\n {train_dataset[0]}\\n\")"
      ],
      "metadata": {
        "id": "AyRVodwIhkuQ",
        "outputId": "d0bfc21f-2835-45a6-de7e-07f430eabcd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of the datasets: <class 'numpy.ndarray'>\n",
            "\n",
            "Training dataset shape: (148126, 2)\n",
            "Validation dataset shape: (18515, 2)\n",
            "Testing dataset shape: (18517, 2)\n",
            "\n",
            "First example in the training dataset looks like: \n",
            " ['(cnn) -- tom de la hunty took dutch bobsledder edwin van calker to the whistler sliding center track one last time tuesday and asked his driver if he could do it. he wasn\\'t asking him to win; he was asking him whether he could compete. the coach and his pilot walked the course, and de la hunty told van calker to think about it, giving him an hour to make a decision. time offered no healing. van calker told his coach he just couldn\\'t drive this track and so on wednesday the four-man no. 1 sled from the netherlands pulled out of the olympics. because their driver was terrified. \"i\\'ve never seen someone get to a major event and not compete because they\\'re scared. you keep your inner fears to yourself and do it,\" de la hunty told reporters at a news conference. \"that\\'s why it\\'s such a popular sport in the military. it\\'s that kind of macho sport. you go over the top together.\" van calker, ranked 11th on the world cup four-man tour, crashed on his first run during two-man practice on saturday. that and the memories of other crashes, including one that resulted in two teammates in the hospital, were too much for van calker. he never felt comfortable on the track during the two-man competition when he and teammate sybren jansma finished 14th. he and the rest of the four-man team were absent from two training runs on tuesday, as he struggled with what to do. it didn\\'t help that eight sleds crashed on that first day of training. and so that night, he made the decision to give up. \"i have to look after my boys and can\\'t close my eyes to that,\" he told reporters. \"for me, it\\'s not about performing. it\\'s about surviving.\" it was a split decision among the team to quit the games, said de la hunty, who talked about how he told his driver he was making a choice he would regret forever. \"i\\'ve told him that to his face,\"de la hunty said, \"but as a coach i have to support it because i\\'m responsible for him sending his team down the track in the right frame of mind.\" for timothy beck, who wanted to continue, it was a heart-wrenching outcome to his last olympics. the man who carried the dutch flag in the opening ceremonies said there was no tension on the team, but he wasn\\'t the one looking out for three teammates. \"if you ask me if i want to slide i\\'d say, \\'yes\\'. but i don\\'t have to steer; i just get in the back and go down. i don\\'t have the responsibility,\" said beck. but he also said he was upset that he\\'d come to his third olympics and would not get a chance to compete. \"this was my last chance to do something special,\" said the 33-year-old, who competed in the 2002 winter olympics and the 2004 summer olympics on the track team. jansma said he was frustrated because he wanted to show the world the progress the netherlands has made in bobsled, but safety was paramount. arnold van calker, the fourth member of the team, supported his brother\\'s decision, pointing to the difference in the size of the two- and four-man sleds. the two-man sled is smaller and easier to control. arnold van calker, who had his doubts about the safety of the track, worried his brother had lost his nerve and wouldn\\'t be able to steer the big sled through turns 11, 12 and 13. not even changes to the track on tuesday could help reassure the brothers. \"it was a lot better, but for us it was maybe too late,\" arnold van calker said. de la hunty pinned some of the blame on arnold\\'s wife, saying that she had been worried about her husband\\'s safety ever since georgian luger nodar kumaritashvili had crashed and died on the same track during the first day of the games. \"when arnold is scared and upset, obviously it has influence,\" he said. but arnold van calker said the death had no influence, and edwin van calker agreed that the track was not to blame for his decision. \"it\\'s a challenging and exciting track. you have to deal with it as a pilot. that comes with the job. sometimes you deal with it less good,\" he said. \"it\\'s nothing to do with the track, just my lack of confidence at the moment.\" competition in the four-man competition starts friday with the medals decided on saturday after the last of four runs.'\n",
            " 'new: coach tom de la hunty: \"i have to support\" the pilot\\'s decision. new: teammate: \"if you ask me if i want to slide i\\'d say, \\'yes\\'. but i don\\'t have to steer\" edwin van calker, driver of the dutch four-man bobsled quits the games citing lack of confidence. van calker said his decision is unrelated to death of georgian luger.']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Tokenizing"
      ],
      "metadata": {
        "id": "dGP0eDXMEhdF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before the tokenization, we need to preprocess the text data so that it can be properly tokenized. In this step we need to choose whether we want to keep punctuations or not, whether we should keep the numbers or not and so on. There are 2 functions I will create, one for simple `standardize` and other to feed the Tokenizer class when creating the `tokenizer`. `standardize` function implements the following steps -\n",
        "\n",
        "1. Lower case the strings passed to it. It is already done but for user data it might not be the case so, we will still perform this step.\n",
        "2. Replace the single and double opening and closing quotes like `  \\u2018`, `  \\u2019`, `  \\u201c` and `  \\u201d` by `'` and `\"` respectively.\n",
        "3. Replace the punctutations ``['.', '?', '!', ',', ':', '-', ''', '\"', '_', '(', ')', '{', '}', '[', ']', '`', ';', '...']`` by `[SPACE]punctutations`.\n",
        "In this process we need to make sure that the floating point numbers like `1.78` do not become `1 .78`. To do that the correct regex expression is ``(?<!\\d)\\s*([!\"#$%&\\'\\(\\)*+,-./:;<=>?@\\[\\]\\\\^_`{|}~])\\s*(?!\\d)``.\n",
        "4. Strip the texts from extra starting or ending spaces. Finally, remove extra spaces using regex expression like `\\s{2,}`.\n",
        "\n",
        "`custom_analyzer` function which will be feed to the Tokenizer as the value for `analyzer`, has some more steps to implement -\n",
        "1. Remove the `START_TOKEN` and `END_TOKEN` from the text. So that tokenizer does not standardize them.\n",
        "2. Standardize the text with `standardizer`.\n",
        "3. Add back the `START_TOKEN` and `END_TOKEN` because you want your tokenizer to learn them.\n",
        "4. Remove unwanted spaces in between words.\n",
        "5. Split the text into words which are seperated by ' '.\n",
        "6. Strip each of the words in the sentence. Finally, return it."
      ],
      "metadata": {
        "id": "TcZCpJ9hCyqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the text data\n",
        "def standardizer(text):\n",
        "  '''Standardize the text provided to the function\n",
        "  The text is lower cased. Then, the opening and closing quotes are removed. I add spaces before the\n",
        "  punctuations like `don't` becomes `don ' t`, ignoring the numerical values so that `1.78` does not become\n",
        "  `1 . 78`. Finally, it strips the text and removes any type of unwanted spaces in it.\n",
        "\n",
        "  Argument:\n",
        "    text: str, the text to standardize\n",
        "\n",
        "  Returns:\n",
        "    returns the standadized text\n",
        "  '''\n",
        "\n",
        "  # Lower case the text\n",
        "  text = text.lower()\n",
        "\n",
        "  # Replace the special single and double opening and closing quotes\n",
        "  text = re.sub(r'[\\u2019\\u2018]', \"'\", text)\n",
        "  text = re.sub(r'[\\u201c\\u201d]', '\"', text)\n",
        "\n",
        "  # Add space before punctuations and ignore floating point numbers.\n",
        "  text = re.sub(r'(?<!\\d)\\s*([!\"#$%&\\'\\(\\)*+,-./:;<=>?@\\[\\]\\\\^_`{|}~])\\s*(?!\\d)',\n",
        "                  r' \\1 ', text)  # It used to also remove commas after numbers like '27,' will be removed\n",
        "\n",
        "  # Remove spaces after sentence end and other unwanted spaces from text\n",
        "  text = text.strip()\n",
        "  text = re.sub('\\s{2,}', ' ', text)\n",
        "\n",
        "  return text\n",
        "\n",
        "# custom analyzer for the Tokenizer class\n",
        "def custom_analyzer(text):\n",
        "  '''Custom analyzer to provide to the `Tokenizer` class when creating the tokenizer.\n",
        "\n",
        "  Argument:\n",
        "    text: str, the text that will be tokenized\n",
        "\n",
        "  Returns:\n",
        "    returns the splitted sentence\n",
        "  '''\n",
        "  # Remove START and END before standardizing\n",
        "  if START_TOKEN in text:\n",
        "    text = re.sub(f'{START_TOKEN} ', '', text)\n",
        "  if END_TOKEN in text:\n",
        "    text = re.sub(f'{END_TOKEN} ', '', text)\n",
        "\n",
        "  # Standardize the text first\n",
        "  text = standardizer(text)\n",
        "\n",
        "  # Add back the START and END tokens\n",
        "  text = ' '.join([START_TOKEN, text, END_TOKEN])\n",
        "\n",
        "  # Split the sentence into words to tokenize\n",
        "  words = text.split(' ')\n",
        "  words = [word.strip() for word in words]\n",
        "\n",
        "  return words"
      ],
      "metadata": {
        "id": "FD2h0OiAxJP_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts = [\"I have been working on, \\nbut \\tnever did it in this way.\",\n",
        "                \"U.S won the world cup and bagged 1.78 million dollars.\",\n",
        "                \"India had M.S. Dhoni won made it this far.\",\n",
        "                \"My email address is arupjana7365@gmail.com.\",\n",
        "                \"It can take care of dailymail single opening quote also.\",\n",
        "                \"I have 10,000 Rs in my bank\",\n",
        "                \"This sentence has , after a number 12,\",\n",
        "                \"This sentence contains <START> token and <END> token.\"]\n",
        "\n",
        "print(f\"After Standardizing the sample texts:\\n{[standardizer(text) for text in sample_texts]}\\n\")\n",
        "print(f\"After applying custom analyzer on sample texts:\\n{[custom_analyzer(text) for text in sample_texts]}\")"
      ],
      "metadata": {
        "id": "AVi3kZhcLXS7",
        "outputId": "432ed183-e302-49c9-a704-c6a4257854ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Standardizing the sample texts:\n",
            "['i have been working on , but never did it in this way .', 'u . s won the world cup and bagged 1.78 million dollars .', 'india had m . s . dhoni won made it this far .', 'my email address is arupjana7365@gmail . com .', \"it can take care of dailymail single opening quote ' also .\", 'i have 10,000 rs in my bank', 'this sentence has , after a number 12,', 'this sentence contains < start > token and < end > token .']\n",
            "\n",
            "After applying custom analyzer on sample texts:\n",
            "[['<START>', 'i', 'have', 'been', 'working', 'on', ',', 'but', 'never', 'did', 'it', 'in', 'this', 'way', '.', '<END>'], ['<START>', 'u', '.', 's', 'won', 'the', 'world', 'cup', 'and', 'bagged', '1.78', 'million', 'dollars', '.', '<END>'], ['<START>', 'india', 'had', 'm', '.', 's', '.', 'dhoni', 'won', 'made', 'it', 'this', 'far', '.', '<END>'], ['<START>', 'my', 'email', 'address', 'is', 'arupjana7365@gmail', '.', 'com', '.', '<END>'], ['<START>', 'it', 'can', 'take', 'care', 'of', 'dailymail', 'single', 'opening', 'quote', \"'\", 'also', '.', '<END>'], ['<START>', 'i', 'have', '10,000', 'rs', 'in', 'my', 'bank', '<END>'], ['<START>', 'this', 'sentence', 'has', ',', 'after', 'a', 'number', '12,', '<END>'], ['<START>', 'this', 'sentence', 'contains', 'token', 'and', 'token', '.', '<END>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I need to find the tokens from the articles. I need to use only training articles not any other and also I will not use summaries data because that will be my target and I won't know what type of words I will encounter when summarizing the source article. So, the only words that I know will be from the articles of training dataset. Here, I am going to use the `tensorflow.keras.preprocessing.text.Tokenizer` in short `Tokenizer` to find the tokens from the articles and then finally converting the articles into sequence of integers. One thing to remember is here we are going to use `oov_token` arguement of `Tokenizer` to mention the token we want to use for out-of-vocabulary words.\n",
        "\n",
        "When fiting the texts on `tokenizer` make sure to remove floating point and integer numbers using the regex expression - `[+-]?[0-9]*[.]?[0-9]+`. I am making sure that tokenizer does learn the numbers because it can always be taken from the original articles data and we do not to remember them in vocab."
      ],
      "metadata": {
        "id": "IiiWRFR64jTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokenizer(texts, num_words, oov_token=None, filters = '#*+/:<=>@[\\\\]/^{|}~\\t\\n'):\n",
        "  '''This will create the tokenizer needed for the task in hand.\n",
        "  The tokenizer will be trained on the `texts`. Tokenizer will have vocabulary length `num_words`.\n",
        "  The `oov_token` will be used as the token represent the out-of-vocabulary words. The `filters` are\n",
        "  the ones which the tokenizer will remove when tokenizing any sentence given to it. The returned\n",
        "  tokenizer is using a custom analyzer that can standardize the sentence before tokenizing using the\n",
        "  `standardizer` function and then splits the sentence into words. After that it tokenizes the sentence.\n",
        "  As for the vocabulary, the returned tokenizer's vocabulary does not contain any number, as I have removed\n",
        "  them before feeding them into `Tokenizer.fit_on_texts` method.\n",
        "\n",
        "  Arguments:\n",
        "    texts: list of strings, the tokenizer will be trained on this strings\n",
        "    num_words: int, number of vocabulary words the tokenizer will consider\n",
        "    oov_token: str, token to represent out-of-vocabulary words\n",
        "    filters: str, all the characters that the tokenizer will remove before tokenizing\n",
        "\n",
        "  Returns:\n",
        "    tokenzier of the `Tokenizer` class after learning vocabulary from `texts`\n",
        "  '''\n",
        "\n",
        "  # Create the tokenizer usinf Tokenizer class\n",
        "  tokenizer = Tokenizer(num_words=num_words,\n",
        "                        filters=filters,\n",
        "                        oov_token=oov_token,\n",
        "                        analyzer=custom_analyzer)\n",
        "\n",
        "  # Remove the numbers from the dataset so that tokenizer does not add them inside vocabulary\n",
        "  texts = [re.sub(r\"[+-]?[0-9]*[.]?[0-9]+\", \"\", text) for text in texts]\n",
        "\n",
        "  # Fit the data with fit_on_texts method\n",
        "  tokenizer.fit_on_texts(texts)\n",
        "\n",
        "  return tokenizer"
      ],
      "metadata": {
        "id": "tR1FD3SESd0G"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length the articles dataset: {len(list(train_dataset[:, 0]))}\")"
      ],
      "metadata": {
        "id": "UsmErFoxqimM",
        "outputId": "1625c203-569e-4a43-f69e-2da2f4d215ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length the articles dataset: 148126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the `tokenizer` using the articles from training dataset by using `train_dataset[:, 0]`, with a vocabulary size of `VOCAB_SIZE` and use `OOV_TOKEN` token to represent out-of-vocabulary words."
      ],
      "metadata": {
        "id": "6KBXcUV2pYrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer(list(train_dataset[:, 0]), VOCAB_SIZE, OOV_TOKEN)"
      ],
      "metadata": {
        "id": "151rEpqo7Pof"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The vocabulary for the tokenizer has a length {len(tokenizer.word_index.keys())}\\n\\n\")\n",
        "\n",
        "\n",
        "print(f\"{OOV_TOKEN} word has index: {tokenizer.word_index[OOV_TOKEN]}\")\n",
        "print(f\"{START_TOKEN} word has index: {tokenizer.word_index[START_TOKEN]}\")\n",
        "print(f\"{END_TOKEN} word has index: {tokenizer.word_index[END_TOKEN]}\\n\\n\")\n",
        "\n",
        "\n",
        "print(f\"'teacher' word has index: {tokenizer.word_index['teacher']}\\n\")\n",
        "\n",
        "print(f\"Text:\\n{train_dataset[0, 0]}\\n\\n\")\n",
        "sample_sequence = tokenizer.texts_to_sequences([train_dataset[0, 0]])\n",
        "print(f\"Text to Sequence of the first article:\\n{sample_sequence}\\n\")\n",
        "print(f\"Sequence to Text of the first acrticle:\\n{tokenizer.sequences_to_texts(sample_sequence)}\")"
      ],
      "metadata": {
        "id": "YUNreIjr8Kng",
        "outputId": "ccabd900-e673-452c-fed3-5ce16481d655",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vocabulary for the tokenizer has a length 225943\n",
            "\n",
            "\n",
            "<OOV> word has index: 1\n",
            "<START> word has index: 80\n",
            "<END> word has index: 81\n",
            "\n",
            "\n",
            "'teacher' word has index: 2096\n",
            "\n",
            "Text:\n",
            "(cnn) -- tom de la hunty took dutch bobsledder edwin van calker to the whistler sliding center track one last time tuesday and asked his driver if he could do it. he wasn't asking him to win; he was asking him whether he could compete. the coach and his pilot walked the course, and de la hunty told van calker to think about it, giving him an hour to make a decision. time offered no healing. van calker told his coach he just couldn't drive this track and so on wednesday the four-man no. 1 sled from the netherlands pulled out of the olympics. because their driver was terrified. \"i've never seen someone get to a major event and not compete because they're scared. you keep your inner fears to yourself and do it,\" de la hunty told reporters at a news conference. \"that's why it's such a popular sport in the military. it's that kind of macho sport. you go over the top together.\" van calker, ranked 11th on the world cup four-man tour, crashed on his first run during two-man practice on saturday. that and the memories of other crashes, including one that resulted in two teammates in the hospital, were too much for van calker. he never felt comfortable on the track during the two-man competition when he and teammate sybren jansma finished 14th. he and the rest of the four-man team were absent from two training runs on tuesday, as he struggled with what to do. it didn't help that eight sleds crashed on that first day of training. and so that night, he made the decision to give up. \"i have to look after my boys and can't close my eyes to that,\" he told reporters. \"for me, it's not about performing. it's about surviving.\" it was a split decision among the team to quit the games, said de la hunty, who talked about how he told his driver he was making a choice he would regret forever. \"i've told him that to his face,\"de la hunty said, \"but as a coach i have to support it because i'm responsible for him sending his team down the track in the right frame of mind.\" for timothy beck, who wanted to continue, it was a heart-wrenching outcome to his last olympics. the man who carried the dutch flag in the opening ceremonies said there was no tension on the team, but he wasn't the one looking out for three teammates. \"if you ask me if i want to slide i'd say, 'yes'. but i don't have to steer; i just get in the back and go down. i don't have the responsibility,\" said beck. but he also said he was upset that he'd come to his third olympics and would not get a chance to compete. \"this was my last chance to do something special,\" said the 33-year-old, who competed in the 2002 winter olympics and the 2004 summer olympics on the track team. jansma said he was frustrated because he wanted to show the world the progress the netherlands has made in bobsled, but safety was paramount. arnold van calker, the fourth member of the team, supported his brother's decision, pointing to the difference in the size of the two- and four-man sleds. the two-man sled is smaller and easier to control. arnold van calker, who had his doubts about the safety of the track, worried his brother had lost his nerve and wouldn't be able to steer the big sled through turns 11, 12 and 13. not even changes to the track on tuesday could help reassure the brothers. \"it was a lot better, but for us it was maybe too late,\" arnold van calker said. de la hunty pinned some of the blame on arnold's wife, saying that she had been worried about her husband's safety ever since georgian luger nodar kumaritashvili had crashed and died on the same track during the first day of the games. \"when arnold is scared and upset, obviously it has influence,\" he said. but arnold van calker said the death had no influence, and edwin van calker agreed that the track was not to blame for his decision. \"it's a challenging and exciting track. you have to deal with it as a pilot. that comes with the job. sometimes you deal with it less good,\" he said. \"it's nothing to do with the track, just my lack of confidence at the moment.\" competition in the four-man competition starts friday with the medals decided on saturday after the last of four runs.\n",
            "\n",
            "\n",
            "Text to Sequence of the first article:\n",
            "[[80, 44, 42, 43, 12, 12, 1769, 929, 1876, 1, 241, 2845, 1, 12557, 1506, 1, 5, 2, 26115, 11352, 299, 1171, 53, 97, 74, 208, 8, 290, 26, 1344, 72, 21, 98, 93, 18, 3, 21, 577, 11, 41, 1307, 96, 5, 373, 167, 21, 20, 1307, 96, 265, 21, 98, 2856, 3, 2, 1179, 8, 26, 1592, 2068, 2, 530, 4, 8, 929, 1876, 1, 88, 1506, 1, 5, 141, 50, 18, 4, 1106, 96, 37, 830, 5, 137, 9, 392, 3, 74, 1231, 77, 6061, 3, 1506, 1, 88, 26, 1179, 21, 84, 1011, 11, 41, 1297, 33, 1171, 8, 73, 19, 223, 2, 204, 12, 194, 77, 3, 1, 18836, 29, 2, 3354, 1694, 65, 7, 2, 1866, 3, 103, 48, 1344, 20, 8133, 3, 6, 24, 11, 205, 212, 353, 517, 114, 5, 9, 404, 595, 8, 36, 2856, 103, 35, 11, 117, 3522, 3, 40, 399, 120, 4900, 2435, 5, 1979, 8, 93, 18, 4, 6, 929, 1876, 1, 88, 672, 25, 9, 189, 836, 3, 6, 14, 11, 13, 246, 18, 11, 13, 160, 9, 818, 1176, 10, 2, 179, 3, 18, 11, 13, 14, 461, 7, 19804, 1176, 3, 40, 165, 91, 2, 257, 480, 3, 6, 1506, 1, 4, 3274, 1, 19, 2, 94, 635, 204, 12, 194, 784, 4, 2580, 19, 26, 87, 326, 153, 75, 12, 194, 1521, 19, 304, 3, 14, 8, 2, 3205, 7, 83, 7034, 4, 185, 53, 14, 3098, 10, 75, 5629, 10, 2, 446, 4, 46, 244, 161, 15, 1506, 1, 3, 21, 212, 803, 2663, 19, 2, 1171, 153, 2, 75, 12, 194, 1422, 59, 21, 8, 4095, 1, 1, 1849, 1, 3, 21, 8, 2, 945, 7, 2, 204, 12, 194, 219, 46, 7885, 29, 75, 857, 1869, 19, 208, 4, 23, 21, 3289, 22, 61, 5, 93, 3, 18, 240, 11, 41, 196, 14, 623, 39958, 2580, 19, 14, 87, 118, 7, 857, 3, 8, 73, 14, 268, 4, 21, 138, 2, 392, 5, 388, 67, 3, 6, 24, 27, 5, 310, 60, 90, 1578, 8, 63, 11, 41, 484, 90, 1379, 5, 14, 4, 6, 21, 88, 672, 3, 6, 15, 130, 4, 18, 11, 13, 36, 50, 3767, 3, 18, 11, 13, 50, 5553, 3, 6, 18, 20, 9, 3087, 392, 293, 2, 219, 5, 4168, 2, 617, 4, 17, 929, 1876, 1, 4, 39, 1909, 50, 107, 21, 88, 26, 1344, 21, 20, 331, 9, 1335, 21, 64, 4563, 3065, 3, 6, 24, 11, 205, 88, 96, 14, 5, 26, 360, 4, 6, 929, 1876, 1, 17, 4, 6, 31, 23, 9, 1179, 24, 27, 5, 254, 18, 103, 24, 11, 133, 1149, 15, 96, 2084, 26, 219, 155, 2, 1171, 10, 2, 198, 4600, 7, 1079, 3, 6, 15, 7135, 7072, 4, 39, 453, 5, 489, 4, 18, 20, 9, 725, 12, 12631, 2902, 5, 26, 97, 1866, 3, 2, 194, 39, 1320, 2, 2845, 2500, 10, 2, 1091, 7856, 17, 58, 20, 77, 4316, 19, 2, 219, 4, 31, 21, 577, 11, 41, 2, 53, 471, 65, 15, 123, 5629, 3, 6, 72, 40, 907, 130, 72, 24, 175, 5, 7136, 24, 11, 260, 142, 4, 11, 1180, 11, 3, 31, 24, 136, 11, 41, 27, 5, 9874, 167, 24, 84, 114, 10, 2, 128, 8, 165, 155, 3, 24, 136, 11, 41, 27, 2, 1187, 4, 6, 17, 7072, 3, 31, 21, 69, 17, 21, 20, 2861, 14, 21, 11, 260, 218, 5, 26, 468, 1866, 8, 64, 36, 114, 9, 771, 5, 2856, 3, 6, 33, 20, 90, 97, 771, 5, 93, 247, 615, 4, 6, 17, 2, 1, 12, 150, 4, 39, 9167, 10, 2, 1, 1607, 1866, 8, 2, 1, 922, 1866, 19, 2, 1171, 219, 3, 1, 17, 21, 20, 4262, 103, 21, 453, 5, 211, 2, 94, 2, 1478, 2, 3354, 34, 138, 10, 28378, 4, 31, 569, 20, 9190, 3, 6673, 1506, 1, 4, 2, 1173, 683, 7, 2, 219, 4, 2252, 26, 993, 11, 13, 392, 4, 4073, 5, 2, 1612, 10, 2, 1638, 7, 2, 75, 12, 8, 204, 12, 194, 39958, 3, 2, 75, 12, 194, 18836, 16, 2353, 8, 2367, 5, 389, 3, 6673, 1506, 1, 4, 39, 51, 26, 5548, 50, 2, 569, 7, 2, 1171, 4, 2326, 26, 993, 51, 434, 26, 6381, 8, 1216, 11, 41, 30, 346, 5, 9874, 2, 287, 18836, 144, 2492, 1, 1, 8, 1, 36, 127, 1092, 5, 2, 1171, 19, 208, 98, 196, 10143, 2, 1970, 3, 6, 18, 20, 9, 259, 317, 4, 31, 15, 164, 18, 20, 1038, 244, 458, 4, 6, 6673, 1506, 1, 17, 3, 929, 1876, 1, 12124, 82, 7, 2, 2253, 19, 6673, 11, 13, 513, 4, 285, 14, 47, 51, 55, 2326, 50, 52, 777, 11, 13, 569, 398, 147, 8815, 40765, 1, 31638, 51, 2580, 8, 348, 19, 2, 195, 1171, 153, 2, 87, 118, 7, 2, 617, 3, 6, 59, 6673, 16, 3522, 8, 2861, 4, 1995, 18, 34, 1725, 4, 6, 21, 17, 3, 31, 6673, 1506, 1, 17, 2, 222, 51, 77, 1725, 4, 8, 12557, 1506, 1, 1145, 14, 2, 1171, 20, 36, 5, 2253, 15, 26, 392, 3, 6, 18, 11, 13, 9, 3344, 8, 3426, 1171, 3, 40, 27, 5, 466, 22, 18, 23, 9, 1592, 3, 14, 520, 22, 2, 481, 3, 873, 40, 466, 22, 18, 386, 199, 4, 6, 21, 17, 3, 6, 18, 11, 13, 541, 5, 93, 22, 2, 1171, 4, 84, 90, 1227, 7, 2055, 25, 2, 804, 3, 6, 1422, 10, 2, 204, 12, 194, 1422, 2988, 230, 22, 2, 5123, 903, 19, 304, 60, 2, 97, 7, 204, 1869, 3, 81]]\n",
            "\n",
            "Sequence to Text of the first acrticle:\n",
            "['<START> ( cnn ) - - tom de la <OOV> took dutch <OOV> edwin van <OOV> to the whistler sliding center track one last time tuesday and asked his driver if he could do it . he wasn \\' t asking him to win ; he was asking him whether he could compete . the coach and his pilot walked the course , and de la <OOV> told van <OOV> to think about it , giving him an hour to make a decision . time offered no healing . van <OOV> told his coach he just couldn \\' t drive this track and so on wednesday the four - man no . <OOV> sled from the netherlands pulled out of the olympics . because their driver was terrified . \" i \\' ve never seen someone get to a major event and not compete because they \\' re scared . you keep your inner fears to yourself and do it , \" de la <OOV> told reporters at a news conference . \" that \\' s why it \\' s such a popular sport in the military . it \\' s that kind of macho sport . you go over the top together . \" van <OOV> , ranked <OOV> on the world cup four - man tour , crashed on his first run during two - man practice on saturday . that and the memories of other crashes , including one that resulted in two teammates in the hospital , were too much for van <OOV> . he never felt comfortable on the track during the two - man competition when he and teammate <OOV> <OOV> finished <OOV> . he and the rest of the four - man team were absent from two training runs on tuesday , as he struggled with what to do . it didn \\' t help that eight sleds crashed on that first day of training . and so that night , he made the decision to give up . \" i have to look after my boys and can \\' t close my eyes to that , \" he told reporters . \" for me , it \\' s not about performing . it \\' s about surviving . \" it was a split decision among the team to quit the games , said de la <OOV> , who talked about how he told his driver he was making a choice he would regret forever . \" i \\' ve told him that to his face , \" de la <OOV> said , \" but as a coach i have to support it because i \\' m responsible for him sending his team down the track in the right frame of mind . \" for timothy beck , who wanted to continue , it was a heart - wrenching outcome to his last olympics . the man who carried the dutch flag in the opening ceremonies said there was no tension on the team , but he wasn \\' t the one looking out for three teammates . \" if you ask me if i want to slide i \\' d say , \\' yes \\' . but i don \\' t have to steer ; i just get in the back and go down . i don \\' t have the responsibility , \" said beck . but he also said he was upset that he \\' d come to his third olympics and would not get a chance to compete . \" this was my last chance to do something special , \" said the <OOV> - old , who competed in the <OOV> winter olympics and the <OOV> summer olympics on the track team . <OOV> said he was frustrated because he wanted to show the world the progress the netherlands has made in bobsled , but safety was paramount . arnold van <OOV> , the fourth member of the team , supported his brother \\' s decision , pointing to the difference in the size of the two - and four - man sleds . the two - man sled is smaller and easier to control . arnold van <OOV> , who had his doubts about the safety of the track , worried his brother had lost his nerve and wouldn \\' t be able to steer the big sled through turns <OOV> <OOV> and <OOV> not even changes to the track on tuesday could help reassure the brothers . \" it was a lot better , but for us it was maybe too late , \" arnold van <OOV> said . de la <OOV> pinned some of the blame on arnold \\' s wife , saying that she had been worried about her husband \\' s safety ever since georgian luger <OOV> kumaritashvili had crashed and died on the same track during the first day of the games . \" when arnold is scared and upset , obviously it has influence , \" he said . but arnold van <OOV> said the death had no influence , and edwin van <OOV> agreed that the track was not to blame for his decision . \" it \\' s a challenging and exciting track . you have to deal with it as a pilot . that comes with the job . sometimes you deal with it less good , \" he said . \" it \\' s nothing to do with the track , just my lack of confidence at the moment . \" competition in the four - man competition starts friday with the medals decided on saturday after the last of four runs . <END>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The oddness you might see if you are that much familiar with `Tokenizer` class is, even though I have specified that `num_words=VOCAB_SIZE` which is `20,000` still the length of the `word_index` is more that that. Does that mean we are doing something wrong?\n",
        "NO, here although tokenizer computes the word_index of all other words apart from those first 20000 words, it will not use them when we convert them into sequence. Let's look at one example to understand that."
      ],
      "metadata": {
        "id": "crn5t_zk6iBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(tokenizer.word_index.keys())[21000]"
      ],
      "metadata": {
        "id": "qhttL-heeP-P",
        "outputId": "3561bbef-d7ac-4c1d-e55d-0c6ce951703b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'coakley'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oov_word = list(tokenizer.word_index.keys())[21000]\n",
        "sample_text = f\"This example is to test the above fact with the word `{oov_word}`\"\n",
        "sample_sequence = tokenizer.texts_to_sequences([sample_text])\n",
        "\n",
        "print(f\"Text: {sample_text}\\n\\n\")\n",
        "print(f\"Tokenized text: {tokenizer.sequences_to_texts(sample_sequence)}\")\n",
        "print(f\"Sequence: {sample_sequence}\")"
      ],
      "metadata": {
        "id": "S_Dnkcig7SIX",
        "outputId": "663e3047-151e-47d0-d44a-0dc2988e5ca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: This example is to test the above fact with the word `coakley`\n",
            "\n",
            "\n",
            "Tokenized text: ['<START> this example is to test the above fact with the word ` coakley ` <END>']\n",
            "Sequence: [[80, 33, 931, 16, 5, 954, 2, 1205, 470, 22, 2, 1096, 23673, 21001, 23673, 81]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the word was present in the `word_index` mapping still tokenizer represented it with `<OOV>`."
      ],
      "metadata": {
        "id": "xvNeazXb-Yq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"What happens when I add a number 2.1 in this sentence!\"\n",
        "sample_sequence = tokenizer.texts_to_sequences([sample_text])\n",
        "\n",
        "print(f\"Text: {sample_text}\\n\\n\")\n",
        "print(f\"Tokenized text: {tokenizer.sequences_to_texts(sample_sequence)}\")\n",
        "print(f\"Sequence: {sample_sequence}\")"
      ],
      "metadata": {
        "id": "ng5MZ_DZ84kk",
        "outputId": "5006fd56-40c0-4876-d780-a341a68044ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: What happens when I add a number 2.1 in this sentence!\n",
            "\n",
            "\n",
            "Tokenized text: ['<START> what happens when i add a number <OOV> in this sentence ! <END>']\n",
            "Sequence: [[80, 61, 1711, 59, 24, 1993, 9, 277, 1, 10, 33, 1325, 305, 81]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"What happens when I add parenthesis (I am inside it!).\"\n",
        "sample_sequence = tokenizer.texts_to_sequences([sample_text])\n",
        "\n",
        "print(f\"Text: {sample_text}\\n\\n\")\n",
        "print(f\"Tokenized text: {tokenizer.sequences_to_texts(sample_sequence)}\")\n",
        "print(f\"Sequence: {sample_sequence}\")"
      ],
      "metadata": {
        "id": "ImlMHniH-Jnt",
        "outputId": "92b365af-3b23-4643-ad61-aa18e60daa47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: What happens when I add parenthesis (I am inside it!).\n",
            "\n",
            "\n",
            "Tokenized text: ['<START> what happens when i add <OOV> ( i am inside it ! ) . <END>']\n",
            "Sequence: [[80, 61, 1711, 59, 24, 1993, 1, 44, 24, 472, 558, 18, 305, 43, 3, 81]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to prepare the data for feeding to the model"
      ],
      "metadata": {
        "id": "EpMm2cNIEm_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have the `tokenizer` to tokenize the articles and summaries. We need to pad those sequences to fit the requirements.\n",
        "\n",
        "In the paper, the articles are limited to have 400 tokens and summary has, 100 tokens at training and 120 tokens for testing.\n",
        "\n",
        "I will be using `pad_sequences` method to pad or truncate the articles and summaries based on their length.\n",
        "\n",
        "NOTE: I am using same tokenizer for article and summary. But, later I might change that to 2 different tokenizers each having different `num_words`."
      ],
      "metadata": {
        "id": "jza9oQYKXB0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_pad(texts, tokenizer, padding, truncating, maxlen):\n",
        "  '''Tokenize the `texts` using the tokenizer. Then, pad the sequences or truncate the sequences\n",
        "  depending the length. If the length exceeds `maxlen` then it will be truncated and if not then it will be\n",
        "  padded. The padding and truncating can happend at the beginning or at the end of the sequence depending\n",
        "  on the value of `padding` and `truncating` respectively.\n",
        "\n",
        "  Arguments:\n",
        "    texts: list of strings, the sentences to tokenize and pad\n",
        "    tokenizer: Tokenizer class object, helps in tokenizing the `texts`\n",
        "    padding: str, can take 2 values `pre` or `post`. If `pre` then padding will happen at the beginning,\n",
        "    if `post` then padding will happen at the end.\n",
        "    truncating: str, can take 2 values `pre` or 'truncating`, works the same as `padding`\n",
        "    maxlen: int, maximum length after padding or truncating\n",
        "\n",
        "  Returns:\n",
        "    returns the tokenized and padded sentences\n",
        "  '''\n",
        "  sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "  padded_sequences = pad_sequences(sequences, maxlen=maxlen, padding=padding, truncating=truncating)\n",
        "\n",
        "  return padded_sequences"
      ],
      "metadata": {
        "id": "Alo70WYjW-tA"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rttUwCiT4FzJ",
        "outputId": "e0db10da-c722-4147-b6c0-3845d3103957"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I have been working on, \\nbut \\tnever did it in this way.',\n",
              " 'U.S won the world cup and bagged 1.78 million dollars.',\n",
              " 'India had M.S. Dhoni won made it this far.',\n",
              " 'My email address is arupjana7365@gmail.com.',\n",
              " 'It can take care of dailymail single opening quote also.',\n",
              " 'I have 10,000 Rs in my bank',\n",
              " 'This sentence has , after a number 12,',\n",
              " 'This sentence contains <START> token and <END> token.']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_pad(sample_texts, tokenizer, padding=\"post\", truncating=\"post\", maxlen=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNuBKpTq4lZW",
        "outputId": "0d73781e-8327-4369-c9a6-8918cd4f259f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   80,    24,    27,    55,   321,    19,     4,    31,   212,\n",
              "          143,    18,    10,    33,   139,     3,    81,     0,     0,\n",
              "            0,     0],\n",
              "       [   80,    79,     3,    13,   270,     2,    94,   635,     8,\n",
              "        23909,     1,   171,  1568,     3,    81,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [   80,   802,    51,   133,     3,    13,     3, 25586,   270,\n",
              "          138,    18,    33,   311,     3,    81,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [   80,    90,  4425,  1004,    16,     1,     3,   409,     3,\n",
              "           81,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [   80,    18,    63,   158,   306,     7,     1,   871,  1091,\n",
              "         6914,    11,    69,     3,    81,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [   80,    24,    27,     1, 16519,    10,    90,  1002,    81,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [   80,    33,  1325,    34,     4,    60,     9,   277,     1,\n",
              "           81,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [   80,    33,  1325,  4805, 17224,     8, 17224,     3,    81,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Model Architecture & Training"
      ],
      "metadata": {
        "id": "Gt31OiYpEymZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After this, we need the model that we can train on this dataset. The model archietecture will be 3-\n",
        "1. Base-line model: Seq-Seq model with attention mechanism.\n",
        "2. Pointer Generetor model: With seq-seq attention model will be implementing the pointer generator that can either copy words from article or generate words from the pre-defined vocabulary.\n",
        "3. Coverage mechanism: Along with the pointer generator that will take case of the out-of-vocabulary words. Coverage mechanism will help prevent the repetition of the words in the summary."
      ],
      "metadata": {
        "id": "yM6KveyaUmfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base-Line Model: Seq-seq with Attention"
      ],
      "metadata": {
        "id": "UarmKLUIVkjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating `tf_train_dataset`, `tf_val_dataset` using tf.data API\n",
        "\n",
        "Now, I need write the `generate_example` function that can help me generate model inputs for training, validation and testing set. For different type of dataset, we will create different generator with the help of the `example_generator` method to create `tf.data.Dataset` object for our model.\n",
        "\n",
        "We can use `tf.data` API to create the input data pipeline for our model. I will use the `tf.data.Dataset` class to get the the examples from the `train_example_generator` function which uses `generate_example`, we can save the generator inside `example_gen` which we can iterate over later to get the examples. We can yield the examples according to the need of the problem.\n",
        "\n",
        "Remember, along with input article tokens and input summary tokens, we need the initial states as an input to the model. So, as we process the examples we can create this zero-value tensors and yield them along with 2 original inputs.\n",
        "\n",
        "For more about datasets from generator, refer to [here](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator)."
      ],
      "metadata": {
        "id": "usV8UchPA35e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `generate_example_v1` function creation\n",
        "Create a Geneator function that generates the source and target for training the model."
      ],
      "metadata": {
        "id": "ZUtzIfXm6UnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_example_v1(inputs, targets, input_tokenizer, target_tokenizer, input_len, target_len):\n",
        "  '''Generates examples for the model. Processes the `inputs` and `targets` with their respective\n",
        "  tokenizers and tokenize them to `input_len` and `target_len` length.\n",
        "\n",
        "  Arguments:\n",
        "    inputs: list of input sentences\n",
        "    targets: list of target sentences\n",
        "    input_tokenizer: Tokenizer class object, tokenizer for inputs\n",
        "    target_tokenizer: Tokenizer class object, tokenizer for targets\n",
        "    input_len: int, the length of the tokenization for inputs\n",
        "    target_len: int, the length of the tokenization for targets\n",
        "\n",
        "  Returns:\n",
        "    returns 2 values, a tuple containing 2 numpy arrays (input_tokens, target_tokens[:-1]) and\n",
        "    another numpy array target_tokens[1:]\n",
        "  '''\n",
        "\n",
        "  for inp, tar in zip(inputs, targets):\n",
        "    # Tokenizing article words\n",
        "    inp_tokens = tokenize_pad([inp],\n",
        "                              input_tokenizer,\n",
        "                              padding=\"post\",\n",
        "                              truncating=\"post\",\n",
        "                              maxlen=input_len)\n",
        "\n",
        "    # Tokenizing summary words\n",
        "    tar_tokens = tokenize_pad([tar],\n",
        "                 target_tokenizer,\n",
        "                 padding=\"post\",\n",
        "                 truncating=\"post\",\n",
        "                 maxlen=target_len)\n",
        "\n",
        "    yield (inp_tokens[0], tar_tokens[0][:-1]), tar_tokens[0][1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8647M-ey6n19",
        "outputId": "0783fcd2-3e99-45dc-cff0-102a8f9572f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Example with the generator function"
      ],
      "metadata": {
        "id": "-nytCw0dFO2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Example generated by the generator v1:\")\n",
        "\n",
        "# (inp_art_tokens, inp_sum_tokens), tar_sum_tokens = generate_example(list(train_dataset[:, 0]),\n",
        "example_gen = generate_example_v1(list(train_dataset[:, 0]),\n",
        "                               list(train_dataset[:, 1]),\n",
        "                               input_tokenizer=tokenizer,\n",
        "                               target_tokenizer=tokenizer,\n",
        "                               input_len=MAX_ARTICLE_TOKENS,\n",
        "                               target_len=MAX_SUMMARY_TOKENS)\n",
        "\n",
        "inps, tar = next(example_gen)\n",
        "print(f\"Inputs:\\n{inps[0]}\\n{inps[1]}\\n\\n\")\n",
        "print(f\"Target:\\n{tar}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "id": "BKKyIeVa5B20",
        "outputId": "f424eca8-5f29-4dd0-915b-7f5e362399ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example generated by the generator :\n",
            "Inputs:\n",
            "[   80    44    42    43    12    12   831   127  3951  3915   152    36\n",
            " 18545   821     5     9     1  1296    10  3733     4  1330  4243  1151\n",
            "     4    31  9579   812    50     2   258   173  7545    11    13  9225\n",
            "    15 17603     9   587  1606     3   831   127  3064     9   978     8\n",
            "  2466  1296    10  3733    19   233     3  3733    11    13  4038     1\n",
            "  6059   267    73   108   292    57    52   396  2268    15     9   227\n",
            "   591    10  1087     8    17    14   127    11    13  1029    12    12\n",
            "    66  5408  5142    32   201    79     3    13     3  3087   377  1582\n",
            "     3  1501     8  4316  2867    59     2  3546   150    20    10     2\n",
            "  1556   237 18546    12    12    99   112    27    55   135    10     2\n",
            "  1330   635     3     6   831   127    11    13  1029   280    38    27\n",
            "    55     1     8    18  2239   567    11    41     1    12  5157     3\n",
            "    31    22    71 13873     8     2   740     7    33     1    12   151\n",
            "     4    18  1214    20     2  3859     7     9    68  1828    15     9\n",
            "    68  1513    19   193  1388     7     2  2687     4     6     2  1104\n",
            "    17     3     6    61   314   399    99    27   550     5   163    76\n",
            "     2   794   212   100     7     2    79     3    13     3  2153    33\n",
            "   740     5     2    94    29   207    77     6   127   902    19    29\n",
            "  1087     5   741    19   230   111    21    20   841     5   887  1155\n",
            "    22   100  5382  5729     3    21    16    69  7619     5   891   506\n",
            "   586   347  4459   784     8   710   438   702  2908    10   464   236\n",
            "   230     3  1330  6944     1    17   127    52     1    26  1377     7\n",
            "     2   169  1569    12    12     2   735    14  1068    63   310     2\n",
            "    94    47     6  2521   941  1990     3   768     4    21   822     5\n",
            "    93    33    10  2731    22   295     4   698   746     3    14    11\n",
            "    13    26   740    29  3733    47   474    11    13   538    33   469\n",
            "   302     6    31     1  1525    14    36   127  2677    65   223  2082\n",
            "  2809    19  1532  2089   161    23  1087     4    66  1487    64    22\n",
            "   279    90     2   237    10   370     8    34  1649     5  4475  1894\n",
            "   618     5  1405  1093    10   532     3  2182     3   411    47  1003\n",
            "   971    29     2   906     3     6    21   238    11    41   141    61\n",
            "    21  4059     4    31    18    11    13    38   393     5  1311    18\n",
            "    64     3    21    11   372   379    15    54  1330  4656   152   199\n",
            "  7498   165    21    11]\n",
            "[  80 1330 3696 1835   14  831  127  265 3915   22 3733  821    3 4038\n",
            "    1   47  127   11   13  821    9    6 3859    7    9   68 1828   15\n",
            "    9   68 1513    6   31  603 3153 4711   90  258  173 7545   11   13\n",
            " 9225    3 3696  141  127   45 1628   54 1330  618   15  532    3   81\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0]\n",
            "\n",
            "\n",
            "Target:\n",
            "[1330 3696 1835   14  831  127  265 3915   22 3733  821    3 4038    1\n",
            "   47  127   11   13  821    9    6 3859    7    9   68 1828   15    9\n",
            "   68 1513    6   31  603 3153 4711   90  258  173 7545   11   13 9225\n",
            "    3 3696  141  127   45 1628   54 1330  618   15  532    3   81    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shapes of the Inputs:\\n{inps[0].shape}\\n{inps[1].shape}\\n\\n\")\n",
        "print(f\"Shape of the Target:\\n{tar.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "E-w0hmecDcho",
        "outputId": "dc67edf1-88c5-4f30-935e-e3ea04f8b0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of the Inputs:\n",
            "(400,)\n",
            "(99,)\n",
            "\n",
            "\n",
            "Shape of the Target:\n",
            "(99,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Data Type of the Inputs data:\\n{inps[0].dtype}\\n{inps[1].dtype}\\n\\n\")\n",
        "print(f\"Data Type of the Target data:\\n{tar.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "suZmEEhfDvcu",
        "outputId": "0e2da90a-79b0-4b89-a5da-5b28d899609c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Type of the Inputs data:\n",
            "int32\n",
            "int32\n",
            "\n",
            "\n",
            "Data Type of the Target data:\n",
            "int32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inps, tar = next(example_gen)\n",
        "print(f\"Second Inputs:\\n{inps[0]}\\n{inps[1]}\\n\\n\")\n",
        "print(f\"Second Target:\\n{tar}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "82m4io2PSyt3",
        "outputId": "d95bc6aa-4364-4c1f-c3de-8b0a11ce5f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second Inputs:\n",
            "[   80    44    42    43    12    12   222  6837     1     1     8     1\n",
            "    10   454   695    19   230  1234    60  7293    10  8812  1046  1015\n",
            "    49  5048   378    10     2   118     3  1450     1     8  3349    29\n",
            "     2   695   254     7  1881    48   145   321    10     2   308     4\n",
            "  9036  1031 12160     1    17     3     6  2072  1280     5  1046     8\n",
            "  1351  1274    72    25    62   476     4     6    46    17     3     6\n",
            "   344    15  1491     8  1450     3     6  8812  1046    52  9698   647\n",
            "     5  7643   549  6953     7  5879     1  7318     7     9     1  4173\n",
            "     7     2  5879    48  1231    10   193  7266    29  1675  8390     5\n",
            "  2537     1     4     1    17     3    58    48   282  4843     4   185\n",
            "     9   105   620    39    20   442    32     9   419   117   359     5\n",
            "   114     5   174  1479    19  5879     1     2   620    20  4267   233\n",
            "  1439    22  2781  1373     4    42  1260     1   234     3  1239  1450\n",
            "    69  1015     2  5048     7    79     3    13     3  2807     1   612\n",
            "     7  1675  8390     5     2    68   683   107   501     3     2   171\n",
            "   990   336  4705 10582    15   230   270     8   305    10  1675  8390\n",
            "     4  2537     1     8     1     4    22   426  6523    32   305   270\n",
            "     3    81     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n",
            "[   80   998     7     1     1     8     1    48  2158   102     7  1450\n",
            "     8  7293     3  1450     1     8  3349  1154  3089     3  6246  5327\n",
            " 10582   144   305     4   131   426  6523     3    81     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n",
            "\n",
            "\n",
            "Second Target:\n",
            "[  998     7     1     1     8     1    48  2158   102     7  1450     8\n",
            "  7293     3  1450     1     8  3349  1154  3089     3  6246  5327 10582\n",
            "   144   305     4   131   426  6523     3    81     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Making training, validation set examples for baseline model"
      ],
      "metadata": {
        "id": "9m3U7a0pFULD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_example_generetor_v1():\n",
        "  example_gen = generate_example_v1(list(train_dataset[:, 0]),\n",
        "                                list(train_dataset[:, 1]),\n",
        "                                input_tokenizer=tokenizer,\n",
        "                                target_tokenizer=tokenizer,\n",
        "                                input_len=MAX_ARTICLE_TOKENS,\n",
        "                                target_len=MAX_SUMMARY_TOKENS)\n",
        "\n",
        "  for example in example_gen:\n",
        "    s0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "    c0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "\n",
        "    (input_0, input_1), target = example\n",
        "    yield (input_0, input_1, s0, c0), target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "J_0r7ajRR8wk",
        "outputId": "367e274d-63e4-4e55-ae53-a7a96011f899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_signature = (\n",
        "    (tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32)),\n",
        "    tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32)\n",
        ")\n",
        "\n",
        "tf_train_dataset = tf.data.Dataset.from_generator(generator=train_example_generetor_v1,\n",
        "                                                  output_signature=output_signature)\n",
        "tf_train_dataset = tf_train_dataset.shuffle(BUFFER_SIZE)\n",
        "tf_train_dataset = tf_train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "tf_train_dataset = tf_train_dataset.prefetch(1)"
      ],
      "metadata": {
        "id": "Zj-H_fEh5Zu9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "524e02fb-448c-4b19-b09f-4d81b72f57a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def val_example_generetor_v1():\n",
        "  example_gen = generate_example_v1(list(val_dataset[:, 0]),\n",
        "                                list(val_dataset[:, 1]),\n",
        "                                input_tokenizer=tokenizer,\n",
        "                                target_tokenizer=tokenizer,\n",
        "                                input_len=MAX_ARTICLE_TOKENS,\n",
        "                                target_len=MAX_SUMMARY_TOKENS)\n",
        "\n",
        "  for example in example_gen:\n",
        "    s0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "    c0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "\n",
        "    (input_0, input_1), target = example\n",
        "    yield (input_0, input_1, s0, c0), target\n",
        "\n",
        "\n",
        "output_signature = (\n",
        "    (tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32)),\n",
        "    tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32)\n",
        ")\n",
        "\n",
        "tf_val_dataset = tf.data.Dataset.from_generator(generator=val_example_generetor_v1,\n",
        "                                                  output_signature=output_signature)\n",
        "tf_val_dataset = tf_val_dataset.shuffle(BUFFER_SIZE)\n",
        "tf_val_dataset = tf_val_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "-2qJcIbjRZXd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "89e83c15-798b-4136-818d-bac52016ad60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (art_inp, sum_inp, s0, c0), sum_tar in tf_train_dataset.take(1):\n",
        "  print(f\"Input tokenized article shape: {art_inp.shape}\")\n",
        "  print(f\"Input tokenized summary shape: {sum_inp.shape}\\n\")\n",
        "\n",
        "  print(f\"Target tokenized summary shape: {sum_tar.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "no4oMl22Fm6r",
        "outputId": "d3c68da1-cb08-4c1b-8e09-b769ccfcbb97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokenized article shape: (16, 400)\n",
            "Input tokenized summary shape: (16, 99)\n",
            "\n",
            "Target tokenized summary shape: (16, 99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A small demonstration of how Dot layer works"
      ],
      "metadata": {
        "id": "-2S_Jxhf25-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(10).reshape(1, 2, 5)\n",
        "res1 = tf.keras.layers.Dense(units=10)(x)\n",
        "res2 = tf.keras.layers.Dense(units=12)(res1)\n",
        "print(f\"After applying dense layer on x of shape:{x.shape}, res1 has{res1.shape} & res2 has {res2.shape} shape\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxBGPuOWKubc",
        "outputId": "125bcc6b-03c9-4c0e-e5aa-5920b47d29f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After applying dense layer on x of shape:(1, 2, 5), res1 has(1, 2, 10) & res2 has (1, 2, 12) shape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = np.arange(10).reshape(1, 2, 5)\n",
        "x2 = np.arange(10, 22).reshape(1, 2, 6)\n",
        "print(f\"x1: {x1}\\nx2: {x2}\")\n",
        "\n",
        "Dot(axes=1)([x1, x2])"
      ],
      "metadata": {
        "id": "_WLTScTp1x-R",
        "outputId": "82c0a1d8-f90a-4d8c-8520-f25a9c06b0e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1: [[[0 1 2 3 4]\n",
            "  [5 6 7 8 9]]]\n",
            "x2: [[[10 11 12 13 14 15]\n",
            "  [16 17 18 19 20 21]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 5, 6), dtype=int64, numpy=\n",
              "array([[[ 80,  85,  90,  95, 100, 105],\n",
              "        [106, 113, 120, 127, 134, 141],\n",
              "        [132, 141, 150, 159, 168, 177],\n",
              "        [158, 169, 180, 191, 202, 213],\n",
              "        [184, 197, 210, 223, 236, 249]]])>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attention Mechanism"
      ],
      "metadata": {
        "id": "BVsZ_DeVmaie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_time_attention_v1(a, s_prev,\n",
        "                       repeater, concatenator, densor_1, densor_2, softmax_layer, dotter):\n",
        "  '''Calculates the attention score and returns the context for the current timestep in the decoder.\n",
        "  Attention mechanism uses encoder outputs `a` of shape `(batch, timesteps, features)` and decoder\n",
        "  previous hidden state `s_prev` of shape `(batch, features)`, then calculates alignment scores `alphas`\n",
        "  for each encoder timestep with the help of energies computed with 2 dense layers using `a` and `s_prev`.\n",
        "\n",
        "  Arguments:\n",
        "    a: tf.Tensor object, encoder output of shape `(batch, timesteps, features)` or `(batch, Tx, 2*n_a)`\n",
        "    s_prev: tf.Tensor object, decoder previous hidden state of shape `(batch, features)` or `(batch, n_s)`\n",
        "    repeater: RepeatVector layer, repeat the `s_prev` `Tx` times\n",
        "    concatenator: Concatenate layer, concatenates `a` and repeated `s_prev`, Concatenates along axis=-1\n",
        "    densor_1: Dense layer, calculates the pertial energies `e`, with `units=d1_units`\n",
        "    refer to `baseline_model` function for details about this variable\n",
        "    densor_2: Dense layer, calculated the energies `energies`, with `units=d2_units`\n",
        "    refer to `baseline_model` function for details about this variable\n",
        "    softmax_layer: Activation layer, computes softmax of the energies and calculates `alphas`, with\n",
        "    `units=article_vocab_size` refer to `baseline_model` function for details about this variable\n",
        "    dotter: Dot layer, Performs dot operation between `alphas` and `a` along axis=1\n",
        "\n",
        "  Returns:\n",
        "    returns the context of shape `(batch, features)`\n",
        "  '''\n",
        "\n",
        "  # Repeat the `s_prev` `Tx` times\n",
        "  s_prev = repeater(s_prev) # (batch, Tx, n_s)\n",
        "\n",
        "  # Concatenate `a` and `s_prev` along axis=-1\n",
        "  concat = concatenator([a, s_prev]) # (batch, Tx, n_a + n_s)\n",
        "\n",
        "  # Apply dense layer to get partial energies e\n",
        "  e = densor_1(concat) # (batch, Tx, d1_units)\n",
        "\n",
        "  # Apply dense layer again to get energies\n",
        "  energies = densor_2(e) # (batch, Tx, d2_units)\n",
        "\n",
        "  # Apply softmax over the energies\n",
        "  alphas = softmax_layer(energies) # (batch, Tx, d2_units)\n",
        "\n",
        "  # Dot the alphas and a along axes=1\n",
        "  context = dotter([alphas, a]) # (batch, d2_units, 2*n_a)\n",
        "\n",
        "  return context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "B_rPlnWardTC",
        "outputId": "2b856755-06a5-47b7-90fb-30f2001b4690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder-decoder Model using Attention mechanism"
      ],
      "metadata": {
        "id": "QxkE_-Ifn2k3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model(Tx, Ty,\n",
        "                   emb_dim, n_a, n_s, d1_units, d2_units, d_units,\n",
        "                   article_vocab_size, summary_vocab_size):\n",
        "  '''This implements the bas-line model archietecture for summarization.\n",
        "  It is a seq-seq model with attention mechanism implemented in it. The encoder take an input\n",
        "  with `Tx` time-steps and summarizes with the help of decoder into Ty words. The encoder and decoder\n",
        "  hidden states are `n_a` and `n_s` dimension respectively. The words are taken from the vocabulary of\n",
        "  article and summary `article_vocab` and `summary_vocab` with size `article_vocab_size` and\n",
        "  `summary_vocab_size` respectively.\n",
        "\n",
        "  Arguments:\n",
        "    Tx: int, length of the input article\n",
        "    Ty: int, length of the output summary\n",
        "    n_a: int, dimension of the encoder hidden states\n",
        "    n_s: int, dimension of the deocder hidden states\n",
        "    d1_units: int, units for the first dense layer in attention mechanism\n",
        "    d2_units: int, units for the second dense layer in attention mechanism\n",
        "    d_units: int, units for the dense layer before output layer\n",
        "    article_vocab_size: int, length of the article vocabulary\n",
        "    summary_vocab_size: int, length of the summary vocabulary\n",
        "\n",
        "  Returns:\n",
        "    returns the base line model\n",
        "  '''\n",
        "  # Defining the input for our model with shape (None, Tx) and (None, Ty) for encoder input and decoder input\n",
        "  X_inp = Input(shape=(Tx))\n",
        "  X_tar = Input(shape=(Ty))\n",
        "\n",
        "  # Initialize s0\n",
        "  s0 = Input(shape=(n_s, ), name=\"s0\")\n",
        "  # Initialize c0\n",
        "  c0 = Input(shape=(n_s, ), name=\"c0\")\n",
        "\n",
        "  # Initialize the a and s with a0 and s0\n",
        "  s = s0 # (batch, n_s)\n",
        "  c = c0 # (batch, n_s)\n",
        "\n",
        "  # Define the outputs as empty list\n",
        "  outputs = []\n",
        "\n",
        "  # First embedding layer for the article input\n",
        "  encoder_inp = Embedding(article_vocab_size, emb_dim)(X_inp) # (batch, Tx, emb_dim)\n",
        "\n",
        "  # Encoder: Bidirectional layer with LSTM cells\n",
        "  a = Bidirectional(LSTM(units=n_a, return_sequences=True))(encoder_inp) # (batch, Tx, n_a)\n",
        "\n",
        "  # Define the embedding for decoder\n",
        "  decoder_inp = Embedding(summary_vocab_size, emb_dim)(X_tar) # (batch, Ty, emb_dim)\n",
        "\n",
        "  # Define the layers for Attention so that we can use the same weights for all decoder timesteps\n",
        "  repeater = RepeatVector(Tx)\n",
        "  concatenator = Concatenate(axis=-1)\n",
        "  attn_densor1 = Dense(units=d1_units, activation='tanh')\n",
        "  attn_densor2 = Dense(units=d2_units, activation='linear', use_bias=False)\n",
        "  softmax_layer = Activation('softmax', name=\"attention_weights\")\n",
        "  dotter = Dot(axes=1)\n",
        "\n",
        "  # Define the Decoder unidirectional LSTM for shared weights\n",
        "  post_attention_lstm = LSTM(units=n_s, return_state=True)\n",
        "\n",
        "  # Define the last dense layer before output layer with linear activation\n",
        "  densor = Dense(units=d_units, activation='linear')\n",
        "\n",
        "  # Define the output layer so that it does not initalize again and again for shared weights\n",
        "  output_layer = Dense(units=summary_vocab_size, activation='softmax')\n",
        "\n",
        "  # Decoder: Appends outputs from the output layer in each timestep\n",
        "  for t in range(Ty):\n",
        "    # Get the decoder input for current timestep\n",
        "    curr_dec_in = decoder_inp[:, t:t+1, :] # (batch, 1, emb_dim)\n",
        "\n",
        "    # Get the context from the attention mechanism\n",
        "    context = one_time_attention_v1(a, s, # (batch, d2_units, 2*n_a)\n",
        "                                 repeater, concatenator, attn_densor1, attn_densor2, softmax_layer, dotter)\n",
        "\n",
        "    concat = Concatenate(axis=-1)([curr_dec_in, context]) # (batch, d2_units, emb_dim+2*n_a); d2_units=1 otherwise error\n",
        "    _, s, c = post_attention_lstm(concat, initial_state=[s, c]) # _, (batch, n_s), (batch, n_s)\n",
        "\n",
        "    # Calculate the output after using 2 linear dense layers\n",
        "    out = densor(s) # (batch, d_units)\n",
        "    out = densor(out) # (batch, d_units)\n",
        "    # Use the output_layer to get the output\n",
        "    out  = output_layer(out) # (batch, summary_vocab_size)\n",
        "\n",
        "    # Append the final output to the outputs list\n",
        "    outputs.append(out)\n",
        "\n",
        "  # Stack the list of each timesteps output along axis=1\n",
        "  outputs = tf.stack(outputs, axis=1) # (batch, Ty, summary_vocab_size)\n",
        "\n",
        "  model = Model(inputs=[X_inp, X_tar, s0, c0], outputs=outputs)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mudpzB78HDvZ",
        "outputId": "2fb0d213-077a-45c1-ada0-1648edd12e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset states generated by Keras\n",
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "APJAr_NwcRRj",
        "outputId": "d41ea3e1-367f-462a-f038-33ffdb99bc6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Baseline Model Creation and Training"
      ],
      "metadata": {
        "id": "moztj-HfDOls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tx = MAX_ARTICLE_TOKENS\n",
        "Ty = MAX_SUMMARY_TOKENS - 1\n",
        "emb_dim = EMB_OUT\n",
        "n_a = ENCODER_STATE_DIM\n",
        "n_s= DECODER_STATE_DIM\n",
        "d1_units = DENSE1_UNITS\n",
        "d2_units = DENSE2_UNITS\n",
        "d_units = DENSE_UNITS\n",
        "article_vocab_size = VOCAB_SIZE\n",
        "summary_vocab_size = VOCAB_SIZE\n",
        "\n",
        "base_model = baseline_model(Tx, Ty,\n",
        "                       emb_dim, n_a, n_s, d1_units, d2_units, d_units,\n",
        "                       article_vocab_size, summary_vocab_size)"
      ],
      "metadata": {
        "id": "V3ZAtG5I8mZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model has {base_model.count_params():,} parameters.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2eMakRHeZzrF",
        "outputId": "08d0700c-d496-412d-fff3-456f4d3e5dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model has 2,644,096 parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A look into how model will output on the above input."
      ],
      "metadata": {
        "id": "sN_nIO_-LdDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_model_out = base_model((art_inp, sum_inp, s0, c0))\n",
        "\n",
        "print(f\"Model output has a type: {type(sample_model_out)}\")\n",
        "print(f\"Model Output list for the Inputs above are of length: {len(sample_model_out)}\")\n",
        "print(f\"Model Output list has each output of shape: {sample_model_out[0].shape}\")"
      ],
      "metadata": {
        "id": "xzqmZfKoLcfJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "32287225-4fc5-4b3a-dc15-8b2c005978ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output has a type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Model Output list for the Inputs above are of length: 16\n",
            "Model Output list has each output of shape: (99, 20000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creating Custom Loss and Accuracy Version 1"
      ],
      "metadata": {
        "id": "C62CukniFhmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss_v1(y_true, y_pred):\n",
        "  '''Calculates the loss for the baseline model. The loss is calculated by taking the negative\n",
        "  log-likelihood of the target word(w*_t) in the current timestep. Then the overall loss\n",
        "  is the summation over all timesteps divided by T (not Ty because it would include paddings also).\n",
        "\n",
        "  Arguments:\n",
        "    y_true: tf.Tensor object, true values for the target\n",
        "    y_pred: list of tf.Tensor objects, predicted probablities of the summary words\n",
        "\n",
        "  Returns:\n",
        "    returns the loss on the predicted values for the model\n",
        "  '''\n",
        "  # Calculate the loss for each item in the batch.\n",
        "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "  # Remove the paddings from calculation of loss\n",
        "  mask = tf.cast(y_true != 0, loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  # Divide the total loss after masking out paddings divided by total words which are not paddings\n",
        "  return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def custom_accuracy_v1(y_true, y_pred):\n",
        "  '''Calculates accuracy of the baseline model. The accuracy is calculated by matching how many correct\n",
        "  words were predicted excluding the paddings. Then, just add those which are correct and you will get the\n",
        "  the accuracy and then just divide it by total words not including padding.\n",
        "\n",
        "  Arguments:\n",
        "    y_true: tf.Tensor object, expected target values\n",
        "    y_pred: list of tf.Tensor object, predicted target values by model\n",
        "\n",
        "  Returns:\n",
        "    returns the total accuracy over the batch of data\n",
        "  '''\n",
        "  # Find the word index with maximum probablity\n",
        "  y_pred = tf.argmax(y_pred, axis=-1)\n",
        "  y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "\n",
        "  # Count the words that matches with true values\n",
        "  match = tf.cast(y_pred == y_true, tf.float32)\n",
        "  mask = tf.cast(y_true != 0, tf.float32)\n",
        "\n",
        "  # Mask out the paddings\n",
        "  match *= mask\n",
        "\n",
        "  return tf.reduce_sum(match) / tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "dw-z3KccJdpj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "194cd324-9fd0-44e9-8aa1-e8a4f3b73e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Testing with loss and accuracy"
      ],
      "metadata": {
        "id": "BR02DedPFrDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sample y true values: {sum_tar}\")\n",
        "print(f\"Sample y pred values(first 10 values of first 2 timestep): {sample_model_out[:2]}\")\n",
        "\n",
        "sample_loss = custom_loss_v1(sum_tar, sample_model_out)\n",
        "print(f\"Loss of the sample y_true and y_pred: {sample_loss}\")\n",
        "\n",
        "sample_acc = custom_accuracy_v1(sum_tar, sample_model_out)\n",
        "print(f\"Accuracy of the sample y_true and y_pred: {sample_acc}\")"
      ],
      "metadata": {
        "id": "SR25pZHrACmA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "ee0770bc-19c8-4c74-d6cd-be5a51114c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample y true values: [[   2 1594 1589 ...    0    0    0]\n",
            " [  36 2526 7765 ...    0    0    0]\n",
            " [1024  358 5136 ...    0    0    0]\n",
            " ...\n",
            " [ 446  178    2 ...    0    0    0]\n",
            " [  68   47 1745 ...    0    0    0]\n",
            " [ 241 1043    1 ...    0    0    0]]\n",
            "Sample y pred values(first 10 values of first 2 timestep): [[[4.9766826e-05 4.9918344e-05 4.9897033e-05 ... 4.9849703e-05\n",
            "   5.0315728e-05 5.0180632e-05]\n",
            "  [4.9540908e-05 4.9899852e-05 4.9744962e-05 ... 4.9732076e-05\n",
            "   5.0619914e-05 5.0087474e-05]\n",
            "  [4.9342078e-05 4.9915510e-05 4.9560989e-05 ... 4.9633010e-05\n",
            "   5.0835100e-05 4.9942733e-05]\n",
            "  ...\n",
            "  [4.8487480e-05 5.0055794e-05 4.8468002e-05 ... 4.9327318e-05\n",
            "   5.1671042e-05 4.9163184e-05]\n",
            "  [4.8487480e-05 5.0055794e-05 4.8468002e-05 ... 4.9327318e-05\n",
            "   5.1671042e-05 4.9163184e-05]\n",
            "  [4.8487480e-05 5.0055794e-05 4.8468009e-05 ... 4.9327322e-05\n",
            "   5.1671042e-05 4.9163184e-05]]\n",
            "\n",
            " [[4.9986847e-05 4.9694067e-05 5.0172279e-05 ... 5.0206174e-05\n",
            "   5.0213788e-05 5.0044073e-05]\n",
            "  [5.0031969e-05 4.9539321e-05 5.0381001e-05 ... 5.0354411e-05\n",
            "   5.0285667e-05 5.0100505e-05]\n",
            "  [5.0090632e-05 4.9461749e-05 5.0534971e-05 ... 5.0449049e-05\n",
            "   5.0280312e-05 5.0154122e-05]\n",
            "  ...\n",
            "  [5.0358569e-05 4.9316510e-05 5.0878778e-05 ... 5.0763316e-05\n",
            "   5.0129740e-05 5.0536150e-05]\n",
            "  [5.0358594e-05 4.9316495e-05 5.0878807e-05 ... 5.0763316e-05\n",
            "   5.0129740e-05 5.0536142e-05]\n",
            "  [5.0358627e-05 4.9316488e-05 5.0878847e-05 ... 5.0763323e-05\n",
            "   5.0129747e-05 5.0536146e-05]]]\n",
            "Loss of the sample y_true and y_pred: 9.907593727111816\n",
            "Accuracy of the sample y_true and y_pred: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Compiling base line model"
      ],
      "metadata": {
        "id": "cs0e3XjqFwdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LEARNING_RATE\n",
        "initial_accumulator_value = INIT_ACC_VAL\n",
        "clipnorm = MAX_GRAD_NORM\n",
        "\n",
        "opt = Adagrad(learning_rate=lr,\n",
        "              initial_accumulator_value=initial_accumulator_value,\n",
        "              clipnorm=clipnorm)\n",
        "\n",
        "base_model.compile(loss=custom_loss_v1, optimizer=opt, metrics=[custom_loss_v1, custom_accuracy_v1])"
      ],
      "metadata": {
        "id": "bOTfC4BNnFgj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "48f21c46-7ca9-461a-c987-c53e1689dae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creating callbacks for model"
      ],
      "metadata": {
        "id": "_P1vbkDSF0T3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mention the checkpoint path and it's directory where you will save the model\n",
        "checkpoint_path = BASELINE_MODEL_CHECKPOINT\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Calculate no of batches, I am taking floor because when creating the training data I used drop_remainder\n",
        "n_batches = int(train_dataset.shape[0] / BATCH_SIZE)\n",
        "\n",
        "# Create the checkpoint for model saving, monitoring val_custom_accuracy_v1 and save only weights of the model\n",
        "saving_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                monitor='val_custom_accuracy_v1',\n",
        "                                                verbose=1,\n",
        "                                                save_weights_only=True,\n",
        "                                                save_freq=n_batches//2)\n",
        "\n",
        "# Create the checkpoint for stopping early after noticing that val_custom_accuracy_v1 is not increasing even after 5 consecutive epochs\n",
        "earlystop_cb = tf.keras.callbacks.EarlyStopping(monitor='val_custom_accuracy_v1',\n",
        "                                                    patience=PATIENCE,\n",
        "                                                    mode='max',\n",
        "                                                    )\n",
        "\n",
        "# Store the checkpoints in a list\n",
        "callbacks = [saving_cb, earlystop_cb]"
      ],
      "metadata": {
        "id": "_OFR6b5hD10E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training baseline model"
      ],
      "metadata": {
        "id": "tLyxWD4MF6W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = EPOCHS\n",
        "steps_per_epoch = STEPS_PER_EPOCHS\n",
        "\n",
        "history = base_model.fit(tf_train_dataset.repeat(),\n",
        "                    epochs=epochs,\n",
        "                    validation_data=tf_val_dataset,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    callbacks=callbacks\n",
        "                    )"
      ],
      "metadata": {
        "id": "OQE9gr_Bd9cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pointer Generetor model: Adding Pointer Generator to avoid getting OOV tokens in the summary"
      ],
      "metadata": {
        "id": "cDBfIISTS0j3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating `tf_train_dataset`, `tf_val_dataset` dataset using tf.data API\n",
        "\n",
        "I already have created to the `generate_example` function, I can use it again to generate examples for training and validation respectively.\n",
        "\n",
        "But this time I have to also consider the `<OOV>` with token value `1`. Instead of using `1`, I have to generate a new token value for each of the `<OOV>` words.\n",
        "\n",
        "How to do it?"
      ],
      "metadata": {
        "id": "0Y9oJUdnUM_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `find_oovs`, `map_oovs` & `tokenize_oovs` function"
      ],
      "metadata": {
        "id": "nJY4-VAaEfuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_oovs(sent, sent_token, sent_len):\n",
        "  '''Finds the out of vocabulary words from `sent` with the help of already tokenized `sent_tokens`.\n",
        "\n",
        "  Arguments:\n",
        "    sent: str, sentence to find the oov from\n",
        "    sent_token: 2D np.array, the tokenized form of the sentence with sent_len length\n",
        "    sent_len: int, length of the tokenized sentence\n",
        "\n",
        "  Returns:\n",
        "    Returns a list of all oov words in the `sent`\n",
        "  '''\n",
        "  analyzed_sent = custom_analyzer(sent)\n",
        "  oov_words = [w for i, w in enumerate(analyzed_sent[:sent_len]) if (sent_token[0][i] == 1)]\n",
        "  return oov_words\n",
        "\n",
        "def map_oovs(oovs, oov_start_token):\n",
        "  '''Stores the out of vocabulary words in a dictionary and sets the values of each oov key to\n",
        "  a temporary unique tokens.\n",
        "\n",
        "  Arguments:\n",
        "    oovs: list of oov words\n",
        "    oov_start_token: int, the first value to use as oov token then increase by 1\n",
        "\n",
        "  Returns:\n",
        "    dictionary of (oov, token) as (key, value) pairs\n",
        "  '''\n",
        "  unique_oovs = list(set(oovs))\n",
        "  oov_tokens = [oov_start_token+i for i in range(len(unique_oovs))]\n",
        "\n",
        "  oov_dict = dict(zip(unique_oovs, oov_tokens))\n",
        "\n",
        "  return oov_dict\n",
        "\n",
        "def tokenize_oovs(sent, sent_token, oov_dict, sent_len):\n",
        "  '''Tokenize the sent by replacing the oov tokens by new unique tokens from oov_dict.\n",
        "\n",
        "  Arguments:\n",
        "    sent: str, sentence to handle the oovs\n",
        "    sent_token: 2D np.array of tokens\n",
        "    oov_dict: dictionary, oov words and their tokens are stored here\n",
        "    sent_len: int, length of the sentence token array\n",
        "\n",
        "  Returns:\n",
        "    tokenized sentence with oov words tokenized to temporary oov tokens\n",
        "  '''\n",
        "  analyzed_sent = custom_analyzer(sent)\n",
        "\n",
        "  for i, w in enumerate(analyzed_sent[:sent_len]):\n",
        "    if w in oov_dict.keys():\n",
        "      sent_token[0, i] = oov_dict[w]\n",
        "\n",
        "  return sent_token"
      ],
      "metadata": {
        "id": "WkfC7nfwghMI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Applying functions on Examples"
      ],
      "metadata": {
        "id": "MygLMzLXEouR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Article:\\n{sample_article}\\n\\n\")\n",
        "\n",
        "sample_article_tokens = tokenize_pad([sample_article],\n",
        "                              tokenizer,\n",
        "                              padding=\"post\",\n",
        "                              truncating=\"post\",\n",
        "                              maxlen=MAX_ARTICLE_TOKENS)\n",
        "print(f\"sample article tokens:\\n{sample_article_tokens}\\n\\n\")\n",
        "\n",
        "sample_oovs = find_oovs(sample_article, sample_article_tokens, MAX_ARTICLE_TOKENS)\n",
        "print(f\"OOVs in the sample article:\\n{sample_oovs}\\n\\n\")\n",
        "\n",
        "sample_oov_dict = map_oovs(sample_oovs, VOCAB_SIZE)\n",
        "print(f\"OOV dictionary:\\n{sample_oov_dict}\\n\\n\")\n",
        "\n",
        "sample_article_tokens_with_oovs = tokenize_oovs(sample_article, sample_article_tokens, sample_oov_dict, MAX_ARTICLE_TOKENS)\n",
        "print(f\"sample article tokens with oov tokens:\\n{sample_article_tokens_with_oovs}\")"
      ],
      "metadata": {
        "id": "cqzj5WV-ihFC",
        "outputId": "9870ca93-d734-4d2d-bf84-bdd7e64fae10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article:\n",
            "new york (cnn) -- the u.s. population is expected to top out at close to 312.8 million people just around the time crowds gather to watch the ball drop on new year's eve, according to new census data released thursday. the figure represents a 0.7% increase from last year, adding 2,250,129 people to the u.s. population since the start of 2011, and a 1.3% increase since census day, april 1, 2010. the agency estimates that beginning in january, one american will be born every eight seconds and one will die every 12 seconds. u.s.-bound immigrants are also expected to add one person every 46 seconds. that combination of births, deaths and migration is expected to add a single person to the u.s. population every 17 seconds, the census bureau said. meanwhile, millions are set to ring in the new year. in new york, authorities are preparing for large crowds in manhattan's times square, where lady gaga is expected to join mayor michael bloomberg to push the button that drops the waterford crystal ball at 11:59 p.m. et on new year's eve. \"and i'm so looking forward to performing on nye+dropping the ball with mayor bloomberg!\" the pop star posted on twitter. \"what an honor as a new yorker.\" past guests have included muhammad ali, rudy giuliani, colin powell and bill and hillary clinton. on thursday, officials conducted new york's annual \"airworthiness test\" -- a process in which confetti is tossed by handfuls above times square -- in preparation for the annual city tradition of dumping one ton of confetti over revelers in the iconic square. the big apple this year edged out las vegas for the first time in seven years as the top travel u.s. destination for those celebrating the new year, according to a december travel booking website poll. seven new york neighborhoods made the top 10 list, with two districts in las vegas and one in new orleans making up the other three, according to the priceline poll. \"it appears that new york city will be helped this year by a weather forecast that calls for warmer than usual temperatures over the holiday weekend,\" said company spokesman brian ek.\n",
            "\n",
            "\n",
            "sample article tokens:\n",
            "[[   80    68   243    44    42    43    12    12     2    79     3    13\n",
            "      3   943    16   524     5   257    65    25   484     5     1   171\n",
            "     57    84   178     2    74  3281  4402     5   345     2  1603  1982\n",
            "     19    68    70    11    13  4514     4   104     5    68  5009   786\n",
            "    369   233     3     2  1313  2774     9     1  1099    29    97    70\n",
            "      4  1090     1    57     5     2    79     3    13     3   943   147\n",
            "      2   442     7     1     8     9     1  1099   147  5009   118     4\n",
            "    770     1     1     2   352  2416    14  1287    10   661     4    53\n",
            "    170    45    30   883   231   623  1987     8    53    45  1582   231\n",
            "      1  1987     3    79     3    13     3    12  3479  1981    28    69\n",
            "    524     5  1993    53   355   231     1  1987     3    14  3605     7\n",
            "  11208     4  1055     8  6911    16   524     5  1993     9   871   355\n",
            "      5     2    79     3    13     3   943   231     1  1987     4     2\n",
            "   5009  2389    17     3  1054     4  1082    28   258     5  3029    10\n",
            "      2    68    70     3    10    68   243     4   220    28  3285    15\n",
            "    556  3281    10  3091    11    13   281  1254     4   111  2094  7239\n",
            "     16   524     5  1382  1196   600  4301     5  1650     2  3607    14\n",
            "   7560     2 41240  5853  1603    25     1   763     3   133     3  2177\n",
            "     19    68    70    11    13  4514     3     6     8    24    11   133\n",
            "     73   471   701     5  3767    19 23499  3715  4737     2  1603    22\n",
            "   1196  4301   305     6     2  2004   604  1041    19   634     3     6\n",
            "     61    37  1581    23     9    68  9885     3     6   292  2409    27\n",
            "    926  6867  2015     4 11161 11111     4  8632  5497     8   482     8\n",
            "   1956   537     3    19   233     4   180  1792    68   243    11    13\n",
            "   1673     6 38227   954     6    12    12     9   509    10    66 26276\n",
            "     16  7789    32 49035  1205   281  1254    12    12    10  5688    15\n",
            "      2  1673   151  2936     7 11934    53  7410     7 26276    91 16479\n",
            "     10     2  3657  1254     3     2   287  1018    33    70  9102    65\n",
            "   3099  2919    15     2    87    74    10   583    92    23     2   257\n",
            "    647    79     3    13     3  3554    15   110  4620     2    68    70\n",
            "      4   104     5     9   799   647  8539   562  1765     3   583    68\n",
            "    243  3945   138     2   257     1   739     4    22    75  4899    10\n",
            "   3099  2919     8    53    10    68  2791   331    67     2    83   123\n",
            "      4   104     5     2]]\n",
            "\n",
            "\n",
            "OOVs in the sample article:\n",
            "['312.8', '0.7%', '2,250,129', '2011,', '1.3%', '1,', '2010.', '12', '46', '17', '11:59', '10']\n",
            "\n",
            "\n",
            "OOV dictionary:\n",
            "{'0.7%': 50000, '1.3%': 50001, '17': 50002, '12': 50003, '11:59': 50004, '46': 50005, '2011,': 50006, '10': 50007, '1,': 50008, '2010.': 50009, '312.8': 50010, '2,250,129': 50011}\n",
            "\n",
            "\n",
            "sample article tokens with oov tokens:\n",
            "[[   80    68   243    44    42    43    12    12     2    79     3    13\n",
            "      3   943    16   524     5   257    65    25   484     5 50010   171\n",
            "     57    84   178     2    74  3281  4402     5   345     2  1603  1982\n",
            "     19    68    70    11    13  4514     4   104     5    68  5009   786\n",
            "    369   233     3     2  1313  2774     9 50000  1099    29    97    70\n",
            "      4  1090 50011    57     5     2    79     3    13     3   943   147\n",
            "      2   442     7 50006     8     9 50001  1099   147  5009   118     4\n",
            "    770 50008 50009     2   352  2416    14  1287    10   661     4    53\n",
            "    170    45    30   883   231   623  1987     8    53    45  1582   231\n",
            "  50003  1987     3    79     3    13     3    12  3479  1981    28    69\n",
            "    524     5  1993    53   355   231 50005  1987     3    14  3605     7\n",
            "  11208     4  1055     8  6911    16   524     5  1993     9   871   355\n",
            "      5     2    79     3    13     3   943   231 50002  1987     4     2\n",
            "   5009  2389    17     3  1054     4  1082    28   258     5  3029    10\n",
            "      2    68    70     3    10    68   243     4   220    28  3285    15\n",
            "    556  3281    10  3091    11    13   281  1254     4   111  2094  7239\n",
            "     16   524     5  1382  1196   600  4301     5  1650     2  3607    14\n",
            "   7560     2 41240  5853  1603    25 50004   763     3   133     3  2177\n",
            "     19    68    70    11    13  4514     3     6     8    24    11   133\n",
            "     73   471   701     5  3767    19 23499  3715  4737     2  1603    22\n",
            "   1196  4301   305     6     2  2004   604  1041    19   634     3     6\n",
            "     61    37  1581    23     9    68  9885     3     6   292  2409    27\n",
            "    926  6867  2015     4 11161 11111     4  8632  5497     8   482     8\n",
            "   1956   537     3    19   233     4   180  1792    68   243    11    13\n",
            "   1673     6 38227   954     6    12    12     9   509    10    66 26276\n",
            "     16  7789    32 49035  1205   281  1254    12    12    10  5688    15\n",
            "      2  1673   151  2936     7 11934    53  7410     7 26276    91 16479\n",
            "     10     2  3657  1254     3     2   287  1018    33    70  9102    65\n",
            "   3099  2919    15     2    87    74    10   583    92    23     2   257\n",
            "    647    79     3    13     3  3554    15   110  4620     2    68    70\n",
            "      4   104     5     9   799   647  8539   562  1765     3   583    68\n",
            "    243  3945   138     2   257 50007   739     4    22    75  4899    10\n",
            "   3099  2919     8    53    10    68  2791   331    67     2    83   123\n",
            "      4   104     5     2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `generate_example_v2` function creation"
      ],
      "metadata": {
        "id": "b4U6JUL9ExLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_example_v2(inputs, targets,\n",
        "                        input_tokenizer, target_tokenizer,\n",
        "                        input_len, target_len,\n",
        "                        padding=\"post\", truncating=\"post\",\n",
        "                        vocab_size=VOCAB_SIZE):\n",
        "\n",
        "  '''Generates examples for the Pointer Generator model. Processes the `inputs` and `targets`\n",
        "  with their respective tokenizers and tokenize them to `input_len` and `target_len` length.\n",
        "  After tokenizing the article words, it looks for the out-of-vocabulary words and creates unique tokens\n",
        "  for each of those OOV words. Then, instead of keeping the oov word tokens as 1, it replaces them\n",
        "  with their respective newly generated tokens. This tokens are temporary\n",
        "\n",
        "  Arguments:\n",
        "    inputs: list of input sentences\n",
        "    targets: list of target sentences\n",
        "    input_tokenizer: Tokenizer class object, tokenizer for inputs\n",
        "    target_tokenizer: Tokenizer class object, tokenizer for targets\n",
        "    input_len: int, the length of the tokenization for inputs\n",
        "    target_len: int, the length of the tokenization for targets\n",
        "\n",
        "  Returns:\n",
        "    returns 2 values, a tuple containing 2 numpy arrays (input_tokens, target_tokens[:-1]) and\n",
        "    another numpy array target_tokens[1:]\n",
        "  '''\n",
        "\n",
        "  for inp, tar in zip(inputs, targets):\n",
        "    # Tokenizing article words\n",
        "    inp_token = tokenize_pad([inp],\n",
        "                              input_tokenizer,\n",
        "                              padding=padding,\n",
        "                              truncating=truncating,\n",
        "                              maxlen=input_len)\n",
        "\n",
        "    oov_words = find_oovs(inp, inp_token, input_len)\n",
        "    oov_dict = map_oovs(oov_words, oov_start_token=vocab_size)\n",
        "    inp_token = tokenize_oovs(inp, inp_token, oov_dict, input_len)\n",
        "\n",
        "    # Tokenizing summary words\n",
        "    tar_token = tokenize_pad([tar],\n",
        "                 target_tokenizer,\n",
        "                 padding=padding,\n",
        "                 truncating=truncating,\n",
        "                 maxlen=target_len)\n",
        "    tar_token = tokenize_oovs(tar, tar_token, oov_dict, target_len)\n",
        "\n",
        "    yield (inp_token[0], tar_token[0][:-1]), tar_token[0][1:]"
      ],
      "metadata": {
        "id": "bWzy1fmHTG_j"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Examples with the generator function"
      ],
      "metadata": {
        "id": "g66B6U8bE3jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Example generated by the generator v2:\")\n",
        "\n",
        "# (inp_art_tokens, inp_sum_tokens), tar_sum_tokens = generate_example(list(train_dataset[:, 0]),\n",
        "example_gen = generate_example_v2(list(train_dataset[:, 0]),\n",
        "                               list(train_dataset[:, 1]),\n",
        "                               input_tokenizer=tokenizer,\n",
        "                               target_tokenizer=tokenizer,\n",
        "                               input_len=MAX_ARTICLE_TOKENS,\n",
        "                               target_len=MAX_SUMMARY_TOKENS)\n",
        "\n",
        "inps, tar = next(example_gen)\n",
        "print(f\"Inputs:\\n{inps[0]}\\n{inps[1]}\\n\\n\")\n",
        "print(f\"Target:\\n{tar}\")"
      ],
      "metadata": {
        "id": "eA3joMNfbcjL",
        "outputId": "45e75c51-882f-4132-99de-f5ba713c43d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example generated by the generator v2:\n",
            "Inputs:\n",
            "[   80    44    42    43    12    12  1769   929  1876 50003   241  2845\n",
            " 50007 12557  1506 50004     5     2 26115 11352   299  1171    53    97\n",
            "    74   208     8   290    26  1344    72    21    98    93    18     3\n",
            "    21   577    11    41  1307    96     5   373   167    21    20  1307\n",
            "    96   265    21    98  2856     3     2  1179     8    26  1592  2068\n",
            "     2   530     4     8   929  1876 50003    88  1506 50004     5   141\n",
            "    50    18     4  1106    96    37   830     5   137     9   392     3\n",
            "    74  1231    77  6061     3  1506 50004    88    26  1179    21    84\n",
            "  1011    11    41  1297    33  1171     8    73    19   223     2   204\n",
            "    12   194    77     3 50006 18836    29     2  3354  1694    65     7\n",
            "     2  1866     3   103    48  1344    20  8133     3     6    24    11\n",
            "   205   212   353   517   114     5     9   404   595     8    36  2856\n",
            "   103    35    11   117  3522     3    40   399   120  4900  2435     5\n",
            "  1979     8    93    18     4     6   929  1876 50003    88   672    25\n",
            "     9   189   836     3     6    14    11    13   246    18    11    13\n",
            "   160     9   818  1176    10     2   179     3    18    11    13    14\n",
            "   461     7 19804  1176     3    40   165    91     2   257   480     3\n",
            "     6  1506 50004     4  3274 50001    19     2    94   635   204    12\n",
            "   194   784     4  2580    19    26    87   326   153    75    12   194\n",
            "  1521    19   304     3    14     8     2  3205     7    83  7034     4\n",
            "   185    53    14  3098    10    75  5629    10     2   446     4    46\n",
            "   244   161    15  1506 50004     3    21   212   803  2663    19     2\n",
            "  1171   153     2    75    12   194  1422    59    21     8  4095 50000\n",
            " 50002  1849 50005     3    21     8     2   945     7     2   204    12\n",
            "   194   219    46  7885    29    75   857  1869    19   208     4    23\n",
            "    21  3289    22    61     5    93     3    18   240    11    41   196\n",
            "    14   623 39958  2580    19    14    87   118     7   857     3     8\n",
            "    73    14   268     4    21   138     2   392     5   388    67     3\n",
            "     6    24    27     5   310    60    90  1578     8    63    11    41\n",
            "   484    90  1379     5    14     4     6    21    88   672     3     6\n",
            "    15   130     4    18    11    13    36    50  3767     3    18    11\n",
            "    13    50  5553     3     6    18    20     9  3087   392   293     2\n",
            "   219     5  4168     2   617     4    17   929  1876 50003     4    39\n",
            "  1909    50   107    21]\n",
            "[   80    68    49  1179  1769   929  1876 50003    49     6    24    27\n",
            "     5   254     6     2  1592    11    13   392     3    68    49  4095\n",
            "    49     6    72    40   907   130    72    24   175     5  7136    24\n",
            "    11   260   142     4    11  1180    11     3    31    24   136    11\n",
            "    41    27     5  9874     6 12557  1506 50004     4  1344     7     2\n",
            "  2845   204    12   194 28378 19440     2   617  2111  1227     7  2055\n",
            "     3  1506 50004    17    26   392    16  7544     5   222     7  8815\n",
            " 40765     3    81     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n",
            "\n",
            "\n",
            "Target:\n",
            "[   68    49  1179  1769   929  1876 50003    49     6    24    27     5\n",
            "   254     6     2  1592    11    13   392     3    68    49  4095    49\n",
            "     6    72    40   907   130    72    24   175     5  7136    24    11\n",
            "   260   142     4    11  1180    11     3    31    24   136    11    41\n",
            "    27     5  9874     6 12557  1506 50004     4  1344     7     2  2845\n",
            "   204    12   194 28378 19440     2   617  2111  1227     7  2055     3\n",
            "  1506 50004    17    26   392    16  7544     5   222     7  8815 40765\n",
            "     3    81     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inps, tar = next(example_gen)\n",
        "print(f\"Inputs:\\n{inps[0]}\\n{inps[1]}\\n\\n\")\n",
        "print(f\"Target:\\n{tar}\")"
      ],
      "metadata": {
        "id": "hIuAkQbO7Bzz",
        "outputId": "37076516-319c-4750-a9f7-917e0ff937b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "[   80    44    42    43    12    12   491    11    13   257  5222   252\n",
            "   681     2   121   124     7     6 38013     6  1975    85  3947  1245\n",
            "   646  1221    15   416    11    13  1851 17919    14    64   764     2\n",
            "   878     7   462    72   416 50003     3   416    34  1145     5   388\n",
            "    67    71  2687     7  1851   659   192   201   968     8  2495    37\n",
            " 12632     7    71  7704  1034  9365     5     2   572    15     2  8117\n",
            "     7  1851   659    91     2   801     3    31    79     3   655     3\n",
            "   177   745   261    28   145   361     5  7901    65     9  1973     5\n",
            " 11985     2   509     4    22   491     8   916  2474    25  3594    91\n",
            "     2  1458     3    10     9   252   652    19   622   866     4  7326\n",
            "    17   280    20  2585     5  7140     2   466  2274     2  1973    20\n",
            "  2850    67   192  4081 16748     7     2    79     3   655     3  5670\n",
            "     4    66    64 10241     2   238     7   462   129   416    72    18\n",
            "   397    11    41  5784     3    23   416    11    13   825  3821     4\n",
            "   491    34  2466  1695     7   179   506     3     6     2    79     3\n",
            "    13     3  2405    28 38013   164     4     6  7326    88     2   106\n",
            "    12  2013  2903    53   842     3     6    35   142    35    45  4168\n",
            "     2   166    25     2 16590    10     2  6359    72   491   296    36\n",
            "   128     2  1973   320    19  4081 16748    25     2    79     3   655\n",
            "     3   177   745     3     6  7326    17     2   364     6    28  2394\n",
            "    10  7127    48 18750     4     8    33    16  1940    36     2  5879\n",
            "    14  5644   164    12    12     5  3549     2   514     7  1851   659\n",
            "    10   416     3     6   491    19   416    12    77    54    11 50004\n",
            "    78    11  1193    19  1228     7  5341     4     9   697    79     3\n",
            "    13     3   106   249   255  1660    14   280   709    11    41  1599\n",
            "    19   849     4     6    31  1122     3     6     6    61    95   219\n",
            "    25     2    79     3   655     3    16  1599    19   198   102    16\n",
            "   321   144     2  1029     7     9    79     3   655     3   177   745\n",
            "  1973    22     2  5224   469   861  8314     4     6     2   255    17\n",
            "     3     6    38    11   117    36   149     5 37678     2  1029     7\n",
            "     9   785  1973    10   191     3     6   416    16 50002 50001    92\n",
            "    85     9   666   237    14    34   334   248    54    76 50000   568\n",
            "     4   104     5     2   121   552     3     2   121   124     8   282\n",
            "     7    71  2108     4]\n",
            "[   80   491    11    13   421   347 22280     7    79     3    13     3\n",
            "   968    10    79     3   655     3  1105     3     2   364     6    28\n",
            "  2394    10  7127    48 18750     4     6  7326    99     3    79     3\n",
            "    13     3   824     6     2  5224   469   861  8314     4     6   255\n",
            "    99     3    81     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n",
            "\n",
            "\n",
            "Target:\n",
            "[  491    11    13   421   347 22280     7    79     3    13     3   968\n",
            "    10    79     3   655     3  1105     3     2   364     6    28  2394\n",
            "    10  7127    48 18750     4     6  7326    99     3    79     3    13\n",
            "     3   824     6     2  5224   469   861  8314     4     6   255    99\n",
            "     3    81     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Making training, validation set examples for pointer generator model"
      ],
      "metadata": {
        "id": "Ix6RsiveGSQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_example_generetor_v2():\n",
        "  example_gen = generate_example_v2(list(train_dataset[:, 0]),\n",
        "                                list(train_dataset[:, 1]),\n",
        "                                input_tokenizer=tokenizer,\n",
        "                                target_tokenizer=tokenizer,\n",
        "                                input_len=MAX_ARTICLE_TOKENS,\n",
        "                                target_len=MAX_SUMMARY_TOKENS)\n",
        "\n",
        "  for example in example_gen:\n",
        "    s0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "    c0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "\n",
        "    (input_0, input_1), target = example\n",
        "    yield (input_0, input_1, s0, c0), target"
      ],
      "metadata": {
        "id": "ZCRXKTLZGX_I"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_signature = (\n",
        "    (tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32)),\n",
        "    tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32)\n",
        ")\n",
        "\n",
        "tf_train_dataset = tf.data.Dataset.from_generator(generator=train_example_generetor_v2,\n",
        "                                                  output_signature=output_signature)\n",
        "tf_train_dataset = tf_train_dataset.shuffle(BUFFER_SIZE)\n",
        "tf_train_dataset = tf_train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "tf_train_dataset = tf_train_dataset.prefetch(1)"
      ],
      "metadata": {
        "id": "NBdNpR7rGw7m"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_example_generetor_v2():\n",
        "  example_gen = generate_example_v2(list(val_dataset[:, 0]),\n",
        "                                list(val_dataset[:, 1]),\n",
        "                                input_tokenizer=tokenizer,\n",
        "                                target_tokenizer=tokenizer,\n",
        "                                input_len=MAX_ARTICLE_TOKENS,\n",
        "                                target_len=MAX_SUMMARY_TOKENS)\n",
        "\n",
        "  for example in example_gen:\n",
        "    s0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "    c0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "\n",
        "    (input_0, input_1), target = example\n",
        "    yield (input_0, input_1, s0, c0), target\n",
        "\n",
        "\n",
        "output_signature = (\n",
        "    (tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32)),\n",
        "    tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32)\n",
        ")\n",
        "\n",
        "tf_val_dataset = tf.data.Dataset.from_generator(generator=val_example_generetor_v2,\n",
        "                                                  output_signature=output_signature)\n",
        "tf_val_dataset = tf_val_dataset.shuffle(BUFFER_SIZE)\n",
        "tf_val_dataset = tf_val_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "byX6PXAKGw7y"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (art_inp, sum_inp, s0, c0), sum_tar in tf_train_dataset.take(1):\n",
        "  print(f\"Input tokenized article shape: {art_inp.shape}\")\n",
        "  print(f\"Input tokenized summary shape: {sum_inp.shape}\\n\")\n",
        "\n",
        "  print(f\"Target tokenized summary shape: {sum_tar.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0bdb027-6b00-4229-ebe4-f55c93e2964d",
        "id": "2fZlevYZGw7y"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokenized article shape: (16, 400)\n",
            "Input tokenized summary shape: (16, 99)\n",
            "\n",
            "Target tokenized summary shape: (16, 99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attention Mechanism for Pointer Generator Model\n",
        "\n",
        "It now involves the attention weights also because they will be used to calculate the final distribution."
      ],
      "metadata": {
        "id": "bokn5sDnsnEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_time_attention_v2(a, s_prev,\n",
        "                       repeater, concatenator, densor_1, densor_2, softmax_layer, dotter):\n",
        "  '''Calculates the attention score and returns the context and attention distribution for the current\n",
        "  timestep in the decoder.\n",
        "  Attention mechanism uses encoder outputs `a` of shape `(batch, timesteps, features)` and decoder\n",
        "  previous hidden state `s_prev` of shape `(batch, features)`, then calculates alignment scores `alphas`\n",
        "  for each encoder timestep with the help of energies computed with 2 dense layers using `a` and `s_prev`.\n",
        "\n",
        "  Arguments:\n",
        "    a: tf.Tensor object, encoder output of shape `(batch, timesteps, features)` or `(batch, Tx, 2*n_a)`\n",
        "    s_prev: tf.Tensor object, decoder previous hidden state of shape `(batch, features)` or `(batch, n_s)`\n",
        "    repeater: RepeatVector layer, repeat the `s_prev` `Tx` times\n",
        "    concatenator: Concatenate layer, concatenates `a` and repeated `s_prev`, Concatenates along axis=-1\n",
        "    densor_1: Dense layer, calculates the pertial energies `e`, with `units=d1_units`\n",
        "    refer to `baseline_model` function for details about this variable\n",
        "    densor_2: Dense layer, calculated the energies `energies`, with `units=d2_units`\n",
        "    refer to `baseline_model` function for details about this variable\n",
        "    softmax_layer: Activation layer, computes softmax of the energies and calculates `alphas`, with\n",
        "    `units=article_vocab_size` refer to `baseline_model` function for details about this variable\n",
        "    dotter: Dot layer, Performs dot operation between `alphas` and `a` along axis=1\n",
        "\n",
        "  Returns:\n",
        "    returns the context of shape `(batch, 1, 2*n_a)` and\n",
        "    attention distribution of shape `(batch, Tx, d2_units)`\n",
        "  '''\n",
        "\n",
        "  # Repeat the `s_prev` `Tx` times\n",
        "  s_prev = repeater(s_prev) # (batch, Tx, n_s)\n",
        "\n",
        "  # Concatenate `a` and `s_prev` along axis=-1\n",
        "  concat = concatenator([a, s_prev]) # (batch, Tx, n_a + n_s)\n",
        "\n",
        "  # Apply dense layer to get partial energies e\n",
        "  e = densor_1(concat) # (batch, Tx, d1_units)\n",
        "\n",
        "  # Apply dense layer again to get energies\n",
        "  energies = densor_2(e) # (batch, Tx, d2_units)\n",
        "\n",
        "  # Apply softmax over the energies\n",
        "  alphas = softmax_layer(energies) # (batch, Tx, d2_units)\n",
        "\n",
        "  # Dot the alphas and a along axes=1\n",
        "  context = dotter([alphas, a]) # (batch, d2_units, 2*n_a)\n",
        "\n",
        "  return context, alphas"
      ],
      "metadata": {
        "id": "aDPDm6MJLIEz"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pointer Generator\n",
        "\n",
        "The function `generate_pointer` will return the $p_{gen}$. $p_{gen}$ will be used to decide whether the next word needs to be copied from the article or we should generate a new word from the vocabulary. This decision will be taken using the equation- $$P(w) = p_{gen}*P_{vocab}(w) + (1-p_{gen})*\\sum_{i:w_i=w}a^t_i$$\n",
        "\n",
        "Where\n",
        "- $P$ is the extended vocabulary containing words from vocabulary and article both.\n",
        "- $a^t_i$ is the attention $t^{th}$ time step need to give to $i^{th}$ article word.\n",
        "- $P_{vocab}$ is the previous vocabulary distribution without considering words from article."
      ],
      "metadata": {
        "id": "j7wikoNOuKsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Pointer Generator Network\n",
        "\n",
        "Pointer network takes the context vector ($h^{*(t)}$), decoder embedding input($x^{(t)}$) and decoder hidden state ($s^{(t)}$). The equation of the pointer network is - $$p_{gen} = \\sigma(W_h^Th^{*(t)}+W_x^Tx^{(t)}+W_s^Ts^{(t)}+b_{ptr})$$"
      ],
      "metadata": {
        "id": "PlMlegsIEbsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pointer_generator_v1(context_vector, decoder_state, decoder_inp):\n",
        "  '''Generates the p_gen needed to calculate the final vocabulary distribution.\n",
        "  It takes the context, decoder hidden state and decoder embedding input as it's input and then\n",
        "  passes them through a dense layer to get the pointer generator.\n",
        "\n",
        "  Arguments:\n",
        "    context_vector: Tensor of shape (batch, n_a)\n",
        "    decoder_state: Tensor of shape (batch, n_s)\n",
        "    decoder_inp: Tensor of shape (batch, emb_dim)\n",
        "\n",
        "  Returns:\n",
        "    returns the pointer generator p_gen\n",
        "  '''\n",
        "  concat = Concatenate(axis=-1)([context_vector, decoder_state, decoder_inp])\n",
        "  p_gen = tf.keras.layers.Dense(units=1, activation='sigmoid')(concat)\n",
        "\n",
        "  return p_gen"
      ],
      "metadata": {
        "id": "P7y1utw3mAZw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Pointer Generator Model"
      ],
      "metadata": {
        "id": "AKSoa2YRENVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A demo on how to use `scatter_nd` method from tensorflow to map the copy probablities to the appropriate indices of final extended vocabulary distribution.\n",
        "\n",
        "This example simulates the situation of already having encoder input(`x`), vocabulary distribution(`vocab_dist`) and copy probablities using pointer generator(`copy_dist`). Now, we just need to find the final extended vocabulary distribution `final_dist`.\n",
        "\n",
        "The simulated example has `vocabulary size = 100`, `encoder input length is 10`, `batch size = 5`, `encoder input has 3 OOV words`.\n",
        "\n",
        "The main logic here is- $$P_{final}[X[i]]+=P_{copy}[i]$$\n",
        "P.S we are not considering batch dimension.\n",
        "\n",
        "Programming this concept in tensorflow:\n",
        "\n",
        "1. Convert the input tensor(`x`) to another 2D tensor(`x_ind`) with `shape=(Batch size * Input Length, 2)`, where $$x_ind[i*BatchSize+j] = [i, x[i][j]] where\\ i[0, Batch Size-1], j[0, Input Length-1]$$\n",
        "2. Flatten the `copy_dist`.\n",
        "3. Use `tf.scatter_nd` method."
      ],
      "metadata": {
        "id": "FWfZ0s_mwDn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant([[ 2, 100,  50, 10,  67,  16,  101,  23,  102,  3],\n",
        "                [ 2, 45, 100,  91,  99,  35,  101, 48,  102,  3],\n",
        "                [ 2,  100, 67,  95,  65,  101,  90,  102,  9,  3],\n",
        "                [ 2, 102, 100, 101,  90,  36,  96,  35,  98,  3],\n",
        "                [ 2,  91,  91,  16, 101, 100,  87,  94,  102,  3]], dtype=tf.int32)\n",
        "print(f\"The simulated input to encoder:\\n{x}\")"
      ],
      "metadata": {
        "id": "oqA-OnHrwC2r",
        "outputId": "1b433749-abb2-4301-bdb0-04483c8da8c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The simulated input to encoder:\n",
            "[[  2 100  50  10  67  16 101  23 102   3]\n",
            " [  2  45 100  91  99  35 101  48 102   3]\n",
            " [  2 100  67  95  65 101  90 102   9   3]\n",
            " [  2 102 100 101  90  36  96  35  98   3]\n",
            " [  2  91  91  16 101 100  87  94 102   3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_dist = tf.random.uniform(shape=[5, 100])\n",
        "print(f\"The vocabulary distribution without OOV:\\n{vocab_dist}\")"
      ],
      "metadata": {
        "id": "6HiLv8ody5A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_dist = tf.random.uniform(shape=[5, 10])\n",
        "print(f\"The copy distribution is:\\n{copy_dist}\")"
      ],
      "metadata": {
        "id": "BQPY3-kL2nqk",
        "outputId": "1fcbb37c-f1da-41b0-b0dd-77e5b1afe193",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The copy distribution is:\n",
            "[[0.61269236 0.64587617 0.42781377 0.89383984 0.776726   0.84031785\n",
            "  0.6618594  0.16318285 0.63771677 0.83437455]\n",
            " [0.5981734  0.81490314 0.8568847  0.82646525 0.46994913 0.3737619\n",
            "  0.08056331 0.6472466  0.91811645 0.00921619]\n",
            " [0.05203843 0.43726695 0.947369   0.03758478 0.8479793  0.5959269\n",
            "  0.14269722 0.58229387 0.45928466 0.5349685 ]\n",
            " [0.7924501  0.11300254 0.5394218  0.73507    0.511932   0.69597065\n",
            "  0.01186478 0.84462047 0.20952487 0.38607156]\n",
            " [0.5974941  0.50169194 0.04830074 0.88857806 0.694643   0.78583467\n",
            "  0.1834507  0.3915795  0.3287815  0.6674315 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_dist = tf.concat([vocab_dist, tf.zeros_like(x, dtype=float)], axis=-1)\n",
        "print(f\"The shape of the final distribution is {final_dist.shape}\")"
      ],
      "metadata": {
        "id": "Be5dQGAD210m",
        "outputId": "2bd3f46f-2f61-461e-8c41-9e8ffa8c909a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the final distribution is (5, 110)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rows, cols = tf.meshgrid(tf.range(x.shape[0]), tf.range(x.shape[1]), indexing='ij')\n",
        "rows"
      ],
      "metadata": {
        "id": "0ukZjfdY5ANG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped = tf.reshape(x, [-1])\n",
        "x_reshaped"
      ],
      "metadata": {
        "id": "0gL7N4gIDJTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices_to_update = tf.stack([tf.reshape(rows, [-1]), x_reshaped], axis=1)\n",
        "indices_to_update"
      ],
      "metadata": {
        "id": "nTeHuxIyDPzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.scatter_nd(indices=indices_to_update, updates=tf.reshape(copy_dist, [-1]), shape=final_dist.shape)"
      ],
      "metadata": {
        "id": "wXu-uc6344Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at whether we can actually add the `copy_dist` to `final_dist`.\n",
        "\n",
        "We are looking at the word, from first example input of the batch, which has token `50`. It is the 3rd word of the input `x[0, 2] = 50`.\n",
        "\n",
        "This corresponds to `copy_word[0, 2]`, `final_dist[0, 50]`."
      ],
      "metadata": {
        "id": "LhCAQ46wEhvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_dist[0, 50]"
      ],
      "metadata": {
        "id": "GRWF5dCNEPiB",
        "outputId": "add0ff60-9966-4a88-ef3a-4dd7ba02067e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.074389815>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "copy_dist[0, 2]"
      ],
      "metadata": {
        "id": "UhpXrTw_EbmR",
        "outputId": "52b8fe11-dc0e-4277-eef0-039e38bdd1c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.42781377>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_dist[0, 50]+copy_dist[0, 2]"
      ],
      "metadata": {
        "id": "DoaOgSiAFv1z",
        "outputId": "6dc31238-4919-439f-e103-6d343451fa8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5022036>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices_to_update[2]"
      ],
      "metadata": {
        "id": "uStJXJe2GRpN",
        "outputId": "44d240c6-458a-4903-9a67-356aac5752cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 0, 50], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.tensor_scatter_nd_add(tensor=final_dist, indices=indices_to_update, updates=tf.reshape(copy_dist, [-1]))[0, 50]"
      ],
      "metadata": {
        "id": "Cq6KSsrgDtxv",
        "outputId": "0ce919ce-da5f-4498-c89f-d26046ecbe0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5022036>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_final_distribution(final_dist, copy_dist, inp_tokens):\n",
        "  rows_range = tf.range(tf.shape(inp_tokens)[0])\n",
        "  cols_range = tf.range(tf.shape(inp_tokens)[1])\n",
        "  rows, _ = tf.meshgrid(rows_range, cols_range, indexing='ij')\n",
        "\n",
        "  indices_to_update = tf.stack([tf.reshape(rows, [-1]), tf.reshape(inp_tokens, [-1])], axis=1)\n",
        "\n",
        "  return tf.tensor_scatter_nd_add(tensor=final_dist,\n",
        "                                  indices=indices_to_update,\n",
        "                                  updates=tf.reshape(copy_dist, [-1]))"
      ],
      "metadata": {
        "id": "CzPfYicOG7sF"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pointer_gen_model(Tx, Ty,\n",
        "                   emb_dim, n_a, n_s, d1_units, d2_units, d_units,\n",
        "                   article_vocab_size, summary_vocab_size):\n",
        "  '''This implements the bas-line model archietecture for summarization.\n",
        "  It is a seq-seq model with attention mechanism implemented in it. The encoder take an input\n",
        "  with `Tx` time-steps and summarizes with the help of decoder into Ty words. The encoder and decoder\n",
        "  hidden states are `n_a` and `n_s` dimension respectively. The words are taken from the vocabulary of\n",
        "  article and summary `article_vocab` and `summary_vocab` with size `article_vocab_size` and\n",
        "  `summary_vocab_size` respectively.\n",
        "\n",
        "  Arguments:\n",
        "    Tx: int, length of the input article\n",
        "    Ty: int, length of the output summary\n",
        "    n_a: int, dimension of the encoder hidden states\n",
        "    n_s: int, dimension of the deocder hidden states\n",
        "    d1_units: int, units for the first dense layer in attention mechanism\n",
        "    d2_units: int, units for the second dense layer in attention mechanism\n",
        "    d_units: int, units for the dense layer before output layer\n",
        "    article_vocab_size: int, length of the article vocabulary\n",
        "    summary_vocab_size: int, length of the summary vocabulary\n",
        "\n",
        "  Returns:\n",
        "    returns the base line model\n",
        "  '''\n",
        "  # Defining the input for our model with shape (None, Tx) and (None, Ty) for encoder input and decoder input\n",
        "  X_inp = Input(shape=(Tx), dtype=tf.int32)\n",
        "  X_tar = Input(shape=(Ty), dtype=tf.int32)\n",
        "\n",
        "  # Initialize s0\n",
        "  s0 = Input(shape=(n_s, ), name=\"s0\")\n",
        "  # Initialize c0\n",
        "  c0 = Input(shape=(n_s, ), name=\"c0\")\n",
        "\n",
        "  # Initialize the a and s with a0 and s0\n",
        "  s = s0 # (batch, n_s)\n",
        "  c = c0 # (batch, n_s)\n",
        "\n",
        "  # Define the outputs as empty list\n",
        "  outputs = []\n",
        "\n",
        "  # First embedding layer for the article input\n",
        "  encoder_inp = Embedding(article_vocab_size+Tx, emb_dim)(X_inp) # (batch, Tx, emb_dim)\n",
        "\n",
        "  # Encoder: Bidirectional layer with LSTM cells\n",
        "  a = Bidirectional(LSTM(units=n_a, return_sequences=True))(encoder_inp) # (batch, Tx, n_a)\n",
        "\n",
        "  # Define the embedding for decoder\n",
        "  decoder_inp = Embedding(summary_vocab_size+Tx, emb_dim)(X_tar) # (batch, Ty, emb_dim)\n",
        "\n",
        "  # Define the layers for Attention so that we can use the same weights for all decoder timesteps\n",
        "  repeater = RepeatVector(Tx)\n",
        "  concatenator = Concatenate(axis=-1)\n",
        "  attn_densor1 = Dense(units=d1_units, activation='tanh')\n",
        "  attn_densor2 = Dense(units=d2_units, activation='linear', use_bias=False)\n",
        "  softmax_layer = Activation('softmax', name=\"attention_weights\")\n",
        "  dotter = Dot(axes=1)\n",
        "\n",
        "  # Define the Decoder unidirectional LSTM for shared weights\n",
        "  post_attention_lstm = LSTM(units=n_s, return_state=True)\n",
        "\n",
        "  # Define the last dense layer before output layer with linear activation\n",
        "  densor = Dense(units=d_units, activation='linear')\n",
        "\n",
        "  # Define the output layer so that it does not initalize again and again for shared weights\n",
        "  output_layer = Dense(units=summary_vocab_size, activation='softmax')\n",
        "\n",
        "  # Initialize the extension\n",
        "  extension = tf.zeros_like(X_inp, dtype=float)\n",
        "\n",
        "  # Decoder: Appends outputs from the output layer in each timestep\n",
        "  for t in range(Ty):\n",
        "    # Get the decoder input for current timestep\n",
        "    curr_dec_in = decoder_inp[:, t:t+1, :] # (batch, 1, emb_dim)\n",
        "\n",
        "    # Get the context from the attention mechanism\n",
        "    context, attn_dist = one_time_attention_v2(a, s, # (batch, d2_units, 2*n_a), (batch, Tx, d2_units)\n",
        "                                 repeater, concatenator, attn_densor1, attn_densor2, softmax_layer, dotter)\n",
        "\n",
        "    concat = Concatenate(axis=-1)([curr_dec_in, context]) # (batch, d2_units, emb_dim+2*n_a); d2_units=1 otherwise error\n",
        "    _, s, c = post_attention_lstm(concat, initial_state=[s, c]) # _, (batch, n_s), (batch, n_s)\n",
        "\n",
        "    # Calculate the output after using 2 linear dense layers\n",
        "    den1 = densor(s) # (batch, d_units)\n",
        "    den2 = densor(den1) # (batch, d_units)\n",
        "    # Use the output_layer to get the vocabulary distribution\n",
        "    P_vocab  = output_layer(den2) # (batch, summary_vocab_size)\n",
        "\n",
        "    # Generate pointer\n",
        "    p_gen = pointer_generator_v1(context[:, 0, :], s, curr_dec_in[:, 0, :]) # (batch, 1)\n",
        "\n",
        "    # Calculate the total probablity of copying words from source text\n",
        "    P_copy = (1 - p_gen) * attn_dist[:, :, 0] # (batch, Tx)\n",
        "\n",
        "    # Calculate the probablity to generate new word\n",
        "    P_final = p_gen * P_vocab # (batch, summary_vocab_size)\n",
        "\n",
        "    # Extend the final vocabulary to take new temporary words from source text\n",
        "    P_final = Concatenate(axis=-1)([P_final, extension]) # (batch, summary_vocab_size+Tx)\n",
        "\n",
        "    # Calculate the extended vocabulary distribution\n",
        "    P_final = calculate_final_distribution(P_final, P_copy, X_inp)\n",
        "\n",
        "    # Append the final output to the outputs list\n",
        "    outputs.append(P_final)\n",
        "\n",
        "  # Stack the list of each timesteps output along axis=1\n",
        "  outputs = tf.stack(outputs, axis=1) # (batch, Ty, summary_vocab_size)\n",
        "\n",
        "  model = Model(inputs=[X_inp, X_tar, s0, c0], outputs=outputs)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "hLrsABvkICua"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pointer Generator Model Creation and Training"
      ],
      "metadata": {
        "id": "l5lRYuUrDih7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tx = MAX_ARTICLE_TOKENS\n",
        "Ty = MAX_SUMMARY_TOKENS - 1\n",
        "emb_dim = EMB_OUT\n",
        "n_a = ENCODER_STATE_DIM\n",
        "n_s= DECODER_STATE_DIM\n",
        "d1_units = DENSE1_UNITS\n",
        "d2_units = DENSE2_UNITS\n",
        "d_units = DENSE_UNITS\n",
        "article_vocab_size = VOCAB_SIZE\n",
        "summary_vocab_size = VOCAB_SIZE\n",
        "\n",
        "pointer_model = pointer_gen_model(Tx, Ty,\n",
        "                          emb_dim, n_a, n_s, d1_units, d2_units, d_units,\n",
        "                          article_vocab_size, summary_vocab_size)"
      ],
      "metadata": {
        "id": "n7-mN-LfD69k"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model has {pointer_model.count_params():,} parameters.\")"
      ],
      "metadata": {
        "id": "AkrDZxHbIjFE",
        "outputId": "21ab711c-7c82-4a2f-f55f-28dbe5340521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model has 42,210,355 parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A look into how model will output on the above input."
      ],
      "metadata": {
        "id": "4pJCgf-3IwUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_model_out = pointer_model((art_inp, sum_inp, s0, c0))\n",
        "\n",
        "print(f\"Model output has a type: {type(sample_model_out)}\")\n",
        "print(f\"Model Output list for the Inputs above are of length: {len(sample_model_out)}\")\n",
        "print(f\"Model Output list has each output of shape: {sample_model_out[0].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b6914cd-aac6-494d-9aa1-0f1a780ee600",
        "id": "jl_ewDpoIwUi"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output has a type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Model Output list for the Inputs above are of length: 16\n",
            "Model Output list has each output of shape: (99, 50400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Custom Loss and Accuracy Version 2"
      ],
      "metadata": {
        "id": "7Vgp0zJ0EDkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss_v2(y_true, y_pred):\n",
        "  '''Calculates the loss for the baseline model. The loss is calculated by taking the negative\n",
        "  log-likelihood of the target word(w*_t) in the current timestep. Then the overall loss\n",
        "  is the summation over all timesteps divided by T (not Ty because it would include paddings also).\n",
        "\n",
        "  Arguments:\n",
        "    y_true: tf.Tensor object, true values for the target\n",
        "    y_pred: list of tf.Tensor objects, predicted probablities of the summary words\n",
        "\n",
        "  Returns:\n",
        "    returns the loss on the predicted values for the model\n",
        "  '''\n",
        "  # Calculate the loss for each item in the batch.\n",
        "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "  # Remove the paddings from calculation of loss\n",
        "  mask = tf.cast(y_true != 0, loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  # Divide the total loss after masking out paddings divided by total words which are not paddings\n",
        "  return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def custom_accuracy_v2(y_true, y_pred):\n",
        "  '''Calculates accuracy of the baseline model. The accuracy is calculated by matching how many correct\n",
        "  words were predicted excluding the paddings. Then, just add those which are correct and you will get the\n",
        "  the accuracy and then just divide it by total words not including padding.\n",
        "\n",
        "  Arguments:\n",
        "    y_true: tf.Tensor object, expected target values\n",
        "    y_pred: list of tf.Tensor object, predicted target values by model\n",
        "\n",
        "  Returns:\n",
        "    returns the total accuracy over the batch of data\n",
        "  '''\n",
        "  # Find the word index with maximum probablity\n",
        "  y_pred = tf.argmax(y_pred, axis=-1)\n",
        "  y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "\n",
        "  # Count the words that matches with true values\n",
        "  match = tf.cast(y_pred == y_true, tf.float32)\n",
        "  mask = tf.cast(y_true != 0, tf.float32)\n",
        "\n",
        "  # Mask out the paddings\n",
        "  match *= mask\n",
        "\n",
        "  return tf.reduce_sum(match) / tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "E_SW6SzNDH1E"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Testing with loss and accuracy"
      ],
      "metadata": {
        "id": "ShbQdiQqILXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sample y true values: {sum_tar}\")\n",
        "print(f\"Sample y pred values(first 10 values of first 2 timestep): {sample_model_out[:2]}\")\n",
        "\n",
        "sample_loss = custom_loss_v2(sum_tar, sample_model_out)\n",
        "print(f\"Loss of the sample y_true and y_pred: {sample_loss}\")\n",
        "\n",
        "sample_acc = custom_accuracy_v2(sum_tar, sample_model_out)\n",
        "print(f\"Accuracy of the sample y_true and y_pred: {sample_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2bc229-776f-4259-9605-4f003e2e2c4c",
        "id": "NOapo56oILX5"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample y true values: [[   68    49     3 ...     0     0     0]\n",
            " [  220   235  7015 ...     0     0     0]\n",
            " [12595  8464   776 ...     0     0     0]\n",
            " ...\n",
            " [31661 23778 22177 ...     0     0     0]\n",
            " [32385    27   181 ...     0     0     0]\n",
            " [  200   100 44787 ...     0     0     0]]\n",
            "Sample y pred values(first 10 values of first 2 timestep): [[[1.2197511e-05 1.2384101e-05 1.0203107e+01 ... 0.0000000e+00\n",
            "   0.0000000e+00 0.0000000e+00]\n",
            "  [1.0969686e-05 1.1255971e-05 1.1676810e+01 ... 0.0000000e+00\n",
            "   0.0000000e+00 0.0000000e+00]\n",
            "  [9.0160820e-06 9.3278859e-06 1.4266440e+01 ... 0.0000000e+00\n",
            "   0.0000000e+00 0.0000000e+00]\n",
            "  ...\n",
            "  [9.4162115e-06 9.8931405e-06 1.3365297e+01 ... 0.0000000e+00\n",
            "   0.0000000e+00 0.0000000e+00]\n",
            "  [8.8289698e-06 9.2761547e-06 1.4215631e+01 ... 0.0000000e+00\n",
            "   0.0000000e+00 0.0000000e+00]\n",
            "  [7.3025531e-06 7.6724255e-06 1.6425888e+01 ... 0.0000000e+00\n",
            "   0.0000000e+00 0.0000000e+00]]\n",
            "\n",
            " [[9.7016746e-06 9.7254688e-06 1.3674545e+01 ... 0.0000000e+00\n",
            "   0.0000000e+00 0.0000000e+00]\n",
            "  [1.1372827e-05 1.1433329e-05 1.1173131e+01 ... 0.0000000e+00\n",
            "   0.0000000e+00 0.0000000e+00]\n",
            "  [1.0219656e-05 1.0288063e-05 1.2648096e+01 ... 0.0000000e+00\n",
            "   0.0000000e+00 0.0000000e+00]\n",
            "  ...\n",
            "  [9.5747891e-06 9.6116892e-06 1.3234888e+01 ... 0.0000000e+00\n",
            "   0.0000000e+00 0.0000000e+00]\n",
            "  [8.2629476e-06 8.2947890e-06 1.5120843e+01 ... 0.0000000e+00\n",
            "   0.0000000e+00 0.0000000e+00]\n",
            "  [8.1234475e-06 8.1547496e-06 1.5321398e+01 ... 0.0000000e+00\n",
            "   0.0000000e+00 0.0000000e+00]]]\n",
            "Loss of the sample y_true and y_pred: 11.07374382019043\n",
            "Accuracy of the sample y_true and y_pred: 0.03086419776082039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Compiling pointer generator model"
      ],
      "metadata": {
        "id": "nT2RqhLFMlHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LEARNING_RATE\n",
        "initial_accumulator_value = INIT_ACC_VAL\n",
        "clipnorm = MAX_GRAD_NORM\n",
        "\n",
        "opt = Adagrad(learning_rate=lr,\n",
        "              initial_accumulator_value=initial_accumulator_value,\n",
        "              clipnorm=clipnorm)\n",
        "\n",
        "pointer_model.compile(loss=custom_loss_v2, optimizer=opt, metrics=[custom_loss_v2, custom_accuracy_v2])"
      ],
      "metadata": {
        "id": "WTayhfQFMlH0"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creating callbacks for model"
      ],
      "metadata": {
        "id": "pQSFBBfYMlH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mention the checkpoint path and it's directory where you will save the model\n",
        "checkpoint_path = POINTER_MODEL_CHECKPOINT\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Calculate no of batches, I am taking floor because when creating the training data I used drop_remainder\n",
        "n_batches = int(train_dataset.shape[0] / BATCH_SIZE)\n",
        "\n",
        "# Create the checkpoint for model saving, monitoring val_custom_accuracy_v1 and save only weights of the model\n",
        "saving_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                monitor='val_custom_accuracy_v2',\n",
        "                                                verbose=1,\n",
        "                                                save_weights_only=True,\n",
        "                                                save_freq=n_batches//2)\n",
        "\n",
        "# Create the checkpoint for stopping early after noticing that val_custom_accuracy_v1 is not increasing even after 5 consecutive epochs\n",
        "earlystop_cb = tf.keras.callbacks.EarlyStopping(monitor='val_custom_accuracy_v2',\n",
        "                                                    patience=PATIENCE,\n",
        "                                                    mode='max',\n",
        "                                                    )\n",
        "\n",
        "# Store the checkpoints in a list\n",
        "callbacks = [saving_cb, earlystop_cb]"
      ],
      "metadata": {
        "id": "BXuC_RPbMlH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training pointer generator model"
      ],
      "metadata": {
        "id": "S4iHgb8KMlH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = POINTER_EPOCHS\n",
        "steps_per_epoch = POINTER_STEPS_PER_EPOCHS\n",
        "\n",
        "history = pointer_model.fit(tf_train_dataset.repeat(),\n",
        "                    epochs=epochs,\n",
        "                    validation_data=tf_val_dataset,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    callbacks=callbacks\n",
        "                    )"
      ],
      "metadata": {
        "id": "z0ZekuBoMlH0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}