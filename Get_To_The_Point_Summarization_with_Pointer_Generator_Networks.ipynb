{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Arup3201/Summarization-Project-using-Pointer-Gen/blob/main/Get_To_The_Point_Summarization_with_Pointer_Generator_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"For the wraping the outputs of colab","metadata":{"id":"aWWumM-N6C31"}},{"cell_type":"code","source":"from IPython.display import HTML, display\n\ndef set_css():\n    display(HTML('''\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    '''))\nget_ipython().events.register('pre_run_cell', set_css)","metadata":{"id":"J2_Q63jmdSp3","execution":{"iopub.status.busy":"2023-08-22T08:30:40.036505Z","iopub.execute_input":"2023-08-22T08:30:40.037564Z","iopub.status.idle":"2023-08-22T08:30:40.068146Z","shell.execute_reply.started":"2023-08-22T08:30:40.037525Z","shell.execute_reply":"2023-08-22T08:30:40.067225Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Imports Libraries","metadata":{"id":"A3eWiUNHDwjn"}},{"cell_type":"code","source":"import os\nimport pathlib\nimport re\nimport random\nimport numpy as np\nimport tensorflow as tf\nimport pickle\n\n# For tokenizing and processing the examples for the model training\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Layers for the Encoder, Attention and Decoder\nfrom tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM\nfrom tensorflow.keras.layers import RepeatVector, Concatenate, Activation, Dot\nfrom tensorflow.keras.layers import Dense\n\n# For model initialization\nfrom tensorflow.keras import Model\n\n# For training the model\nfrom tensorflow.keras.optimizers.experimental import Adagrad","metadata":{"id":"x6QucUCZ0q2V","execution":{"iopub.status.busy":"2023-08-22T08:30:40.069638Z","iopub.execute_input":"2023-08-22T08:30:40.070151Z","iopub.status.idle":"2023-08-22T08:30:49.138223Z","shell.execute_reply.started":"2023-08-22T08:30:40.070100Z","shell.execute_reply":"2023-08-22T08:30:49.137060Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Download Data","metadata":{"id":"Z-SylnbUD2s6"}},{"cell_type":"code","source":"# Download the CNN stories from the url into cnn_stories_tgz file\ncnn_stories_tgz = tf.keras.utils.get_file(\n    origin=\"https://huggingface.co/datasets/cnn_dailymail/resolve/main/data/cnn_stories.tgz\",\n)\n\n# Download the Dailymail stories from the url into dailymail_stories_tgz file\ndailymail_stories_tgz = tf.keras.utils.get_file(\n    origin=\"https://huggingface.co/datasets/cnn_dailymail/resolve/main/data/dailymail_stories.tgz\",\n)","metadata":{"id":"k_03wyoLlFhO","outputId":"ad1d3d12-a264-45b5-8773-b5c923cf5fd9","execution":{"iopub.status.busy":"2023-08-22T08:30:49.140149Z","iopub.execute_input":"2023-08-22T08:30:49.141006Z","iopub.status.idle":"2023-08-22T08:30:57.449576Z","shell.execute_reply.started":"2023-08-22T08:30:49.140965Z","shell.execute_reply":"2023-08-22T08:30:57.448456Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Downloading data from https://huggingface.co/datasets/cnn_dailymail/resolve/main/data/cnn_stories.tgz\n158577824/158577824 [==============================] - 3s 0us/step\nDownloading data from https://huggingface.co/datasets/cnn_dailymail/resolve/main/data/dailymail_stories.tgz\n375893739/375893739 [==============================] - 4s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"cnn_stories_tgz, dailymail_stories_tgz","metadata":{"id":"fyid1XyFl1sp","outputId":"fa9020ad-37f3-4249-f23b-c41499da48d5","execution":{"iopub.status.busy":"2023-08-22T08:30:57.451209Z","iopub.execute_input":"2023-08-22T08:30:57.452070Z","iopub.status.idle":"2023-08-22T08:30:57.461341Z","shell.execute_reply.started":"2023-08-22T08:30:57.452018Z","shell.execute_reply":"2023-08-22T08:30:57.460134Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"('/root/.keras/datasets/cnn_stories.tgz',\n '/root/.keras/datasets/dailymail_stories.tgz')"},"metadata":{}}]},{"cell_type":"code","source":"!tar -xzf /root/.keras/datasets/cnn_stories.tgz\n!tar -xzf /root/.keras/datasets/dailymail_stories.tgz","metadata":{"id":"EHJtYhZpls0i","execution":{"iopub.status.busy":"2023-08-22T08:30:57.464024Z","iopub.execute_input":"2023-08-22T08:30:57.464386Z","iopub.status.idle":"2023-08-22T08:31:27.967709Z","shell.execute_reply.started":"2023-08-22T08:30:57.464349Z","shell.execute_reply":"2023-08-22T08:31:27.966213Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"cnn_stories_dir = pathlib.Path('/kaggle/working/cnn/stories')\ndailymail_stories_dir = pathlib.Path('/kaggle/working/dailymail/stories')","metadata":{"id":"ag5ubSt7l88l","execution":{"iopub.status.busy":"2023-08-22T08:31:27.969489Z","iopub.execute_input":"2023-08-22T08:31:27.969876Z","iopub.status.idle":"2023-08-22T08:31:27.977433Z","shell.execute_reply.started":"2023-08-22T08:31:27.969841Z","shell.execute_reply":"2023-08-22T08:31:27.976256Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"cnn_stories_dir, dailymail_stories_dir","metadata":{"id":"UmMCM--Yhm3B","outputId":"8cb6a093-72f6-40df-a083-2d5c4e35f2e1","execution":{"iopub.status.busy":"2023-08-22T08:31:27.979342Z","iopub.execute_input":"2023-08-22T08:31:27.979664Z","iopub.status.idle":"2023-08-22T08:31:27.993563Z","shell.execute_reply.started":"2023-08-22T08:31:27.979639Z","shell.execute_reply":"2023-08-22T08:31:27.992357Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(PosixPath('/kaggle/working/cnn/stories'),\n PosixPath('/kaggle/working/dailymail/stories'))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Print Stories","metadata":{"id":"WqScGmO6D5XI"}},{"cell_type":"code","source":"def print_filenames(dir_path, num_files=5):\n    '''Prints the name of the files that are present at `dir_path`.\n    Maximum `num_files` number of files are shown.\n\n    Arguments:\n    dir_path: PosixPath, pointing to the directory of which the user\n              wants to prints the file names.\n    num_files: int, number of files user wants to print.\n\n    returns:\n    nothing\n    '''\n\n    count = 0\n    for f in dir_path.glob('*.story'):\n        print(f.name)\n        count += 1\n\n        if count == num_files:\n            break\n    else:\n        print(f\"Less than {num_files} is present!\")","metadata":{"id":"dZFFXG7Pg86H","execution":{"iopub.status.busy":"2023-08-22T08:31:27.995516Z","iopub.execute_input":"2023-08-22T08:31:27.996267Z","iopub.status.idle":"2023-08-22T08:31:28.005849Z","shell.execute_reply.started":"2023-08-22T08:31:27.996191Z","shell.execute_reply":"2023-08-22T08:31:28.004644Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"print_filenames(cnn_stories_dir)","metadata":{"id":"nv3g7-M316yL","outputId":"1cb2a81e-2da0-4875-ed50-778ef6351829","execution":{"iopub.status.busy":"2023-08-22T08:31:28.007603Z","iopub.execute_input":"2023-08-22T08:31:28.008311Z","iopub.status.idle":"2023-08-22T08:31:28.115929Z","shell.execute_reply.started":"2023-08-22T08:31:28.008268Z","shell.execute_reply":"2023-08-22T08:31:28.114670Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"f649d6d2f0bfb431c4e772b2e65e6e67066c540f.story\nabd1d83c876ba0101640593c560a84ac7c9be4af.story\nf381b58b95713f9f1ee82d61b3baf82ac6603289.story\n748c3b60ccef81bb027471b7ed7872ba1e49c598.story\n3979c9a05c3ea72c19b99b19873551816658fd4d.story\n","output_type":"stream"}]},{"cell_type":"code","source":"print_filenames(dailymail_stories_dir)","metadata":{"id":"WcyW1wJa2EaN","outputId":"a8c02393-6b34-4fd4-b013-edf41ebb38f9","execution":{"iopub.status.busy":"2023-08-22T08:31:28.117421Z","iopub.execute_input":"2023-08-22T08:31:28.118065Z","iopub.status.idle":"2023-08-22T08:31:28.342688Z","shell.execute_reply.started":"2023-08-22T08:31:28.118022Z","shell.execute_reply":"2023-08-22T08:31:28.341539Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"1ba1e3be3b326e442cd78bf0455d80954f3397ab.story\n0568ca1b25187a3ab2bc27a32aa816c4bc3e4059.story\ne1bee977b5eca0c89cfdbe5775b35c4fa71f6851.story\ndb7dabdf59e9c81d7ee49aaef9bb5cc862538e10.story\n813502cc0cb53516a3194e133b7d3e14e3586b73.story\n","output_type":"stream"}]},{"cell_type":"code","source":"# Taking a sample .story file from cnn stories\nsample_filename = \"438411e10e1ef79b47cc48cd95296d85798c1e38.story\"\nsample_filedir = cnn_stories_dir\n\nsample_filepath = sample_filedir / sample_filename\nwith open(sample_filepath, 'r') as f:\n    sample_story = f.read()\n\nprint(f\"A sample story:\\n{sample_story}\")","metadata":{"id":"Uw0kqchX3X7X","outputId":"b8a73eb0-be8e-4c46-d84c-6b67080ca83f","execution":{"iopub.status.busy":"2023-08-22T08:31:28.346880Z","iopub.execute_input":"2023-08-22T08:31:28.347282Z","iopub.status.idle":"2023-08-22T08:31:28.356287Z","shell.execute_reply.started":"2023-08-22T08:31:28.347249Z","shell.execute_reply":"2023-08-22T08:31:28.355149Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"A sample story:\nNew York (CNN) -- The U.S. population is expected to top out at close to 312.8 million people just around the time crowds gather to watch the ball drop on New Year's Eve, according to new census data released Thursday.\n\nThe figure represents a 0.7% increase from last year, adding 2,250,129 people to the U.S. population since the start of 2011, and a 1.3% increase since Census Day, April 1, 2010.\n\nThe agency estimates that beginning in January, one American will be born every eight seconds and one will die every 12 seconds.\n\nU.S.-bound immigrants are also expected to add one person every 46 seconds.\n\nThat combination of births, deaths and migration is expected to add a single person to the U.S. population every 17 seconds, the Census Bureau said.\n\nMeanwhile, millions are set to ring in the new year.\n\nIn New York, authorities are preparing for large crowds in Manhattan's Times Square, where Lady Gaga is expected to join Mayor Michael Bloomberg to push the button that drops the Waterford Crystal ball at 11:59 p.m. ET on New Year's Eve.\n\n\"And I'm so looking forward to performing on NYE+dropping the Ball with Mayor Bloomberg!\" the pop star posted on Twitter. \"What an honor as a New Yorker.\"\n\nPast guests have included Muhammad Ali, Rudy Giuliani, Colin Powell and Bill and Hillary Clinton.\n\nOn Thursday, officials conducted New York's annual \"airworthiness test\" -- a process in which confetti is tossed by handfuls above Times Square -- in preparation for the annual city tradition of dumping one ton of confetti over revelers in the iconic square.\n\nThe Big Apple this year edged out Las Vegas for the first time in seven years as the top travel U.S. destination for those celebrating the new year, according to a December travel booking website poll.\n\nSeven New York neighborhoods made the top 10 list, with two districts in Las Vegas and one in New Orleans making up the other three, according to the Priceline poll.\n\n\"It appears that New York City will be helped this year by a weather forecast that calls for warmer than usual temperatures over the holiday weekend,\" said company spokesman Brian Ek.\n\n@highlight\n\nCensus Bureau: U.S. population is expected to be 312.8 million on New Year's Day\n\n@highlight\n\nThat figure represents a 0.7% increase from last year\n\n@highlight\n\nLady Gaga, mayor to activate ball drop at Times Square on New Year's Eve\n\n@highlight\n\nNYC has supplanted Las Vegas as the top New Year's destination, Priceline poll says\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Define Global Variables","metadata":{"id":"ihAsXBceD7ew"}},{"cell_type":"code","source":"# Define the global variables\ndm_single_close_quote = u'\\u2019' # unicode for closing single quote\ndm_double_close_quote = u'\\u201d' # unicode for closing double quote\nEND_TOKENS = ['.', '!', '?', '...', \"'\", \"`\", '\"',\n              dm_single_close_quote, dm_double_close_quote, \")\"]\n\n# Maximum stories to process from cnn and dailymail each\nMAX_STORIES = 310000\n\n# From the total data how to split into train, val and test\nTRAIN_SIZE = 0.8 # Fraction of the total dataset to use for training\nVAL_SIZE = 0.1 # Fraction of the total dataset to use for validation\nTEST_SIZE = 0.1 # Fraction of the total dataset to use for testing\n\n# For tokenization\nVOCAB_SIZE = 50000 # Vocabulary size or no of unique words\nOOV_TOKEN = \"<OOV>\" # Word token to represent the out-of-vocabulary words\n\n# For standardization\nSTART_TOKEN = '<START>' # Starting word of each sentence\nEND_TOKEN = '<END>' # Ending word of each sentence\n\n# Total tokens to represent encoder input sentence and decoder input sentence(Values are taken from paper)\nMAX_ARTICLE_TOKENS = 400 # Maximum no of tokens to consider in article when processing them for model\nMAX_SUMMARY_TOKENS = 100 # Maximum no of tokens to consider in summary when processing them for model\n\n# For dataset creation hyperparameters\nBUFFER_SIZE = 5000 # Buffer size when using shuffle\nBATCH_SIZE = 16 # No of examples in each batch\n\n# Model Archietecture hyperparameters (Values are taken from the paper)\nEMB_OUT = 128 # Embedding output dimension\nENCODER_STATE_DIM = 256 # Encoder hidden(also cell) state dimension\nDECODER_STATE_DIM = 2*ENCODER_STATE_DIM # Decoder hidden(also cell) state dimension\nDENSE1_UNITS = 128 # Attention first dense layer units(calculates partial energy)\nDENSE2_UNITS = 1 # Attention secodn dense layer units(calculated final energy)\nDENSE_UNITS = 512 # Units of the Dense layers before output layer, make sure it is same as decoder state dimension\n\n# Model Optimizer hyperparameters (Values are taken from the paper)\nLEARNING_RATE=0.15 # Learning rate\nINIT_ACC_VAL=0.1 # Initial accumulator value\nMAX_GRAD_NORM=2 # Gardient norm\n\n# Model Checkpoint hyperparameters\nBASELINE_MODEL_CHECKPOINT = \"/kaggle/working/baseline-model/cp-{epoch:04d}.ckpt\"\nPOINTER_MODEL_CHECKPOINT = \"/kaggle/working/pointer-model/cp-{epoch:04d}.ckpt\"\nCOVERAGE_MODEL_CHECKPOINT = \"/kaggle/working/coverage-model/cp-{epoch:04d}.ckpt\"\nPATIENCE = 5\n\n## Model Fit (All values are choosen closer to the ones in the paper)\n# Base model\nBASE_EPOCHS = 33\nSTEPS_PER_EPOCHS_BASE = 18181\n# Pointer Model\nPOINTER_EPOCHS = 13\nPOINTER_STEPS_PER_EPOCHS = 18000\n# Coverage Model\nCOVERAGE_EPOCHS = 1\nCOVERAGE_STEPS_PER_EPOCHS = 3000\n\n# Coverage mechanism\nLAMBDA_VAL = 1","metadata":{"id":"cubLAm1Q3SuG","execution":{"iopub.status.busy":"2023-08-22T08:31:28.358126Z","iopub.execute_input":"2023-08-22T08:31:28.358596Z","iopub.status.idle":"2023-08-22T08:31:28.374103Z","shell.execute_reply.started":"2023-08-22T08:31:28.358552Z","shell.execute_reply":"2023-08-22T08:31:28.372680Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"## Fixing periods of the stories","metadata":{"id":"UXHUPXvlEDTo"}},{"cell_type":"markdown","source":"I am creating a function `fix_missing_period` where I am taking 2 arguements, one for the `line` for which I am checking and fixing the period and other is `end_tokens` which is a list that has all the tokens that I should consider as ending of a sentence.\n\nThese are the steps -\n1. Check if line contains `@highlight`, if True then just return the line.\n2. Check if line is empty, then return line as it is.\n3. Check is line ends with any of the `end_tokens`, if so then return line as it is.\n4. Only is none of the above conditions match then append `.` to the current line.","metadata":{"id":"iZPt8EVBzJ8a"}},{"cell_type":"code","source":"def fix_missing_period(line, end_tokens=END_TOKENS):\n    '''function to fix the missing periods for some story lines which do not end with\n    any of the end_tokens mentioned.\n\n    Argument:\n    line: string, line of the story to fix the missing the period of.\n    end_tokens: list of strings, all the tokens that are considered as line end.\n\n    Returns:\n    new line with fixed the ending part by adding an ending token if not present.\n    '''\n    if \"@highlight\" in line:\n        return line\n    elif line == \"\":\n        return line\n    elif line[-1] in end_tokens:\n        return line\n\n    return line + '.'","metadata":{"id":"i-S-Hss12TPk","execution":{"iopub.status.busy":"2023-08-22T08:31:28.376099Z","iopub.execute_input":"2023-08-22T08:31:28.376586Z","iopub.status.idle":"2023-08-22T08:31:28.391637Z","shell.execute_reply.started":"2023-08-22T08:31:28.376543Z","shell.execute_reply":"2023-08-22T08:31:28.390463Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"sample_text = \"i have a bad habit of not giving full-stop after sentence\\nLike this setence\"\nprint(f\"Fixing {fix_missing_period(sample_text)}\")","metadata":{"id":"L1hiNysxnmAO","outputId":"1493cc4e-e13e-49d1-bb3d-907b44d3c67d","execution":{"iopub.status.busy":"2023-08-22T08:31:28.393141Z","iopub.execute_input":"2023-08-22T08:31:28.393815Z","iopub.status.idle":"2023-08-22T08:31:28.408706Z","shell.execute_reply.started":"2023-08-22T08:31:28.393779Z","shell.execute_reply":"2023-08-22T08:31:28.407824Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Fixing i have a bad habit of not giving full-stop after sentence\nLike this setence.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Splitting the Stories into articles and summaries","metadata":{"id":"fEoN3HDSEHjI"}},{"cell_type":"markdown","source":"I am creating a function `split_article_summary` which will split the story into article and summary parts.\n\nThe function takes only 1 arguement and that is the `story` which will be splitted into article and summary.\n\nThe steps to follow are -\n1. Split the story by new line `\\n`. I will get a list of lines.\n2. Strip the lines by using list comprehension.\n3. Use list comprehension to make lower case each line by using `.lower()`.\n4. Fix each line by adding period if there is none in that line using `fix_missing_period` function.\n5. Make 2 empty list for `article` and `summary`.\n6. Go through each line. In each line, I need to check 4 things,\n  * line contains `@highlight` or not, if True then set `next_highlight` to `True` because the next to next line is going to be a summary line.\n  * line is `\"\"` empty or not, if True then ignore.\n  * `next_highlight` is True or not, if True then append the line to `summary`.\n  * If non of the ebove then append to `article`.\n7. After done with filling the `article` and `summary` list with lines, join those sentences to make the whole article and summary. Here, I am using `.join()` method.","metadata":{"id":"5-tqWtoowXxl"}},{"cell_type":"code","source":"def split_article_summary(story):\n    '''Splits the story into 2 parts, one for article and other for summary of that\n    article. Returns the article and summary.\n\n    Argument:\n    story: string file that contains both article and summary combiningly.\n\n    Returns:\n    article, summary seperately from the story.\n\n    '''\n    lines = story.split('\\n')\n    lines = [line.strip() for line in lines]\n    lines = [line.lower() for line in lines]\n\n    # Fix the ending period\n    lines = [fix_missing_period(line) for line in lines]\n\n    # List to contain the article and summary lines\n    article = []\n    summary = []\n\n    # Indicator of whether the next line is the summary or not\n    next_highlight = False\n\n    for line in lines:\n        if \"@highlight\" in line:\n            next_highlight = True\n        elif line==\"\":\n            continue\n        elif next_highlight:\n            summary.append(line)\n        else:\n            article.append(line)\n\n    article = ' '.join(article)\n    summary = ' '.join(summary)\n\n    return article, summary","metadata":{"id":"-X4eMltQnf10","execution":{"iopub.status.busy":"2023-08-22T08:31:28.410275Z","iopub.execute_input":"2023-08-22T08:31:28.410712Z","iopub.status.idle":"2023-08-22T08:31:28.423558Z","shell.execute_reply.started":"2023-08-22T08:31:28.410660Z","shell.execute_reply":"2023-08-22T08:31:28.422449Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"sample_article, sample_summary = split_article_summary(sample_story)\n\nprint(f\"Sample Article after spliting:\\n{sample_article}\")\nprint(f\"Sample Summary after spliting:\\n{sample_summary}\")","metadata":{"id":"nuUjOaN9orGU","outputId":"e0133cca-84cd-4b01-e063-ec57f7244ae3","execution":{"iopub.status.busy":"2023-08-22T08:31:28.425263Z","iopub.execute_input":"2023-08-22T08:31:28.425618Z","iopub.status.idle":"2023-08-22T08:31:28.439744Z","shell.execute_reply.started":"2023-08-22T08:31:28.425589Z","shell.execute_reply":"2023-08-22T08:31:28.438550Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Sample Article after spliting:\nnew york (cnn) -- the u.s. population is expected to top out at close to 312.8 million people just around the time crowds gather to watch the ball drop on new year's eve, according to new census data released thursday. the figure represents a 0.7% increase from last year, adding 2,250,129 people to the u.s. population since the start of 2011, and a 1.3% increase since census day, april 1, 2010. the agency estimates that beginning in january, one american will be born every eight seconds and one will die every 12 seconds. u.s.-bound immigrants are also expected to add one person every 46 seconds. that combination of births, deaths and migration is expected to add a single person to the u.s. population every 17 seconds, the census bureau said. meanwhile, millions are set to ring in the new year. in new york, authorities are preparing for large crowds in manhattan's times square, where lady gaga is expected to join mayor michael bloomberg to push the button that drops the waterford crystal ball at 11:59 p.m. et on new year's eve. \"and i'm so looking forward to performing on nye+dropping the ball with mayor bloomberg!\" the pop star posted on twitter. \"what an honor as a new yorker.\" past guests have included muhammad ali, rudy giuliani, colin powell and bill and hillary clinton. on thursday, officials conducted new york's annual \"airworthiness test\" -- a process in which confetti is tossed by handfuls above times square -- in preparation for the annual city tradition of dumping one ton of confetti over revelers in the iconic square. the big apple this year edged out las vegas for the first time in seven years as the top travel u.s. destination for those celebrating the new year, according to a december travel booking website poll. seven new york neighborhoods made the top 10 list, with two districts in las vegas and one in new orleans making up the other three, according to the priceline poll. \"it appears that new york city will be helped this year by a weather forecast that calls for warmer than usual temperatures over the holiday weekend,\" said company spokesman brian ek.\nSample Summary after spliting:\ncensus bureau: u.s. population is expected to be 312.8 million on new year's day. that figure represents a 0.7% increase from last year. lady gaga, mayor to activate ball drop at times square on new year's eve. nyc has supplanted las vegas as the top new year's destination, priceline poll says.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"I am creating a function `get_articles_summaries` which will process each of the stories present in the directory of cnn and dailymail and return the articles, summaries in the form of list.\n\nThis function will take 2 arguements. One will be the `stories_dir` which is a Posix format string from `pathlib` library and another arguement is of `max_stories` which is the maximum number of stories that we will extract from those directories.\n\nThe process is simple. We will follow this steps -\n1. Create 2 empty lists of `articles` and `summaries`.\n2. Loop through all the files present in the directory `stories_dir` using `.glob` generator method.\n3. Make a `count` variable which will count the number of processed strories and when it hits `max_stories`, break from the loop.\n4. Inside the loop, you will open the file in `r` reading format, then just use `.read()` method to read the story.\n5. Everytime after reading the story, split the article and summary part from it and then append them inside the `articles` and `summaries` list.\n6. Return the 2 lists.","metadata":{"id":"oTEa0m3Huxz4"}},{"cell_type":"code","source":"def get_articles_summaries(stories_dir, max_stories):\n    '''stores the stories from stories_dir folder into a list and returns the list\n\n    Arguments:\n    stories_dir: Posix string, the directory where the stories are stored\n    max_stories: maximum number of stories to store\n\n    Returns:\n    list of stories.\n\n    '''\n    articles = []\n    summaries = []\n\n    count = 0\n    for f in stories_dir.glob(\"*.story\"):\n        count += 1\n        with open(f, 'r') as reader:\n            story = reader.read()\n\n            article, summary = split_article_summary(story)\n\n            articles.append(article)\n            summaries.append(summary)\n\n        if count == max_stories:\n            break\n\n    return articles, summaries","metadata":{"id":"4VUmbYSpnjAr","execution":{"iopub.status.busy":"2023-08-22T08:31:28.440863Z","iopub.execute_input":"2023-08-22T08:31:28.441250Z","iopub.status.idle":"2023-08-22T08:31:28.454738Z","shell.execute_reply.started":"2023-08-22T08:31:28.441217Z","shell.execute_reply":"2023-08-22T08:31:28.453550Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"Out of all available .story files, we will only take `MAX_STORIES` number of files and then open them.","metadata":{"id":"Uk-BuCM4rIiO"}},{"cell_type":"code","source":"cnn_articles, cnn_summaries = get_articles_summaries(cnn_stories_dir, MAX_STORIES)","metadata":{"id":"aa9ZDQntpHQZ","execution":{"iopub.status.busy":"2023-08-22T08:31:28.456159Z","iopub.execute_input":"2023-08-22T08:31:28.456512Z","iopub.status.idle":"2023-08-22T08:31:38.612580Z","shell.execute_reply.started":"2023-08-22T08:31:28.456482Z","shell.execute_reply":"2023-08-22T08:31:38.611436Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Total no of cnn stories captured are {len(cnn_articles)}\\n\\n\")\nprint(f\"One of the CNN articles: {cnn_articles[0]}\\n\\n\")\nprint(f\"The summary of this article: {cnn_summaries[0]}\\n\\n\")","metadata":{"id":"-q_i-69YqJnj","outputId":"6078cf9e-816e-49fd-a540-7fda9f3b03c1","execution":{"iopub.status.busy":"2023-08-22T08:31:38.613972Z","iopub.execute_input":"2023-08-22T08:31:38.614432Z","iopub.status.idle":"2023-08-22T08:31:38.622436Z","shell.execute_reply.started":"2023-08-22T08:31:38.614401Z","shell.execute_reply":"2023-08-22T08:31:38.621234Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Total no of cnn stories captured are 92579\n\n\nOne of the CNN articles: (cnn) -- when pro quarterback michael vick pleaded guilty to bankrolling a dogfighting operation in 2007, there was a spike in reports of dogfighting in the united states. one of six dogs recovered from a sumter county, south carolina, dogfight waits in a kennel last week. but when the headlines faded, the blood sport grew stronger and went even more underground, with thugs taking inventive precautions to keep police at bay, animal cruelty experts say. \"they know it's just not smart to have large crowds anymore, so we've seen fights where you've got the two handlers, a referee and web cams everywhere broadcasting the fight on the internet,\" said mark kumpf, an investigator based in ohio who directs the national animal control association. fights are also being staged on the move -- in 18-wheelers. \"these guys are very sophisticated,\" kumpf said. \"if you're driving down the road, there could be dogs in that truck driving next to you that are dying.\" dozens more dogfighting cases have been investigated and prosecuted since the vick case, said alison gianotto, who runs the database petabuse.com. the computer programmer,  horrified when a neighbor's cat was set on fire eight years ago, created the california-based organization to track animal cruelty cases and animal abusers. the database, which logs media stories, has also become a popular place for law enforcement to send reports. \"there's not a central body keeping track of what's happening nationally, which is unfortunate when you consider that a lot of these cases cross state lines,\" she said. still, detectives, animal welfare professionals and prosecutors agree that the attention the vick case has brought to dogfighting has been positive because more people are inclined to report their suspicions. dogfighting is illegal in all states; penalties vary but usually include heavy jail time or steep fines. the national football league suspended vick indefinitely in august 2007 after he pleaded guilty to a federal charge of bankrolling a dogfighting operation at a home he owned in virginia. vick, 29, was freed from federal prison in leavenworth, kansas, on may 20 and returned to virginia to serve the last two months of his 23-month sentence in home confinement. \"at the height of attention on the vick case, things quieted down across the country with some of these dogfighters getting out of the business,\" veteran animal abuse investigator tim rickey said. \"but then, the headlines went away, and people thought the attention was off. it just started right back up, almost stronger than before.\" \"every saturday night in every county in missouri, there is a dogfight going on,\" rickey said. while the vick case was making its way through the court system, rickey, who directs the animal cruelty task force at the humane society of missouri, was initiating what would become an 18-month investigation linking dogfighting rings in eight states. that probe led to the july 8 arrest of 28 people from eight states. as many as 400 dogs were confiscated in raids coordinated by federal, state and local law enforcement agencies, rickey said. he said it was the largest such case involving dogfighting in the u.s. while those involved with the national case declined monday to give details about that investigation, cnn spoke with several detectives across america who have worked other dogfighting cases. among the abuses they've uncovered:. • dogs with missing ears and patches of skin. • animals with teeth shaved down to the bone. • \"vets\" who have used leg splints that are to tight to \"treat\" animals in dogfighting rings. •  contraptions, usually fashioned out of wood, much like a treadmill, that force chained dogs to run or be choked. detective keith coberly of the police vice squad in dayton, ohio, described a case he recently investigated that resulted in the convictions of three men. a neighbor called police when she saw a mangled dog that had apparently escaped from a home where investigators found 60 chained pit bull terriers, many being starved and wallowing in their own waste. there were thousands of hypodermic needles scattered across the ground. \"they were using steroids on the animals,\" he said. \"there was one dog -- in such bad shape, man -- tethered to a logging chain, and another was kept in a two-foot shed without ventilation or food.\" the suffering is incalculable, and the cost of caring for the animals is steep. because the national investigation originated in missouri, the state is harboring about 400 of the rescued dogs, some that have had puppies recently. \"these dogs are bred to attack each other, so just caring for them is a tremendous job. you have to keep them separate, and you have to protect volunteers who are devoting 12, 14 hours of their day,\" rickey said. \"and we're doing all of that in this economy.\" investigating dogfighting is dangerous -- and hugely popular in russian mafia circles and with drug traffickers in mexico, experts say. dogfighting is reliant on word of mouth, and on what one undercover officer described as \"bad character\" references. \"if you can get someone to vouch for you, a match is set up,\" kumpf said. \"they'll have everyone go to a hotel and come pick you up and drive you around in an unmarked van.\" driving around town helps shake any police tail, he said. those betting on fights aren't likely to get paid on site any more. money is often kept at another location, making it more difficult to make arrests. in late july, nfl commissioner roger goodell conditionally reinstated vick, who said on \"60 minutes\" on sunday night that he cried in prison because of the guilt he felt about dogfighting. vick's agent announced thursday that the former atlanta falcon signed a two-year deal with the philadelphia eagles, which reportedly could be worth more than $6 million. \"i hope people realize [dogfighting] is not just about michael vick,\" rickey said. \"it's a lot bigger than him.\"\n\n\nThe summary of this article: dogfighters are using web cams, staging fights in 18-wheelers to avoid police. vick case brought attention to dogfighting, but cases have not decreased. detective: anyone who wants to get into dogfighting needs \"bad character\" reference.\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"dailymail_articles, dailymail_summaries = get_articles_summaries(dailymail_stories_dir,\n                                                                 MAX_STORIES)","metadata":{"id":"KT4Hrp6nqeKu","execution":{"iopub.status.busy":"2023-08-22T08:31:38.623916Z","iopub.execute_input":"2023-08-22T08:31:38.624242Z","iopub.status.idle":"2023-08-22T08:32:17.997089Z","shell.execute_reply.started":"2023-08-22T08:31:38.624215Z","shell.execute_reply":"2023-08-22T08:32:17.995940Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Total no of dailymail stories captured are {len(dailymail_articles)}\\n\\n\")\nprint(f\"One of the Dailymail articles: {dailymail_articles[0]}\\n\\n\")\nprint(f\"The summary of this article: {dailymail_summaries[0]}\\n\\n\")","metadata":{"id":"nkzwSP9kh4VK","outputId":"0d3aaab8-5a41-46ae-95b9-d2949dc9e336","execution":{"iopub.status.busy":"2023-08-22T08:32:17.998397Z","iopub.execute_input":"2023-08-22T08:32:17.998710Z","iopub.status.idle":"2023-08-22T08:32:18.005958Z","shell.execute_reply.started":"2023-08-22T08:32:17.998684Z","shell.execute_reply":"2023-08-22T08:32:18.004794Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Total no of dailymail stories captured are 219506\n\n\nOne of the Dailymail articles: by. daily mail reporter. an oklahoma father is fighting to get custody of his twin daughters after their little brother was allegedly beaten to death by his estranged wife's boyfriend. brian dockery said he and his wife, tennille downey, moved the family to alaska over a year ago to be nearer her family, but the relationship broke down and he moved back to his native oklahoma last june without his three children. but on march 21, police were called to his downey's wasilla home because 23-month-old ezekiel had stopped breathing. downey's boyfriend, jyzyk sharpe, who had been watching the children while downey was at work, was arrested friday and charged with second-degree murder by extreme indifference and manslaughter in ezekiel's death. the 40-year-old said the toddler slipped getting into the bath but the medical examiner's office found his injuries - several cuts, broken ribs and bruises on both lungs - were not consistent with a fall. scroll down for video. tragic: little ezekiel dockery, pictured, was beaten to death while at his mother's house in alaska last month. 'i can't believe that an adult could be so vicious to a child so innocent and so sweet,' dockery told news 9. 'why was he trusted in a home with my children?' wasilla police department officers responded to an east quincy circle home just after 1 p.m. where police had been told cpr was in progress on dockery. the boy was taken to mat-su regional medical center, where he was pronounced dead shortly before 2 p.m. 'at the hospital, i observed jyzyk sharpe stuttering and displaying involuntary body movements, and (he) was unable to articulate his thoughts,' investigator daniel bennett wrote in a criminal complaint. he added that sharpe's aunt and uncle who knew him very well reported that they had not seen such behavior from him in the past.' sharpe told the investigator that ezekiel fell while climbing into the bath to join his sisters. he said he was undressing to join them when he heard a smack. 'sharpe was talking about (dockery) and stated, \"i saw him step over, and i could hear a fall, (a-a) slippery fall, i walk over and look and it was a split second, you just knew instantly, instantly, instantly,\"' bennett wrote, according to ktuu.com. after the alleged fall, sharpe said he. brought the child to a bed, called his mother and 911 and began. performing cpr. he told bennett he'd broken the child's ribs during cpr. heartbroken: brian dockery, pictured at his son's memorial service, is devastated after the death. fight: dockery is now fighting to get custody of his twin daughters ava, and veloria dockery, pictured with their brother. downey denies that sharpe would have intentionally hurt the boy. she told police she had been traveling home fro work in anchorage when she received the frantic call. 'i asked (downey) if she had any suspicion that (sharpe) hurt her child at all,' bennett wrote in the complaint. '(downey) stated that she did not have any suspicion that (sharpe) would hurt her. children because he takes care of the kids as if they were his own.' in a sweep of the residence, police found a blood smear in the master bedroom, which tested positive to ezekiel's blood. they also found a glass plate with white powder on it, that tested positive to cocaine. downey told investigators the drug was hers not sharpe's and that the blood stain was from when the twins had pushed ezekiel down, slitting his lip. according to ktuu, ezekiel suffered bruises around his head and back, lacerations to his lips, a fractured rib and a tear of his aorta arch, all of which are indicate 'major blunt force trauma.' the medical examiner said the injuries were more consistent with 'a victim in a car accident' rather than a fall or cpr. dockery's family held a memorial service in seminole last monday for the little boy who would have turned two on april 18. the swearingen funeral home was covered in pictures of ezekiel's smiling face. lost: 'ezekiel was a beautiful, pure, innocent spirit,' the toddler's aunt natasha parks said of the boy, pictured. 'we were robbed of his life. the suffering is unspeakable and we're utterly devastated' twins: 'i think they've endured enough. i'm ready for them to come home. their home is here with me and my family,' dockery said of his daughters, pictured. a proper funeral however, is on hold. the family told news 9 that ezekiel's body is in a holding room in. alaska and cannot be buried until around june because the ground needs. to thaw out. dockery said he hopes to bring his son's body to oklahoma and have him buried in seminole. 'ezekiel. was a beautiful, pure, innocent spirit,' the toddler's aunt natasha. parks told news 9. 'we were robbed of his life. the suffering is. unspeakable and we're utterly devastated.' the family want ezekiel's 4-year-old daughters to come back to seminole. 'i think they've endured enough. i'm ready for them to come home. their home is here with me and my family,' dockery said. 'and i'm not going to stop until i get my girls.' parks described the plight as 'the biggest fight of our lives.' 'it's too late for ezekiel, but it's not too late for ava and veloria,' she said. 'we love them dearly, and we need justice for ezekiel.' sharpe is due in court for a hearing on april 14. news9.com - oklahoma city, ok - news, weather, video and sports |.\n\n\nThe summary of this article: oklahoma man brian dockery is fighting to get custody of his twins ava and veloria after his 23-month-old son ezekiel was beaten to death. his estranged wife said the toddler slipped getting into the bath. but the medical examiner's office said his injuries - several cuts, broken ribs and bruises on both lungs - were not consistent with a fall. the woman's boyfriend jyzyk sharpe, 40, has been arrested and charged with second-degree murder by extreme indifference and manslaughter. an unexplained blood stain and cocaine were discovered at the residence. the family moved to alaska a year ago, but after the marriage fell apart brian moved back to oklahoma and left the children with their mother.\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Splitting data into training, validation and testing set","metadata":{"id":"nEaIcT3lEaez"}},{"cell_type":"markdown","source":"I am creating another function -\n`split_dataset(train_size, val_size, test_size)`: I am creating this function to split the original 1,00,000 examples into 80,000 training samples, 10,000 val samples and 10,000 test samples.","metadata":{"id":"8ea-PhS3iIJZ"}},{"cell_type":"code","source":"def split_dataset(dataset, train_size, val_size, test_size):\n    first_split = train_size\n    second_split = train_size+val_size\n    third_split = train_size+val_size+test_size\n    return dataset[:first_split, :], dataset[first_split:second_split, :], dataset[second_split:third_split, :]","metadata":{"id":"v-iZDbUCqkdC","execution":{"iopub.status.busy":"2023-08-22T08:32:18.007400Z","iopub.execute_input":"2023-08-22T08:32:18.008241Z","iopub.status.idle":"2023-08-22T08:32:18.044389Z","shell.execute_reply.started":"2023-08-22T08:32:18.008199Z","shell.execute_reply":"2023-08-22T08:32:18.043086Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"Let us create a function `make_datasets`, that will be make training, validation and testing datasets. This function will -\n1. This functions will have many argumenets and among them 2 argumenets `cnn_stories` and `dailymail_stories` are lists which has list of articles and summaries at 0 and 1 index. It means `cnn_stories[0]` is articles of cnn news and `cnn_stories[1]` is summaries of cnn news. It applies to `dailymail_stories` as well.\nObjective of this step is to concatenate the cnn articles with dailymail articles and cnn summaries with dailymail summaries.\n```python\n[1, 2] + [3, 4] = [1, 2, 3, 4]\n```\n\n3. Convert the articles and summaries list into tensors and then concatenate them along a new axis. To create new axis I can use `tf.newaxis` in the indexing. E.g.\n```python\n  np.concatenate([articles[:, tf.newaxis], summaries[:, tf.newaxis]], axis=-1)\n```\n4. Shuffle the dataset using `random.sample` method.\n```python\nrandom.seed(seed_value) # To make sure that everytime it gives the same shuffle\nrandom.sample(list_to_shuffle, len(list_to_shuffle))\n```\n5. Split the dataset into 3 parts, one for training, other for validation and last one for testing. All the tensors are of shape `(num_samples, 2)`.","metadata":{"id":"FTB5eNzJrqyr"}},{"cell_type":"code","source":"def make_datasets(cnn_stories, dailymail_stories, train_fraction, val_fraction, test_fraction, seed_value=0):\n    '''Create 3 datasets each for training, validation and testing respectively.\n    This function concatenates the articles, summaries of cnn and dailymail news. After that it will tokenize\n    them one by one in a loop. After it is done with the tokenization, it will shuffle the articles and\n    summaries using random.sample method (although we have a helper function for it). Finally we do the\n    splitting of the whole dataset. Remember here the returned values become tensors.\n\n    Arguments:\n    cnn_stories: list of 2 values, one for cnn articles and other for cnn summaries.\n    dailymail_stories: list of 2 values, one for dailymail articles and other for dailymail summaries.\n    train_size: float, specifying how much fraction of the original dataset to take for training.\n    val_size: float, specifying how much fraction of the original dataset to take for validation.\n    test_size: float, specifying how much fraction of the original dataset to take for testing.\n\n    Returns:\n    returns a tuple with 3 values inside it, `training_data`, `validation_data` and `testing_data`\n    with the specified amount of data in it.\n    Each one of them are tensor with shape `(num_samples, 2)`. `shape[1]=2` for article and summary.\n    '''\n    articles = cnn_stories[0] + dailymail_stories[0]\n    summaries = cnn_stories[1] + dailymail_stories[1]\n\n    articles = np.array(articles, dtype=object)\n    summaries = np.array(summaries, dtype=object)\n\n    dataset = np.concatenate((articles[:, tf.newaxis], summaries[:, tf.newaxis]), axis=-1)\n\n    random.seed(seed_value)\n    shuffled_indices = random.sample(list(range(dataset.shape[0])), dataset.shape[0])\n\n    dataset = dataset[shuffled_indices, :]\n\n    train_size = int(train_fraction * dataset.shape[0])\n    val_size = int(val_fraction * dataset.shape[0])\n    test_size = dataset.shape[0] - (train_size + val_size)\n\n    training_samples, validation_samples, testing_samples = split_dataset(dataset,\n                                                                        train_size,\n                                                                        val_size,\n                                                                        test_size)\n\n    return (training_samples, validation_samples, testing_samples)","metadata":{"id":"QDB0_32RrnHk","execution":{"iopub.status.busy":"2023-08-22T08:32:18.046303Z","iopub.execute_input":"2023-08-22T08:32:18.046927Z","iopub.status.idle":"2023-08-22T08:32:18.060895Z","shell.execute_reply.started":"2023-08-22T08:32:18.046866Z","shell.execute_reply":"2023-08-22T08:32:18.059689Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"train_dataset, val_dataset, test_dataset = make_datasets([cnn_articles, cnn_summaries], [dailymail_articles, dailymail_summaries], TRAIN_SIZE, VAL_SIZE, TEST_SIZE)","metadata":{"id":"GTnXBwd6Sa-U","execution":{"iopub.status.busy":"2023-08-22T08:32:18.062788Z","iopub.execute_input":"2023-08-22T08:32:18.063801Z","iopub.status.idle":"2023-08-22T08:32:18.661902Z","shell.execute_reply.started":"2023-08-22T08:32:18.063750Z","shell.execute_reply":"2023-08-22T08:32:18.660680Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Type of the datasets: {type(train_dataset)}\\n\")\n\nprint(f\"Training dataset shape: {train_dataset.shape}\")\nprint(f\"Validation dataset shape: {val_dataset.shape}\")\nprint(f\"Testing dataset shape: {test_dataset.shape}\\n\")\n\nprint(f\"First example in the training dataset looks like: \\n {train_dataset[0]}\\n\")","metadata":{"id":"AyRVodwIhkuQ","outputId":"d0bfc21f-2835-45a6-de7e-07f430eabcd0","execution":{"iopub.status.busy":"2023-08-22T08:32:18.663311Z","iopub.execute_input":"2023-08-22T08:32:18.663668Z","iopub.status.idle":"2023-08-22T08:32:18.672841Z","shell.execute_reply.started":"2023-08-22T08:32:18.663639Z","shell.execute_reply":"2023-08-22T08:32:18.671730Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Type of the datasets: <class 'numpy.ndarray'>\n\nTraining dataset shape: (249668, 2)\nValidation dataset shape: (31208, 2)\nTesting dataset shape: (31209, 2)\n\nFirst example in the training dataset looks like: \n [\"danny welbeck's arsenal hat-trick was the story on everyone's lips on thursday morning, but the fa still think he is a manchester united player. roy hodgson's england squad for the euro 2016 qualifiers against san marino and estonia has been announced, but in a gaffe from the fa, the official squad sheet listed welbeck as a manchester united player, despite his move to the emirates. arsenal signed welbeck for £16million on deadline day in september, and scored his first career hat-trick for the gunners on wednesday night. at the bottom of the fa's england squad sheet, 'daniel welbeck' is listed as a manchester united player. welbeck scored his first career hat-trick on wednesday in the red and white of arsenal, at the emirates. until his move to north london, welbeck had spent the whole of his professional contract at united, bar loan moves to preston and sunderland. he made his debut for the old trafford outfit in 2008, but after six years and 92 appearances, called a halt to his united career and moved to arsenal. welbeck was picked alongside wayne rooney and rickie lambert to lead the line for his country, but the striker's time at united still appears to live long in the memory of someone at the fa. goalkeepers. fraser forster (southampton), ben foster (west brom), joe hart (manchester city) defenders. leighton baines (everton), gary cahill (chelsea), nathaniel clyne (southampton), kieran gibbs (arsenal), phil jagielka (everton), john stones (everton) midfielders. fabian delph (aston villa), jordan henderson (liverpool), adam lallana (liverpool), james milner (manchester city), alex oxlade-chamberlain (arsenal), jonjo shelvey (swansea), raheem sterling (liverpool), andros townsend (tottenham), jack wilshere (arsenal) strikers. rickie lambert (liverpool), wayne rooney (manchester united), danny welbeck (arsenal). welbeck spent six years in the first team at united, pictured (second right) after scoring against arsenal. danny welbeck (right) celebrates his second goal on wednesday, with team-mate calum chambers.\"\n 'arsenal signed danny welbeck from man unitedon deadline day. welbeck cost the gunners £16million. the fa referred to welbeck as a man utd player in their official team-sheet released to the press.']\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Start Tokenizing","metadata":{"id":"dGP0eDXMEhdF"}},{"cell_type":"markdown","source":"Before the tokenization, we need to preprocess the text data so that it can be properly tokenized. In this step we need to choose whether we want to keep punctuations or not, whether we should keep the numbers or not and so on. There are 2 functions I will create, one for simple `standardize` and other to feed the Tokenizer class when creating the `tokenizer`. `standardize` function implements the following steps -\n\n1. Lower case the strings passed to it. It is already done but for user data it might not be the case so, we will still perform this step.\n2. Replace the single and double opening and closing quotes like `‘ → \\u2018`, `’ → \\u2019`, `“ → \\u201c` and `” → \\u201d` by `'` and `\"` respectively.\n3. Replace the punctutations ``['.', '?', '!', ',', ':', '-', ''', '\"', '_', '(', ')', '{', '}', '[', ']', '`', ';', '...']`` by `[SPACE]punctutations`.\nIn this process we need to make sure that the floating point numbers like `1.78` do not become `1 .78`. To do that the correct regex expression is ``(?<!\\d)\\s*([!\"#$£%&\\'\\(\\)*+,-./:;<=>?@\\[\\]\\\\^_`{|}~])\\s*(?!\\d)``.\n4. Strip the texts from extra starting or ending spaces. Finally, remove extra spaces using regex expression like `\\s{2,}`.\n\n`custom_analyzer` function which will be feed to the Tokenizer as the value for `analyzer`, has some more steps to implement -\n1. Remove the `START_TOKEN` and `END_TOKEN` from the text. So that tokenizer does not standardize them.\n2. Standardize the text with `standardizer`.\n3. Add back the `START_TOKEN` and `END_TOKEN` because you want your tokenizer to learn them.\n4. Remove unwanted spaces in between words.\n5. Split the text into words which are seperated by ' '.\n6. Strip each of the words in the sentence. Finally, return it.","metadata":{"id":"TcZCpJ9hCyqf"}},{"cell_type":"code","source":"# Standardize the text data\ndef standardizer(text):\n    '''Standardize the text provided to the function\n    The text is lower cased. Then, the opening and closing quotes are removed. I add spaces before the\n    punctuations like `don't` becomes `don ' t`, ignoring the numerical values so that `1.78` does not become\n    `1 . 78`. Finally, it strips the text and removes any type of unwanted spaces in it.\n\n    Argument:\n    text: str, the text to standardize\n\n    Returns:\n    returns the standadized text\n    '''\n\n    # Lower case the text\n    text = text.lower()\n\n    # Replace the special single and double opening and closing quotes\n    text = re.sub(r'[\\u2019\\u2018]', \"'\", text)\n    text = re.sub(r'[\\u201c\\u201d]', '\"', text)\n\n    # Add space before punctuations and ignore floating point numbers.\n    text = re.sub(r'(?<!\\d)\\s*([!\"#$£%&\\'\\(\\)*+,-./:;<=>?@\\[\\]\\\\^_`{|}~])\\s*(?!\\d)',\n                  r' \\1 ', text)  # It used to also remove commas after numbers like '27,' will be removed\n\n    # Remove spaces after sentence end and other unwanted spaces from text\n    text = text.strip()\n    text = re.sub('\\s{2,}', ' ', text)\n\n    return text\n\n# custom analyzer for the Tokenizer class\ndef custom_analyzer(text):\n    '''Custom analyzer to provide to the `Tokenizer` class when creating the tokenizer.\n\n    Argument:\n    text: str, the text that will be tokenized\n\n    Returns:\n    returns the splitted sentence\n    '''\n    # Remove START and END before standardizing\n    if START_TOKEN in text:\n        text = re.sub(f'{START_TOKEN} ', '', text)\n    if END_TOKEN in text:\n        text = re.sub(f'{END_TOKEN} ', '', text)\n\n    # Standardize the text first\n    text = standardizer(text)\n\n    # Add back the START and END tokens\n    text = ' '.join([START_TOKEN, text, END_TOKEN])\n\n    # Split the sentence into words to tokenize\n    words = text.split(' ')\n    words = [word.strip() for word in words]\n\n    return words","metadata":{"id":"FD2h0OiAxJP_","execution":{"iopub.status.busy":"2023-08-22T08:32:18.674146Z","iopub.execute_input":"2023-08-22T08:32:18.674476Z","iopub.status.idle":"2023-08-22T08:32:18.686914Z","shell.execute_reply.started":"2023-08-22T08:32:18.674449Z","shell.execute_reply":"2023-08-22T08:32:18.685926Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"sample_texts = [\"I have been working on, \\nbut \\tnever did it in this way.\",\n                \"U.S won the world cup and bagged 1.78 million dollars.\",\n                \"India had M.S. Dhoni won made it this far.\",\n                \"My email address is arupjana7365@gmail.com.\",\n                \"It can take care of dailymail single opening quote’ also.\",\n                \"I have 10,000 Rs in my bank\",\n                \"This sentence has , after a number 12,\",\n                \"This sentence contains <START> token and <END> token.\"]\n\nprint(f\"After Standardizing the sample texts:\\n{[standardizer(text) for text in sample_texts]}\\n\")\nprint(f\"After applying custom analyzer on sample texts:\\n{[custom_analyzer(text) for text in sample_texts]}\")","metadata":{"id":"AVi3kZhcLXS7","outputId":"432ed183-e302-49c9-a704-c6a4257854ad","execution":{"iopub.status.busy":"2023-08-22T08:32:18.688197Z","iopub.execute_input":"2023-08-22T08:32:18.688626Z","iopub.status.idle":"2023-08-22T08:32:18.706991Z","shell.execute_reply.started":"2023-08-22T08:32:18.688596Z","shell.execute_reply":"2023-08-22T08:32:18.705823Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"After Standardizing the sample texts:\n['i have been working on , but never did it in this way .', 'u . s won the world cup and bagged 1.78 million dollars .', 'india had m . s . dhoni won made it this far .', 'my email address is arupjana7365@gmail . com .', \"it can take care of dailymail single opening quote ' also .\", 'i have 10,000 rs in my bank', 'this sentence has , after a number 12,', 'this sentence contains < start > token and < end > token .']\n\nAfter applying custom analyzer on sample texts:\n[['<START>', 'i', 'have', 'been', 'working', 'on', ',', 'but', 'never', 'did', 'it', 'in', 'this', 'way', '.', '<END>'], ['<START>', 'u', '.', 's', 'won', 'the', 'world', 'cup', 'and', 'bagged', '1.78', 'million', 'dollars', '.', '<END>'], ['<START>', 'india', 'had', 'm', '.', 's', '.', 'dhoni', 'won', 'made', 'it', 'this', 'far', '.', '<END>'], ['<START>', 'my', 'email', 'address', 'is', 'arupjana7365@gmail', '.', 'com', '.', '<END>'], ['<START>', 'it', 'can', 'take', 'care', 'of', 'dailymail', 'single', 'opening', 'quote', \"'\", 'also', '.', '<END>'], ['<START>', 'i', 'have', '10,000', 'rs', 'in', 'my', 'bank', '<END>'], ['<START>', 'this', 'sentence', 'has', ',', 'after', 'a', 'number', '12,', '<END>'], ['<START>', 'this', 'sentence', 'contains', 'token', 'and', 'token', '.', '<END>']]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now, I need to find the tokens from the articles. I need to use only training articles not any other and also I will not use summaries data because that will be my target and I won't know what type of words I will encounter when summarizing the source article. So, the only words that I know will be from the articles of training dataset. Here, I am going to use the `tensorflow.keras.preprocessing.text.Tokenizer` in short `Tokenizer` to find the tokens from the articles and then finally converting the articles into sequence of integers. One thing to remember is here we are going to use `oov_token` arguement of `Tokenizer` to mention the token we want to use for out-of-vocabulary words.\n\nWhen fiting the texts on `tokenizer` make sure to remove floating point and integer numbers using the regex expression - `[+-]?[0-9]*[.]?[0-9]+`. I am making sure that tokenizer does learn the numbers because it can always be taken from the original articles data and we do not to remember them in vocab.","metadata":{"id":"IiiWRFR64jTP"}},{"cell_type":"code","source":"def get_tokenizer(texts, num_words, oov_token=None, filters = '#*+/:<=>@[\\\\]/^{|}~\\t\\n'):\n    '''This will create the tokenizer needed for the task in hand.\n    The tokenizer will be trained on the `texts`. Tokenizer will have vocabulary length `num_words`.\n    The `oov_token` will be used as the token represent the out-of-vocabulary words. The `filters` are\n    the ones which the tokenizer will remove when tokenizing any sentence given to it. The returned\n    tokenizer is using a custom analyzer that can standardize the sentence before tokenizing using the\n    `standardizer` function and then splits the sentence into words. After that it tokenizes the sentence.\n    As for the vocabulary, the returned tokenizer's vocabulary does not contain any number, as I have removed\n    them before feeding them into `Tokenizer.fit_on_texts` method.\n\n    Arguments:\n    texts: list of strings, the tokenizer will be trained on this strings\n    num_words: int, number of vocabulary words the tokenizer will consider\n    oov_token: str, token to represent out-of-vocabulary words\n    filters: str, all the characters that the tokenizer will remove before tokenizing\n\n    Returns:\n    tokenzier of the `Tokenizer` class after learning vocabulary from `texts`\n    '''\n\n    # Create the tokenizer usinf Tokenizer class\n    tokenizer = Tokenizer(num_words=num_words,\n                        filters=filters,\n                        oov_token=oov_token,\n                        analyzer=custom_analyzer)\n\n    # Remove the numbers from the dataset so that tokenizer does not add them inside vocabulary\n    texts = [re.sub(r\"[+-]?[0-9]*[.]?[0-9]+\", \"\", text) for text in texts]\n\n    # Fit the data with fit_on_texts method\n    tokenizer.fit_on_texts(texts)\n\n    return tokenizer","metadata":{"id":"tR1FD3SESd0G","execution":{"iopub.status.busy":"2023-08-22T08:32:18.708026Z","iopub.execute_input":"2023-08-22T08:32:18.708358Z","iopub.status.idle":"2023-08-22T08:32:18.726943Z","shell.execute_reply.started":"2023-08-22T08:32:18.708331Z","shell.execute_reply":"2023-08-22T08:32:18.725902Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Length the articles dataset: {len(list(train_dataset[:, 0]))}\")","metadata":{"id":"UsmErFoxqimM","outputId":"1625c203-569e-4a43-f69e-2da2f4d215ba","execution":{"iopub.status.busy":"2023-08-22T08:32:18.732272Z","iopub.execute_input":"2023-08-22T08:32:18.733184Z","iopub.status.idle":"2023-08-22T08:32:18.790902Z","shell.execute_reply.started":"2023-08-22T08:32:18.733140Z","shell.execute_reply":"2023-08-22T08:32:18.789755Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Length the articles dataset: 249668\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Create the `tokenizer` using the articles from training dataset by using `train_dataset[:, 0]`, with a vocabulary size of `VOCAB_SIZE` and use `OOV_TOKEN` token to represent out-of-vocabulary words.","metadata":{"id":"6KBXcUV2pYrm"}},{"cell_type":"code","source":"tokenizer = get_tokenizer(list(train_dataset[:, 0]), VOCAB_SIZE, OOV_TOKEN)","metadata":{"id":"151rEpqo7Pof","execution":{"iopub.status.busy":"2023-08-22T08:32:18.791972Z","iopub.execute_input":"2023-08-22T08:32:18.792404Z","iopub.status.idle":"2023-08-22T08:39:21.133508Z","shell.execute_reply.started":"2023-08-22T08:32:18.792373Z","shell.execute_reply":"2023-08-22T08:39:21.132340Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"print(f\"The vocabulary for the tokenizer has a length {len(tokenizer.word_index.keys())}\\n\\n\")\n\n\nprint(f\"{OOV_TOKEN} word has index: {tokenizer.word_index[OOV_TOKEN]}\")\nprint(f\"{START_TOKEN} word has index: {tokenizer.word_index[START_TOKEN]}\")\nprint(f\"{END_TOKEN} word has index: {tokenizer.word_index[END_TOKEN]}\\n\\n\")\n\n\nprint(f\"'teacher' word has index: {tokenizer.word_index['teacher']}\\n\")\n\nprint(f\"Text:\\n{train_dataset[0, 0]}\\n\\n\")\nsample_sequence = tokenizer.texts_to_sequences([train_dataset[0, 0]])\nprint(f\"Text to Sequence of the first article:\\n{sample_sequence}\\n\")\nprint(f\"Sequence to Text of the first acrticle:\\n{tokenizer.sequences_to_texts(sample_sequence)}\")","metadata":{"id":"YUNreIjr8Kng","outputId":"ccabd900-e673-452c-fed3-5ce16481d655","execution":{"iopub.status.busy":"2023-08-22T08:39:21.135171Z","iopub.execute_input":"2023-08-22T08:39:21.135610Z","iopub.status.idle":"2023-08-22T08:39:21.147424Z","shell.execute_reply.started":"2023-08-22T08:39:21.135572Z","shell.execute_reply":"2023-08-22T08:39:21.146283Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"The vocabulary for the tokenizer has a length 471347\n\n\n<OOV> word has index: 1\n<START> word has index: 76\n<END> word has index: 77\n\n\n'teacher' word has index: 1438\n\nText:\ndanny welbeck's arsenal hat-trick was the story on everyone's lips on thursday morning, but the fa still think he is a manchester united player. roy hodgson's england squad for the euro 2016 qualifiers against san marino and estonia has been announced, but in a gaffe from the fa, the official squad sheet listed welbeck as a manchester united player, despite his move to the emirates. arsenal signed welbeck for £16million on deadline day in september, and scored his first career hat-trick for the gunners on wednesday night. at the bottom of the fa's england squad sheet, 'daniel welbeck' is listed as a manchester united player. welbeck scored his first career hat-trick on wednesday in the red and white of arsenal, at the emirates. until his move to north london, welbeck had spent the whole of his professional contract at united, bar loan moves to preston and sunderland. he made his debut for the old trafford outfit in 2008, but after six years and 92 appearances, called a halt to his united career and moved to arsenal. welbeck was picked alongside wayne rooney and rickie lambert to lead the line for his country, but the striker's time at united still appears to live long in the memory of someone at the fa. goalkeepers. fraser forster (southampton), ben foster (west brom), joe hart (manchester city) defenders. leighton baines (everton), gary cahill (chelsea), nathaniel clyne (southampton), kieran gibbs (arsenal), phil jagielka (everton), john stones (everton) midfielders. fabian delph (aston villa), jordan henderson (liverpool), adam lallana (liverpool), james milner (manchester city), alex oxlade-chamberlain (arsenal), jonjo shelvey (swansea), raheem sterling (liverpool), andros townsend (tottenham), jack wilshere (arsenal) strikers. rickie lambert (liverpool), wayne rooney (manchester united), danny welbeck (arsenal). welbeck spent six years in the first team at united, pictured (second right) after scoring against arsenal. danny welbeck (right) celebrates his second goal on wednesday, with team-mate calum chambers.\n\n\nText to Sequence of the first article:\n[[76, 2945, 5479, 5, 12, 862, 2856, 11, 4100, 13, 3, 589, 16, 658, 5, 12, 5932, 16, 386, 409, 4, 34, 3, 1770, 153, 173, 19, 17, 7, 453, 179, 575, 2, 3151, 3455, 5, 12, 266, 1244, 15, 3, 2992, 1, 14183, 124, 1088, 12952, 8, 10577, 31, 46, 680, 4, 34, 10, 7, 14450, 30, 3, 1770, 4, 3, 486, 1244, 5331, 2598, 5479, 26, 7, 453, 179, 575, 4, 333, 24, 402, 6, 3, 4211, 2, 862, 1164, 5479, 15, 1, 16, 4885, 112, 10, 509, 4, 8, 1085, 24, 83, 707, 2856, 11, 4100, 15, 3, 5896, 16, 360, 194, 2, 25, 3, 1656, 9, 3, 1770, 5, 12, 266, 1244, 5331, 4, 5, 1630, 5479, 5, 17, 2598, 26, 7, 453, 179, 575, 2, 5479, 1085, 24, 83, 707, 2856, 11, 4100, 16, 360, 10, 3, 542, 8, 306, 9, 862, 4, 25, 3, 4211, 2, 274, 24, 402, 6, 282, 213, 4, 5479, 41, 561, 3, 843, 9, 24, 1495, 1460, 25, 179, 4, 1434, 1875, 2998, 6, 5946, 8, 2833, 2, 19, 118, 24, 2447, 15, 3, 94, 2976, 3935, 10, 1, 34, 44, 245, 87, 8, 1, 2791, 4, 191, 7, 5253, 6, 24, 179, 707, 8, 732, 6, 862, 2, 5479, 13, 1696, 1364, 2575, 2090, 8, 10029, 4812, 6, 598, 3, 512, 15, 24, 181, 4, 34, 3, 1166, 5, 12, 71, 25, 179, 153, 1104, 6, 418, 185, 10, 3, 2184, 9, 554, 25, 3, 1770, 2, 15514, 2, 7150, 12232, 50, 2094, 49, 4, 1805, 3384, 50, 295, 4651, 49, 4, 1662, 3397, 50, 453, 148, 49, 5594, 2, 10541, 10147, 50, 2145, 49, 4, 2219, 7212, 50, 638, 49, 4, 12901, 15700, 50, 2094, 49, 4, 7276, 7647, 50, 862, 49, 4, 2768, 13526, 50, 2145, 49, 4, 373, 4663, 50, 2145, 49, 12837, 2, 13058, 14821, 50, 3267, 1936, 49, 4, 2009, 4973, 50, 637, 49, 4, 2108, 8081, 50, 637, 49, 4, 590, 9120, 50, 453, 148, 49, 4, 1633, 9887, 11, 7615, 50, 862, 49, 4, 24304, 18496, 50, 2988, 49, 4, 6327, 2344, 50, 637, 49, 4, 18948, 8834, 50, 1913, 49, 4, 1709, 6424, 50, 862, 49, 8335, 2, 10029, 4812, 50, 637, 49, 4, 2575, 2090, 50, 453, 179, 49, 4, 2945, 5479, 50, 862, 49, 2, 5479, 561, 245, 87, 10, 3, 83, 162, 25, 179, 4, 192, 50, 207, 123, 49, 44, 1725, 124, 862, 2, 2945, 5479, 50, 123, 49, 2149, 24, 207, 558, 16, 360, 4, 21, 162, 11, 2579, 11573, 5164, 2, 77]]\n\nSequence to Text of the first acrticle:\n[\"<START> danny welbeck ' s arsenal hat - trick was the story on everyone ' s lips on thursday morning , but the fa still think he is a manchester united player . roy hodgson ' s england squad for the euro <OOV> qualifiers against san marino and estonia has been announced , but in a gaffe from the fa , the official squad sheet listed welbeck as a manchester united player , despite his move to the emirates . arsenal signed welbeck for <OOV> on deadline day in september , and scored his first career hat - trick for the gunners on wednesday night . at the bottom of the fa ' s england squad sheet , ' daniel welbeck ' is listed as a manchester united player . welbeck scored his first career hat - trick on wednesday in the red and white of arsenal , at the emirates . until his move to north london , welbeck had spent the whole of his professional contract at united , bar loan moves to preston and sunderland . he made his debut for the old trafford outfit in <OOV> but after six years and <OOV> appearances , called a halt to his united career and moved to arsenal . welbeck was picked alongside wayne rooney and rickie lambert to lead the line for his country , but the striker ' s time at united still appears to live long in the memory of someone at the fa . goalkeepers . fraser forster ( southampton ) , ben foster ( west brom ) , joe hart ( manchester city ) defenders . leighton baines ( everton ) , gary cahill ( chelsea ) , nathaniel clyne ( southampton ) , kieran gibbs ( arsenal ) , phil jagielka ( everton ) , john stones ( everton ) midfielders . fabian delph ( aston villa ) , jordan henderson ( liverpool ) , adam lallana ( liverpool ) , james milner ( manchester city ) , alex oxlade - chamberlain ( arsenal ) , jonjo shelvey ( swansea ) , raheem sterling ( liverpool ) , andros townsend ( tottenham ) , jack wilshere ( arsenal ) strikers . rickie lambert ( liverpool ) , wayne rooney ( manchester united ) , danny welbeck ( arsenal ) . welbeck spent six years in the first team at united , pictured ( second right ) after scoring against arsenal . danny welbeck ( right ) celebrates his second goal on wednesday , with team - mate calum chambers . <END>\"]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The oddness you might see if you are that much familiar with `Tokenizer` class is, even though I have specified that `num_words=VOCAB_SIZE` which is `20,000` still the length of the `word_index` is more that that. Does that mean we are doing something wrong?\nNO, here although tokenizer computes the word_index of all other words apart from those first 20000 words, it will not use them when we convert them into sequence. Let's look at one example to understand that.","metadata":{"id":"crn5t_zk6iBN"}},{"cell_type":"code","source":"list(tokenizer.word_index.keys())[21000]","metadata":{"id":"qhttL-heeP-P","outputId":"3561bbef-d7ac-4c1d-e55d-0c6ce951703b","execution":{"iopub.status.busy":"2023-08-22T08:39:21.149022Z","iopub.execute_input":"2023-08-22T08:39:21.149673Z","iopub.status.idle":"2023-08-22T08:39:21.192027Z","shell.execute_reply.started":"2023-08-22T08:39:21.149633Z","shell.execute_reply":"2023-08-22T08:39:21.191219Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'psycho'"},"metadata":{}}]},{"cell_type":"code","source":"oov_word = list(tokenizer.word_index.keys())[21000]\nsample_text = f\"This example is to test the above fact with the word `{oov_word}`\"\nsample_sequence = tokenizer.texts_to_sequences([sample_text])\n\nprint(f\"Text: {sample_text}\\n\\n\")\nprint(f\"Tokenized text: {tokenizer.sequences_to_texts(sample_sequence)}\")\nprint(f\"Sequence: {sample_sequence}\")","metadata":{"id":"S_Dnkcig7SIX","outputId":"663e3047-151e-47d0-d44a-0dc2988e5ca9","execution":{"iopub.status.busy":"2023-08-22T08:39:21.193361Z","iopub.execute_input":"2023-08-22T08:39:21.193713Z","iopub.status.idle":"2023-08-22T08:39:21.226231Z","shell.execute_reply.started":"2023-08-22T08:39:21.193686Z","shell.execute_reply":"2023-08-22T08:39:21.225154Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Text: This example is to test the above fact with the word `psycho`\n\n\nTokenized text: ['<START> this example is to test the above fact with the word ` psycho ` <END>']\nSequence: [[76, 39, 1204, 17, 6, 811, 3, 645, 599, 21, 3, 1401, 14697, 21001, 14697, 77]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Although the word was present in the `word_index` mapping still tokenizer represented it with `<OOV>`.","metadata":{"id":"xvNeazXb-Yq9"}},{"cell_type":"code","source":"sample_text = \"What happens when I add a number 2.1 in this sentence!\"\nsample_sequence = tokenizer.texts_to_sequences([sample_text])\n\nprint(f\"Text: {sample_text}\\n\\n\")\nprint(f\"Tokenized text: {tokenizer.sequences_to_texts(sample_sequence)}\")\nprint(f\"Sequence: {sample_sequence}\")","metadata":{"id":"ng5MZ_DZ84kk","outputId":"5006fd56-40c0-4876-d780-a341a68044ba","execution":{"iopub.status.busy":"2023-08-22T08:39:21.227557Z","iopub.execute_input":"2023-08-22T08:39:21.227866Z","iopub.status.idle":"2023-08-22T08:39:21.239979Z","shell.execute_reply.started":"2023-08-22T08:39:21.227831Z","shell.execute_reply":"2023-08-22T08:39:21.238942Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Text: What happens when I add a number 2.1 in this sentence!\n\n\nTokenized text: ['<START> what happens when i add a number <OOV> in this sentence ! <END>']\nSequence: [[76, 79, 2269, 53, 27, 1952, 7, 258, 1, 10, 39, 1016, 284, 77]]\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_text = \"What happens when I add parenthesis (I am inside it!).\"\nsample_sequence = tokenizer.texts_to_sequences([sample_text])\n\nprint(f\"Text: {sample_text}\\n\\n\")\nprint(f\"Tokenized text: {tokenizer.sequences_to_texts(sample_sequence)}\")\nprint(f\"Sequence: {sample_sequence}\")","metadata":{"id":"ImlMHniH-Jnt","outputId":"92b365af-3b23-4643-ad61-aa18e60daa47","execution":{"iopub.status.busy":"2023-08-22T08:39:21.241594Z","iopub.execute_input":"2023-08-22T08:39:21.242432Z","iopub.status.idle":"2023-08-22T08:39:21.253359Z","shell.execute_reply.started":"2023-08-22T08:39:21.242391Z","shell.execute_reply":"2023-08-22T08:39:21.252332Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Text: What happens when I add parenthesis (I am inside it!).\n\n\nTokenized text: ['<START> what happens when i add <OOV> ( i am inside it ! ) . <END>']\nSequence: [[76, 79, 2269, 53, 27, 1952, 1, 50, 27, 285, 496, 20, 284, 49, 2, 77]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Function to prepare the data for feeding to the model","metadata":{"id":"EpMm2cNIEm_L"}},{"cell_type":"markdown","source":"We have the `tokenizer` to tokenize the articles and summaries. We need to pad those sequences to fit the requirements.\n\nIn the paper, the articles are limited to have 400 tokens and summary has, 100 tokens at training and 120 tokens for testing.\n\nI will be using `pad_sequences` method to pad or truncate the articles and summaries based on their length.\n\nNOTE: I am using same tokenizer for article and summary. But, later I might change that to 2 different tokenizers each having different `num_words`.","metadata":{"id":"jza9oQYKXB0m"}},{"cell_type":"code","source":"def tokenize_pad(texts, tokenizer, padding, truncating, maxlen):\n    '''Tokenize the `texts` using the tokenizer. Then, pad the sequences or truncate the sequences\n    depending the length. If the length exceeds `maxlen` then it will be truncated and if not then it will be\n    padded. The padding and truncating can happend at the beginning or at the end of the sequence depending\n    on the value of `padding` and `truncating` respectively.\n\n    Arguments:\n    texts: list of strings, the sentences to tokenize and pad\n    tokenizer: Tokenizer class object, helps in tokenizing the `texts`\n    padding: str, can take 2 values `pre` or `post`. If `pre` then padding will happen at the beginning,\n    if `post` then padding will happen at the end.\n    truncating: str, can take 2 values `pre` or 'truncating`, works the same as `padding`\n    maxlen: int, maximum length after padding or truncating\n\n    Returns:\n    returns the tokenized and padded sentences\n    '''\n    sequences = tokenizer.texts_to_sequences(texts)\n\n    padded_sequences = pad_sequences(sequences, maxlen=maxlen, padding=padding, truncating=truncating)\n\n    return padded_sequences","metadata":{"id":"Alo70WYjW-tA","execution":{"iopub.status.busy":"2023-08-22T08:39:21.254699Z","iopub.execute_input":"2023-08-22T08:39:21.254984Z","iopub.status.idle":"2023-08-22T08:39:21.264746Z","shell.execute_reply.started":"2023-08-22T08:39:21.254961Z","shell.execute_reply":"2023-08-22T08:39:21.263980Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"sample_texts","metadata":{"id":"rttUwCiT4FzJ","outputId":"e0db10da-c722-4147-b6c0-3845d3103957","execution":{"iopub.status.busy":"2023-08-22T08:39:21.265836Z","iopub.execute_input":"2023-08-22T08:39:21.266297Z","iopub.status.idle":"2023-08-22T08:39:21.282680Z","shell.execute_reply.started":"2023-08-22T08:39:21.266269Z","shell.execute_reply":"2023-08-22T08:39:21.281969Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"['I have been working on, \\nbut \\tnever did it in this way.',\n 'U.S won the world cup and bagged 1.78 million dollars.',\n 'India had M.S. Dhoni won made it this far.',\n 'My email address is arupjana7365@gmail.com.',\n 'It can take care of dailymail single opening quote’ also.',\n 'I have 10,000 Rs in my bank',\n 'This sentence has , after a number 12,',\n 'This sentence contains <START> token and <END> token.']"},"metadata":{}}]},{"cell_type":"code","source":"tokenize_pad(sample_texts, tokenizer, padding=\"post\", truncating=\"post\", maxlen=20)","metadata":{"id":"QNuBKpTq4lZW","outputId":"0d73781e-8327-4369-c9a6-8918cd4f259f","execution":{"iopub.status.busy":"2023-08-22T08:39:21.283652Z","iopub.execute_input":"2023-08-22T08:39:21.284100Z","iopub.status.idle":"2023-08-22T08:39:21.297543Z","shell.execute_reply.started":"2023-08-22T08:39:21.284073Z","shell.execute_reply":"2023-08-22T08:39:21.296859Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"array([[   76,    27,    29,    46,   326,    16,     4,    34,   208,\n          147,    20,    10,    39,   144,     2,    77,     0,     0,\n            0,     0],\n       [   76,   139,     2,    12,   309,     3,   104,   338,     8,\n        16628,     1,   152,  2490,     2,    77,     0,     0,     0,\n            0,     0],\n       [   76,  1191,    41,   136,     2,    12,     2, 18582,   309,\n          118,    20,    39,   329,     2,    77,     0,     0,     0,\n            0,     0],\n       [   76,    86,  2148,  1361,    17,     1,     2,   747,     2,\n           77,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0],\n       [   76,    20,    67,   150,   388,     9, 14943,   864,  1070,\n         8677,     5,    65,     2,    77,     0,     0,     0,     0,\n            0,     0],\n       [   76,    27,    29,     1, 16976,    10,    86,   829,    77,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0],\n       [   76,    39,  1016,    31,     4,    44,     7,   258,     1,\n           77,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0],\n       [   76,    39,  1016,  3664, 17858,     8, 17858,     2,    77,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0]], dtype=int32)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Defining Model Architecture & Training","metadata":{"id":"Gt31OiYpEymZ"}},{"cell_type":"markdown","source":"After this, we need the model that we can train on this dataset. The model archietecture will be 3-\n1. Base-line model: Seq-Seq model with attention mechanism.\n2. Pointer Generetor model: With seq-seq attention model will be implementing the pointer generator that can either copy words from article or generate words from the pre-defined vocabulary.\n3. Coverage mechanism: Along with the pointer generator that will take case of the out-of-vocabulary words. Coverage mechanism will help prevent the repetition of the words in the summary.","metadata":{"id":"yM6KveyaUmfL"}},{"cell_type":"markdown","source":"### Base-Line Model: Seq-seq with Attention","metadata":{"id":"UarmKLUIVkjC"}},{"cell_type":"markdown","source":"#### Creating `tf_train_dataset`, `tf_val_dataset` using tf.data API\n\nNow, I need write the `generate_example` function that can help me generate model inputs for training, validation and testing set. For different type of dataset, we will create different generator with the help of the `example_generator` method to create `tf.data.Dataset` object for our model.\n\nWe can use `tf.data` API to create the input data pipeline for our model. I will use the `tf.data.Dataset` class to get the the examples from the `train_example_generator` function which uses `generate_example`, we can save the generator inside `example_gen` which we can iterate over later to get the examples. We can yield the examples according to the need of the problem.\n\nRemember, along with input article tokens and input summary tokens, we need the initial states as an input to the model. So, as we process the examples we can create this zero-value tensors and yield them along with 2 original inputs.\n\nFor more about datasets from generator, refer to [here](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator).","metadata":{"id":"usV8UchPA35e"}},{"cell_type":"markdown","source":"##### `generate_example_v1` function creation\nCreate a Geneator function that generates the source and target for training the model.","metadata":{"id":"ZUtzIfXm6UnX"}},{"cell_type":"code","source":"def generate_example_v1(inputs, targets, input_tokenizer, target_tokenizer, input_len, target_len):\n    '''Generates examples for the model. Processes the `inputs` and `targets` with their respective\n    tokenizers and tokenize them to `input_len` and `target_len` length.\n\n    Arguments:\n    inputs: list of input sentences\n    targets: list of target sentences\n    input_tokenizer: Tokenizer class object, tokenizer for inputs\n    target_tokenizer: Tokenizer class object, tokenizer for targets\n    input_len: int, the length of the tokenization for inputs\n    target_len: int, the length of the tokenization for targets\n\n    Returns:\n    returns 2 values, a tuple containing 2 numpy arrays (input_tokens, target_tokens[:-1]) and\n    another numpy array target_tokens[1:]\n    '''\n\n    for inp, tar in zip(inputs, targets):\n        # Tokenizing article words\n        inp_tokens = tokenize_pad([inp],\n                                  input_tokenizer,\n                                  padding=\"post\",\n                                  truncating=\"post\",\n                                  maxlen=input_len)\n\n        # Tokenizing summary words\n        tar_tokens = tokenize_pad([tar],\n                     target_tokenizer,\n                     padding=\"post\",\n                     truncating=\"post\",\n                     maxlen=target_len)\n\n        yield (inp_tokens[0], tar_tokens[0][:-1]), tar_tokens[0][1:]","metadata":{"id":"8647M-ey6n19","outputId":"0783fcd2-3e99-45dc-cff0-102a8f9572f5","execution":{"iopub.status.busy":"2023-08-18T09:37:27.402462Z","iopub.execute_input":"2023-08-18T09:37:27.403176Z","iopub.status.idle":"2023-08-18T09:37:27.416380Z","shell.execute_reply.started":"2023-08-18T09:37:27.403134Z","shell.execute_reply":"2023-08-18T09:37:27.415523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Example with the generator function","metadata":{"id":"-nytCw0dFO2Y"}},{"cell_type":"code","source":"print(f\"Example generated by the generator v1:\")\n\n# (inp_art_tokens, inp_sum_tokens), tar_sum_tokens = generate_example(list(train_dataset[:, 0]),\nexample_gen = generate_example_v1(list(train_dataset[:, 0]),\n                               list(train_dataset[:, 1]),\n                               input_tokenizer=tokenizer,\n                               target_tokenizer=tokenizer,\n                               input_len=MAX_ARTICLE_TOKENS,\n                               target_len=MAX_SUMMARY_TOKENS)\n\ninps, tar = next(example_gen)\nprint(f\"Inputs:\\n{inps[0]}\\n{inps[1]}\\n\\n\")\nprint(f\"Target:\\n{tar}\")","metadata":{"id":"BKKyIeVa5B20","outputId":"f424eca8-5f29-4dd0-915b-7f5e362399ec","execution":{"iopub.status.busy":"2023-08-18T09:37:27.417967Z","iopub.execute_input":"2023-08-18T09:37:27.418713Z","iopub.status.idle":"2023-08-18T09:37:27.503510Z","shell.execute_reply.started":"2023-08-18T09:37:27.418672Z","shell.execute_reply":"2023-08-18T09:37:27.502280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Shapes of the Inputs:\\n{inps[0].shape}\\n{inps[1].shape}\\n\\n\")\nprint(f\"Shape of the Target:\\n{tar.shape}\")","metadata":{"id":"E-w0hmecDcho","outputId":"dc67edf1-88c5-4f30-935e-e3ea04f8b0f2","execution":{"iopub.status.busy":"2023-08-18T09:37:27.505520Z","iopub.execute_input":"2023-08-18T09:37:27.506011Z","iopub.status.idle":"2023-08-18T09:37:27.514929Z","shell.execute_reply.started":"2023-08-18T09:37:27.505956Z","shell.execute_reply":"2023-08-18T09:37:27.513822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Data Type of the Inputs data:\\n{inps[0].dtype}\\n{inps[1].dtype}\\n\\n\")\nprint(f\"Data Type of the Target data:\\n{tar.dtype}\")","metadata":{"id":"suZmEEhfDvcu","outputId":"0e2da90a-79b0-4b89-a5da-5b28d899609c","execution":{"iopub.status.busy":"2023-08-18T09:37:27.516463Z","iopub.execute_input":"2023-08-18T09:37:27.516866Z","iopub.status.idle":"2023-08-18T09:37:27.533503Z","shell.execute_reply.started":"2023-08-18T09:37:27.516835Z","shell.execute_reply":"2023-08-18T09:37:27.532368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inps, tar = next(example_gen)\nprint(f\"Second Inputs:\\n{inps[0]}\\n{inps[1]}\\n\\n\")\nprint(f\"Second Target:\\n{tar}\")","metadata":{"id":"82m4io2PSyt3","outputId":"d95bc6aa-4364-4c1f-c3de-8b0a11ce5f25","execution":{"iopub.status.busy":"2023-08-18T09:37:27.534756Z","iopub.execute_input":"2023-08-18T09:37:27.535172Z","iopub.status.idle":"2023-08-18T09:37:27.553354Z","shell.execute_reply.started":"2023-08-18T09:37:27.535130Z","shell.execute_reply":"2023-08-18T09:37:27.552141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Making training, validation set examples for baseline model","metadata":{"id":"9m3U7a0pFULD"}},{"cell_type":"code","source":"def train_example_generetor_v1():\n    example_gen = generate_example_v1(list(train_dataset[:, 0]),\n                                list(train_dataset[:, 1]),\n                                input_tokenizer=tokenizer,\n                                target_tokenizer=tokenizer,\n                                input_len=MAX_ARTICLE_TOKENS,\n                                target_len=MAX_SUMMARY_TOKENS)\n\n    for example in example_gen:\n        s0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n        c0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n\n        (input_0, input_1), target = example\n        yield (input_0, input_1, s0, c0), target","metadata":{"id":"J_0r7ajRR8wk","outputId":"367e274d-63e4-4e55-ae53-a7a96011f899","execution":{"iopub.status.busy":"2023-08-18T09:37:27.554682Z","iopub.execute_input":"2023-08-18T09:37:27.555213Z","iopub.status.idle":"2023-08-18T09:37:27.594413Z","shell.execute_reply.started":"2023-08-18T09:37:27.555181Z","shell.execute_reply":"2023-08-18T09:37:27.593373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_signature = (\n    (tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, ), dtype=tf.int32),\n     tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32),\n     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32),\n     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32)),\n    tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32)\n)\n\ntf_train_dataset = tf.data.Dataset.from_generator(generator=train_example_generetor_v1,\n                                                  output_signature=output_signature)\ntf_train_dataset = tf_train_dataset.shuffle(BUFFER_SIZE)\ntf_train_dataset = tf_train_dataset.batch(BATCH_SIZE, drop_remainder=True)\ntf_train_dataset = tf_train_dataset.prefetch(1)","metadata":{"id":"Zj-H_fEh5Zu9","outputId":"524e02fb-448c-4b19-b09f-4d81b72f57a2","execution":{"iopub.status.busy":"2023-08-18T09:37:27.596828Z","iopub.execute_input":"2023-08-18T09:37:27.597340Z","iopub.status.idle":"2023-08-18T09:37:27.852509Z","shell.execute_reply.started":"2023-08-18T09:37:27.597257Z","shell.execute_reply":"2023-08-18T09:37:27.851314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_example_generetor_v1():\n    example_gen = generate_example_v1(list(val_dataset[:, 0]),\n                                list(val_dataset[:, 1]),\n                                input_tokenizer=tokenizer,\n                                target_tokenizer=tokenizer,\n                                input_len=MAX_ARTICLE_TOKENS,\n                                target_len=MAX_SUMMARY_TOKENS)\n\n    for example in example_gen:\n        s0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n        c0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n\n        (input_0, input_1), target = example\n        yield (input_0, input_1, s0, c0), target\n\n\noutput_signature = (\n    (tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, ), dtype=tf.int32),\n     tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32),\n     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32),\n     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32)),\n    tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32)\n)\n\ntf_val_dataset = tf.data.Dataset.from_generator(generator=val_example_generetor_v1,\n                                                  output_signature=output_signature)\ntf_val_dataset = tf_val_dataset.shuffle(BUFFER_SIZE)\ntf_val_dataset = tf_val_dataset.batch(BATCH_SIZE, drop_remainder=True)","metadata":{"id":"-2qJcIbjRZXd","outputId":"89e83c15-798b-4136-818d-bac52016ad60","execution":{"iopub.status.busy":"2023-08-18T09:37:27.853893Z","iopub.execute_input":"2023-08-18T09:37:27.854245Z","iopub.status.idle":"2023-08-18T09:37:27.900216Z","shell.execute_reply.started":"2023-08-18T09:37:27.854200Z","shell.execute_reply":"2023-08-18T09:37:27.899290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (art_inp, sum_inp, s0, c0), sum_tar in tf_train_dataset.take(1):\n    print(f\"Input tokenized article shape: {art_inp.shape}\")\n    print(f\"Input tokenized summary shape: {sum_inp.shape}\\n\")\n\n    print(f\"Target tokenized summary shape: {sum_tar.shape}\")","metadata":{"id":"no4oMl22Fm6r","outputId":"d3c68da1-cb08-4c1b-8e09-b769ccfcbb97","execution":{"iopub.status.busy":"2023-08-18T09:37:27.901579Z","iopub.execute_input":"2023-08-18T09:37:27.902108Z","iopub.status.idle":"2023-08-18T09:37:42.549532Z","shell.execute_reply.started":"2023-08-18T09:37:27.902077Z","shell.execute_reply":"2023-08-18T09:37:42.548337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A small demonstration of how Dot layer works","metadata":{"id":"-2S_Jxhf25-g"}},{"cell_type":"markdown","source":"#### Attention Mechanism","metadata":{"id":"BVsZ_DeVmaie"}},{"cell_type":"code","source":"def one_time_attention_v1(a, s_prev,\n                       repeater, concatenator, densor_1, densor_2, softmax_layer, dotter):\n    '''Calculates the attention score and returns the context for the current timestep in the decoder.\n    Attention mechanism uses encoder outputs `a` of shape `(batch, timesteps, features)` and decoder\n    previous hidden state `s_prev` of shape `(batch, features)`, then calculates alignment scores `alphas`\n    for each encoder timestep with the help of energies computed with 2 dense layers using `a` and `s_prev`.\n\n    Arguments:\n    a: tf.Tensor object, encoder output of shape `(batch, timesteps, features)` or `(batch, Tx, 2*n_a)`\n    s_prev: tf.Tensor object, decoder previous hidden state of shape `(batch, features)` or `(batch, n_s)`\n    repeater: RepeatVector layer, repeat the `s_prev` `Tx` times\n    concatenator: Concatenate layer, concatenates `a` and repeated `s_prev`, Concatenates along axis=-1\n    densor_1: Dense layer, calculates the pertial energies `e`, with `units=d1_units`\n    refer to `baseline_model` function for details about this variable\n    densor_2: Dense layer, calculated the energies `energies`, with `units=d2_units`\n    refer to `baseline_model` function for details about this variable\n    softmax_layer: Activation layer, computes softmax of the energies and calculates `alphas`, with\n    `units=article_vocab_size` refer to `baseline_model` function for details about this variable\n    dotter: Dot layer, Performs dot operation between `alphas` and `a` along axis=1\n\n    Returns:\n    returns the context of shape `(batch, features)`\n    '''\n\n    # Repeat the `s_prev` `Tx` times\n    s_prev = repeater(s_prev) # (batch, Tx, n_s)\n\n    # Concatenate `a` and `s_prev` along axis=-1\n    concat = concatenator([a, s_prev]) # (batch, Tx, n_a + n_s)\n\n    # Apply dense layer to get partial energies e\n    e = densor_1(concat) # (batch, Tx, d1_units)\n\n    # Apply dense layer again to get energies\n    energies = densor_2(e) # (batch, Tx, d2_units)\n\n    # Apply softmax over the energies\n    alphas = softmax_layer(energies) # (batch, Tx, d2_units)\n\n    # Dot the alphas and a along axes=1\n    context = dotter([alphas, a]) # (batch, d2_units, 2*n_a)\n\n    return context","metadata":{"id":"B_rPlnWardTC","outputId":"2b856755-06a5-47b7-90fb-30f2001b4690","execution":{"iopub.status.busy":"2023-08-18T09:37:42.551580Z","iopub.execute_input":"2023-08-18T09:37:42.552201Z","iopub.status.idle":"2023-08-18T09:37:42.563684Z","shell.execute_reply.started":"2023-08-18T09:37:42.552150Z","shell.execute_reply":"2023-08-18T09:37:42.562411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Encoder-decoder Model using Attention mechanism","metadata":{"id":"QxkE_-Ifn2k3"}},{"cell_type":"code","source":"def baseline_model(Tx, Ty,\n                   emb_dim, n_a, n_s, d1_units, d2_units, d_units,\n                   article_vocab_size, summary_vocab_size):\n    '''This implements the bas-line model archietecture for summarization.\n    It is a seq-seq model with attention mechanism implemented in it. The encoder take an input\n    with `Tx` time-steps and summarizes with the help of decoder into Ty words. The encoder and decoder\n    hidden states are `n_a` and `n_s` dimension respectively. The words are taken from the vocabulary of\n    article and summary `article_vocab` and `summary_vocab` with size `article_vocab_size` and\n    `summary_vocab_size` respectively.\n\n    Arguments:\n    Tx: int, length of the input article\n    Ty: int, length of the output summary\n    n_a: int, dimension of the encoder hidden states\n    n_s: int, dimension of the deocder hidden states\n    d1_units: int, units for the first dense layer in attention mechanism\n    d2_units: int, units for the second dense layer in attention mechanism\n    d_units: int, units for the dense layer before output layer\n    article_vocab_size: int, length of the article vocabulary\n    summary_vocab_size: int, length of the summary vocabulary\n\n    Returns:\n    returns the base line model\n    '''\n    # Defining the input for our model with shape (None, Tx) and (None, Ty) for encoder input and decoder input\n    X_inp = Input(shape=(Tx))\n    X_tar = Input(shape=(Ty))\n\n    # Initialize s0\n    s0 = Input(shape=(n_s, ), name=\"s0\")\n    # Initialize c0\n    c0 = Input(shape=(n_s, ), name=\"c0\")\n\n    # Initialize the a and s with a0 and s0\n    s = s0 # (batch, n_s)\n    c = c0 # (batch, n_s)\n\n    # Define the outputs as empty list\n    outputs = []\n\n    # First embedding layer for the article input\n    encoder_inp = Embedding(article_vocab_size, emb_dim)(X_inp) # (batch, Tx, emb_dim)\n\n    # Encoder: Bidirectional layer with LSTM cells\n    a = Bidirectional(LSTM(units=n_a, return_sequences=True))(encoder_inp) # (batch, Tx, n_a)\n\n    # Define the embedding for decoder\n    decoder_inp = Embedding(summary_vocab_size, emb_dim)(X_tar) # (batch, Ty, emb_dim)\n\n    # Define the layers for Attention so that we can use the same weights for all decoder timesteps\n    repeater = RepeatVector(Tx)\n    concatenator = Concatenate(axis=-1)\n    attn_densor1 = Dense(units=d1_units, activation='tanh')\n    attn_densor2 = Dense(units=d2_units, activation='linear', use_bias=False)\n    softmax_layer = Activation('softmax', name=\"attention_weights\")\n    dotter = Dot(axes=1)\n\n    # Define the Decoder unidirectional LSTM for shared weights\n    post_attention_lstm = LSTM(units=n_s, return_state=True)\n\n    # Define the last dense layer before output layer with linear activation\n    densor = Dense(units=d_units, activation='linear')\n\n    # Define the output layer so that it does not initalize again and again for shared weights\n    output_layer = Dense(units=summary_vocab_size, activation='softmax')\n\n    # Decoder: Appends outputs from the output layer in each timestep\n    for t in range(Ty):\n        # Get the decoder input for current timestep\n        curr_dec_in = decoder_inp[:, t:t+1, :] # (batch, 1, emb_dim)\n\n        # Get the context from the attention mechanism\n        context = one_time_attention_v1(a, s, # (batch, d2_units, 2*n_a)\n                                     repeater, concatenator, attn_densor1, attn_densor2, softmax_layer, dotter)\n\n        concat = Concatenate(axis=-1)([curr_dec_in, context]) # (batch, d2_units, emb_dim+2*n_a); d2_units=1 otherwise error\n        _, s, c = post_attention_lstm(concat, initial_state=[s, c]) # _, (batch, n_s), (batch, n_s)\n\n        # Calculate the output after using 2 linear dense layers\n        out = densor(s) # (batch, d_units)\n        out = densor(out) # (batch, d_units)\n        # Use the output_layer to get the output\n        out  = output_layer(out) # (batch, summary_vocab_size)\n\n        # Append the final output to the outputs list\n        outputs.append(out)\n\n    # Stack the list of each timesteps output along axis=1\n    outputs = tf.stack(outputs, axis=1) # (batch, Ty, summary_vocab_size)\n\n    model = Model(inputs=[X_inp, X_tar, s0, c0], outputs=outputs)\n\n    return model","metadata":{"id":"mudpzB78HDvZ","outputId":"2fb0d213-077a-45c1-ada0-1648edd12e2d","execution":{"iopub.status.busy":"2023-08-18T09:37:42.566015Z","iopub.execute_input":"2023-08-18T09:37:42.566586Z","iopub.status.idle":"2023-08-18T09:37:42.587713Z","shell.execute_reply.started":"2023-08-18T09:37:42.566522Z","shell.execute_reply":"2023-08-18T09:37:42.586653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reset states generated by Keras\ntf.keras.backend.clear_session()","metadata":{"id":"APJAr_NwcRRj","outputId":"d41ea3e1-367f-462a-f038-33ffdb99bc6b","execution":{"iopub.status.busy":"2023-08-18T09:37:42.589594Z","iopub.execute_input":"2023-08-18T09:37:42.593710Z","iopub.status.idle":"2023-08-18T09:37:42.611377Z","shell.execute_reply.started":"2023-08-18T09:37:42.593669Z","shell.execute_reply":"2023-08-18T09:37:42.610214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Baseline Model Creation and Training","metadata":{"id":"moztj-HfDOls"}},{"cell_type":"code","source":"Tx = MAX_ARTICLE_TOKENS\nTy = MAX_SUMMARY_TOKENS - 1\nemb_dim = EMB_OUT\nn_a = ENCODER_STATE_DIM\nn_s= DECODER_STATE_DIM\nd1_units = DENSE1_UNITS\nd2_units = DENSE2_UNITS\nd_units = DENSE_UNITS\narticle_vocab_size = VOCAB_SIZE\nsummary_vocab_size = VOCAB_SIZE\n\nbase_model = baseline_model(Tx, Ty,\n                       emb_dim, n_a, n_s, d1_units, d2_units, d_units,\n                       article_vocab_size, summary_vocab_size)","metadata":{"id":"V3ZAtG5I8mZN","execution":{"iopub.status.busy":"2023-08-18T09:37:42.613434Z","iopub.execute_input":"2023-08-18T09:37:42.613848Z","iopub.status.idle":"2023-08-18T09:38:21.062046Z","shell.execute_reply.started":"2023-08-18T09:37:42.613815Z","shell.execute_reply":"2023-08-18T09:38:21.060982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Model has {base_model.count_params():,} parameters.\")","metadata":{"id":"2eMakRHeZzrF","outputId":"08d0700c-d496-412d-fff3-456f4d3e5dd0","execution":{"iopub.status.busy":"2023-08-18T09:38:21.063696Z","iopub.execute_input":"2023-08-18T09:38:21.064011Z","iopub.status.idle":"2023-08-18T09:38:21.075495Z","shell.execute_reply.started":"2023-08-18T09:38:21.063984Z","shell.execute_reply":"2023-08-18T09:38:21.074409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A look into how model will output on the above input.","metadata":{"id":"sN_nIO_-LdDp"}},{"cell_type":"code","source":"sample_model_out = base_model((art_inp, sum_inp, s0, c0))\n\nprint(f\"Model output has a type: {type(sample_model_out)}\")\nprint(f\"Model Output list for the Inputs above are of length: {len(sample_model_out)}\")\nprint(f\"Model Output list has each output of shape: {sample_model_out[0].shape}\")","metadata":{"id":"xzqmZfKoLcfJ","outputId":"32287225-4fc5-4b3a-dc15-8b2c005978ab","execution":{"iopub.status.busy":"2023-08-18T09:38:21.077324Z","iopub.execute_input":"2023-08-18T09:38:21.078230Z","iopub.status.idle":"2023-08-18T09:38:30.152565Z","shell.execute_reply.started":"2023-08-18T09:38:21.078190Z","shell.execute_reply":"2023-08-18T09:38:30.151416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Creating Custom Loss and Accuracy Version 1","metadata":{"id":"C62CukniFhmx"}},{"cell_type":"code","source":"def custom_loss_v1(y_true, y_pred):\n    '''Calculates the loss for the baseline model. The loss is calculated by taking the negative\n    log-likelihood of the target word(w*_t) in the current timestep. Then the overall loss\n    is the summation over all timesteps divided by T (not Ty because it would include paddings also).\n\n    Arguments:\n    y_true: tf.Tensor object, true values for the target\n    y_pred: list of tf.Tensor objects, predicted probablities of the summary words\n\n    Returns:\n    returns the loss on the predicted values for the model\n    '''\n    # Calculate the loss for each item in the batch.\n    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n    loss = loss_fn(y_true, y_pred)\n\n    # Remove the paddings from calculation of loss\n    mask = tf.cast(y_true != 0, loss.dtype)\n    loss *= mask\n\n    # Divide the total loss after masking out paddings divided by total words which are not paddings\n    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n\n\ndef custom_accuracy_v1(y_true, y_pred):\n    '''Calculates accuracy of the baseline model. The accuracy is calculated by matching how many correct\n    words were predicted excluding the paddings. Then, just add those which are correct and you will get the\n    the accuracy and then just divide it by total words not including padding.\n\n    Arguments:\n    y_true: tf.Tensor object, expected target values\n    y_pred: list of tf.Tensor object, predicted target values by model\n\n    Returns:\n    returns the total accuracy over the batch of data\n    '''\n    # Find the word index with maximum probablity\n    y_pred = tf.argmax(y_pred, axis=-1)\n    y_pred = tf.cast(y_pred, y_true.dtype)\n\n    # Count the words that matches with true values\n    match = tf.cast(y_pred == y_true, tf.float32)\n    mask = tf.cast(y_true != 0, tf.float32)\n\n    # Mask out the paddings\n    match *= mask\n\n    return tf.reduce_sum(match) / tf.reduce_sum(mask)","metadata":{"id":"dw-z3KccJdpj","outputId":"194cd324-9fd0-44e9-8aa1-e8a4f3b73e50","execution":{"iopub.status.busy":"2023-08-18T09:38:30.154136Z","iopub.execute_input":"2023-08-18T09:38:30.154484Z","iopub.status.idle":"2023-08-18T09:38:30.166453Z","shell.execute_reply.started":"2023-08-18T09:38:30.154453Z","shell.execute_reply":"2023-08-18T09:38:30.165507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Testing with loss and accuracy","metadata":{"id":"BR02DedPFrDk"}},{"cell_type":"code","source":"print(f\"Sample y true values: {sum_tar}\")\nprint(f\"Sample y pred values(first 10 values of first 2 timestep): {sample_model_out[:2]}\")\n\nsample_loss = custom_loss_v1(sum_tar, sample_model_out)\nprint(f\"Loss of the sample y_true and y_pred: {sample_loss}\")\n\nsample_acc = custom_accuracy_v1(sum_tar, sample_model_out)\nprint(f\"Accuracy of the sample y_true and y_pred: {sample_acc}\")","metadata":{"id":"SR25pZHrACmA","outputId":"ee0770bc-19c8-4c74-d6cd-be5a51114c64","execution":{"iopub.status.busy":"2023-08-18T09:38:30.168206Z","iopub.execute_input":"2023-08-18T09:38:30.168801Z","iopub.status.idle":"2023-08-18T09:38:31.464456Z","shell.execute_reply.started":"2023-08-18T09:38:30.168667Z","shell.execute_reply":"2023-08-18T09:38:31.463372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Compiling base line model","metadata":{"id":"cs0e3XjqFwdR"}},{"cell_type":"code","source":"lr = LEARNING_RATE\ninitial_accumulator_value = INIT_ACC_VAL\nclipnorm = MAX_GRAD_NORM\n\nopt = Adagrad(learning_rate=lr,\n              initial_accumulator_value=initial_accumulator_value,\n              clipnorm=clipnorm)\n\nbase_model.compile(loss=custom_loss_v1, optimizer=opt, metrics=[custom_loss_v1, custom_accuracy_v1])","metadata":{"id":"bOTfC4BNnFgj","outputId":"48f21c46-7ca9-461a-c987-c53e1689dae8","execution":{"iopub.status.busy":"2023-08-18T09:41:24.534450Z","iopub.execute_input":"2023-08-18T09:41:24.534833Z","iopub.status.idle":"2023-08-18T09:41:24.992874Z","shell.execute_reply.started":"2023-08-18T09:41:24.534800Z","shell.execute_reply":"2023-08-18T09:41:24.991476Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Creating callbacks for model","metadata":{"id":"_P1vbkDSF0T3"}},{"cell_type":"code","source":"# Mention the checkpoint path and it's directory where you will save the model\ncheckpoint_path = BASELINE_MODEL_CHECKPOINT\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Calculate no of batches, I am taking floor because when creating the training data I used drop_remainder\nn_batches = int(train_dataset.shape[0] / BATCH_SIZE)\n\n# Create the checkpoint for model saving, monitoring val_custom_accuracy_v1 and save only weights of the model\nsaving_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                monitor='val_custom_accuracy_v1',\n                                                verbose=1,\n                                                save_weights_only=True,\n                                                save_freq=n_batches//2)\n\n# Create the checkpoint for stopping early after noticing that val_custom_accuracy_v1 is not increasing even after 5 consecutive epochs\nearlystop_cb = tf.keras.callbacks.EarlyStopping(monitor='val_custom_accuracy_v1',\n                                                    patience=PATIENCE,\n                                                    mode='max',\n                                                    )\n\n# Store the checkpoints in a list\ncallbacks = [saving_cb, earlystop_cb]","metadata":{"id":"_OFR6b5hD10E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Training baseline model","metadata":{"id":"tLyxWD4MF6W-"}},{"cell_type":"code","source":"epochs = EPOCHS\nsteps_per_epoch = STEPS_PER_EPOCHS\n\nhistory = base_model.fit(tf_train_dataset.repeat(),\n                    epochs=epochs,\n                    validation_data=tf_val_dataset,\n                    steps_per_epoch=steps_per_epoch,\n                    callbacks=callbacks\n                    )","metadata":{"id":"OQE9gr_Bd9cJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pointer Generetor model: Adding Pointer Generator to avoid getting OOV tokens in the summary","metadata":{"id":"cDBfIISTS0j3"}},{"cell_type":"markdown","source":"#### Creating `tf_train_dataset`, `tf_val_dataset` dataset using tf.data API\n\nI already have created to the `generate_example` function, I can use it again to generate examples for training and validation respectively.\n\nBut this time I have to also consider the `<OOV>` with token value `1`. Instead of using `1`, I have to generate a new token value for each of the `<OOV>` words.\n\nHow to do it?","metadata":{"id":"0Y9oJUdnUM_Z"}},{"cell_type":"markdown","source":"##### `find_oovs`, `map_oovs` & `tokenize_oovs` function","metadata":{"id":"nJY4-VAaEfuF"}},{"cell_type":"code","source":"def find_oovs(sent, sent_token, sent_len):\n    '''Finds the out of vocabulary words from `sent` with the help of already tokenized `sent_tokens`.\n\n    Arguments:\n    sent: str, sentence to find the oov from\n    sent_token: 2D np.array, the tokenized form of the sentence with sent_len length\n    sent_len: int, length of the tokenized sentence\n\n    Returns:\n    Returns a list of all oov words in the `sent`\n    '''\n    analyzed_sent = custom_analyzer(sent)\n    oov_words = [w for i, w in enumerate(analyzed_sent[:sent_len]) if (sent_token[0][i] == 1)]\n    return oov_words\n\ndef map_oovs(oovs, oov_start_token):\n    '''Stores the out of vocabulary words in a dictionary and sets the values of each oov key to\n    a temporary unique tokens.\n\n    Arguments:\n    oovs: list of oov words\n    oov_start_token: int, the first value to use as oov token then increase by 1\n\n    Returns:\n    dictionary of (oov, token) as (key, value) pairs\n    '''\n    unique_oovs = list(set(oovs))\n    oov_tokens = [oov_start_token+i for i in range(len(unique_oovs))]\n\n    oov_dict = dict(zip(unique_oovs, oov_tokens))\n\n    return oov_dict\n\ndef tokenize_oovs(sent, sent_token, oov_dict, sent_len):\n    '''Tokenize the sent by replacing the oov tokens by new unique tokens from oov_dict.\n\n    Arguments:\n    sent: str, sentence to handle the oovs\n    sent_token: 2D np.array of tokens\n    oov_dict: dictionary, oov words and their tokens are stored here\n    sent_len: int, length of the sentence token array\n\n    Returns:\n    tokenized sentence with oov words tokenized to temporary oov tokens\n    '''\n    analyzed_sent = custom_analyzer(sent)\n\n    for i, w in enumerate(analyzed_sent[:sent_len]):\n        if w in oov_dict.keys():\n            sent_token[0, i] = oov_dict[w]\n\n    return sent_token","metadata":{"id":"WkfC7nfwghMI","execution":{"iopub.status.busy":"2023-08-22T09:11:18.198391Z","iopub.execute_input":"2023-08-22T09:11:18.198831Z","iopub.status.idle":"2023-08-22T09:11:18.209162Z","shell.execute_reply.started":"2023-08-22T09:11:18.198798Z","shell.execute_reply":"2023-08-22T09:11:18.208023Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"##### Applying functions on Examples","metadata":{"id":"MygLMzLXEouR"}},{"cell_type":"code","source":"print(f\"Article:\\n{sample_article}\\n\\n\")\n\nsample_article_tokens = tokenize_pad([sample_article],\n                              tokenizer,\n                              padding=\"post\",\n                              truncating=\"post\",\n                              maxlen=MAX_ARTICLE_TOKENS)\nprint(f\"sample article tokens:\\n{sample_article_tokens}\\n\\n\")\n\nsample_oovs = find_oovs(sample_article, sample_article_tokens, MAX_ARTICLE_TOKENS)\nprint(f\"OOVs in the sample article:\\n{sample_oovs}\\n\\n\")\n\nsample_oov_dict = map_oovs(sample_oovs, VOCAB_SIZE)\nprint(f\"OOV dictionary:\\n{sample_oov_dict}\\n\\n\")\n\nsample_article_tokens_with_oovs = tokenize_oovs(sample_article, sample_article_tokens, sample_oov_dict, MAX_ARTICLE_TOKENS)\nprint(f\"sample article tokens with oov tokens:\\n{sample_article_tokens_with_oovs}\")","metadata":{"id":"cqzj5WV-ihFC","outputId":"9870ca93-d734-4d2d-bf84-bdd7e64fae10","execution":{"iopub.status.busy":"2023-08-22T09:11:30.205095Z","iopub.execute_input":"2023-08-22T09:11:30.205501Z","iopub.status.idle":"2023-08-22T09:11:30.220926Z","shell.execute_reply.started":"2023-08-22T09:11:30.205471Z","shell.execute_reply":"2023-08-22T09:11:30.219981Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Article:\nnew york (cnn) -- the u.s. population is expected to top out at close to 312.8 million people just around the time crowds gather to watch the ball drop on new year's eve, according to new census data released thursday. the figure represents a 0.7% increase from last year, adding 2,250,129 people to the u.s. population since the start of 2011, and a 1.3% increase since census day, april 1, 2010. the agency estimates that beginning in january, one american will be born every eight seconds and one will die every 12 seconds. u.s.-bound immigrants are also expected to add one person every 46 seconds. that combination of births, deaths and migration is expected to add a single person to the u.s. population every 17 seconds, the census bureau said. meanwhile, millions are set to ring in the new year. in new york, authorities are preparing for large crowds in manhattan's times square, where lady gaga is expected to join mayor michael bloomberg to push the button that drops the waterford crystal ball at 11:59 p.m. et on new year's eve. \"and i'm so looking forward to performing on nye+dropping the ball with mayor bloomberg!\" the pop star posted on twitter. \"what an honor as a new yorker.\" past guests have included muhammad ali, rudy giuliani, colin powell and bill and hillary clinton. on thursday, officials conducted new york's annual \"airworthiness test\" -- a process in which confetti is tossed by handfuls above times square -- in preparation for the annual city tradition of dumping one ton of confetti over revelers in the iconic square. the big apple this year edged out las vegas for the first time in seven years as the top travel u.s. destination for those celebrating the new year, according to a december travel booking website poll. seven new york neighborhoods made the top 10 list, with two districts in las vegas and one in new orleans making up the other three, according to the priceline poll. \"it appears that new york city will be helped this year by a weather forecast that calls for warmer than usual temperatures over the holiday weekend,\" said company spokesman brian ek.\n\n\nsample article tokens:\n[[   76    69   279    50   126    49    11    11     3   139     2    12\n      2  1409    17   502     6   232    58    25   394     6     1   152\n     64    75   130     3    71  3442  4135     6   500     3   737  1839\n     16    69    56     5    12  3644     4   143     6    69  7953   911\n    408   386     2     3  1251  3475     7     1  1141    30    74    56\n      4  1131     1    64     6     3   139     2    12     2  1409   142\n      3   411     9     1     8     7     1  1141   142  7953   112     4\n    544     1     1     3   687  3730    14  1719    10   443     4    52\n    307    48    32   652   243   490  1737     8    52    48  1513   243\n      1  1737     2   139     2    12     2    11  3494  3021    35    65\n    502     6  1952    52   412   243     1  1737     2    14  3945     9\n   9192     4  1414     8  6402    17   502     6  1952     7   864   412\n      6     3   139     2    12     2  1409   243     1  1737     4     3\n   7953  3872    23     2  1175     4  1285    35   222     6  1898    10\n      3    69    56     2    10    69   279     4   376    35  2905    15\n    574  3442    10  2592     5    12   241  1330     4   106  1470  8770\n     17   502     6  1381  1459   534  5404     6  2051     3  3517    14\n   7137     3 39788  2801   737    25     1  1120     2   136     2  4978\n     16    69    56     5    12  3644     2    18     8    27     5   136\n     72   381   594     6  3146    16 12946  4835  4329     3   737    21\n   1459  5404   284    18     3  2409   385   726    16   602     2    18\n     79    38  2825    26     7    69 12664     2    18   346  1835    29\n    935  7681  2510     4 12507 15918     4  5235  4404     8   695     8\n   3042  1098     2    16   386     4   310  2458    69   279     5    12\n   1614    18 49905   811    18    11    11     7   761    10    55 23442\n     17 10004    28 40643   645   241  1330    11    11    10  5064    15\n      3  1614   148  3701     9 10286    52  8555     9 23442    82 21027\n     10     3  2918  1330     2     3   301  1005    39    56 10488    58\n   2897  2795    15     3    83    71    10   465    87    26     3   232\n    856   139     2    12     2  3973    15   146  3448     3    69    56\n      4   143     6     7   517   856  6738   632  2217     2   465    69\n    279  7361   118     3   232     1   816     4    21    68  8489    10\n   2897  2795     8    52    10    69  4642   342    57     3    95   107\n      4   143     6     3]]\n\n\nOOVs in the sample article:\n['312.8', '0.7%', '2,250,129', '2011,', '1.3%', '1,', '2010.', '12', '46', '17', '11:59', '10']\n\n\nOOV dictionary:\n{'312.8': 50000, '0.7%': 50001, '10': 50002, '1,': 50003, '17': 50004, '11:59': 50005, '2011,': 50006, '12': 50007, '2010.': 50008, '2,250,129': 50009, '46': 50010, '1.3%': 50011}\n\n\nsample article tokens with oov tokens:\n[[   76    69   279    50   126    49    11    11     3   139     2    12\n      2  1409    17   502     6   232    58    25   394     6 50000   152\n     64    75   130     3    71  3442  4135     6   500     3   737  1839\n     16    69    56     5    12  3644     4   143     6    69  7953   911\n    408   386     2     3  1251  3475     7 50001  1141    30    74    56\n      4  1131 50009    64     6     3   139     2    12     2  1409   142\n      3   411     9 50006     8     7 50011  1141   142  7953   112     4\n    544 50003 50008     3   687  3730    14  1719    10   443     4    52\n    307    48    32   652   243   490  1737     8    52    48  1513   243\n  50007  1737     2   139     2    12     2    11  3494  3021    35    65\n    502     6  1952    52   412   243 50010  1737     2    14  3945     9\n   9192     4  1414     8  6402    17   502     6  1952     7   864   412\n      6     3   139     2    12     2  1409   243 50004  1737     4     3\n   7953  3872    23     2  1175     4  1285    35   222     6  1898    10\n      3    69    56     2    10    69   279     4   376    35  2905    15\n    574  3442    10  2592     5    12   241  1330     4   106  1470  8770\n     17   502     6  1381  1459   534  5404     6  2051     3  3517    14\n   7137     3 39788  2801   737    25 50005  1120     2   136     2  4978\n     16    69    56     5    12  3644     2    18     8    27     5   136\n     72   381   594     6  3146    16 12946  4835  4329     3   737    21\n   1459  5404   284    18     3  2409   385   726    16   602     2    18\n     79    38  2825    26     7    69 12664     2    18   346  1835    29\n    935  7681  2510     4 12507 15918     4  5235  4404     8   695     8\n   3042  1098     2    16   386     4   310  2458    69   279     5    12\n   1614    18 49905   811    18    11    11     7   761    10    55 23442\n     17 10004    28 40643   645   241  1330    11    11    10  5064    15\n      3  1614   148  3701     9 10286    52  8555     9 23442    82 21027\n     10     3  2918  1330     2     3   301  1005    39    56 10488    58\n   2897  2795    15     3    83    71    10   465    87    26     3   232\n    856   139     2    12     2  3973    15   146  3448     3    69    56\n      4   143     6     7   517   856  6738   632  2217     2   465    69\n    279  7361   118     3   232 50002   816     4    21    68  8489    10\n   2897  2795     8    52    10    69  4642   342    57     3    95   107\n      4   143     6     3]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### `generate_example_v2` function creation","metadata":{"id":"b4U6JUL9ExLh"}},{"cell_type":"code","source":"def generate_example_v2(inputs, targets,\n                        input_tokenizer, target_tokenizer,\n                        input_len, target_len,\n                        padding=\"post\", truncating=\"post\",\n                        vocab_size=VOCAB_SIZE):\n\n    '''Generates examples for the Pointer Generator model. Processes the `inputs` and `targets`\n    with their respective tokenizers and tokenize them to `input_len` and `target_len` length.\n    After tokenizing the article words, it looks for the out-of-vocabulary words and creates unique tokens\n    for each of those OOV words. Then, instead of keeping the oov word tokens as 1, it replaces them\n    with their respective newly generated tokens. This tokens are temporary\n\n    Arguments:\n    inputs: list of input sentences\n    targets: list of target sentences\n    input_tokenizer: Tokenizer class object, tokenizer for inputs\n    target_tokenizer: Tokenizer class object, tokenizer for targets\n    input_len: int, the length of the tokenization for inputs\n    target_len: int, the length of the tokenization for targets\n\n    Returns:\n    returns 2 values, a tuple containing 2 numpy arrays (input_tokens, target_tokens[:-1]) and\n    another numpy array target_tokens[1:]\n    '''\n\n    for inp, tar in zip(inputs, targets):\n        # Tokenizing article words\n        inp_token = tokenize_pad([inp],\n                                  input_tokenizer,\n                                  padding=padding,\n                                  truncating=truncating,\n                                  maxlen=input_len)\n\n        oov_words = find_oovs(inp, inp_token, input_len)\n        oov_dict = map_oovs(oov_words, oov_start_token=vocab_size)\n        inp_token = tokenize_oovs(inp, inp_token, oov_dict, input_len)\n\n        # Tokenizing summary words\n        tar_token = tokenize_pad([tar],\n                     target_tokenizer,\n                     padding=padding,\n                     truncating=truncating,\n                     maxlen=target_len)\n        tar_token = tokenize_oovs(tar, tar_token, oov_dict, target_len)\n\n        yield (inp_token[0], tar_token[0][:-1]), tar_token[0][1:]","metadata":{"id":"bWzy1fmHTG_j","execution":{"iopub.status.busy":"2023-08-22T09:11:44.211598Z","iopub.execute_input":"2023-08-22T09:11:44.212029Z","iopub.status.idle":"2023-08-22T09:11:44.222757Z","shell.execute_reply.started":"2023-08-22T09:11:44.211994Z","shell.execute_reply":"2023-08-22T09:11:44.221604Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"##### Examples with the generator function","metadata":{"id":"g66B6U8bE3jA"}},{"cell_type":"code","source":"print(f\"Example generated by the generator v2:\")\n\n# (inp_art_tokens, inp_sum_tokens), tar_sum_tokens = generate_example(list(train_dataset[:, 0]),\nexample_gen = generate_example_v2(list(train_dataset[:, 0]),\n                               list(train_dataset[:, 1]),\n                               input_tokenizer=tokenizer,\n                               target_tokenizer=tokenizer,\n                               input_len=MAX_ARTICLE_TOKENS,\n                               target_len=MAX_SUMMARY_TOKENS)\n\ninps, tar = next(example_gen)\nprint(f\"Inputs:\\n{inps[0]}\\n{inps[1]}\\n\\n\")\nprint(f\"Target:\\n{tar}\")","metadata":{"id":"eA3joMNfbcjL","outputId":"45e75c51-882f-4132-99de-f5ba713c43d7","execution":{"iopub.status.busy":"2023-08-22T09:12:01.006681Z","iopub.execute_input":"2023-08-22T09:12:01.007085Z","iopub.status.idle":"2023-08-22T09:12:01.078522Z","shell.execute_reply.started":"2023-08-22T09:12:01.007051Z","shell.execute_reply":"2023-08-22T09:12:01.077432Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Example generated by the generator v2:\nInputs:\n[   76  2945  5479     5    12   862  2856    11  4100    13     3   589\n    16   658     5    12  5932    16   386   409     4    34     3  1770\n   153   173    19    17     7   453   179   575     2  3151  3455     5\n    12   266  1244    15     3  2992 50003 14183   124  1088 12952     8\n 10577    31    46   680     4    34    10     7 14450    30     3  1770\n     4     3   486  1244  5331  2598  5479    26     7   453   179   575\n     4   333    24   402     6     3  4211     2   862  1164  5479    15\n 50000    16  4885   112    10   509     4     8  1085    24    83   707\n  2856    11  4100    15     3  5896    16   360   194     2    25     3\n  1656     9     3  1770     5    12   266  1244  5331     4     5  1630\n  5479     5    17  2598    26     7   453   179   575     2  5479  1085\n    24    83   707  2856    11  4100    16   360    10     3   542     8\n   306     9   862     4    25     3  4211     2   274    24   402     6\n   282   213     4  5479    41   561     3   843     9    24  1495  1460\n    25   179     4  1434  1875  2998     6  5946     8  2833     2    19\n   118    24  2447    15     3    94  2976  3935    10 50002    34    44\n   245    87     8 50001  2791     4   191     7  5253     6    24   179\n   707     8   732     6   862     2  5479    13  1696  1364  2575  2090\n     8 10029  4812     6   598     3   512    15    24   181     4    34\n     3  1166     5    12    71    25   179   153  1104     6   418   185\n    10     3  2184     9   554    25     3  1770     2 15514     2  7150\n 12232    50  2094    49     4  1805  3384    50   295  4651    49     4\n  1662  3397    50   453   148    49  5594     2 10541 10147    50  2145\n    49     4  2219  7212    50   638    49     4 12901 15700    50  2094\n    49     4  7276  7647    50   862    49     4  2768 13526    50  2145\n    49     4   373  4663    50  2145    49 12837     2 13058 14821    50\n  3267  1936    49     4  2009  4973    50   637    49     4  2108  8081\n    50   637    49     4   590  9120    50   453   148    49     4  1633\n  9887    11  7615    50   862    49     4 24304 18496    50  2988    49\n     4  6327  2344    50   637    49     4 18948  8834    50  1913    49\n     4  1709  6424    50   862    49  8335     2 10029  4812    50   637\n    49     4  2575  2090    50   453   179    49     4  2945  5479    50\n   862    49     2  5479   561   245    87    10     3    83   162    25\n   179     4   192    50]\n[   76   862  1164  2945  5479    30   138     1  4885   112     2  5479\n   686     3  5896 50000     2     3  1770  2749     6  5479    26     7\n   138 17570   575    10    45   486   162    11  5331   408     6     3\n   655     2    77     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0]\n\n\nTarget:\n[  862  1164  2945  5479    30   138     1  4885   112     2  5479   686\n     3  5896 50000     2     3  1770  2749     6  5479    26     7   138\n 17570   575    10    45   486   162    11  5331   408     6     3   655\n     2    77     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0]\n","output_type":"stream"}]},{"cell_type":"code","source":"inps, tar = next(example_gen)\nprint(f\"Inputs:\\n{inps[0]}\\n{inps[1]}\\n\\n\")\nprint(f\"Target:\\n{tar}\")","metadata":{"id":"hIuAkQbO7Bzz","outputId":"37076516-319c-4750-a9f7-917e0ff937b0","execution":{"iopub.status.busy":"2023-08-22T09:12:05.685426Z","iopub.execute_input":"2023-08-22T09:12:05.686154Z","iopub.status.idle":"2023-08-22T09:12:05.699223Z","shell.execute_reply.started":"2023-08-22T09:12:05.686121Z","shell.execute_reply":"2023-08-22T09:12:05.698134Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Inputs:\n[   76    28     2   534 21289     2     7   631    11 43294  9896 21290\n  2322   113  3185   739    39   409    44    19   205     7  4544   113\n     7  8263   631   970 13059     4   374     8  2138   107    85   380\n     8  4004     7  1244   240    92    19    13  7266    99    10     3\n   435    21    38  9570     2     3 13660   451    25 50000   323    53\n  5356 50003   552     6  3059     7 29036    10   270  9591     8     3\n   715   230 15554   803     2    85   155    19   205     7  4544    10\n    38  1178     6   116    79    19   382     2    85   408     7  2314\n   936   836  1119 50002    11    94 50003    21    24  1728   130     7\n   981  4544     5    12  4059   101    19   802     7 23804  6515    25\n    33   261     2    36    13   206   408 10191     2  1885    23 50003\n    13   831     2  7858  2010    15    24  7971     8   413 10105   467\n    14    13     2 12189    21    24   218   456     2   367    99    15\n   158     2  8003    22    85   155    39  2314   936   836   429  5356\n 50003     4 50006    44    19   205     7  4544   113     7  8263   631\n   970  3314     2  3987  1241   212     7   247    40   767   508  1012\n    30     7  1176  1455  1937    44     7    85  2136    11    58    14\n   271    68  2239     2     7   138    40   815    25     3   715   543\n     8  1235   446    26 50003     5    12   463    81     3  2322  4932\n    14 50003  7108     3 11027     6   293    24   631  4424     2    19\n    23    14 50003    41    46    38 42210  3749    92    19     5   989\n    10    21     3   803  1324     2     5    60 50005     4  2322   507\n 18122  3347  1643 50003     5    12  2010    25     7  5361   427    60\n    68   626    30     3  3314   543     2  1253    22  5356 50003     4\n 50006    17     7   631  8883    40    13   419     6   116   269    15\n    24  4424     4     7   463    81  1326     2    53     3 50004    85\n  2367  2850     3  1004     4 50003   374    70    10     3  2888     2\n     3  8911   117   205     3   507     5    12  6515     8 10200   115\n    10    24  1244   240     2 50001    11   576   609    14  3347    90\n    32   387 20638    15  4359    26    19 25240    10     7  5514     9\n     3   138    40   374    70     2     5   306  1436     2   542  1789\n     2  3958  5280     2   507    99     2     5    14     2   222   115\n     7  9860  8345   314     3   148     2   296    38   739   206     4\n     3     2  1244   240]\n[   76  5356 50003     4 50006  7108     7 29036     8   186    24   467\n  2010    21    24   218   456 14788    16    20    26     7  8673  1004\n     2    19   374    38   507    10     3  2888     8  4004    24   848\n     8  1244   240    53    19    13   125     2    19 12479     3  1244\n   240     8   205   115    21    38  9570    10    24  2451     5    12\n 16134     2 50003  2347     3 16134     8  1136   397    25   380     2\n    68    59   380    47  2138     2    85   879   397     8   271   201\n   242    10     3   240     2    77     0     0     0     0     0     0\n     0     0     0]\n\n\nTarget:\n[ 5356 50003     4 50006  7108     7 29036     8   186    24   467  2010\n    21    24   218   456 14788    16    20    26     7  8673  1004     2\n    19   374    38   507    10     3  2888     8  4004    24   848     8\n  1244   240    53    19    13   125     2    19 12479     3  1244   240\n     8   205   115    21    38  9570    10    24  2451     5    12 16134\n     2 50003  2347     3 16134     8  1136   397    25   380     2    68\n    59   380    47  2138     2    85   879   397     8   271   201   242\n    10     3   240     2    77     0     0     0     0     0     0     0\n     0     0     0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### Making training, validation set examples for pointer generator model","metadata":{"id":"Ix6RsiveGSQS"}},{"cell_type":"code","source":"def train_example_generetor_v2():\n    example_gen = generate_example_v2(list(train_dataset[:, 0]),\n                                list(train_dataset[:, 1]),\n                                input_tokenizer=tokenizer,\n                                target_tokenizer=tokenizer,\n                                input_len=MAX_ARTICLE_TOKENS,\n                                target_len=MAX_SUMMARY_TOKENS)\n\n    for example in example_gen:\n        s0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n        c0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n\n        (input_0, input_1), target = example\n        yield (input_0, input_1, s0, c0), target","metadata":{"id":"ZCRXKTLZGX_I","execution":{"iopub.status.busy":"2023-08-22T09:12:12.286955Z","iopub.execute_input":"2023-08-22T09:12:12.287701Z","iopub.status.idle":"2023-08-22T09:12:12.296041Z","shell.execute_reply.started":"2023-08-22T09:12:12.287662Z","shell.execute_reply":"2023-08-22T09:12:12.294993Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"output_signature = (\n    (tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, ), dtype=tf.int32),\n     tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32),\n     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32),\n     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32)),\n    tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32)\n)\n\ntf_train_dataset = tf.data.Dataset.from_generator(generator=train_example_generetor_v2,\n                                                  output_signature=output_signature)\ntf_train_dataset = tf_train_dataset.shuffle(BUFFER_SIZE)\ntf_train_dataset = tf_train_dataset.batch(BATCH_SIZE, drop_remainder=True)\ntf_train_dataset = tf_train_dataset.prefetch(1)","metadata":{"id":"NBdNpR7rGw7m","execution":{"iopub.status.busy":"2023-08-22T09:12:17.785615Z","iopub.execute_input":"2023-08-22T09:12:17.786542Z","iopub.status.idle":"2023-08-22T09:12:18.004672Z","shell.execute_reply.started":"2023-08-22T09:12:17.786505Z","shell.execute_reply":"2023-08-22T09:12:18.003585Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"def val_example_generetor_v2():\n    example_gen = generate_example_v2(list(val_dataset[:, 0]),\n                                list(val_dataset[:, 1]),\n                                input_tokenizer=tokenizer,\n                                target_tokenizer=tokenizer,\n                                input_len=MAX_ARTICLE_TOKENS,\n                                target_len=MAX_SUMMARY_TOKENS)\n\n    for example in example_gen:\n        s0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n        c0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n\n        (input_0, input_1), target = example\n        yield (input_0, input_1, s0, c0), target\n\n\noutput_signature = (\n    (tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, ), dtype=tf.int32),\n     tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32),\n     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32),\n     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32)),\n    tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32)\n)\n\ntf_val_dataset = tf.data.Dataset.from_generator(generator=val_example_generetor_v2,\n                                                  output_signature=output_signature)\ntf_val_dataset = tf_val_dataset.shuffle(BUFFER_SIZE)\ntf_val_dataset = tf_val_dataset.batch(BATCH_SIZE, drop_remainder=True)","metadata":{"id":"byX6PXAKGw7y","execution":{"iopub.status.busy":"2023-08-22T09:12:20.794871Z","iopub.execute_input":"2023-08-22T09:12:20.795290Z","iopub.status.idle":"2023-08-22T09:12:20.839673Z","shell.execute_reply.started":"2023-08-22T09:12:20.795256Z","shell.execute_reply":"2023-08-22T09:12:20.838564Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"for (art_inp, sum_inp, s0, c0), sum_tar in tf_train_dataset.take(1):\n    print(f\"Input tokenized article shape: {art_inp.shape}\")\n    print(f\"Input tokenized summary shape: {sum_inp.shape}\\n\")\n\n    print(f\"Target tokenized summary shape: {sum_tar.shape}\")","metadata":{"outputId":"e0bdb027-6b00-4229-ebe4-f55c93e2964d","id":"2fZlevYZGw7y","execution":{"iopub.status.busy":"2023-08-22T09:12:23.409639Z","iopub.execute_input":"2023-08-22T09:12:23.410167Z","iopub.status.idle":"2023-08-22T09:12:43.892262Z","shell.execute_reply.started":"2023-08-22T09:12:23.410131Z","shell.execute_reply":"2023-08-22T09:12:43.890495Z"},"trusted":true},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Input tokenized article shape: (16, 400)\nInput tokenized summary shape: (16, 99)\n\nTarget tokenized summary shape: (16, 99)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Attention Mechanism for Pointer Generator Model\n\nIt now involves the attention weights also because they will be used to calculate the final distribution.","metadata":{"id":"bokn5sDnsnEI"}},{"cell_type":"code","source":"def one_time_attention_v2(a, s_prev,\n                       repeater, concatenator, densor_1, densor_2, softmax_layer, dotter):\n    '''Calculates the attention score and returns the context and attention distribution for the current\n    timestep in the decoder.\n    Attention mechanism uses encoder outputs `a` of shape `(batch, timesteps, features)` and decoder\n    previous hidden state `s_prev` of shape `(batch, features)`, then calculates alignment scores `alphas`\n    for each encoder timestep with the help of energies computed with 2 dense layers using `a` and `s_prev`.\n\n    Arguments:\n    a: tf.Tensor object, encoder output of shape `(batch, timesteps, features)` or `(batch, Tx, 2*n_a)`\n    s_prev: tf.Tensor object, decoder previous hidden state of shape `(batch, features)` or `(batch, n_s)`\n    repeater: RepeatVector layer, repeat the `s_prev` `Tx` times\n    concatenator: Concatenate layer, concatenates `a` and repeated `s_prev`, Concatenates along axis=-1\n    densor_1: Dense layer, calculates the pertial energies `e`, with `units=d1_units`\n    refer to `baseline_model` function for details about this variable\n    densor_2: Dense layer, calculated the energies `energies`, with `units=d2_units`\n    refer to `baseline_model` function for details about this variable\n    softmax_layer: Activation layer, computes softmax of the energies and calculates `alphas`, with\n    `units=article_vocab_size` refer to `baseline_model` function for details about this variable\n    dotter: Dot layer, Performs dot operation between `alphas` and `a` along axis=1\n\n    Returns:\n    returns the context of shape `(batch, 1, 2*n_a)` and\n    attention distribution of shape `(batch, Tx, d2_units)`\n    '''\n\n    # Repeat the `s_prev` `Tx` times\n    s_prev = repeater(s_prev) # (batch, Tx, n_s)\n\n    # Concatenate `a` and `s_prev` along axis=-1\n    concat = concatenator([a, s_prev]) # (batch, Tx, n_a + n_s)\n\n    # Apply dense layer to get partial energies e\n    e = densor_1(concat) # (batch, Tx, d1_units)\n\n    # Apply dense layer again to get energies\n    energies = densor_2(e) # (batch, Tx, d2_units)\n\n    # Apply softmax over the energies\n    alphas = softmax_layer(energies) # (batch, Tx, d2_units)\n\n    # Dot the alphas and a along axes=1\n    context = dotter([alphas, a]) # (batch, d2_units, 2*n_a)\n\n    return context, alphas","metadata":{"id":"aDPDm6MJLIEz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Pointer Generator\n\nThe function `generate_pointer` will return the $p_{gen}$. $p_{gen}$ will be used to decide whether the next word needs to be copied from the article or we should generate a new word from the vocabulary. This decision will be taken using the equation- $$P(w) = p_{gen}*P_{vocab}(w) + (1-p_{gen})*\\sum_{i:w_i=w}a^t_i$$\n\nWhere\n- $P$ is the extended vocabulary containing words from vocabulary and article both.\n- $a^t_i$ is the attention $t^{th}$ time step need to give to $i^{th}$ article word.\n- $P_{vocab}$ is the previous vocabulary distribution without considering words from article.","metadata":{"id":"j7wikoNOuKsd"}},{"cell_type":"markdown","source":"##### Pointer Generator Network\n\nPointer network takes the context vector ($h^{*(t)}$), decoder embedding input($x^{(t)}$) and decoder hidden state ($s^{(t)}$). The equation of the pointer network is - $$p_{gen} = \\sigma(W_h^Th^{*(t)}+W_x^Tx^{(t)}+W_s^Ts^{(t)}+b_{ptr})$$","metadata":{"id":"PlMlegsIEbsG"}},{"cell_type":"code","source":"def pointer_generator_v1(context_vector, decoder_state, decoder_inp):\n    '''Generates the p_gen needed to calculate the final vocabulary distribution.\n    It takes the context, decoder hidden state and decoder embedding input as it's input and then\n    passes them through a dense layer to get the pointer generator.\n\n    Arguments:\n    context_vector: Tensor of shape (batch, n_a)\n    decoder_state: Tensor of shape (batch, n_s)\n    decoder_inp: Tensor of shape (batch, emb_dim)\n\n    Returns:\n    returns the pointer generator p_gen\n    '''\n    concat = Concatenate(axis=-1)([context_vector, decoder_state, decoder_inp])\n    p_gen = tf.keras.layers.Dense(units=1, activation='sigmoid')(concat)\n\n    return p_gen","metadata":{"id":"P7y1utw3mAZw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Pointer Generator Model","metadata":{"id":"AKSoa2YRENVV"}},{"cell_type":"markdown","source":"A demo on how to use `scatter_nd` method from tensorflow to map the copy probablities to the appropriate indices of final extended vocabulary distribution.\n\nThis example simulates the situation of already having encoder input(`x`), vocabulary distribution(`vocab_dist`) and copy probablities using pointer generator(`copy_dist`). Now, we just need to find the final extended vocabulary distribution `final_dist`.\n\nThe simulated example has `vocabulary size = 100`, `encoder input length is 10`, `batch size = 5`, `encoder input has 3 OOV words`.\n\nThe main logic here is- $$P_{final}[X[i]]+=P_{copy}[i]$$\nP.S we are not considering batch dimension.\n\nProgramming this concept in tensorflow:\n\n1. Convert the input tensor(`x`) to another 2D tensor(`x_ind`) with `shape=(Batch size * Input Length, 2)`, where $$x_{ind}[i*BatchSize+j] = [i, x[i][j]] where\\ iϵ[0, Batch Size-1], jϵ[0, Input Length-1]$$\n2. Flatten the `copy_dist`.\n3. Use `tf.scatter_nd` method.","metadata":{"id":"FWfZ0s_mwDn4"}},{"cell_type":"code","source":"x = tf.constant([[ 2, 100,  50, 10,  67,  16,  101,  23,  102,  3],\n                [ 2, 45, 100,  91,  99,  35,  101, 48,  102,  3],\n                [ 2,  100, 67,  95,  65,  101,  90,  102,  9,  3],\n                [ 2, 102, 100, 101,  90,  36,  96,  35,  98,  3],\n                [ 2,  91,  91,  16, 101, 100,  87,  94,  102,  3]], dtype=tf.int32)\nprint(f\"The simulated input to encoder:\\n{x}\")","metadata":{"id":"oqA-OnHrwC2r","outputId":"1b433749-abb2-4301-bdb0-04483c8da8c0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_dist = tf.random.uniform(shape=[5, 100])\nprint(f\"The vocabulary distribution without OOV:\\n{vocab_dist}\")","metadata":{"id":"6HiLv8ody5A9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"copy_dist = tf.random.uniform(shape=[5, 10])\nprint(f\"The copy distribution is:\\n{copy_dist}\")","metadata":{"id":"BQPY3-kL2nqk","outputId":"1fcbb37c-f1da-41b0-b0dd-77e5b1afe193"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_dist = tf.concat([vocab_dist, tf.zeros_like(x, dtype=float)], axis=-1)\nprint(f\"The shape of the final distribution is {final_dist.shape}\")","metadata":{"id":"Be5dQGAD210m","outputId":"2bd3f46f-2f61-461e-8c41-9e8ffa8c909a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows, cols = tf.meshgrid(tf.range(x.shape[0]), tf.range(x.shape[1]), indexing='ij')\nrows","metadata":{"id":"0ukZjfdY5ANG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_reshaped = tf.reshape(x, [-1])\nx_reshaped","metadata":{"id":"0gL7N4gIDJTX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices_to_update = tf.stack([tf.reshape(rows, [-1]), x_reshaped], axis=1)\nindices_to_update","metadata":{"id":"nTeHuxIyDPzn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.scatter_nd(indices=indices_to_update, updates=tf.reshape(copy_dist, [-1]), shape=final_dist.shape)","metadata":{"id":"wXu-uc6344Vs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at whether we can actually add the `copy_dist` to `final_dist`.\n\nWe are looking at the word, from first example input of the batch, which has token `50`. It is the 3rd word of the input `x[0, 2] = 50`.\n\nThis corresponds to `copy_word[0, 2]`, `final_dist[0, 50]`.","metadata":{"id":"LhCAQ46wEhvc"}},{"cell_type":"code","source":"final_dist[0, 50]","metadata":{"id":"GRWF5dCNEPiB","outputId":"add0ff60-9966-4a88-ef3a-4dd7ba02067e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"copy_dist[0, 2]","metadata":{"id":"UhpXrTw_EbmR","outputId":"52b8fe11-dc0e-4277-eef0-039e38bdd1c2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_dist[0, 50]+copy_dist[0, 2]","metadata":{"id":"DoaOgSiAFv1z","outputId":"6dc31238-4919-439f-e103-6d343451fa8a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices_to_update[2]","metadata":{"id":"uStJXJe2GRpN","outputId":"44d240c6-458a-4903-9a67-356aac5752cc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.tensor_scatter_nd_add(tensor=final_dist, indices=indices_to_update, updates=tf.reshape(copy_dist, [-1]))[0, 50]","metadata":{"id":"Cq6KSsrgDtxv","outputId":"0ce919ce-da5f-4498-c89f-d26046ecbe0c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_final_distribution(final_dist, copy_dist, inp_tokens):\n    rows_range = tf.range(tf.shape(inp_tokens)[0])\n    cols_range = tf.range(tf.shape(inp_tokens)[1])\n    rows, _ = tf.meshgrid(rows_range, cols_range, indexing='ij')\n\n    indices_to_update = tf.stack([tf.reshape(rows, [-1]), tf.reshape(inp_tokens, [-1])], axis=1)\n\n    return tf.tensor_scatter_nd_add(tensor=final_dist,\n                                  indices=indices_to_update,\n                                  updates=tf.reshape(copy_dist, [-1]))","metadata":{"id":"CzPfYicOG7sF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pointer_gen_model(Tx, Ty,\n                   emb_dim, n_a, n_s, d1_units, d2_units, d_units,\n                   article_vocab_size, summary_vocab_size):\n    '''This implements the bas-line model archietecture for summarization.\n    It is a seq-seq model with attention mechanism implemented in it. The encoder take an input\n    with `Tx` time-steps and summarizes with the help of decoder into Ty words. The encoder and decoder\n    hidden states are `n_a` and `n_s` dimension respectively. The words are taken from the vocabulary of\n    article and summary `article_vocab` and `summary_vocab` with size `article_vocab_size` and\n    `summary_vocab_size` respectively.\n\n    Arguments:\n    Tx: int, length of the input article\n    Ty: int, length of the output summary\n    n_a: int, dimension of the encoder hidden states\n    n_s: int, dimension of the deocder hidden states\n    d1_units: int, units for the first dense layer in attention mechanism\n    d2_units: int, units for the second dense layer in attention mechanism\n    d_units: int, units for the dense layer before output layer\n    article_vocab_size: int, length of the article vocabulary\n    summary_vocab_size: int, length of the summary vocabulary\n\n    Returns:\n    returns the base line model\n    '''\n    # Defining the input for our model with shape (None, Tx) and (None, Ty) for encoder input and decoder input\n    X_inp = Input(shape=(Tx), dtype=tf.int32)\n    X_tar = Input(shape=(Ty), dtype=tf.int32)\n\n    # Initialize s0\n    s0 = Input(shape=(n_s, ), name=\"s0\")\n    # Initialize c0\n    c0 = Input(shape=(n_s, ), name=\"c0\")\n\n    # Initialize the a and s with a0 and s0\n    s = s0 # (batch, n_s)\n    c = c0 # (batch, n_s)\n\n    # Define the outputs as empty list\n    outputs = []\n\n    # First embedding layer for the article input\n    encoder_inp = Embedding(article_vocab_size+Tx, emb_dim)(X_inp) # (batch, Tx, emb_dim)\n\n    # Encoder: Bidirectional layer with LSTM cells\n    a = Bidirectional(LSTM(units=n_a, return_sequences=True))(encoder_inp) # (batch, Tx, n_a)\n\n    # Define the embedding for decoder\n    decoder_inp = Embedding(summary_vocab_size+Tx, emb_dim)(X_tar) # (batch, Ty, emb_dim)\n\n    # Define the layers for Attention so that we can use the same weights for all decoder timesteps\n    repeater = RepeatVector(Tx)\n    concatenator = Concatenate(axis=-1)\n    attn_densor1 = Dense(units=d1_units, activation='tanh')\n    attn_densor2 = Dense(units=d2_units, activation='linear', use_bias=False)\n    softmax_layer = Activation('softmax', name=\"attention_weights\")\n    dotter = Dot(axes=1)\n\n    # Define the Decoder unidirectional LSTM for shared weights\n    post_attention_lstm = LSTM(units=n_s, return_state=True)\n\n    # Define the last dense layer before output layer with linear activation\n    densor = Dense(units=d_units, activation='linear')\n\n    # Define the output layer so that it does not initalize again and again for shared weights\n    output_layer = Dense(units=summary_vocab_size, activation='softmax')\n\n    # Initialize the extension\n    extension = tf.zeros_like(X_inp, dtype=float)\n\n    # Decoder: Appends outputs from the output layer in each timestep\n    for t in range(Ty):\n        # Get the decoder input for current timestep\n        curr_dec_in = decoder_inp[:, t:t+1, :] # (batch, 1, emb_dim)\n\n        # Get the context from the attention mechanism\n        context, attn_dist = one_time_attention_v2(a, s, # (batch, d2_units, 2*n_a), (batch, Tx, d2_units)\n                                     repeater, concatenator, attn_densor1, attn_densor2, softmax_layer, dotter)\n\n        concat = Concatenate(axis=-1)([curr_dec_in, context]) # (batch, d2_units, emb_dim+2*n_a); d2_units=1 otherwise error\n        _, s, c = post_attention_lstm(concat, initial_state=[s, c]) # _, (batch, n_s), (batch, n_s)\n\n        # Calculate the output after using 2 linear dense layers\n        den1 = densor(s) # (batch, d_units)\n        den2 = densor(den1) # (batch, d_units)\n        # Use the output_layer to get the vocabulary distribution\n        P_vocab  = output_layer(den2) # (batch, summary_vocab_size)\n\n        # Generate pointer\n        p_gen = pointer_generator_v1(context[:, 0, :], s, curr_dec_in[:, 0, :]) # (batch, 1)\n\n        # Calculate the total probablity of copying words from source text\n        P_copy = (1 - p_gen) * attn_dist[:, :, 0] # (batch, Tx)\n\n        # Calculate the probablity to generate new word\n        P_final = p_gen * P_vocab # (batch, summary_vocab_size)\n\n        # Extend the final vocabulary to take new temporary words from source text\n        P_final = Concatenate(axis=-1)([P_final, extension]) # (batch, summary_vocab_size+Tx)\n\n        # Calculate the extended vocabulary distribution\n        P_final = calculate_final_distribution(P_final, P_copy, X_inp)\n\n        # Append the final output to the outputs list\n        outputs.append(P_final)\n\n    # Stack the list of each timesteps output along axis=1\n    outputs = tf.stack(outputs, axis=1) # (batch, Ty, summary_vocab_size)\n\n    model = Model(inputs=[X_inp, X_tar, s0, c0], outputs=outputs)\n\n    return model","metadata":{"id":"hLrsABvkICua"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Pointer Generator Model Creation and Training","metadata":{"id":"l5lRYuUrDih7"}},{"cell_type":"code","source":"Tx = MAX_ARTICLE_TOKENS\nTy = MAX_SUMMARY_TOKENS - 1\nemb_dim = EMB_OUT\nn_a = ENCODER_STATE_DIM\nn_s= DECODER_STATE_DIM\nd1_units = DENSE1_UNITS\nd2_units = DENSE2_UNITS\nd_units = DENSE_UNITS\narticle_vocab_size = VOCAB_SIZE\nsummary_vocab_size = VOCAB_SIZE\n\npointer_model = pointer_gen_model(Tx, Ty,\n                          emb_dim, n_a, n_s, d1_units, d2_units, d_units,\n                          article_vocab_size, summary_vocab_size)","metadata":{"id":"n7-mN-LfD69k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Model has {pointer_model.count_params():,} parameters.\")","metadata":{"id":"AkrDZxHbIjFE","outputId":"21ab711c-7c82-4a2f-f55f-28dbe5340521"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A look into how model will output on the above input.","metadata":{"id":"4pJCgf-3IwUW"}},{"cell_type":"code","source":"sample_model_out = pointer_model((art_inp, sum_inp, s0, c0))\n\nprint(f\"Model output has a type: {type(sample_model_out)}\")\nprint(f\"Model Output list for the Inputs above are of length: {len(sample_model_out)}\")\nprint(f\"Model Output list has each output of shape: {sample_model_out[0].shape}\")","metadata":{"outputId":"0b6914cd-aac6-494d-9aa1-0f1a780ee600","id":"jl_ewDpoIwUi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Custom Loss and Accuracy Version 2","metadata":{"id":"7Vgp0zJ0EDkq"}},{"cell_type":"code","source":"def custom_loss_v2(y_true, y_pred):\n    '''Calculates the loss for the baseline model. The loss is calculated by taking the negative\n    log-likelihood of the target word(w*_t) in the current timestep. Then the overall loss\n    is the summation over all timesteps divided by T (not Ty because it would include paddings also).\n\n    Arguments:\n    y_true: tf.Tensor object, true values for the target\n    y_pred: list of tf.Tensor objects, predicted probablities of the summary words\n\n    Returns:\n    returns the loss on the predicted values for the model\n    '''\n    # Calculate the loss for each item in the batch.\n    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n    loss = loss_fn(y_true, y_pred)\n\n    # Remove the paddings from calculation of loss\n    mask = tf.cast(y_true != 0, loss.dtype)\n    loss *= mask\n\n    # Divide the total loss after masking out paddings divided by total words which are not paddings\n    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n\n\ndef custom_accuracy_v2(y_true, y_pred):\n    '''Calculates accuracy of the baseline model. The accuracy is calculated by matching how many correct\n    words were predicted excluding the paddings. Then, just add those which are correct and you will get the\n    the accuracy and then just divide it by total words not including padding.\n\n    Arguments:\n    y_true: tf.Tensor object, expected target values\n    y_pred: list of tf.Tensor object, predicted target values by model\n\n    Returns:\n    returns the total accuracy over the batch of data\n    '''\n    # Find the word index with maximum probablity\n    y_pred = tf.argmax(y_pred, axis=-1)\n    y_pred = tf.cast(y_pred, y_true.dtype)\n\n    # Count the words that matches with true values\n    match = tf.cast(y_pred == y_true, tf.float32)\n    mask = tf.cast(y_true != 0, tf.float32)\n\n    # Mask out the paddings\n    match *= mask\n\n    return tf.reduce_sum(match) / tf.reduce_sum(mask)","metadata":{"id":"E_SW6SzNDH1E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Testing with loss and accuracy","metadata":{"id":"ShbQdiQqILXu"}},{"cell_type":"code","source":"print(f\"Sample y true values: {sum_tar}\")\nprint(f\"Sample y pred values(first 10 values of first 2 timestep): {sample_model_out[:2]}\")\n\nsample_loss = custom_loss_v2(sum_tar, sample_model_out)\nprint(f\"Loss of the sample y_true and y_pred: {sample_loss}\")\n\nsample_acc = custom_accuracy_v2(sum_tar, sample_model_out)\nprint(f\"Accuracy of the sample y_true and y_pred: {sample_acc}\")","metadata":{"outputId":"5b2bc229-776f-4259-9605-4f003e2e2c4c","id":"NOapo56oILX5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Compiling pointer generator model","metadata":{"id":"nT2RqhLFMlHp"}},{"cell_type":"code","source":"lr = LEARNING_RATE\ninitial_accumulator_value = INIT_ACC_VAL\nclipnorm = MAX_GRAD_NORM\n\nopt = Adagrad(learning_rate=lr,\n              initial_accumulator_value=initial_accumulator_value,\n              clipnorm=clipnorm)\n\npointer_model.compile(loss=custom_loss_v2, optimizer=opt, metrics=[custom_loss_v2, custom_accuracy_v2])","metadata":{"id":"WTayhfQFMlH0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Creating callbacks for model","metadata":{"id":"pQSFBBfYMlH0"}},{"cell_type":"code","source":"# Mention the checkpoint path and it's directory where you will save the model\ncheckpoint_path = POINTER_MODEL_CHECKPOINT\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Calculate no of batches, I am taking floor because when creating the training data I used drop_remainder\nn_batches = int(train_dataset.shape[0] / BATCH_SIZE)\n\n# Create the checkpoint for model saving, monitoring val_custom_accuracy_v1 and save only weights of the model\nsaving_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                monitor='val_custom_accuracy_v2',\n                                                verbose=1,\n                                                save_weights_only=True,\n                                                save_freq=n_batches//2)\n\n# Create the checkpoint for stopping early after noticing that val_custom_accuracy_v1 is not increasing even after 5 consecutive epochs\nearlystop_cb = tf.keras.callbacks.EarlyStopping(monitor='val_custom_accuracy_v2',\n                                                    patience=PATIENCE,\n                                                    mode='max',\n                                                    )\n\n# Store the checkpoints in a list\ncallbacks = [saving_cb, earlystop_cb]","metadata":{"id":"BXuC_RPbMlH0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Training pointer generator model","metadata":{"id":"S4iHgb8KMlH0"}},{"cell_type":"code","source":"epochs = POINTER_EPOCHS\nsteps_per_epoch = POINTER_STEPS_PER_EPOCHS\n\nhistory = pointer_model.fit(tf_train_dataset.repeat(),\n                    epochs=epochs,\n                    validation_data=tf_val_dataset,\n                    steps_per_epoch=steps_per_epoch,\n                    callbacks=callbacks\n                    )","metadata":{"id":"z0ZekuBoMlH0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Coverage model: Adding coverage mechanism to prevent repetition","metadata":{}},{"cell_type":"markdown","source":"#### Creating `tf_train_dataset`, `tf_val_dataset` dataset using tf.data API\n\nI already have created to the `generate_example` function, I can use it again to generate examples for training and validation respectively.\n\nBut this time I have to also consider the `<OOV>` with token value `1`. Instead of using `1`, I have to generate a new token value for each of the `<OOV>` words.\n\nHow to do it?","metadata":{"id":"0Y9oJUdnUM_Z"}},{"cell_type":"markdown","source":"##### `find_oovs`, `map_oovs` & `tokenize_oovs` function","metadata":{"id":"nJY4-VAaEfuF"}},{"cell_type":"code","source":"def find_oovs(sent, sent_token, sent_len):\n    '''Finds the out of vocabulary words from `sent` with the help of already tokenized `sent_tokens`.\n\n    Arguments:\n    sent: str, sentence to find the oov from\n    sent_token: 2D np.array, the tokenized form of the sentence with sent_len length\n    sent_len: int, length of the tokenized sentence\n\n    Returns:\n    Returns a list of all oov words in the `sent`\n    '''\n    analyzed_sent = custom_analyzer(sent)\n    oov_words = [w for i, w in enumerate(analyzed_sent[:sent_len]) if (sent_token[0][i] == 1)]\n    return oov_words\n\ndef map_oovs(oovs, oov_start_token):\n    '''Stores the out of vocabulary words in a dictionary and sets the values of each oov key to\n    a temporary unique tokens.\n\n    Arguments:\n    oovs: list of oov words\n    oov_start_token: int, the first value to use as oov token then increase by 1\n\n    Returns:\n    dictionary of (oov, token) as (key, value) pairs\n    '''\n    unique_oovs = list(set(oovs))\n    oov_tokens = [oov_start_token+i for i in range(len(unique_oovs))]\n\n    oov_dict = dict(zip(unique_oovs, oov_tokens))\n\n    return oov_dict\n\ndef tokenize_oovs(sent, sent_token, oov_dict, sent_len):\n    '''Tokenize the sent by replacing the oov tokens by new unique tokens from oov_dict.\n\n    Arguments:\n    sent: str, sentence to handle the oovs\n    sent_token: 2D np.array of tokens\n    oov_dict: dictionary, oov words and their tokens are stored here\n    sent_len: int, length of the sentence token array\n\n    Returns:\n    tokenized sentence with oov words tokenized to temporary oov tokens\n    '''\n    analyzed_sent = custom_analyzer(sent)\n\n    for i, w in enumerate(analyzed_sent[:sent_len]):\n        if w in oov_dict.keys():\n            sent_token[0, i] = oov_dict[w]\n\n    return sent_token","metadata":{"id":"WkfC7nfwghMI","execution":{"iopub.status.busy":"2023-08-22T09:50:48.697322Z","iopub.execute_input":"2023-08-22T09:50:48.697750Z","iopub.status.idle":"2023-08-22T09:50:48.708321Z","shell.execute_reply.started":"2023-08-22T09:50:48.697717Z","shell.execute_reply":"2023-08-22T09:50:48.707261Z"},"trusted":true},"execution_count":57,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"##### Applying functions on Examples","metadata":{"id":"MygLMzLXEouR"}},{"cell_type":"code","source":"print(f\"Article:\\n{sample_article}\\n\\n\")\n\nsample_article_tokens = tokenize_pad([sample_article],\n                              tokenizer,\n                              padding=\"post\",\n                              truncating=\"post\",\n                              maxlen=MAX_ARTICLE_TOKENS)\nprint(f\"sample article tokens:\\n{sample_article_tokens}\\n\\n\")\n\nsample_oovs = find_oovs(sample_article, sample_article_tokens, MAX_ARTICLE_TOKENS)\nprint(f\"OOVs in the sample article:\\n{sample_oovs}\\n\\n\")\n\nsample_oov_dict = map_oovs(sample_oovs, VOCAB_SIZE)\nprint(f\"OOV dictionary:\\n{sample_oov_dict}\\n\\n\")\n\nsample_article_tokens_with_oovs = tokenize_oovs(sample_article, sample_article_tokens, sample_oov_dict, MAX_ARTICLE_TOKENS)\nprint(f\"sample article tokens with oov tokens:\\n{sample_article_tokens_with_oovs}\")","metadata":{"id":"cqzj5WV-ihFC","outputId":"9870ca93-d734-4d2d-bf84-bdd7e64fae10","execution":{"iopub.status.busy":"2023-08-22T09:50:52.196747Z","iopub.execute_input":"2023-08-22T09:50:52.197155Z","iopub.status.idle":"2023-08-22T09:50:52.211524Z","shell.execute_reply.started":"2023-08-22T09:50:52.197123Z","shell.execute_reply":"2023-08-22T09:50:52.210500Z"},"trusted":true},"execution_count":58,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Article:\nnew york (cnn) -- the u.s. population is expected to top out at close to 312.8 million people just around the time crowds gather to watch the ball drop on new year's eve, according to new census data released thursday. the figure represents a 0.7% increase from last year, adding 2,250,129 people to the u.s. population since the start of 2011, and a 1.3% increase since census day, april 1, 2010. the agency estimates that beginning in january, one american will be born every eight seconds and one will die every 12 seconds. u.s.-bound immigrants are also expected to add one person every 46 seconds. that combination of births, deaths and migration is expected to add a single person to the u.s. population every 17 seconds, the census bureau said. meanwhile, millions are set to ring in the new year. in new york, authorities are preparing for large crowds in manhattan's times square, where lady gaga is expected to join mayor michael bloomberg to push the button that drops the waterford crystal ball at 11:59 p.m. et on new year's eve. \"and i'm so looking forward to performing on nye+dropping the ball with mayor bloomberg!\" the pop star posted on twitter. \"what an honor as a new yorker.\" past guests have included muhammad ali, rudy giuliani, colin powell and bill and hillary clinton. on thursday, officials conducted new york's annual \"airworthiness test\" -- a process in which confetti is tossed by handfuls above times square -- in preparation for the annual city tradition of dumping one ton of confetti over revelers in the iconic square. the big apple this year edged out las vegas for the first time in seven years as the top travel u.s. destination for those celebrating the new year, according to a december travel booking website poll. seven new york neighborhoods made the top 10 list, with two districts in las vegas and one in new orleans making up the other three, according to the priceline poll. \"it appears that new york city will be helped this year by a weather forecast that calls for warmer than usual temperatures over the holiday weekend,\" said company spokesman brian ek.\n\n\nsample article tokens:\n[[   76    69   279    50   126    49    11    11     3   139     2    12\n      2  1409    17   502     6   232    58    25   394     6     1   152\n     64    75   130     3    71  3442  4135     6   500     3   737  1839\n     16    69    56     5    12  3644     4   143     6    69  7953   911\n    408   386     2     3  1251  3475     7     1  1141    30    74    56\n      4  1131     1    64     6     3   139     2    12     2  1409   142\n      3   411     9     1     8     7     1  1141   142  7953   112     4\n    544     1     1     3   687  3730    14  1719    10   443     4    52\n    307    48    32   652   243   490  1737     8    52    48  1513   243\n      1  1737     2   139     2    12     2    11  3494  3021    35    65\n    502     6  1952    52   412   243     1  1737     2    14  3945     9\n   9192     4  1414     8  6402    17   502     6  1952     7   864   412\n      6     3   139     2    12     2  1409   243     1  1737     4     3\n   7953  3872    23     2  1175     4  1285    35   222     6  1898    10\n      3    69    56     2    10    69   279     4   376    35  2905    15\n    574  3442    10  2592     5    12   241  1330     4   106  1470  8770\n     17   502     6  1381  1459   534  5404     6  2051     3  3517    14\n   7137     3 39788  2801   737    25     1  1120     2   136     2  4978\n     16    69    56     5    12  3644     2    18     8    27     5   136\n     72   381   594     6  3146    16 12946  4835  4329     3   737    21\n   1459  5404   284    18     3  2409   385   726    16   602     2    18\n     79    38  2825    26     7    69 12664     2    18   346  1835    29\n    935  7681  2510     4 12507 15918     4  5235  4404     8   695     8\n   3042  1098     2    16   386     4   310  2458    69   279     5    12\n   1614    18 49905   811    18    11    11     7   761    10    55 23442\n     17 10004    28 40643   645   241  1330    11    11    10  5064    15\n      3  1614   148  3701     9 10286    52  8555     9 23442    82 21027\n     10     3  2918  1330     2     3   301  1005    39    56 10488    58\n   2897  2795    15     3    83    71    10   465    87    26     3   232\n    856   139     2    12     2  3973    15   146  3448     3    69    56\n      4   143     6     7   517   856  6738   632  2217     2   465    69\n    279  7361   118     3   232     1   816     4    21    68  8489    10\n   2897  2795     8    52    10    69  4642   342    57     3    95   107\n      4   143     6     3]]\n\n\nOOVs in the sample article:\n['312.8', '0.7%', '2,250,129', '2011,', '1.3%', '1,', '2010.', '12', '46', '17', '11:59', '10']\n\n\nOOV dictionary:\n{'312.8': 50000, '0.7%': 50001, '10': 50002, '1,': 50003, '17': 50004, '11:59': 50005, '2011,': 50006, '12': 50007, '2010.': 50008, '2,250,129': 50009, '46': 50010, '1.3%': 50011}\n\n\nsample article tokens with oov tokens:\n[[   76    69   279    50   126    49    11    11     3   139     2    12\n      2  1409    17   502     6   232    58    25   394     6 50000   152\n     64    75   130     3    71  3442  4135     6   500     3   737  1839\n     16    69    56     5    12  3644     4   143     6    69  7953   911\n    408   386     2     3  1251  3475     7 50001  1141    30    74    56\n      4  1131 50009    64     6     3   139     2    12     2  1409   142\n      3   411     9 50006     8     7 50011  1141   142  7953   112     4\n    544 50003 50008     3   687  3730    14  1719    10   443     4    52\n    307    48    32   652   243   490  1737     8    52    48  1513   243\n  50007  1737     2   139     2    12     2    11  3494  3021    35    65\n    502     6  1952    52   412   243 50010  1737     2    14  3945     9\n   9192     4  1414     8  6402    17   502     6  1952     7   864   412\n      6     3   139     2    12     2  1409   243 50004  1737     4     3\n   7953  3872    23     2  1175     4  1285    35   222     6  1898    10\n      3    69    56     2    10    69   279     4   376    35  2905    15\n    574  3442    10  2592     5    12   241  1330     4   106  1470  8770\n     17   502     6  1381  1459   534  5404     6  2051     3  3517    14\n   7137     3 39788  2801   737    25 50005  1120     2   136     2  4978\n     16    69    56     5    12  3644     2    18     8    27     5   136\n     72   381   594     6  3146    16 12946  4835  4329     3   737    21\n   1459  5404   284    18     3  2409   385   726    16   602     2    18\n     79    38  2825    26     7    69 12664     2    18   346  1835    29\n    935  7681  2510     4 12507 15918     4  5235  4404     8   695     8\n   3042  1098     2    16   386     4   310  2458    69   279     5    12\n   1614    18 49905   811    18    11    11     7   761    10    55 23442\n     17 10004    28 40643   645   241  1330    11    11    10  5064    15\n      3  1614   148  3701     9 10286    52  8555     9 23442    82 21027\n     10     3  2918  1330     2     3   301  1005    39    56 10488    58\n   2897  2795    15     3    83    71    10   465    87    26     3   232\n    856   139     2    12     2  3973    15   146  3448     3    69    56\n      4   143     6     7   517   856  6738   632  2217     2   465    69\n    279  7361   118     3   232 50002   816     4    21    68  8489    10\n   2897  2795     8    52    10    69  4642   342    57     3    95   107\n      4   143     6     3]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### `generate_example_v2` function creation","metadata":{"id":"b4U6JUL9ExLh"}},{"cell_type":"code","source":"def generate_example_v3(inputs, targets,\n                        input_tokenizer, target_tokenizer,\n                        input_len, target_len,\n                        padding=\"post\", truncating=\"post\",\n                        vocab_size=VOCAB_SIZE):\n\n    '''Generates examples for the Pointer Generator model. Processes the `inputs` and `targets`\n    with their respective tokenizers and tokenize them to `input_len` and `target_len` length.\n    After tokenizing the article words, it looks for the out-of-vocabulary words and creates unique tokens\n    for each of those OOV words. Then, instead of keeping the oov word tokens as 1, it replaces them\n    with their respective newly generated tokens. This tokens are temporary\n\n    Arguments:\n    inputs: list of input sentences\n    targets: list of target sentences\n    input_tokenizer: Tokenizer class object, tokenizer for inputs\n    target_tokenizer: Tokenizer class object, tokenizer for targets\n    input_len: int, the length of the tokenization for inputs\n    target_len: int, the length of the tokenization for targets\n\n    Returns:\n    returns 2 values, a tuple containing 2 numpy arrays (input_tokens, target_tokens[:-1]) and\n    another numpy array target_tokens[1:]\n    '''\n\n    for inp, tar in zip(inputs, targets):\n        # Tokenizing article words\n        inp_token = tokenize_pad([inp],\n                                  input_tokenizer,\n                                  padding=padding,\n                                  truncating=truncating,\n                                  maxlen=input_len)\n\n        oov_words = find_oovs(inp, inp_token, input_len)\n        oov_dict = map_oovs(oov_words, oov_start_token=vocab_size)\n        inp_token = tokenize_oovs(inp, inp_token, oov_dict, input_len)\n\n        # Tokenizing summary words\n        tar_token = tokenize_pad([tar],\n                     target_tokenizer,\n                     padding=padding,\n                     truncating=truncating,\n                     maxlen=target_len)\n        tar_token = tokenize_oovs(tar, tar_token, oov_dict, target_len)\n\n        yield (inp_token[0], tar_token[0][:-1]), tar_token[0][1:]","metadata":{"id":"bWzy1fmHTG_j","execution":{"iopub.status.busy":"2023-08-22T09:50:56.683181Z","iopub.execute_input":"2023-08-22T09:50:56.683598Z","iopub.status.idle":"2023-08-22T09:50:56.693709Z","shell.execute_reply.started":"2023-08-22T09:50:56.683559Z","shell.execute_reply":"2023-08-22T09:50:56.692869Z"},"trusted":true},"execution_count":59,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"##### Examples with the generator function","metadata":{"id":"g66B6U8bE3jA"}},{"cell_type":"code","source":"print(f\"Example generated by the generator v3:\")\n\n# (inp_art_tokens, inp_sum_tokens), tar_sum_tokens = generate_example(list(train_dataset[:, 0]),\nexample_gen = generate_example_v3(list(train_dataset[:, 0]),\n                               list(train_dataset[:, 1]),\n                               input_tokenizer=tokenizer,\n                               target_tokenizer=tokenizer,\n                               input_len=MAX_ARTICLE_TOKENS,\n                               target_len=MAX_SUMMARY_TOKENS)\n\ninps, tar = next(example_gen)\nprint(f\"Inputs:\\n{inps[0]}\\n{inps[1]}\\n\\n\")\nprint(f\"Target:\\n{tar}\")","metadata":{"id":"eA3joMNfbcjL","outputId":"45e75c51-882f-4132-99de-f5ba713c43d7","execution":{"iopub.status.busy":"2023-08-22T09:51:00.591512Z","iopub.execute_input":"2023-08-22T09:51:00.592587Z","iopub.status.idle":"2023-08-22T09:51:00.660524Z","shell.execute_reply.started":"2023-08-22T09:51:00.592548Z","shell.execute_reply":"2023-08-22T09:51:00.659129Z"},"trusted":true},"execution_count":60,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Example generated by the generator v3:\nInputs:\n[   76  2945  5479     5    12   862  2856    11  4100    13     3   589\n    16   658     5    12  5932    16   386   409     4    34     3  1770\n   153   173    19    17     7   453   179   575     2  3151  3455     5\n    12   266  1244    15     3  2992 50003 14183   124  1088 12952     8\n 10577    31    46   680     4    34    10     7 14450    30     3  1770\n     4     3   486  1244  5331  2598  5479    26     7   453   179   575\n     4   333    24   402     6     3  4211     2   862  1164  5479    15\n 50000    16  4885   112    10   509     4     8  1085    24    83   707\n  2856    11  4100    15     3  5896    16   360   194     2    25     3\n  1656     9     3  1770     5    12   266  1244  5331     4     5  1630\n  5479     5    17  2598    26     7   453   179   575     2  5479  1085\n    24    83   707  2856    11  4100    16   360    10     3   542     8\n   306     9   862     4    25     3  4211     2   274    24   402     6\n   282   213     4  5479    41   561     3   843     9    24  1495  1460\n    25   179     4  1434  1875  2998     6  5946     8  2833     2    19\n   118    24  2447    15     3    94  2976  3935    10 50002    34    44\n   245    87     8 50001  2791     4   191     7  5253     6    24   179\n   707     8   732     6   862     2  5479    13  1696  1364  2575  2090\n     8 10029  4812     6   598     3   512    15    24   181     4    34\n     3  1166     5    12    71    25   179   153  1104     6   418   185\n    10     3  2184     9   554    25     3  1770     2 15514     2  7150\n 12232    50  2094    49     4  1805  3384    50   295  4651    49     4\n  1662  3397    50   453   148    49  5594     2 10541 10147    50  2145\n    49     4  2219  7212    50   638    49     4 12901 15700    50  2094\n    49     4  7276  7647    50   862    49     4  2768 13526    50  2145\n    49     4   373  4663    50  2145    49 12837     2 13058 14821    50\n  3267  1936    49     4  2009  4973    50   637    49     4  2108  8081\n    50   637    49     4   590  9120    50   453   148    49     4  1633\n  9887    11  7615    50   862    49     4 24304 18496    50  2988    49\n     4  6327  2344    50   637    49     4 18948  8834    50  1913    49\n     4  1709  6424    50   862    49  8335     2 10029  4812    50   637\n    49     4  2575  2090    50   453   179    49     4  2945  5479    50\n   862    49     2  5479   561   245    87    10     3    83   162    25\n   179     4   192    50]\n[   76   862  1164  2945  5479    30   138     1  4885   112     2  5479\n   686     3  5896 50000     2     3  1770  2749     6  5479    26     7\n   138 17570   575    10    45   486   162    11  5331   408     6     3\n   655     2    77     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0]\n\n\nTarget:\n[  862  1164  2945  5479    30   138     1  4885   112     2  5479   686\n     3  5896 50000     2     3  1770  2749     6  5479    26     7   138\n 17570   575    10    45   486   162    11  5331   408     6     3   655\n     2    77     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0]\n","output_type":"stream"}]},{"cell_type":"code","source":"inps, tar = next(example_gen)\nprint(f\"Inputs:\\n{inps[0]}\\n{inps[1]}\\n\\n\")\nprint(f\"Target:\\n{tar}\")","metadata":{"id":"hIuAkQbO7Bzz","outputId":"37076516-319c-4750-a9f7-917e0ff937b0","execution":{"iopub.status.busy":"2023-08-22T09:51:19.776462Z","iopub.execute_input":"2023-08-22T09:51:19.777223Z","iopub.status.idle":"2023-08-22T09:51:19.791954Z","shell.execute_reply.started":"2023-08-22T09:51:19.777180Z","shell.execute_reply":"2023-08-22T09:51:19.790625Z"},"trusted":true},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Inputs:\n[   76    28     2   534 21289     2     7   631    11 43294  9896 21290\n  2322   113  3185   739    39   409    44    19   205     7  4544   113\n     7  8263   631   970 13059     4   374     8  2138   107    85   380\n     8  4004     7  1244   240    92    19    13  7266    99    10     3\n   435    21    38  9570     2     3 13660   451    25 50000   323    53\n  5356 50003   552     6  3059     7 29036    10   270  9591     8     3\n   715   230 15554   803     2    85   155    19   205     7  4544    10\n    38  1178     6   116    79    19   382     2    85   408     7  2314\n   936   836  1119 50002    11    94 50003    21    24  1728   130     7\n   981  4544     5    12  4059   101    19   802     7 23804  6515    25\n    33   261     2    36    13   206   408 10191     2  1885    23 50003\n    13   831     2  7858  2010    15    24  7971     8   413 10105   467\n    14    13     2 12189    21    24   218   456     2   367    99    15\n   158     2  8003    22    85   155    39  2314   936   836   429  5356\n 50003     4 50006    44    19   205     7  4544   113     7  8263   631\n   970  3314     2  3987  1241   212     7   247    40   767   508  1012\n    30     7  1176  1455  1937    44     7    85  2136    11    58    14\n   271    68  2239     2     7   138    40   815    25     3   715   543\n     8  1235   446    26 50003     5    12   463    81     3  2322  4932\n    14 50003  7108     3 11027     6   293    24   631  4424     2    19\n    23    14 50003    41    46    38 42210  3749    92    19     5   989\n    10    21     3   803  1324     2     5    60 50005     4  2322   507\n 18122  3347  1643 50003     5    12  2010    25     7  5361   427    60\n    68   626    30     3  3314   543     2  1253    22  5356 50003     4\n 50006    17     7   631  8883    40    13   419     6   116   269    15\n    24  4424     4     7   463    81  1326     2    53     3 50004    85\n  2367  2850     3  1004     4 50003   374    70    10     3  2888     2\n     3  8911   117   205     3   507     5    12  6515     8 10200   115\n    10    24  1244   240     2 50001    11   576   609    14  3347    90\n    32   387 20638    15  4359    26    19 25240    10     7  5514     9\n     3   138    40   374    70     2     5   306  1436     2   542  1789\n     2  3958  5280     2   507    99     2     5    14     2   222   115\n     7  9860  8345   314     3   148     2   296    38   739   206     4\n     3     2  1244   240]\n[   76  5356 50003     4 50006  7108     7 29036     8   186    24   467\n  2010    21    24   218   456 14788    16    20    26     7  8673  1004\n     2    19   374    38   507    10     3  2888     8  4004    24   848\n     8  1244   240    53    19    13   125     2    19 12479     3  1244\n   240     8   205   115    21    38  9570    10    24  2451     5    12\n 16134     2 50003  2347     3 16134     8  1136   397    25   380     2\n    68    59   380    47  2138     2    85   879   397     8   271   201\n   242    10     3   240     2    77     0     0     0     0     0     0\n     0     0     0]\n\n\nTarget:\n[ 5356 50003     4 50006  7108     7 29036     8   186    24   467  2010\n    21    24   218   456 14788    16    20    26     7  8673  1004     2\n    19   374    38   507    10     3  2888     8  4004    24   848     8\n  1244   240    53    19    13   125     2    19 12479     3  1244   240\n     8   205   115    21    38  9570    10    24  2451     5    12 16134\n     2 50003  2347     3 16134     8  1136   397    25   380     2    68\n    59   380    47  2138     2    85   879   397     8   271   201   242\n    10     3   240     2    77     0     0     0     0     0     0     0\n     0     0     0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### Making training, validation set examples for pointer generator model","metadata":{"id":"Ix6RsiveGSQS"}},{"cell_type":"code","source":"def train_example_generetor_v3():\n    example_gen = generate_example_v3(list(train_dataset[:, 0]),\n                                list(train_dataset[:, 1]),\n                                input_tokenizer=tokenizer,\n                                target_tokenizer=tokenizer,\n                                input_len=MAX_ARTICLE_TOKENS,\n                                target_len=MAX_SUMMARY_TOKENS)\n\n    for example in example_gen:\n        s0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n        c0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n        cov_0 = np.zeros((MAX_ARTICLE_TOKENS, 2*ENCODER_STATE_DIM), dtype=np.int32)\n\n        (input_0, input_1), target = example\n        yield (input_0, input_1, s0, c0, cov_0), target","metadata":{"id":"ZCRXKTLZGX_I","execution":{"iopub.status.busy":"2023-08-22T09:52:16.231748Z","iopub.execute_input":"2023-08-22T09:52:16.232131Z","iopub.status.idle":"2023-08-22T09:52:16.241076Z","shell.execute_reply.started":"2023-08-22T09:52:16.232087Z","shell.execute_reply":"2023-08-22T09:52:16.240064Z"},"trusted":true},"execution_count":65,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"output_signature = (\n    (\n        tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, ), dtype=tf.int32), \n        tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32), \n        tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32),\n        tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32),\n        tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, 2*ENCODER_STATE_DIM), dtype=tf.int32)\n    ),\n    tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32)\n)\n\ntf_train_dataset = tf.data.Dataset.from_generator(generator=train_example_generetor_v3,\n                                                  output_signature=output_signature)\ntf_train_dataset = tf_train_dataset.shuffle(BUFFER_SIZE)\ntf_train_dataset = tf_train_dataset.batch(BATCH_SIZE, drop_remainder=True)\ntf_train_dataset = tf_train_dataset.prefetch(1)","metadata":{"id":"NBdNpR7rGw7m","execution":{"iopub.status.busy":"2023-08-22T09:52:18.971700Z","iopub.execute_input":"2023-08-22T09:52:18.972078Z","iopub.status.idle":"2023-08-22T09:52:19.014415Z","shell.execute_reply.started":"2023-08-22T09:52:18.972049Z","shell.execute_reply":"2023-08-22T09:52:19.013603Z"},"trusted":true},"execution_count":66,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"def val_example_generetor_v3():\n    example_gen = generate_example_v3(list(val_dataset[:, 0]),\n                                list(val_dataset[:, 1]),\n                                input_tokenizer=tokenizer,\n                                target_tokenizer=tokenizer,\n                                input_len=MAX_ARTICLE_TOKENS,\n                                target_len=MAX_SUMMARY_TOKENS)\n\n    for example in example_gen:\n        s0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n        c0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n        cov_0 = np.zeros((MAX_ARTICLE_TOKENS, 2*ENCODER_STATE_DIM), dtype=np.int32)\n        \n        (input_0, input_1), target = example\n        yield (input_0, input_1, s0, c0, cov_0), target\n\n\noutput_signature = (\n    (\n        tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, ), dtype=tf.int32), \n        tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32), \n        tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32), \n        tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32), \n        tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, 2*ENCODER_STATE_DIM), dtype=tf.int32)\n    ),\n    tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32)\n)\n\ntf_val_dataset = tf.data.Dataset.from_generator(generator=val_example_generetor_v3,\n                                                  output_signature=output_signature)\ntf_val_dataset = tf_val_dataset.shuffle(BUFFER_SIZE)\ntf_val_dataset = tf_val_dataset.batch(BATCH_SIZE, drop_remainder=True)","metadata":{"id":"byX6PXAKGw7y","execution":{"iopub.status.busy":"2023-08-22T09:52:27.711872Z","iopub.execute_input":"2023-08-22T09:52:27.712302Z","iopub.status.idle":"2023-08-22T09:52:27.755292Z","shell.execute_reply.started":"2023-08-22T09:52:27.712270Z","shell.execute_reply":"2023-08-22T09:52:27.754486Z"},"trusted":true},"execution_count":68,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"for (art_inp, sum_inp, s0, c0, cov_0), sum_tar in tf_train_dataset.take(1):\n    print(f\"Input tokenized article shape: {art_inp.shape}\")\n    print(f\"Input tokenized summary shape: {sum_inp.shape}\\n\")\n\n    print(f\"Target tokenized summary shape: {sum_tar.shape}\")","metadata":{"outputId":"e0bdb027-6b00-4229-ebe4-f55c93e2964d","id":"2fZlevYZGw7y","execution":{"iopub.status.busy":"2023-08-22T09:52:39.571758Z","iopub.execute_input":"2023-08-22T09:52:39.572226Z","iopub.status.idle":"2023-08-22T09:53:05.314382Z","shell.execute_reply.started":"2023-08-22T09:52:39.572187Z","shell.execute_reply":"2023-08-22T09:53:05.313162Z"},"trusted":true},"execution_count":69,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Input tokenized article shape: (16, 400)\nInput tokenized summary shape: (16, 99)\n\nTarget tokenized summary shape: (16, 99)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Pointer Generator\n\nThe function `generate_pointer` will return the $p_{gen}$. $p_{gen}$ will be used to decide whether the next word needs to be copied from the article or we should generate a new word from the vocabulary. This decision will be taken using the equation- $$P(w) = p_{gen}*P_{vocab}(w) + (1-p_{gen})*\\sum_{i:w_i=w}a^t_i$$\n\nWhere\n- $P$ is the extended vocabulary containing words from vocabulary and article both.\n- $a^t_i$ is the attention $t^{th}$ time step need to give to $i^{th}$ article word.\n- $P_{vocab}$ is the previous vocabulary distribution without considering words from article.","metadata":{"id":"j7wikoNOuKsd"}},{"cell_type":"markdown","source":"##### Pointer Generator Network\n\nPointer network takes the context vector ($h^{*(t)}$), decoder embedding input($x^{(t)}$) and decoder hidden state ($s^{(t)}$). The equation of the pointer network is - $$p_{gen} = \\sigma(W_h^Th^{*(t)}+W_x^Tx^{(t)}+W_s^Ts^{(t)}+b_{ptr})$$","metadata":{"id":"PlMlegsIEbsG"}},{"cell_type":"code","source":"def pointer_generator_v2(context_vector, decoder_state, decoder_inp):\n    '''Generates the p_gen needed to calculate the final vocabulary distribution.\n    It takes the context, decoder hidden state and decoder embedding input as it's input and then\n    passes them through a dense layer to get the pointer generator.\n\n    Arguments:\n    context_vector: Tensor of shape (batch, n_a)\n    decoder_state: Tensor of shape (batch, n_s)\n    decoder_inp: Tensor of shape (batch, emb_dim)\n\n    Returns:\n    returns the pointer generator p_gen\n    '''\n    concat = Concatenate(axis=-1)([context_vector, decoder_state, decoder_inp])\n    p_gen = tf.keras.layers.Dense(units=1, activation='sigmoid')(concat)\n\n    return p_gen","metadata":{"id":"P7y1utw3mAZw","execution":{"iopub.status.busy":"2023-08-22T09:53:10.613372Z","iopub.execute_input":"2023-08-22T09:53:10.615168Z","iopub.status.idle":"2023-08-22T09:53:10.622883Z","shell.execute_reply.started":"2023-08-22T09:53:10.615090Z","shell.execute_reply":"2023-08-22T09:53:10.622007Z"},"trusted":true},"execution_count":70,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"#### Attention mechanism for coverage integrated model\n\nThe coverage vector is used as extra input to the attention mechanism, $$e^t_i = v^Ttanh(W_hh_i+W_ss_t+w_cc^t_i+b_{ptr})$$","metadata":{}},{"cell_type":"code","source":"def one_time_attention_v3(a, s_prev, c_t,\n                       repeater, concatenator, densor_1, densor_2, softmax_layer, dotter):\n    '''Calculates the attention score and returns the context and attention distribution for the current\n    timestep in the decoder.\n    Attention mechanism uses encoder outputs `a` of shape `(batch, timesteps, features)` and decoder\n    previous hidden state `s_prev` of shape `(batch, features)`, then calculates alignment scores `alphas`\n    for each encoder timestep with the help of energies computed with 2 dense layers using `a` and `s_prev`.\n\n    Arguments:\n    a: tf.Tensor object, encoder output of shape `(batch, timesteps, features)` or `(batch, Tx, 2*n_a)`\n    s_prev: tf.Tensor object, decoder previous hidden state of shape `(batch, features)` or `(batch, n_s)`\n    c_t: tf.Tensor object, coverage vector \n    repeater: RepeatVector layer, repeat the `s_prev` `Tx` times\n    concatenator: Concatenate layer, concatenates `a` and repeated `s_prev`, Concatenates along axis=-1\n    densor_1: Dense layer, calculates the pertial energies `e`, with `units=d1_units`\n    refer to `baseline_model` function for details about this variable\n    densor_2: Dense layer, calculated the energies `energies`, with `units=d2_units`\n    refer to `baseline_model` function for details about this variable\n    softmax_layer: Activation layer, computes softmax of the energies and calculates `alphas`, with\n    `units=article_vocab_size` refer to `baseline_model` function for details about this variable\n    dotter: Dot layer, Performs dot operation between `alphas` and `a` along axis=1\n\n    Returns:\n    returns the context of shape `(batch, 1, 2*n_a)` and\n    attention distribution of shape `(batch, Tx, d2_units)`\n    '''\n\n    # Repeat the `s_prev` `Tx` times\n    s_prev = repeater(s_prev) # (batch, Tx, n_s)\n\n    # Concatenate `a` and `s_prev` along axis=-1\n    concat = concatenator([a, s_prev, c_t]) # (batch, Tx, n_a + n_s)\n\n    # Apply dense layer to get partial energies e\n    e = densor_1(concat) # (batch, Tx, d1_units)\n\n    # Apply dense layer again to get energies\n    energies = densor_2(e) # (batch, Tx, d2_units)\n\n    # Apply softmax over the energies\n    alphas = softmax_layer(energies) # (batch, Tx, d2_units)\n\n    # Dot the alphas and a along axes=1\n    context = dotter([alphas, a]) # (batch, d2_units, 2*n_a)\n\n    return context, alphas","metadata":{"execution":{"iopub.status.busy":"2023-08-22T09:53:15.713483Z","iopub.execute_input":"2023-08-22T09:53:15.713911Z","iopub.status.idle":"2023-08-22T09:53:15.725752Z","shell.execute_reply.started":"2023-08-22T09:53:15.713871Z","shell.execute_reply":"2023-08-22T09:53:15.724340Z"},"trusted":true},"execution_count":71,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"def calculate_final_distribution(final_dist, copy_dist, inp_tokens):\n    rows_range = tf.range(tf.shape(inp_tokens)[0])\n    cols_range = tf.range(tf.shape(inp_tokens)[1])\n    rows, _ = tf.meshgrid(rows_range, cols_range, indexing='ij')\n\n    indices_to_update = tf.stack([tf.reshape(rows, [-1]), tf.reshape(inp_tokens, [-1])], axis=1)\n\n    return tf.tensor_scatter_nd_add(tensor=final_dist,\n                                  indices=indices_to_update,\n                                  updates=tf.reshape(copy_dist, [-1]))","metadata":{"id":"CzPfYicOG7sF","execution":{"iopub.status.busy":"2023-08-22T09:56:38.917150Z","iopub.execute_input":"2023-08-22T09:56:38.917573Z","iopub.status.idle":"2023-08-22T09:56:38.925467Z","shell.execute_reply.started":"2023-08-22T09:56:38.917541Z","shell.execute_reply":"2023-08-22T09:56:38.924753Z"},"trusted":true},"execution_count":74,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"#### Coverage model with pointer generator\n\nHere, we are going to maintain a `coverage vector` $c^t$, which is the sum of all attention distributions over all previous decoder time-steps.\n$$c^t = \\sum_{t'=0}^{t'-1}a^{t'}$$\n\nAlso to address the fact that we do not want repetition, we have to penalize the summaries where same words are given attention multiple times. We can write the following to address this issue and prevent the model from repetition, $$covloss^t = \\sum_{i}min(a^t_i, c^t_i)$$","metadata":{}},{"cell_type":"code","source":"x = tf.random.uniform(shape=[1, 2, 3], minval=-10, maxval=10, dtype=tf.int32)\ny = tf.random.uniform(shape=[1, 2, 3], minval=-10, maxval=10, dtype=tf.int32)\nprint(f\"x:\\n{x}\\n\\ny:\\n{y}\\n\")\nprint(f\"Result of using minimum: {tf.math.minimum(x, y)}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-22T09:43:49.685268Z","iopub.execute_input":"2023-08-22T09:43:49.685991Z","iopub.status.idle":"2023-08-22T09:43:49.697650Z","shell.execute_reply.started":"2023-08-22T09:43:49.685958Z","shell.execute_reply":"2023-08-22T09:43:49.696474Z"},"trusted":true},"execution_count":56,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"x:\n[[[ 0 -6 -2]\n  [-6  9  5]]]\n\ny:\n[[[ -7  -1   2]\n  [ -9 -10   3]]]\n\nResult of using minimum: [[[ -7  -6  -2]\n  [ -9 -10   3]]]\n","output_type":"stream"}]},{"cell_type":"code","source":"def pointer_gen_coverage_model(Tx, Ty, \n                               emb_dim, n_a, n_s, d1_units, d2_units, d_units, \n                               article_vocab_size, summary_vocab_size):\n    '''This implements the pointer generator archietecture with coverage mechanism for summarization.\n    It is a seq-seq model with attention mechanism implemented in it. The encoder take an input\n    with `Tx` time-steps and summarizes with the help of decoder into Ty words. The encoder and decoder\n    hidden states are `n_a` and `n_s` dimension respectively. The words are taken from the vocabulary of\n    article and summary `article_vocab` and `summary_vocab` with size `article_vocab_size` and\n    `summary_vocab_size` respectively.\n\n    Arguments:\n    Tx: int, length of the input article\n    Ty: int, length of the output summary\n    n_a: int, dimension of the encoder hidden states\n    n_s: int, dimension of the deocder hidden states\n    d1_units: int, units for the first dense layer in attention mechanism\n    d2_units: int, units for the second dense layer in attention mechanism\n    d_units: int, units for the dense layer before output layer\n    article_vocab_size: int, length of the article vocabulary\n    summary_vocab_size: int, length of the summary vocabulary\n\n    Returns:\n    returns the base line model\n    '''\n    # Defining the input for our model with shape (None, Tx) and (None, Ty) for encoder input and decoder input\n    X_inp = Input(shape=(Tx), dtype=tf.int32)\n    X_tar = Input(shape=(Ty), dtype=tf.int32)\n\n    # Initialize s0\n    s0 = Input(shape=(n_s, ), name=\"s0\")\n    # Initialize c0\n    c0 = Input(shape=(n_s, ), name=\"c0\")\n\n    # Initialize coverage vector\n    cov_0 = Input(shape=(Tx, 2*n_a), dtype=float)\n    \n    # Initialize the a and s with a0 and s0\n    s = s0 # (batch, n_s)\n    c = c0 # (batch, n_s)\n    \n    # Initialize coverage vector with cov_0\n    cov_t = cov_0\n    \n    # Define the coverage loss\n    covloss_t = 0\n    \n    # Define the outputs as empty list\n    outputs = []\n\n    # First embedding layer for the article input\n    encoder_inp = Embedding(article_vocab_size+Tx, emb_dim)(X_inp) # (batch, Tx, emb_dim)\n\n    # Encoder: Bidirectional layer with LSTM cells\n    a = Bidirectional(LSTM(units=n_a, return_sequences=True))(encoder_inp) # (batch, Tx, n_a)\n\n    # Define the embedding for decoder\n    decoder_inp = Embedding(summary_vocab_size+Tx, emb_dim)(X_tar) # (batch, Ty, emb_dim)\n\n    # Define the layers for Attention so that we can use the same weights for all decoder timesteps\n    repeater = RepeatVector(Tx)\n    concatenator = Concatenate(axis=-1)\n    attn_densor1 = Dense(units=d1_units, activation='tanh')\n    attn_densor2 = Dense(units=d2_units, activation='linear', use_bias=False)\n    softmax_layer = Activation('softmax', name=\"attention_weights\")\n    dotter = Dot(axes=1)\n    \n    \n    # Define the Decoder unidirectional LSTM for shared weights\n    post_attention_lstm = LSTM(units=n_s, return_state=True)\n\n    # Define the last dense layer before output layer with linear activation\n    densor = Dense(units=d_units, activation='linear')\n\n    # Define the output layer so that it does not initalize again and again for shared weights\n    output_layer = Dense(units=summary_vocab_size, activation='softmax')\n\n    # Initialize the extension\n    extension = tf.zeros_like(X_inp, dtype=float)\n  \n    # Decoder: Appends outputs from the output layer in each timestep\n    for t in range(Ty):\n        # Get the decoder input for current timestep\n        curr_dec_in = decoder_inp[:, t:t+1, :] # (batch, 1, emb_dim)\n\n        # Get the context from the attention mechanism\n        context, attn_dist = one_time_attention_v3(a, s, cov_t, # (batch, d2_units, 2*n_a), (batch, Tx, d2_units)\n                                     repeater, concatenator, attn_densor1, attn_densor2, softmax_layer, dotter)\n\n        # Calculate new c_t by summing up the attention dist\n        cov_t += attn_dist\n        \n        covloss_t += tf.reduce_sum(tf.math.minimum(cov_t, attn_dist))\n        \n        concat = Concatenate(axis=-1)([curr_dec_in, context]) # (batch, d2_units, emb_dim+2*n_a); d2_units=1 otherwise error\n        _, s, c = post_attention_lstm(concat, initial_state=[s, c]) # _, (batch, n_s), (batch, n_s)\n\n        # Calculate the output after using 2 linear dense layers\n        den1 = densor(s) # (batch, d_units)\n        den2 = densor(den1) # (batch, d_units)\n        # Use the output_layer to get the vocabulary distribution\n        P_vocab  = output_layer(den2) # (batch, summary_vocab_size)\n\n        # Generate pointer\n        p_gen = pointer_generator_v2(context[:, 0, :], s, curr_dec_in[:, 0, :]) # (batch, 1)\n\n        # Calculate the total probablity of copying words from source text\n        P_copy = (1 - p_gen) * attn_dist[:, :, 0] # (batch, Tx)\n\n        # Calculate the probablity to generate new word\n        P_final = p_gen * P_vocab # (batch, summary_vocab_size)\n\n        # Extend the final vocabulary to take new temporary words from source text\n        P_final = Concatenate(axis=-1)([P_final, extension]) # (batch, summary_vocab_size+Tx)\n\n        # Calculate the extended vocabulary distribution\n        P_final = calculate_final_distribution(P_final, P_copy, X_inp)\n\n        # Append the final output to the outputs list\n        outputs.append(P_final)\n\n    # Stack the list of each timesteps output along axis=1\n    outputs = tf.stack(outputs, axis=1) # (batch, Ty, summary_vocab_size)\n\n    model = Model(inputs=[X_inp, X_tar, s0, c0, cov_0], outputs=outputs)\n    \n    # Add the coverage loss to model\n    model.add_loss(covloss_t)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-08-22T09:56:58.675663Z","iopub.execute_input":"2023-08-22T09:56:58.676048Z","iopub.status.idle":"2023-08-22T09:56:58.695761Z","shell.execute_reply.started":"2023-08-22T09:56:58.676015Z","shell.execute_reply":"2023-08-22T09:56:58.694669Z"},"trusted":true},"execution_count":75,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"#### Coverage model creation and training","metadata":{}},{"cell_type":"code","source":"Tx = MAX_ARTICLE_TOKENS\nTy = MAX_SUMMARY_TOKENS - 1\nemb_dim = EMB_OUT\nn_a = ENCODER_STATE_DIM\nn_s= DECODER_STATE_DIM\nd1_units = DENSE1_UNITS\nd2_units = DENSE2_UNITS\nd_units = DENSE_UNITS\narticle_vocab_size = VOCAB_SIZE\nsummary_vocab_size = VOCAB_SIZE\n\ncoverage_model = pointer_gen_coverage_model(Tx, Ty,\n                          emb_dim, n_a, n_s, d1_units, d2_units, d_units,\n                          article_vocab_size, summary_vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T10:00:55.992462Z","iopub.execute_input":"2023-08-22T10:00:55.992906Z","iopub.status.idle":"2023-08-22T10:01:50.595935Z","shell.execute_reply.started":"2023-08-22T10:00:55.992854Z","shell.execute_reply":"2023-08-22T10:01:50.595004Z"},"trusted":true},"execution_count":77,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Model has {coverage_model.count_params():,} parameters.\")","metadata":{"id":"AkrDZxHbIjFE","outputId":"21ab711c-7c82-4a2f-f55f-28dbe5340521","execution":{"iopub.status.busy":"2023-08-22T10:02:33.571940Z","iopub.execute_input":"2023-08-22T10:02:33.572410Z","iopub.status.idle":"2023-08-22T10:02:33.604343Z","shell.execute_reply.started":"2023-08-22T10:02:33.572372Z","shell.execute_reply":"2023-08-22T10:02:33.603240Z"},"trusted":true},"execution_count":78,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Model has 42,275,891 parameters.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"A look into how model will output on the above input.","metadata":{"id":"4pJCgf-3IwUW"}},{"cell_type":"code","source":"sample_model_out = coverage_model((art_inp, sum_inp, s0, c0, cov_0))\n\nprint(f\"Model output has a type: {type(sample_model_out)}\")\nprint(f\"Model Output list for the Inputs above are of length: {len(sample_model_out)}\")\nprint(f\"Model Output list has each output of shape: {sample_model_out[0].shape}\")","metadata":{"outputId":"0b6914cd-aac6-494d-9aa1-0f1a780ee600","id":"jl_ewDpoIwUi","execution":{"iopub.status.busy":"2023-08-22T10:03:17.272206Z","iopub.execute_input":"2023-08-22T10:03:17.272593Z","iopub.status.idle":"2023-08-22T10:03:29.606696Z","shell.execute_reply.started":"2023-08-22T10:03:17.272565Z","shell.execute_reply":"2023-08-22T10:03:29.605614Z"},"trusted":true},"execution_count":80,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Model output has a type: <class 'tensorflow.python.framework.ops.EagerTensor'>\nModel Output list for the Inputs above are of length: 16\nModel Output list has each output of shape: (99, 50400)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### Custom Loss and Accuracy Version 3","metadata":{"id":"7Vgp0zJ0EDkq"}},{"cell_type":"code","source":"def custom_loss_v3(y_true, y_pred):\n    '''Calculates the loss for the baseline model. The loss is calculated by taking the negative\n    log-likelihood of the target word(w*_t) in the current timestep. Then the overall loss\n    is the summation over all timesteps divided by T (not Ty because it would include paddings also).\n\n    Arguments:\n    y_true: tf.Tensor object, true values for the target\n    y_pred: list of tf.Tensor objects, predicted probablities of the summary words\n\n    Returns:\n    returns the loss on the predicted values for the model\n    '''\n    # Calculate the loss for each item in the batch.\n    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n    loss = loss_fn(y_true, y_pred)\n\n    # Remove the paddings from calculation of loss\n    mask = tf.cast(y_true != 0, loss.dtype)\n    loss *= mask\n\n    # Divide the total loss after masking out paddings divided by total words which are not paddings\n    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n\n\ndef custom_accuracy_v3(y_true, y_pred):\n    '''Calculates accuracy of the baseline model. The accuracy is calculated by matching how many correct\n    words were predicted excluding the paddings. Then, just add those which are correct and you will get the\n    the accuracy and then just divide it by total words not including padding.\n\n    Arguments:\n    y_true: tf.Tensor object, expected target values\n    y_pred: list of tf.Tensor object, predicted target values by model\n\n    Returns:\n    returns the total accuracy over the batch of data\n    '''\n    # Find the word index with maximum probablity\n    y_pred = tf.argmax(y_pred, axis=-1)\n    y_pred = tf.cast(y_pred, y_true.dtype)\n\n    # Count the words that matches with true values\n    match = tf.cast(y_pred == y_true, tf.float32)\n    mask = tf.cast(y_true != 0, tf.float32)\n\n    # Mask out the paddings\n    match *= mask\n\n    return tf.reduce_sum(match) / tf.reduce_sum(mask)","metadata":{"id":"E_SW6SzNDH1E","execution":{"iopub.status.busy":"2023-08-22T10:03:34.141859Z","iopub.execute_input":"2023-08-22T10:03:34.142893Z","iopub.status.idle":"2023-08-22T10:03:34.154097Z","shell.execute_reply.started":"2023-08-22T10:03:34.142836Z","shell.execute_reply":"2023-08-22T10:03:34.153038Z"},"trusted":true},"execution_count":81,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"##### Testing with loss and accuracy","metadata":{"id":"ShbQdiQqILXu"}},{"cell_type":"code","source":"print(f\"Sample y true values: {sum_tar}\")\nprint(f\"Sample y pred values(first 10 values of first 2 timestep): {sample_model_out[:2]}\")\n\nsample_loss = custom_loss_v3(sum_tar, sample_model_out)\nprint(f\"Loss of the sample y_true and y_pred: {sample_loss}\")\n\nsample_acc = custom_accuracy_v3(sum_tar, sample_model_out)\nprint(f\"Accuracy of the sample y_true and y_pred: {sample_acc}\")","metadata":{"outputId":"5b2bc229-776f-4259-9605-4f003e2e2c4c","id":"NOapo56oILX5","execution":{"iopub.status.busy":"2023-08-22T10:03:58.213852Z","iopub.execute_input":"2023-08-22T10:03:58.214281Z","iopub.status.idle":"2023-08-22T10:03:59.438786Z","shell.execute_reply.started":"2023-08-22T10:03:58.214244Z","shell.execute_reply":"2023-08-22T10:03:59.438013Z"},"trusted":true},"execution_count":83,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}},{"name":"stdout","text":"Sample y true values: [[  534  3823     4 ...     0     0     0]\n [ 5992 27592     4 ...     0     0     0]\n [ 7369  1938   755 ...     0     0     0]\n ...\n [   85     8  1171 ...     0     0     0]\n [ 1826  7956     4 ...     9   409     2]\n [  985  4468  2944 ...     7   472     9]]\nSample y pred values(first 10 values of first 2 timestep): [[[9.17961279e-06 9.16716726e-06 1.03038931e+01 ... 0.00000000e+00\n   0.00000000e+00 0.00000000e+00]\n  [1.48596428e-05 1.47867659e-05 4.97121286e+00 ... 0.00000000e+00\n   0.00000000e+00 0.00000000e+00]\n  [1.09373632e-05 1.08378290e-05 8.71077442e+00 ... 0.00000000e+00\n   0.00000000e+00 0.00000000e+00]\n  ...\n  [8.90064985e-06 8.66691698e-06 1.06866264e+01 ... 0.00000000e+00\n   0.00000000e+00 0.00000000e+00]\n  [9.41078088e-06 9.16375120e-06 1.02101898e+01 ... 0.00000000e+00\n   0.00000000e+00 0.00000000e+00]\n  [1.58303537e-05 1.54149639e-05 4.21425533e+00 ... 0.00000000e+00\n   0.00000000e+00 0.00000000e+00]]\n\n [[1.18776125e-05 1.20716368e-05 1.25469646e+01 ... 0.00000000e+00\n   0.00000000e+00 0.00000000e+00]\n  [7.70851966e-06 7.91782350e-06 1.90085278e+01 ... 0.00000000e+00\n   0.00000000e+00 0.00000000e+00]\n  [1.06605585e-05 1.10323108e-05 1.44159393e+01 ... 0.00000000e+00\n   0.00000000e+00 0.00000000e+00]\n  ...\n  [1.22667607e-05 1.29155515e-05 1.21154976e+01 ... 0.00000000e+00\n   0.00000000e+00 0.00000000e+00]\n  [9.24736378e-06 9.73646183e-06 1.67638092e+01 ... 0.00000000e+00\n   0.00000000e+00 0.00000000e+00]\n  [1.31356146e-05 1.38303676e-05 1.07779160e+01 ... 0.00000000e+00\n   0.00000000e+00 0.00000000e+00]]]\nLoss of the sample y_true and y_pred: 10.291533470153809\nAccuracy of the sample y_true and y_pred: 0.035785287618637085\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### Compiling pointer generator model","metadata":{"id":"nT2RqhLFMlHp"}},{"cell_type":"code","source":"lr = LEARNING_RATE\ninitial_accumulator_value = INIT_ACC_VAL\nclipnorm = MAX_GRAD_NORM\n\nopt = Adagrad(learning_rate=lr,\n              initial_accumulator_value=initial_accumulator_value,\n              clipnorm=clipnorm)\n\npointer_model.compile(loss=custom_loss_v3, optimizer=opt, metrics=[custom_loss_v3, custom_accuracy_v3])","metadata":{"id":"WTayhfQFMlH0","execution":{"iopub.status.busy":"2023-08-22T10:04:03.731734Z","iopub.execute_input":"2023-08-22T10:04:03.732556Z","iopub.status.idle":"2023-08-22T10:04:03.791325Z","shell.execute_reply.started":"2023-08-22T10:04:03.732517Z","shell.execute_reply":"2023-08-22T10:04:03.790398Z"},"trusted":true},"execution_count":84,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"##### Creating callbacks for model","metadata":{"id":"pQSFBBfYMlH0"}},{"cell_type":"code","source":"# Mention the checkpoint path and it's directory where you will save the model\ncheckpoint_path = COVERAGE_MODEL_CHECKPOINT\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Calculate no of batches, I am taking floor because when creating the training data I used drop_remainder\nn_batches = int(train_dataset.shape[0] / BATCH_SIZE)\n\n# Create the checkpoint for model saving, monitoring val_custom_accuracy_v1 and save only weights of the model\nsaving_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                monitor='val_custom_accuracy_v3',\n                                                verbose=1,\n                                                save_weights_only=True,\n                                                save_freq=n_batches//2)\n\n# Create the checkpoint for stopping early after noticing that val_custom_accuracy_v1 is not increasing even after 5 consecutive epochs\nearlystop_cb = tf.keras.callbacks.EarlyStopping(monitor='val_custom_accuracy_v3',\n                                                    patience=PATIENCE,\n                                                    mode='max',\n                                                    )\n\n# Store the checkpoints in a list\ncallbacks = [saving_cb, earlystop_cb]","metadata":{"id":"BXuC_RPbMlH0","execution":{"iopub.status.busy":"2023-08-22T10:04:08.477221Z","iopub.execute_input":"2023-08-22T10:04:08.477610Z","iopub.status.idle":"2023-08-22T10:04:08.486332Z","shell.execute_reply.started":"2023-08-22T10:04:08.477581Z","shell.execute_reply":"2023-08-22T10:04:08.485198Z"},"trusted":true},"execution_count":85,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n    pre {\n        white-space: pre-wrap;\n    }\n    </style>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"##### Training coverage model","metadata":{"id":"S4iHgb8KMlH0"}},{"cell_type":"code","source":"epochs = COVERAGE_EPOCHS\nsteps_per_epoch = COVERAGE_STEPS_PER_EPOCHS\n\nhistory = coverage_model.fit(tf_train_dataset.repeat(),\n                    epochs=epochs,\n                    validation_data=tf_val_dataset,\n                    steps_per_epoch=steps_per_epoch,\n                    callbacks=callbacks\n                    )","metadata":{"id":"z0ZekuBoMlH0"},"execution_count":null,"outputs":[]}]}