{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arup3201/Summarization-Project-using-Pointer-Gen/blob/main/Get_To_The_Point_Summarization_with_Pointer_Generator_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the wraping the outputs of colab"
      ],
      "metadata": {
        "id": "aWWumM-N6C31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "J2_Q63jmdSp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports Libraries"
      ],
      "metadata": {
        "id": "A3eWiUNHDwjn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x6QucUCZ0q2V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "# For tokenizing and processing the examples for the model training\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Layers for the Encoder, Attention and Decoder\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM\n",
        "from tensorflow.keras.layers import RepeatVector, Concatenate, Activation, Dot\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# For model initialization\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "# For training the model\n",
        "from tensorflow.keras.optimizers.experimental import Adagrad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data"
      ],
      "metadata": {
        "id": "Z-SylnbUD2s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the CNN stories from the url into cnn_stories_tgz file\n",
        "cnn_stories_tgz = tf.keras.utils.get_file(\n",
        "    origin=\"https://huggingface.co/datasets/cnn_dailymail/resolve/main/data/cnn_stories.tgz\",\n",
        ")\n",
        "\n",
        "# Download the Dailymail stories from the url into dailymail_stories_tgz file\n",
        "dailymail_stories_tgz = tf.keras.utils.get_file(\n",
        "    origin=\"https://huggingface.co/datasets/cnn_dailymail/resolve/main/data/dailymail_stories.tgz\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_03wyoLlFhO",
        "outputId": "6822d7a2-b43f-468e-dc42-2eff5802307b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://huggingface.co/datasets/cnn_dailymail/resolve/main/data/cnn_stories.tgz\n",
            "158577824/158577824 [==============================] - 4s 0us/step\n",
            "Downloading data from https://huggingface.co/datasets/cnn_dailymail/resolve/main/data/dailymail_stories.tgz\n",
            "375893739/375893739 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_stories_tgz, dailymail_stories_tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyid1XyFl1sp",
        "outputId": "37ab487d-6bd2-4956-e57d-31dea8da89aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/root/.keras/datasets/cnn_stories.tgz',\n",
              " '/root/.keras/datasets/dailymail_stories.tgz')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf /root/.keras/datasets/cnn_stories.tgz\n",
        "!tar -xzf /root/.keras/datasets/dailymail_stories.tgz"
      ],
      "metadata": {
        "id": "EHJtYhZpls0i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_stories_dir = pathlib.Path('/content/cnn/stories')\n",
        "dailymail_stories_dir = pathlib.Path('/content/cnn/stories')"
      ],
      "metadata": {
        "id": "ag5ubSt7l88l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_stories_dir, dailymail_stories_dir"
      ],
      "metadata": {
        "id": "UmMCM--Yhm3B",
        "outputId": "e6577021-5546-4900-e6be-d6045681d919",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('/content/cnn/stories'), PosixPath('/content/cnn/stories'))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print Stories"
      ],
      "metadata": {
        "id": "WqScGmO6D5XI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_filenames(dir_path, num_files=5):\n",
        "  '''Prints the name of the files that are present at `dir_path`.\n",
        "  Maximum `num_files` number of files are shown.\n",
        "\n",
        "  Arguments:\n",
        "    dir_path: PosixPath, pointing to the directory of which the user\n",
        "              wants to prints the file names.\n",
        "    num_files: int, number of files user wants to print.\n",
        "\n",
        "  returns:\n",
        "    nothing\n",
        "  '''\n",
        "\n",
        "  count = 0\n",
        "  for f in dir_path.glob('*.story'):\n",
        "    print(f.name)\n",
        "    count += 1\n",
        "\n",
        "    if count == num_files:\n",
        "      break\n",
        "  else:\n",
        "    print(f\"Less than {num_files} is present!\")"
      ],
      "metadata": {
        "id": "dZFFXG7Pg86H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_filenames(cnn_stories_dir)"
      ],
      "metadata": {
        "id": "nv3g7-M316yL",
        "outputId": "9bbe1fb6-64a5-4f98-f3bc-1597214c21e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3723ededeaee98918eebbbfbef545a05d6602c23.story\n",
            "3cd409988490e4cdf933193b8243277661da38eb.story\n",
            "5da013c4d8904ff4c30ee8b5abd27effa214bc4b.story\n",
            "6247e325fbb432b91e490c5a4e4c5b1e9b19cb76.story\n",
            "a0441e465cc642f17b12f7c1e56f8fd461bff117.story\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_filenames(dailymail_stories_dir)"
      ],
      "metadata": {
        "id": "WcyW1wJa2EaN",
        "outputId": "7b36d021-c1c8-4940-b7dc-0acc07ba1fd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3723ededeaee98918eebbbfbef545a05d6602c23.story\n",
            "3cd409988490e4cdf933193b8243277661da38eb.story\n",
            "5da013c4d8904ff4c30ee8b5abd27effa214bc4b.story\n",
            "6247e325fbb432b91e490c5a4e4c5b1e9b19cb76.story\n",
            "a0441e465cc642f17b12f7c1e56f8fd461bff117.story\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking a sample .story file from cnn stories\n",
        "sample_filename = \"438411e10e1ef79b47cc48cd95296d85798c1e38.story\"\n",
        "sample_filedir = cnn_stories_dir\n",
        "\n",
        "sample_filepath = sample_filedir / sample_filename\n",
        "with open(sample_filepath, 'r') as f:\n",
        "  sample_story = f.read()\n",
        "\n",
        "print(f\"A sample story:\\n{sample_story}\")"
      ],
      "metadata": {
        "id": "Uw0kqchX3X7X",
        "outputId": "a0c30c8d-2284-483b-f993-53cb7011d2b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample story:\n",
            "New York (CNN) -- The U.S. population is expected to top out at close to 312.8 million people just around the time crowds gather to watch the ball drop on New Year's Eve, according to new census data released Thursday.\n",
            "\n",
            "The figure represents a 0.7% increase from last year, adding 2,250,129 people to the U.S. population since the start of 2011, and a 1.3% increase since Census Day, April 1, 2010.\n",
            "\n",
            "The agency estimates that beginning in January, one American will be born every eight seconds and one will die every 12 seconds.\n",
            "\n",
            "U.S.-bound immigrants are also expected to add one person every 46 seconds.\n",
            "\n",
            "That combination of births, deaths and migration is expected to add a single person to the U.S. population every 17 seconds, the Census Bureau said.\n",
            "\n",
            "Meanwhile, millions are set to ring in the new year.\n",
            "\n",
            "In New York, authorities are preparing for large crowds in Manhattan's Times Square, where Lady Gaga is expected to join Mayor Michael Bloomberg to push the button that drops the Waterford Crystal ball at 11:59 p.m. ET on New Year's Eve.\n",
            "\n",
            "\"And I'm so looking forward to performing on NYE+dropping the Ball with Mayor Bloomberg!\" the pop star posted on Twitter. \"What an honor as a New Yorker.\"\n",
            "\n",
            "Past guests have included Muhammad Ali, Rudy Giuliani, Colin Powell and Bill and Hillary Clinton.\n",
            "\n",
            "On Thursday, officials conducted New York's annual \"airworthiness test\" -- a process in which confetti is tossed by handfuls above Times Square -- in preparation for the annual city tradition of dumping one ton of confetti over revelers in the iconic square.\n",
            "\n",
            "The Big Apple this year edged out Las Vegas for the first time in seven years as the top travel U.S. destination for those celebrating the new year, according to a December travel booking website poll.\n",
            "\n",
            "Seven New York neighborhoods made the top 10 list, with two districts in Las Vegas and one in New Orleans making up the other three, according to the Priceline poll.\n",
            "\n",
            "\"It appears that New York City will be helped this year by a weather forecast that calls for warmer than usual temperatures over the holiday weekend,\" said company spokesman Brian Ek.\n",
            "\n",
            "@highlight\n",
            "\n",
            "Census Bureau: U.S. population is expected to be 312.8 million on New Year's Day\n",
            "\n",
            "@highlight\n",
            "\n",
            "That figure represents a 0.7% increase from last year\n",
            "\n",
            "@highlight\n",
            "\n",
            "Lady Gaga, mayor to activate ball drop at Times Square on New Year's Eve\n",
            "\n",
            "@highlight\n",
            "\n",
            "NYC has supplanted Las Vegas as the top New Year's destination, Priceline poll says\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Global Variables"
      ],
      "metadata": {
        "id": "ihAsXBceD7ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the global variables\n",
        "dm_single_close_quote = u'\\u2019' # unicode for closing single quote\n",
        "dm_double_close_quote = u'\\u201d' # unicode for closing double quote\n",
        "END_TOKENS = ['.', '!', '?', '...', \"'\", \"`\", '\"',\n",
        "              dm_single_close_quote, dm_double_close_quote, \")\"]\n",
        "\n",
        "# Maximum stories to process from cnn and dailymail each\n",
        "MAX_STORIES = 310000\n",
        "\n",
        "# From the total data how to split into train, val and test\n",
        "TRAIN_SIZE = 0.8 # Fraction of the total dataset to use for training\n",
        "VAL_SIZE = 0.1 # Fraction of the total dataset to use for validation\n",
        "TEST_SIZE = 0.1 # Fraction of the total dataset to use for testing\n",
        "\n",
        "# For tokenization\n",
        "VOCAB_SIZE = 50000 # Vocabulary size or no of unique words\n",
        "OOV_TOKEN = \"<OOV>\" # Word token to represent the out-of-vocabulary words\n",
        "\n",
        "# For standardization\n",
        "START_TOKEN = '<START>' # Starting word of each sentence\n",
        "END_TOKEN = '<END>' # Ending word of each sentence\n",
        "\n",
        "# Total tokens to represent encoder input sentence and decoder input sentence(Values are taken from paper)\n",
        "MAX_ARTICLE_TOKENS = 400 # Maximum no of tokens to consider in article when processing them for model\n",
        "MAX_SUMMARY_TOKENS = 100 # Maximum no of tokens to consider in summary when processing them for model\n",
        "\n",
        "# For dataset creation hyperparameters\n",
        "BUFFER_SIZE = 5000 # Buffer size when using shuffle\n",
        "BATCH_SIZE = 16 # No of examples in each batch\n",
        "\n",
        "# Model Archietecture hyperparameters (Values are taken from the paper)\n",
        "EMB_OUT = 128 # Embedding output dimension\n",
        "ENCODER_STATE_DIM = 256 # Encoder hidden(also cell) state dimension\n",
        "DECODER_STATE_DIM = 2*ENCODER_STATE_DIM # Decoder hidden(also cell) state dimension\n",
        "DENSE1_UNITS = 128 # Attention first dense layer units(calculates partial energy)\n",
        "DENSE2_UNITS = 1 # Attention secodn dense layer units(calculated final energy)\n",
        "DENSE_UNITS = 512 # Units of the Dense layers before output layer, make sure it is same as decoder state dimension\n",
        "\n",
        "# Model Optimizer hyperparameters (Values are taken from the paper)\n",
        "LEARNING_RATE=0.15 # Learning rate\n",
        "INIT_ACC_VAL=0.1 # Initial accumulator value\n",
        "MAX_GRAD_NORM=2 # Gardient norm\n",
        "\n",
        "# Model Checkpoint hyperparameters\n",
        "BASELINE_MODEL_CHECKPOINT = \"baseline-model/cp-{epoch:04d}.ckpt\"\n",
        "POINTER_MODEL_CHECKPOINT = \"pointer-model/cp-{epoch:04d}.ckpt\"\n",
        "COVERAGE_MODEL_CHECKPOINT = \"coverage-model/cp-{epoch:04d}.ckpt\"\n",
        "PATIENCE = 5\n",
        "\n",
        "## Model Fit (All values are choosen closer to the ones in the paper)\n",
        "# Base model\n",
        "BASE_EPOCHS = 33\n",
        "STEPS_PER_EPOCHS_BASE = 18181\n",
        "# Pointer Model\n",
        "POINTER_EPOCHS = 13\n",
        "POINTER_STEPS_PER_EPOCHS = 18000\n",
        "# Coverage Model\n",
        "COVERAGE_EPOCHS = 1\n",
        "COVERAGE_STEPS_PER_EPOCHS = 3000\n",
        "\n",
        "# Coverage mechanism\n",
        "LAMBDA_VAL = 1"
      ],
      "metadata": {
        "id": "cubLAm1Q3SuG"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixing periods of the stories"
      ],
      "metadata": {
        "id": "UXHUPXvlEDTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am creating a function `fix_missing_period` where I am taking 2 arguements, one for the `line` for which I am checking and fixing the period and other is `end_tokens` which is a list that has all the tokens that I should consider as ending of a sentence.\n",
        "\n",
        "These are the steps -\n",
        "1. Check if line contains `@highlight`, if True then just return the line.\n",
        "2. Check if line is empty, then return line as it is.\n",
        "3. Check is line ends with any of the `end_tokens`, if so then return line as it is.\n",
        "4. Only is none of the above conditions match then append `.` to the current line."
      ],
      "metadata": {
        "id": "iZPt8EVBzJ8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_missing_period(line, end_tokens=END_TOKENS):\n",
        "  '''function to fix the missing periods for some story lines which do not end with\n",
        "  any of the end_tokens mentioned.\n",
        "\n",
        "  Argument:\n",
        "    line: string, line of the story to fix the missing the period of.\n",
        "    end_tokens: list of strings, all the tokens that are considered as line end.\n",
        "\n",
        "  Returns:\n",
        "    new line with fixed the ending part by adding an ending token if not present.\n",
        "  '''\n",
        "  if \"@highlight\" in line:\n",
        "    return line\n",
        "  elif line == \"\":\n",
        "    return line\n",
        "  elif line[-1] in end_tokens:\n",
        "    return line\n",
        "\n",
        "  return line + '.'"
      ],
      "metadata": {
        "id": "i-S-Hss12TPk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"i have a bad habit of not giving full-stop after sentence\\nLike this setence\"\n",
        "print(f\"Fixing {fix_missing_period(sample_text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1hiNysxnmAO",
        "outputId": "8982deb2-84c5-411d-8b31-15102080277b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixing i have a bad habit of not giving full-stop after sentence\n",
            "Like this setence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the Stories into articles and summaries"
      ],
      "metadata": {
        "id": "fEoN3HDSEHjI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am creating a function `split_article_summary` which will split the story into article and summary parts.\n",
        "\n",
        "The function takes only 1 arguement and that is the `story` which will be splitted into article and summary.\n",
        "\n",
        "The steps to follow are -\n",
        "1. Split the story by new line `\\n`. I will get a list of lines.\n",
        "2. Strip the lines by using list comprehension.\n",
        "3. Use list comprehension to make lower case each line by using `.lower()`.\n",
        "4. Fix each line by adding period if there is none in that line using `fix_missing_period` function.\n",
        "5. Make 2 empty list for `article` and `summary`.\n",
        "6. Go through each line. In each line, I need to check 4 things,\n",
        "  * line contains `@highlight` or not, if True then set `next_highlight` to `True` because the next to next line is going to be a summary line.\n",
        "  * line is `\"\"` empty or not, if True then ignore.\n",
        "  * `next_highlight` is True or not, if True then append the line to `summary`.\n",
        "  * If non of the ebove then append to `article`.\n",
        "7. After done with filling the `article` and `summary` list with lines, join those sentences to make the whole article and summary. Here, I am using `.join()` method."
      ],
      "metadata": {
        "id": "5-tqWtoowXxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_article_summary(story):\n",
        "  '''Splits the story into 2 parts, one for article and other for summary of that\n",
        "  article. Returns the article and summary.\n",
        "\n",
        "  Argument:\n",
        "    story: string file that contains both article and summary combiningly.\n",
        "\n",
        "  Returns:\n",
        "    article, summary seperately from the story.\n",
        "\n",
        "  '''\n",
        "  lines = story.split('\\n')\n",
        "  lines = [line.strip() for line in lines]\n",
        "  lines = [line.lower() for line in lines]\n",
        "\n",
        "  # Fix the ending period\n",
        "  lines = [fix_missing_period(line) for line in lines]\n",
        "\n",
        "  # List to contain the article and summary lines\n",
        "  article = []\n",
        "  summary = []\n",
        "\n",
        "  # Indicator of whether the next line is the summary or not\n",
        "  next_highlight = False\n",
        "\n",
        "  for line in lines:\n",
        "    if \"@highlight\" in line:\n",
        "      next_highlight = True\n",
        "    elif line==\"\":\n",
        "      continue\n",
        "    elif next_highlight:\n",
        "      summary.append(line)\n",
        "    else:\n",
        "      article.append(line)\n",
        "\n",
        "  article = ' '.join(article)\n",
        "  summary = ' '.join(summary)\n",
        "\n",
        "  return article, summary"
      ],
      "metadata": {
        "id": "-X4eMltQnf10"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_article, sample_summary = split_article_summary(sample_story)\n",
        "\n",
        "print(f\"Sample Article after spliting:\\n{sample_article}\")\n",
        "print(f\"Sample Summary after spliting:\\n{sample_summary}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuUjOaN9orGU",
        "outputId": "47958eb2-5489-45b2-df18-5987e5f40606"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Article after spliting:\n",
            "new york (cnn) -- the u.s. population is expected to top out at close to 312.8 million people just around the time crowds gather to watch the ball drop on new year's eve, according to new census data released thursday. the figure represents a 0.7% increase from last year, adding 2,250,129 people to the u.s. population since the start of 2011, and a 1.3% increase since census day, april 1, 2010. the agency estimates that beginning in january, one american will be born every eight seconds and one will die every 12 seconds. u.s.-bound immigrants are also expected to add one person every 46 seconds. that combination of births, deaths and migration is expected to add a single person to the u.s. population every 17 seconds, the census bureau said. meanwhile, millions are set to ring in the new year. in new york, authorities are preparing for large crowds in manhattan's times square, where lady gaga is expected to join mayor michael bloomberg to push the button that drops the waterford crystal ball at 11:59 p.m. et on new year's eve. \"and i'm so looking forward to performing on nye+dropping the ball with mayor bloomberg!\" the pop star posted on twitter. \"what an honor as a new yorker.\" past guests have included muhammad ali, rudy giuliani, colin powell and bill and hillary clinton. on thursday, officials conducted new york's annual \"airworthiness test\" -- a process in which confetti is tossed by handfuls above times square -- in preparation for the annual city tradition of dumping one ton of confetti over revelers in the iconic square. the big apple this year edged out las vegas for the first time in seven years as the top travel u.s. destination for those celebrating the new year, according to a december travel booking website poll. seven new york neighborhoods made the top 10 list, with two districts in las vegas and one in new orleans making up the other three, according to the priceline poll. \"it appears that new york city will be helped this year by a weather forecast that calls for warmer than usual temperatures over the holiday weekend,\" said company spokesman brian ek.\n",
            "Sample Summary after spliting:\n",
            "census bureau: u.s. population is expected to be 312.8 million on new year's day. that figure represents a 0.7% increase from last year. lady gaga, mayor to activate ball drop at times square on new year's eve. nyc has supplanted las vegas as the top new year's destination, priceline poll says.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am creating a function `get_articles_summaries` which will process each of the stories present in the directory of cnn and dailymail and return the articles, summaries in the form of list.\n",
        "\n",
        "This function will take 2 arguements. One will be the `stories_dir` which is a Posix format string from `pathlib` library and another arguement is of `max_stories` which is the maximum number of stories that we will extract from those directories.\n",
        "\n",
        "The process is simple. We will follow this steps -\n",
        "1. Create 2 empty lists of `articles` and `summaries`.\n",
        "2. Loop through all the files present in the directory `stories_dir` using `.glob` generator method.\n",
        "3. Make a `count` variable which will count the number of processed strories and when it hits `max_stories`, break from the loop.\n",
        "4. Inside the loop, you will open the file in `r` reading format, then just use `.read()` method to read the story.\n",
        "5. Everytime after reading the story, split the article and summary part from it and then append them inside the `articles` and `summaries` list.\n",
        "6. Return the 2 lists."
      ],
      "metadata": {
        "id": "oTEa0m3Huxz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_articles_summaries(stories_dir, max_stories):\n",
        "  '''stores the stories from stories_dir folder into a list and returns the list\n",
        "\n",
        "  Arguments:\n",
        "    stories_dir: Posix string, the directory where the stories are stored\n",
        "    max_stories: maximum number of stories to store\n",
        "\n",
        "  Returns:\n",
        "    list of stories.\n",
        "\n",
        "  '''\n",
        "  articles = []\n",
        "  summaries = []\n",
        "\n",
        "  count = 0\n",
        "  for f in stories_dir.glob(\"*.story\"):\n",
        "    count += 1\n",
        "    with open(f, 'r') as reader:\n",
        "      story = reader.read()\n",
        "\n",
        "      article, summary = split_article_summary(story)\n",
        "\n",
        "      articles.append(article)\n",
        "      summaries.append(summary)\n",
        "\n",
        "    if count == max_stories:\n",
        "      break\n",
        "\n",
        "  return articles, summaries"
      ],
      "metadata": {
        "id": "4VUmbYSpnjAr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of all available .story files, we will only take `MAX_STORIES` number of files and then open them."
      ],
      "metadata": {
        "id": "Uk-BuCM4rIiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_articles, cnn_summaries = get_articles_summaries(cnn_stories_dir, MAX_STORIES)"
      ],
      "metadata": {
        "id": "aa9ZDQntpHQZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total no of cnn stories captured are {len(cnn_articles)}\\n\\n\")\n",
        "print(f\"One of the CNN articles: {cnn_articles[0]}\\n\\n\")\n",
        "print(f\"The summary of this article: {cnn_summaries[0]}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q_i-69YqJnj",
        "outputId": "301f0e5b-43e4-4139-ad3f-771b848e8c9f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no of cnn stories captured are 92579\n",
            "\n",
            "\n",
            "One of the CNN articles: (cnn) -- former hostages held at the american embassy in iran are hoping the academy award for best picture for \"argo\" boosts their efforts to be paid reparations for the ordeal. \" 'argo' was a great motion picture; it was a great story. but it's only part of the story,\" says former hostage steven lauterbach. unlike the six whose escape to the canadian embassy was featured in the movie, he was one of the 52 who were held for 444 days in the u.s. embassy. he and other former hostages believe iran has never been held accountable for the episode and should have to pay each of them restitution. \"we feel that we should be entitled to some compensation,\" he said. lauterbach said that during his captivity, he spent four days in solitary confinement. at the end, he was so desperate that he slashed both wrists with a broken drinking glass. \"my shirt, pants, and shoes were soaked in blood,\" he said. \"i was prepared to die.\" attorney tom lankford, who has represented the hostages in court for years, is seeking about $4 million apiece in damages. coming soon: iran's response to 'argo' \"they were beaten; they played russian roulette with them, they stood them up against walls as if they were killing them in mock firing squads,\" he said. \"they destroyed in many cases not only their bodies, but their souls.\" lauterbach was hospitalized and survived the grueling ordeal. but even today, he said: \"i still have occasional (and sometimes not so occasional) nightmares and flashbacks. in my most common nightmare, the deal made to release us has been rescinded, and we have to go back into captivity.\" even now, he said, \"i get feelings of panic and claustrophobia sometimes. it's never really behind you.\" the hostages were released in january 1981 under a set of agreements, the algiers accords, which stipulated that the hostages could not sue iran for damages. but for years, many of them have sought compensation anyway, arguing that an agreement made under duress at gunpoint is not valid. cnn called and e-mailed iran's mission to the united nations for comment but did not receive a response. the state department, however, has argued against breaking the agreement, saying that if the united states were to renege on the algiers deal, the decision would call into question america's commitment to honoring all its other treaties and agreements as well. john sheardown, canadian 'hero' in hostage crisis, dies. \"the united states government remains deeply grateful to the former hostages for their service to their country, and expresses its sympathy for the suffering they experienced during their ordeal,\" the state department said in a statement. \"as an essential condition of their release from captivity, however, the united states agreed in the algiers accords to bar claims by the former hostages against iran from u.s. courts. although we understand their frustration, we are bound by this commitment and must continue to honor it.\" the courts have sided with the state department, and in 2012, the supreme court declined to hear the hostages' appeal. now the group is pushing congress for an alternative. instead of being compensated with iranian government money, which sits in frozen accounts, they propose using money collected from fines against companies caught violating the embargo against iran. \"even though these fines will probably not come directly from the iranians,\" says lauterbach, \"i think it will to some degree right a wrong.\" as part of their efforts to persuade lawmakers, the group is assembling a package of testimonials from the former hostages. one former hostage who will not be able to tell congress his story: former cia agent phillip ward, who committed suicide in october. he was beaten in his cell and subjected to mock executions during captivity, and after his release, he became a recluse and an alcoholic, according to lankford. \"in reality, his life was taken from him 33 years ago,\" he said.\n",
            "\n",
            "\n",
            "The summary of this article: \"argo,\" about the rescue of six american hostages from iran, wins best picture. other hostages rescued later hope the movie's high profile helps case for reparations. ordeal destroyed \"not only their bodies, but their souls,\" lawyer says.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dailymail_articles, dailymail_summaries = get_articles_summaries(dailymail_stories_dir,\n",
        "                                                                 MAX_STORIES)"
      ],
      "metadata": {
        "id": "KT4Hrp6nqeKu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total no of dailymail stories captured are {len(dailymail_articles)}\\n\\n\")\n",
        "print(f\"One of the Dailymail articles: {dailymail_articles[0]}\\n\\n\")\n",
        "print(f\"The summary of this article: {dailymail_summaries[0]}\\n\\n\")"
      ],
      "metadata": {
        "id": "nkzwSP9kh4VK",
        "outputId": "6a1be37e-0cb2-4ab5-87b4-205cda97a287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no of dailymail stories captured are 92579\n",
            "\n",
            "\n",
            "One of the Dailymail articles: (cnn) -- former hostages held at the american embassy in iran are hoping the academy award for best picture for \"argo\" boosts their efforts to be paid reparations for the ordeal. \" 'argo' was a great motion picture; it was a great story. but it's only part of the story,\" says former hostage steven lauterbach. unlike the six whose escape to the canadian embassy was featured in the movie, he was one of the 52 who were held for 444 days in the u.s. embassy. he and other former hostages believe iran has never been held accountable for the episode and should have to pay each of them restitution. \"we feel that we should be entitled to some compensation,\" he said. lauterbach said that during his captivity, he spent four days in solitary confinement. at the end, he was so desperate that he slashed both wrists with a broken drinking glass. \"my shirt, pants, and shoes were soaked in blood,\" he said. \"i was prepared to die.\" attorney tom lankford, who has represented the hostages in court for years, is seeking about $4 million apiece in damages. coming soon: iran's response to 'argo' \"they were beaten; they played russian roulette with them, they stood them up against walls as if they were killing them in mock firing squads,\" he said. \"they destroyed in many cases not only their bodies, but their souls.\" lauterbach was hospitalized and survived the grueling ordeal. but even today, he said: \"i still have occasional (and sometimes not so occasional) nightmares and flashbacks. in my most common nightmare, the deal made to release us has been rescinded, and we have to go back into captivity.\" even now, he said, \"i get feelings of panic and claustrophobia sometimes. it's never really behind you.\" the hostages were released in january 1981 under a set of agreements, the algiers accords, which stipulated that the hostages could not sue iran for damages. but for years, many of them have sought compensation anyway, arguing that an agreement made under duress at gunpoint is not valid. cnn called and e-mailed iran's mission to the united nations for comment but did not receive a response. the state department, however, has argued against breaking the agreement, saying that if the united states were to renege on the algiers deal, the decision would call into question america's commitment to honoring all its other treaties and agreements as well. john sheardown, canadian 'hero' in hostage crisis, dies. \"the united states government remains deeply grateful to the former hostages for their service to their country, and expresses its sympathy for the suffering they experienced during their ordeal,\" the state department said in a statement. \"as an essential condition of their release from captivity, however, the united states agreed in the algiers accords to bar claims by the former hostages against iran from u.s. courts. although we understand their frustration, we are bound by this commitment and must continue to honor it.\" the courts have sided with the state department, and in 2012, the supreme court declined to hear the hostages' appeal. now the group is pushing congress for an alternative. instead of being compensated with iranian government money, which sits in frozen accounts, they propose using money collected from fines against companies caught violating the embargo against iran. \"even though these fines will probably not come directly from the iranians,\" says lauterbach, \"i think it will to some degree right a wrong.\" as part of their efforts to persuade lawmakers, the group is assembling a package of testimonials from the former hostages. one former hostage who will not be able to tell congress his story: former cia agent phillip ward, who committed suicide in october. he was beaten in his cell and subjected to mock executions during captivity, and after his release, he became a recluse and an alcoholic, according to lankford. \"in reality, his life was taken from him 33 years ago,\" he said.\n",
            "\n",
            "\n",
            "The summary of this article: \"argo,\" about the rescue of six american hostages from iran, wins best picture. other hostages rescued later hope the movie's high profile helps case for reparations. ordeal destroyed \"not only their bodies, but their souls,\" lawyer says.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting data into training, validation and testing set"
      ],
      "metadata": {
        "id": "nEaIcT3lEaez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am creating another function -\n",
        "`split_dataset(train_size, val_size, test_size)`: I am creating this function to split the original 1,00,000 examples into 80,000 training samples, 10,000 val samples and 10,000 test samples."
      ],
      "metadata": {
        "id": "8ea-PhS3iIJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataset, train_size, val_size, test_size):\n",
        "  first_split = train_size\n",
        "  second_split = train_size+val_size\n",
        "  third_split = train_size+val_size+test_size\n",
        "  return dataset[:first_split, :], dataset[first_split:second_split, :], dataset[second_split:third_split, :]"
      ],
      "metadata": {
        "id": "v-iZDbUCqkdC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us create a function `make_datasets`, that will be make training, validation and testing datasets. This function will -\n",
        "1. This functions will have many argumenets and among them 2 argumenets `cnn_stories` and `dailymail_stories` are lists which has list of articles and summaries at 0 and 1 index. It means `cnn_stories[0]` is articles of cnn news and `cnn_stories[1]` is summaries of cnn news. It applies to `dailymail_stories` as well.\n",
        "Objective of this step is to concatenate the cnn articles with dailymail articles and cnn summaries with dailymail summaries.\n",
        "```python\n",
        "[1, 2] + [3, 4] = [1, 2, 3, 4]\n",
        "```\n",
        "\n",
        "3. Convert the articles and summaries list into tensors and then concatenate them along a new axis. To create new axis I can use `tf.newaxis` in the indexing. E.g.\n",
        "```python\n",
        "  np.concatenate([articles[:, tf.newaxis], summaries[:, tf.newaxis]], axis=-1)\n",
        "```\n",
        "4. Shuffle the dataset using `random.sample` method.\n",
        "```python\n",
        "random.seed(seed_value) # To make sure that everytime it gives the same shuffle\n",
        "random.sample(list_to_shuffle, len(list_to_shuffle))\n",
        "```\n",
        "5. Split the dataset into 3 parts, one for training, other for validation and last one for testing. All the tensors are of shape `(num_samples, 2)`."
      ],
      "metadata": {
        "id": "FTB5eNzJrqyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_datasets(cnn_stories, dailymail_stories, train_fraction, val_fraction, test_fraction, seed_value=0):\n",
        "  '''Create 3 datasets each for training, validation and testing respectively.\n",
        "  This function concatenates the articles, summaries of cnn and dailymail news. After that it will tokenize\n",
        "  them one by one in a loop. After it is done with the tokenization, it will shuffle the articles and\n",
        "  summaries using random.sample method (although we have a helper function for it). Finally we do the\n",
        "  splitting of the whole dataset. Remember here the returned values become tensors.\n",
        "\n",
        "  Arguments:\n",
        "    cnn_stories: list of 2 values, one for cnn articles and other for cnn summaries.\n",
        "    dailymail_stories: list of 2 values, one for dailymail articles and other for dailymail summaries.\n",
        "    train_size: float, specifying how much fraction of the original dataset to take for training.\n",
        "    val_size: float, specifying how much fraction of the original dataset to take for validation.\n",
        "    test_size: float, specifying how much fraction of the original dataset to take for testing.\n",
        "\n",
        "  Returns:\n",
        "    returns a tuple with 3 values inside it, `training_data`, `validation_data` and `testing_data`\n",
        "    with the specified amount of data in it.\n",
        "    Each one of them are tensor with shape `(num_samples, 2)`. `shape[1]=2` for article and summary.\n",
        "  '''\n",
        "  articles = cnn_stories[0] + dailymail_stories[0]\n",
        "  summaries = cnn_stories[1] + dailymail_stories[1]\n",
        "\n",
        "  articles = np.array(articles, dtype=object)\n",
        "  summaries = np.array(summaries, dtype=object)\n",
        "\n",
        "  dataset = np.concatenate((articles[:, tf.newaxis], summaries[:, tf.newaxis]), axis=-1)\n",
        "\n",
        "  random.seed(seed_value)\n",
        "  shuffled_indices = random.sample(list(range(dataset.shape[0])), dataset.shape[0])\n",
        "\n",
        "  dataset = dataset[shuffled_indices, :]\n",
        "\n",
        "  train_size = int(train_fraction * dataset.shape[0])\n",
        "  val_size = int(val_fraction * dataset.shape[0])\n",
        "  test_size = dataset.shape[0] - (train_size + val_size)\n",
        "\n",
        "  training_samples, validation_samples, testing_samples = split_dataset(dataset,\n",
        "                                                                        train_size,\n",
        "                                                                        val_size,\n",
        "                                                                        test_size)\n",
        "\n",
        "  return (training_samples, validation_samples, testing_samples)"
      ],
      "metadata": {
        "id": "QDB0_32RrnHk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset, test_dataset = make_datasets([cnn_articles, cnn_summaries], [dailymail_articles, dailymail_summaries], TRAIN_SIZE, VAL_SIZE, TEST_SIZE)"
      ],
      "metadata": {
        "id": "GTnXBwd6Sa-U"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Type of the datasets: {type(train_dataset)}\\n\")\n",
        "\n",
        "print(f\"Training dataset shape: {train_dataset.shape}\")\n",
        "print(f\"Validation dataset shape: {val_dataset.shape}\")\n",
        "print(f\"Testing dataset shape: {test_dataset.shape}\\n\")\n",
        "\n",
        "print(f\"First example in the training dataset looks like: \\n {train_dataset[0]}\\n\")"
      ],
      "metadata": {
        "id": "AyRVodwIhkuQ",
        "outputId": "e6bbbe78-ef67-451b-c543-5fc7fdc4d37b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of the datasets: <class 'numpy.ndarray'>\n",
            "\n",
            "Training dataset shape: (148126, 2)\n",
            "Validation dataset shape: (18515, 2)\n",
            "Testing dataset shape: (18517, 2)\n",
            "\n",
            "First example in the training dataset looks like: \n",
            " ['(cnn) -- jenson button is relishing sunday\\'s hungarian grand prix, as the mclaren driver returns to the site of his first-ever victory for the 200th race of his formula one career. the 31-year-old withdrew from last weekend\\'s german grand prix, won by his teammate lewis hamilton, after 35 laps with hydraulics problems, but button is hoping for better luck at the track where he tasted success as a honda driver in 2006. \"it\\'s always fun coming back to hungary as this is the track at which i won my first grand prix,\" the 2009 drivers\\' champion told mclaren\\'s web site. \"after a premature end to my race at the nurburgring, i\\'ll be hoping for better luck at the hungaroring. \"i can\\'t believe i\\'ve already knocked up a double-ton of f1 starts because i don\\'t feel a day older than when i made my debut back in 2000!\" resurgent hamilton triumphs in germany. button made his first appearance in the elite division of motorsport at the australian grand prix in 2000 with williams, and has since gone on to represent benetton, renault, bar, honda, brawn gp and now mclaren in an 11-year career. the briton has notched up 10 grand prix triumphs and secured his only world crown to date in 2009, while racing for brawn. button is hopeful of a strong showing on sunday and is taking encouragement from his third-place finish at the monaco grand prix -- a circuit he feels presents a very similar challenge to the hungaroring. \"the mp4-26 [mclaren\\'s car] was very competitive in monaco a couple of months ago and i hope it will be a similar situation this weekend because the hungaroring has many of the same performance criteria. latest f1 standings after the german gp. \"cockpit temperatures regularly exceed 50 degrees and we\\'re always pulling g-force in the car because there are so many corners. it\\'s tough, but this is definitely a circuit when all the training pays dividends.\" hamilton is also a previous winner in hungary having triumphed at the venue in 2007 and the 26-year-old is eager to build on his success at the nurburgring last time out. \"i\\'ve always gone well in hungary,\" said the 2008 world champion. \"i like the circuit because it\\'s old school. it has a very historic feel to it, with hills and bumps and cambers changes, and it has massive character.\" hamilton beat off fierce competition from ferrari\\'s fernando alonso and mark webber of red bull to earn a hard-fought win in germany and he is anticipating another close contest. \"there wasn\\'t much between mclaren, ferrari and red bull in germany. it\\'s going to be fascinating to see which team holds the advantage next weekend.\" despite hamilton, alonso and webber finishing on the podium last time out, all three drivers trail reigning world champion and current standings leader sebastian vettel. vettel, 24, holds a 77-point lead over his colleague webber at the top of the championship heading into the 11th race of the season.'\n",
            " \"jenson button is preparing for the 200th race of his formula one career. the mclaren driver won his first grand prix in hungary five years ago. his teammate lewis hamilton is looking to build on last weekend's triumph in germany.\"]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Tokenizing"
      ],
      "metadata": {
        "id": "dGP0eDXMEhdF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before the tokenization, we need to preprocess the text data so that it can be properly tokenized. In this step we need to choose whether we want to keep punctuations or not, whether we should keep the numbers or not and so on. There are 2 functions I will create, one for simple `standardize` and other to feed the Tokenizer class when creating the `tokenizer`. `standardize` function implements the following steps -\n",
        "\n",
        "1. Lower case the strings passed to it. It is already done but for user data it might not be the case so, we will still perform this step.\n",
        "2. Replace the single and double opening and closing quotes like `  \\u2018`, `  \\u2019`, `  \\u201c` and `  \\u201d` by `'` and `\"` respectively.\n",
        "3. Replace the punctutations ``['.', '?', '!', ',', ':', '-', ''', '\"', '_', '(', ')', '{', '}', '[', ']', '`', ';', '...']`` by `[SPACE]punctutations`.\n",
        "In this process we need to make sure that the floating point numbers like `1.78` do not become `1 .78`. To do that the correct regex expression is ``(?<!\\d)\\s*([!\"#$%&\\'\\(\\)*+,-./:;<=>?@\\[\\]\\\\^_`{|}~])\\s*(?!\\d)``.\n",
        "4. Strip the texts from extra starting or ending spaces. Finally, remove extra spaces using regex expression like `\\s{2,}`.\n",
        "\n",
        "`custom_analyzer` function which will be feed to the Tokenizer as the value for `analyzer`, has some more steps to implement -\n",
        "1. Remove the `START_TOKEN` and `END_TOKEN` from the text. So that tokenizer does not standardize them.\n",
        "2. Standardize the text with `standardizer`.\n",
        "3. Add back the `START_TOKEN` and `END_TOKEN` because you want your tokenizer to learn them.\n",
        "4. Remove unwanted spaces in between words.\n",
        "5. Split the text into words which are seperated by ' '.\n",
        "6. Strip each of the words in the sentence. Finally, return it."
      ],
      "metadata": {
        "id": "TcZCpJ9hCyqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the text data\n",
        "def standardizer(text):\n",
        "  '''Standardize the text provided to the function\n",
        "  The text is lower cased. Then, the opening and closing quotes are removed. I add spaces before the\n",
        "  punctuations like `don't` becomes `don ' t`, ignoring the numerical values so that `1.78` does not become\n",
        "  `1 . 78`. Finally, it strips the text and removes any type of unwanted spaces in it.\n",
        "\n",
        "  Argument:\n",
        "    text: str, the text to standardize\n",
        "\n",
        "  Returns:\n",
        "    returns the standadized text\n",
        "  '''\n",
        "\n",
        "  # Lower case the text\n",
        "  text = text.lower()\n",
        "\n",
        "  # Replace the special single and double opening and closing quotes\n",
        "  text = re.sub(r'[\\u2019\\u2018]', \"'\", text)\n",
        "  text = re.sub(r'[\\u201c\\u201d]', '\"', text)\n",
        "\n",
        "  # Add space before punctuations and ignore floating point numbers.\n",
        "  text = re.sub(r'(?<!\\d)\\s*([!\"#$%&\\'\\(\\)*+,-./:;<=>?@\\[\\]\\\\^_`{|}~])\\s*(?!\\d)',\n",
        "                  r' \\1 ', text)  # It used to also remove commas after numbers like '27,' will be removed\n",
        "\n",
        "  # Remove spaces after sentence end and other unwanted spaces from text\n",
        "  text = text.strip()\n",
        "  text = re.sub('\\s{2,}', ' ', text)\n",
        "\n",
        "  return text\n",
        "\n",
        "# custom analyzer for the Tokenizer class\n",
        "def custom_analyzer(text):\n",
        "  '''Custom analyzer to provide to the `Tokenizer` class when creating the tokenizer.\n",
        "\n",
        "  Argument:\n",
        "    text: str, the text that will be tokenized\n",
        "\n",
        "  Returns:\n",
        "    returns the splitted sentence\n",
        "  '''\n",
        "  # Remove START and END before standardizing\n",
        "  if START_TOKEN in text:\n",
        "    text = re.sub(f'{START_TOKEN} ', '', text)\n",
        "  if END_TOKEN in text:\n",
        "    text = re.sub(f'{END_TOKEN} ', '', text)\n",
        "\n",
        "  # Standardize the text first\n",
        "  text = standardizer(text)\n",
        "\n",
        "  # Add back the START and END tokens\n",
        "  text = ' '.join([START_TOKEN, text, END_TOKEN])\n",
        "\n",
        "  # Split the sentence into words to tokenize\n",
        "  words = text.split(' ')\n",
        "  words = [word.strip() for word in words]\n",
        "\n",
        "  return words"
      ],
      "metadata": {
        "id": "FD2h0OiAxJP_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts = [\"I have been working on, \\nbut \\tnever did it in this way.\",\n",
        "                \"U.S won the world cup and bagged 1.78 million dollars.\",\n",
        "                \"India had M.S. Dhoni won made it this far.\",\n",
        "                \"My email address is arupjana7365@gmail.com.\",\n",
        "                \"It can take care of dailymail single opening quote also.\",\n",
        "                \"I have 10,000 Rs in my bank\",\n",
        "                \"This sentence has , after a number 12,\",\n",
        "                \"This sentence contains <START> token and <END> token.\"]\n",
        "\n",
        "print(f\"After Standardizing the sample texts:\\n{[standardizer(text) for text in sample_texts]}\\n\")\n",
        "print(f\"After applying custom analyzer on sample texts:\\n{[custom_analyzer(text) for text in sample_texts]}\")"
      ],
      "metadata": {
        "id": "AVi3kZhcLXS7",
        "outputId": "54f93dbf-ad55-42ec-a928-01a972742b3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Standardizing the sample texts:\n",
            "['i have been working on , but never did it in this way .', 'u . s won the world cup and bagged 1.78 million dollars .', 'india had m . s . dhoni won made it this far .', 'my email address is arupjana7365@gmail . com .', \"it can take care of dailymail single opening quote ' also .\", 'i have 10,000 rs in my bank', 'this sentence has , after a number 12,', 'this sentence contains < start > token and < end > token .']\n",
            "\n",
            "After applying custom analyzer on sample texts:\n",
            "[['<START>', 'i', 'have', 'been', 'working', 'on', ',', 'but', 'never', 'did', 'it', 'in', 'this', 'way', '.', '<END>'], ['<START>', 'u', '.', 's', 'won', 'the', 'world', 'cup', 'and', 'bagged', '1.78', 'million', 'dollars', '.', '<END>'], ['<START>', 'india', 'had', 'm', '.', 's', '.', 'dhoni', 'won', 'made', 'it', 'this', 'far', '.', '<END>'], ['<START>', 'my', 'email', 'address', 'is', 'arupjana7365@gmail', '.', 'com', '.', '<END>'], ['<START>', 'it', 'can', 'take', 'care', 'of', 'dailymail', 'single', 'opening', 'quote', \"'\", 'also', '.', '<END>'], ['<START>', 'i', 'have', '10,000', 'rs', 'in', 'my', 'bank', '<END>'], ['<START>', 'this', 'sentence', 'has', ',', 'after', 'a', 'number', '12,', '<END>'], ['<START>', 'this', 'sentence', 'contains', 'token', 'and', 'token', '.', '<END>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I need to find the tokens from the articles. I need to use only training articles not any other and also I will not use summaries data because that will be my target and I won't know what type of words I will encounter when summarizing the source article. So, the only words that I know will be from the articles of training dataset. Here, I am going to use the `tensorflow.keras.preprocessing.text.Tokenizer` in short `Tokenizer` to find the tokens from the articles and then finally converting the articles into sequence of integers. One thing to remember is here we are going to use `oov_token` arguement of `Tokenizer` to mention the token we want to use for out-of-vocabulary words.\n",
        "\n",
        "When fiting the texts on `tokenizer` make sure to remove floating point and integer numbers using the regex expression - `[+-]?[0-9]*[.]?[0-9]+`. I am making sure that tokenizer does learn the numbers because it can always be taken from the original articles data and we do not to remember them in vocab."
      ],
      "metadata": {
        "id": "IiiWRFR64jTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokenizer(texts, num_words, oov_token=None, filters = '#*+/:<=>@[\\\\]/^{|}~\\t\\n'):\n",
        "  '''This will create the tokenizer needed for the task in hand.\n",
        "  The tokenizer will be trained on the `texts`. Tokenizer will have vocabulary length `num_words`.\n",
        "  The `oov_token` will be used as the token represent the out-of-vocabulary words. The `filters` are\n",
        "  the ones which the tokenizer will remove when tokenizing any sentence given to it. The returned\n",
        "  tokenizer is using a custom analyzer that can standardize the sentence before tokenizing using the\n",
        "  `standardizer` function and then splits the sentence into words. After that it tokenizes the sentence.\n",
        "  As for the vocabulary, the returned tokenizer's vocabulary does not contain any number, as I have removed\n",
        "  them before feeding them into `Tokenizer.fit_on_texts` method.\n",
        "\n",
        "  Arguments:\n",
        "    texts: list of strings, the tokenizer will be trained on this strings\n",
        "    num_words: int, number of vocabulary words the tokenizer will consider\n",
        "    oov_token: str, token to represent out-of-vocabulary words\n",
        "    filters: str, all the characters that the tokenizer will remove before tokenizing\n",
        "\n",
        "  Returns:\n",
        "    tokenzier of the `Tokenizer` class after learning vocabulary from `texts`\n",
        "  '''\n",
        "\n",
        "  # Create the tokenizer usinf Tokenizer class\n",
        "  tokenizer = Tokenizer(num_words=num_words,\n",
        "                        filters=filters,\n",
        "                        oov_token=oov_token,\n",
        "                        analyzer=custom_analyzer)\n",
        "\n",
        "  # Remove the numbers from the dataset so that tokenizer does not add them inside vocabulary\n",
        "  texts = [re.sub(r\"[+-]?[0-9]*[.]?[0-9]+\", \"\", text) for text in texts]\n",
        "\n",
        "  # Fit the data with fit_on_texts method\n",
        "  tokenizer.fit_on_texts(texts)\n",
        "\n",
        "  return tokenizer"
      ],
      "metadata": {
        "id": "tR1FD3SESd0G"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length the articles dataset: {len(list(train_dataset[:, 0]))}\")"
      ],
      "metadata": {
        "id": "UsmErFoxqimM",
        "outputId": "5a2d3d61-e305-44b3-a6f0-af37114956d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length the articles dataset: 148126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the `tokenizer` using the articles from training dataset by using `train_dataset[:, 0]`, with a vocabulary size of `VOCAB_SIZE` and use `OOV_TOKEN` token to represent out-of-vocabulary words."
      ],
      "metadata": {
        "id": "6KBXcUV2pYrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer(list(train_dataset[:, 0]), VOCAB_SIZE, OOV_TOKEN)"
      ],
      "metadata": {
        "id": "151rEpqo7Pof"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The vocabulary for the tokenizer has a length {len(tokenizer.word_index.keys())}\\n\\n\")\n",
        "\n",
        "\n",
        "print(f\"{OOV_TOKEN} word has index: {tokenizer.word_index[OOV_TOKEN]}\")\n",
        "print(f\"{START_TOKEN} word has index: {tokenizer.word_index[START_TOKEN]}\")\n",
        "print(f\"{END_TOKEN} word has index: {tokenizer.word_index[END_TOKEN]}\\n\\n\")\n",
        "\n",
        "\n",
        "print(f\"'teacher' word has index: {tokenizer.word_index['teacher']}\\n\")\n",
        "\n",
        "print(f\"Text:\\n{train_dataset[0, 0]}\\n\\n\")\n",
        "sample_sequence = tokenizer.texts_to_sequences([train_dataset[0, 0]])\n",
        "print(f\"Text to Sequence of the first article:\\n{sample_sequence}\\n\")\n",
        "print(f\"Sequence to Text of the first acrticle:\\n{tokenizer.sequences_to_texts(sample_sequence)}\")"
      ],
      "metadata": {
        "id": "YUNreIjr8Kng",
        "outputId": "2f8b58b2-f386-4656-dae2-50f9d394a149",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vocabulary for the tokenizer has a length 225783\n",
            "\n",
            "\n",
            "<OOV> word has index: 1\n",
            "<START> word has index: 80\n",
            "<END> word has index: 81\n",
            "\n",
            "\n",
            "'teacher' word has index: 2110\n",
            "\n",
            "Text:\n",
            "(cnn) -- jenson button is relishing sunday's hungarian grand prix, as the mclaren driver returns to the site of his first-ever victory for the 200th race of his formula one career. the 31-year-old withdrew from last weekend's german grand prix, won by his teammate lewis hamilton, after 35 laps with hydraulics problems, but button is hoping for better luck at the track where he tasted success as a honda driver in 2006. \"it's always fun coming back to hungary as this is the track at which i won my first grand prix,\" the 2009 drivers' champion told mclaren's web site. \"after a premature end to my race at the nurburgring, i'll be hoping for better luck at the hungaroring. \"i can't believe i've already knocked up a double-ton of f1 starts because i don't feel a day older than when i made my debut back in 2000!\" resurgent hamilton triumphs in germany. button made his first appearance in the elite division of motorsport at the australian grand prix in 2000 with williams, and has since gone on to represent benetton, renault, bar, honda, brawn gp and now mclaren in an 11-year career. the briton has notched up 10 grand prix triumphs and secured his only world crown to date in 2009, while racing for brawn. button is hopeful of a strong showing on sunday and is taking encouragement from his third-place finish at the monaco grand prix -- a circuit he feels presents a very similar challenge to the hungaroring. \"the mp4-26 [mclaren's car] was very competitive in monaco a couple of months ago and i hope it will be a similar situation this weekend because the hungaroring has many of the same performance criteria. latest f1 standings after the german gp. \"cockpit temperatures regularly exceed 50 degrees and we're always pulling g-force in the car because there are so many corners. it's tough, but this is definitely a circuit when all the training pays dividends.\" hamilton is also a previous winner in hungary having triumphed at the venue in 2007 and the 26-year-old is eager to build on his success at the nurburgring last time out. \"i've always gone well in hungary,\" said the 2008 world champion. \"i like the circuit because it's old school. it has a very historic feel to it, with hills and bumps and cambers changes, and it has massive character.\" hamilton beat off fierce competition from ferrari's fernando alonso and mark webber of red bull to earn a hard-fought win in germany and he is anticipating another close contest. \"there wasn't much between mclaren, ferrari and red bull in germany. it's going to be fascinating to see which team holds the advantage next weekend.\" despite hamilton, alonso and webber finishing on the podium last time out, all three drivers trail reigning world champion and current standings leader sebastian vettel. vettel, 24, holds a 77-point lead over his colleague webber at the top of the championship heading into the 11th race of the season.\n",
            "\n",
            "\n",
            "Text to Sequence of the first article:\n",
            "[[80, 44, 42, 43, 12, 12, 12267, 3609, 16, 27395, 252, 11, 13, 9873, 832, 3518, 4, 23, 2, 5456, 1344, 3958, 5, 2, 422, 7, 26, 88, 12, 394, 778, 15, 2, 1, 494, 7, 26, 2746, 53, 733, 3, 2, 1, 12, 150, 6683, 29, 96, 802, 11, 13, 1264, 832, 3518, 4, 272, 32, 26, 4079, 2793, 3406, 4, 60, 1, 10183, 22, 1, 640, 4, 31, 3609, 16, 1869, 15, 315, 4443, 25, 2, 1169, 111, 21, 16335, 898, 23, 9, 6879, 1344, 10, 1, 6, 18, 11, 13, 333, 1558, 538, 127, 5, 8050, 23, 33, 16, 2, 1169, 25, 66, 24, 272, 90, 88, 832, 3518, 4, 6, 2, 1, 2292, 11, 1133, 87, 5456, 11, 13, 839, 422, 3, 6, 60, 9, 8231, 234, 5, 90, 494, 25, 2, 34868, 4, 24, 11, 372, 30, 1869, 15, 315, 4443, 25, 2, 42123, 3, 6, 24, 63, 11, 41, 347, 24, 11, 204, 332, 4376, 67, 9, 1701, 12, 7327, 7, 1, 2950, 103, 24, 136, 11, 41, 418, 9, 118, 1667, 76, 59, 24, 138, 90, 2929, 127, 10, 1, 6, 17691, 3406, 12797, 10, 1060, 3, 3609, 138, 26, 88, 1923, 10, 2, 3549, 2268, 7, 10046, 25, 2, 1423, 832, 3518, 10, 1, 22, 1229, 4, 8, 34, 146, 961, 19, 5, 2582, 33809, 4, 10989, 4, 1907, 4, 6879, 4, 16261, 13617, 8, 102, 5456, 10, 37, 1, 733, 3, 2, 9559, 34, 19942, 67, 1, 832, 3518, 12797, 8, 4547, 26, 112, 95, 3565, 5, 1340, 10, 1, 116, 2384, 15, 16261, 3, 3609, 16, 4258, 7, 9, 658, 1502, 19, 252, 8, 16, 402, 9664, 29, 26, 466, 12, 220, 1979, 25, 2, 6312, 832, 3518, 12, 12, 9, 2913, 21, 2106, 6197, 9, 131, 788, 1028, 5, 2, 42123, 3, 6, 2, 1, 584, 5456, 11, 13, 430, 583, 20, 131, 3168, 10, 6312, 9, 727, 7, 288, 317, 8, 24, 497, 18, 45, 30, 9, 788, 546, 33, 802, 103, 2, 42123, 34, 109, 7, 2, 197, 1233, 6556, 3, 776, 1, 7013, 60, 2, 1264, 13617, 3, 6, 5171, 2899, 3044, 10047, 1, 2885, 8, 38, 11, 117, 333, 4308, 2132, 12, 460, 10, 2, 430, 103, 58, 28, 73, 109, 7881, 3, 18, 11, 13, 1271, 4, 31, 33, 16, 2191, 9, 2913, 59, 62, 2, 869, 6271, 16793, 3, 6, 3406, 16, 69, 9, 1094, 1318, 10, 8050, 384, 9920, 25, 2, 5065, 10, 1, 8, 2, 1, 12, 150, 16, 5056, 5, 1150, 19, 26, 898, 25, 2, 34868, 96, 74, 65, 3, 6, 24, 11, 204, 333, 961, 155, 10, 8050, 4, 6, 17, 2, 1, 95, 1133, 3, 6, 24, 86, 2, 2913, 103, 18, 11, 13, 150, 214, 3, 18, 34, 9, 131, 1929, 418, 5, 18, 4, 22, 3945, 8, 14705, 8, 1, 1090, 4, 8, 18, 34, 1443, 1466, 3, 6, 3406, 1230, 154, 4579, 1434, 29, 3963, 11, 13, 4747, 4901, 8, 886, 8346, 7, 684, 3942, 5, 3520, 9, 391, 12, 2275, 378, 10, 1060, 8, 21, 16, 15889, 174, 485, 2884, 3, 6, 58, 582, 11, 41, 161, 173, 5456, 4, 3963, 8, 684, 3942, 10, 1060, 3, 18, 11, 13, 149, 5, 30, 7484, 5, 157, 66, 221, 2704, 2, 1910, 213, 802, 3, 6, 491, 3406, 4, 4901, 8, 8346, 4918, 19, 2, 6361, 96, 74, 65, 4, 62, 123, 2292, 3093, 7539, 95, 1133, 8, 691, 7013, 435, 6533, 5082, 3, 5082, 4, 1, 2704, 9, 1, 527, 91, 26, 5324, 8346, 25, 2, 258, 7, 2, 2069, 2809, 85, 2, 1, 494, 7, 2, 401, 3, 81]]\n",
            "\n",
            "Sequence to Text of the first acrticle:\n",
            "['<START> ( cnn ) - - jenson button is relishing sunday \\' s hungarian grand prix , as the mclaren driver returns to the site of his first - ever victory for the <OOV> race of his formula one career . the <OOV> - old withdrew from last weekend \\' s german grand prix , won by his teammate lewis hamilton , after <OOV> laps with <OOV> problems , but button is hoping for better luck at the track where he tasted success as a honda driver in <OOV> \" it \\' s always fun coming back to hungary as this is the track at which i won my first grand prix , \" the <OOV> drivers \\' champion told mclaren \\' s web site . \" after a premature end to my race at the nurburgring , i \\' ll be hoping for better luck at the hungaroring . \" i can \\' t believe i \\' ve already knocked up a double - ton of <OOV> starts because i don \\' t feel a day older than when i made my debut back in <OOV> \" resurgent hamilton triumphs in germany . button made his first appearance in the elite division of motorsport at the australian grand prix in <OOV> with williams , and has since gone on to represent benetton , renault , bar , honda , brawn gp and now mclaren in an <OOV> career . the briton has notched up <OOV> grand prix triumphs and secured his only world crown to date in <OOV> while racing for brawn . button is hopeful of a strong showing on sunday and is taking encouragement from his third - place finish at the monaco grand prix - - a circuit he feels presents a very similar challenge to the hungaroring . \" the <OOV> [ mclaren \\' s car ] was very competitive in monaco a couple of months ago and i hope it will be a similar situation this weekend because the hungaroring has many of the same performance criteria . latest <OOV> standings after the german gp . \" cockpit temperatures regularly exceed <OOV> degrees and we \\' re always pulling g - force in the car because there are so many corners . it \\' s tough , but this is definitely a circuit when all the training pays dividends . \" hamilton is also a previous winner in hungary having triumphed at the venue in <OOV> and the <OOV> - old is eager to build on his success at the nurburgring last time out . \" i \\' ve always gone well in hungary , \" said the <OOV> world champion . \" i like the circuit because it \\' s old school . it has a very historic feel to it , with hills and bumps and <OOV> changes , and it has massive character . \" hamilton beat off fierce competition from ferrari \\' s fernando alonso and mark webber of red bull to earn a hard - fought win in germany and he is anticipating another close contest . \" there wasn \\' t much between mclaren , ferrari and red bull in germany . it \\' s going to be fascinating to see which team holds the advantage next weekend . \" despite hamilton , alonso and webber finishing on the podium last time out , all three drivers trail reigning world champion and current standings leader sebastian vettel . vettel , <OOV> holds a <OOV> lead over his colleague webber at the top of the championship heading into the <OOV> race of the season . <END>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The oddness you might see if you are that much familiar with `Tokenizer` class is, even though I have specified that `num_words=VOCAB_SIZE` which is `20,000` still the length of the `word_index` is more that that. Does that mean we are doing something wrong?\n",
        "NO, here although tokenizer computes the word_index of all other words apart from those first 20000 words, it will not use them when we convert them into sequence. Let's look at one example to understand that."
      ],
      "metadata": {
        "id": "crn5t_zk6iBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(tokenizer.word_index.keys())[21000]"
      ],
      "metadata": {
        "id": "qhttL-heeP-P",
        "outputId": "5f2784fe-6c25-4194-bb06-23179063077e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'conditional'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oov_word = list(tokenizer.word_index.keys())[21000]\n",
        "sample_text = f\"This example is to test the above fact with the word `{oov_word}`\"\n",
        "sample_sequence = tokenizer.texts_to_sequences([sample_text])\n",
        "\n",
        "print(f\"Text: {sample_text}\\n\\n\")\n",
        "print(f\"Tokenized text: {tokenizer.sequences_to_texts(sample_sequence)}\")\n",
        "print(f\"Sequence: {sample_sequence}\")"
      ],
      "metadata": {
        "id": "S_Dnkcig7SIX",
        "outputId": "b26a6dc2-85e0-4676-b50c-cfa183c80a1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: This example is to test the above fact with the word `conditional`\n",
            "\n",
            "\n",
            "Tokenized text: ['<START> this example is to test the above fact with the word ` conditional ` <END>']\n",
            "Sequence: [[80, 33, 931, 16, 5, 932, 2, 1201, 476, 22, 2, 1096, 24283, 21001, 24283, 81]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the word was present in the `word_index` mapping still tokenizer represented it with `<OOV>`."
      ],
      "metadata": {
        "id": "xvNeazXb-Yq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"What happens when I add a number 2.1 in this sentence!\"\n",
        "sample_sequence = tokenizer.texts_to_sequences([sample_text])\n",
        "\n",
        "print(f\"Text: {sample_text}\\n\\n\")\n",
        "print(f\"Tokenized text: {tokenizer.sequences_to_texts(sample_sequence)}\")\n",
        "print(f\"Sequence: {sample_sequence}\")"
      ],
      "metadata": {
        "id": "ng5MZ_DZ84kk",
        "outputId": "4537aed9-7c67-46cb-b0a4-2f76edf9749f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: What happens when I add a number 2.1 in this sentence!\n",
            "\n",
            "\n",
            "Tokenized text: ['<START> what happens when i add a number <OOV> in this sentence ! <END>']\n",
            "Sequence: [[80, 61, 1711, 59, 24, 1964, 9, 277, 1, 10, 33, 1350, 306, 81]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"What happens when I add parenthesis (I am inside it!).\"\n",
        "sample_sequence = tokenizer.texts_to_sequences([sample_text])\n",
        "\n",
        "print(f\"Text: {sample_text}\\n\\n\")\n",
        "print(f\"Tokenized text: {tokenizer.sequences_to_texts(sample_sequence)}\")\n",
        "print(f\"Sequence: {sample_sequence}\")"
      ],
      "metadata": {
        "id": "ImlMHniH-Jnt",
        "outputId": "7ecc1870-1e95-4278-a95e-1d874fa3f9cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: What happens when I add parenthesis (I am inside it!).\n",
            "\n",
            "\n",
            "Tokenized text: ['<START> what happens when i add <OOV> ( i am inside it ! ) . <END>']\n",
            "Sequence: [[80, 61, 1711, 59, 24, 1964, 1, 44, 24, 475, 553, 18, 306, 43, 3, 81]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to prepare the data for feeding to the model"
      ],
      "metadata": {
        "id": "EpMm2cNIEm_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have the `tokenizer` to tokenize the articles and summaries. We need to pad those sequences to fit the requirements.\n",
        "\n",
        "In the paper, the articles are limited to have 400 tokens and summary has, 100 tokens at training and 120 tokens for testing.\n",
        "\n",
        "I will be using `pad_sequences` method to pad or truncate the articles and summaries based on their length.\n",
        "\n",
        "NOTE: I am using same tokenizer for article and summary. But, later I might change that to 2 different tokenizers each having different `num_words`."
      ],
      "metadata": {
        "id": "jza9oQYKXB0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_pad(texts, tokenizer, padding, truncating, maxlen):\n",
        "  '''Tokenize the `texts` using the tokenizer. Then, pad the sequences or truncate the sequences\n",
        "  depending the length. If the length exceeds `maxlen` then it will be truncated and if not then it will be\n",
        "  padded. The padding and truncating can happend at the beginning or at the end of the sequence depending\n",
        "  on the value of `padding` and `truncating` respectively.\n",
        "\n",
        "  Arguments:\n",
        "    texts: list of strings, the sentences to tokenize and pad\n",
        "    tokenizer: Tokenizer class object, helps in tokenizing the `texts`\n",
        "    padding: str, can take 2 values `pre` or `post`. If `pre` then padding will happen at the beginning,\n",
        "    if `post` then padding will happen at the end.\n",
        "    truncating: str, can take 2 values `pre` or 'truncating`, works the same as `padding`\n",
        "    maxlen: int, maximum length after padding or truncating\n",
        "\n",
        "  Returns:\n",
        "    returns the tokenized and padded sentences\n",
        "  '''\n",
        "  sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "  padded_sequences = pad_sequences(sequences, maxlen=maxlen, padding=padding, truncating=truncating)\n",
        "\n",
        "  return padded_sequences"
      ],
      "metadata": {
        "id": "Alo70WYjW-tA"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rttUwCiT4FzJ",
        "outputId": "52fbabc0-1346-420f-9773-c910b8180e95"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I have been working on, \\nbut \\tnever did it in this way.',\n",
              " 'U.S won the world cup and bagged 1.78 million dollars.',\n",
              " 'India had M.S. Dhoni won made it this far.',\n",
              " 'My email address is arupjana7365@gmail.com.',\n",
              " 'It can take care of dailymail single opening quote also.',\n",
              " 'I have 10,000 Rs in my bank',\n",
              " 'This sentence has , after a number 12,',\n",
              " 'This sentence contains <START> token and <END> token.']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_pad(sample_texts, tokenizer, padding=\"post\", truncating=\"post\", maxlen=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNuBKpTq4lZW",
        "outputId": "1fbfe6ff-4318-4b3c-f534-520e4a9e658a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   80,    24,    27,    55,   320,    19,     4,    31,   212,\n",
              "          144,    18,    10,    33,   139,     3,    81,     0,     0,\n",
              "            0,     0],\n",
              "       [   80,    79,     3,    13,   272,     2,    95,   639,     8,\n",
              "        23410,     1,   169,  1571,     3,    81,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [   80,   796,    51,   133,     3,    13,     3, 24094,   272,\n",
              "          138,    18,    33,   311,     3,    81,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [   80,    90,  4398,  1011,    16,     1,     3,   405,     3,\n",
              "           81,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [   80,    18,    63,   158,   307,     7,     1,   872,  1088,\n",
              "         6800,    11,    69,     3,    81,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [   80,    24,    27,     1, 17171,    10,    90,  1003,    81,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [   80,    33,  1350,    34,     4,    60,     9,   277,     1,\n",
              "           81,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [   80,    33,  1350,  4730, 17599,     8, 17599,     3,    81,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Model Architecture & Training"
      ],
      "metadata": {
        "id": "Gt31OiYpEymZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After this, we need the model that we can train on this dataset. The model archietecture will be 3-\n",
        "1. Base-line model: Seq-Seq model with attention mechanism.\n",
        "2. Pointer Generetor model: With seq-seq attention model will be implementing the pointer generator that can either copy words from article or generate words from the pre-defined vocabulary.\n",
        "3. Coverage mechanism: Along with the pointer generator that will take case of the out-of-vocabulary words. Coverage mechanism will help prevent the repetition of the words in the summary."
      ],
      "metadata": {
        "id": "yM6KveyaUmfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base-Line Model: Seq-seq with Attention"
      ],
      "metadata": {
        "id": "UarmKLUIVkjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating `tf_train_dataset`, `tf_val_dataset` using tf.data API\n",
        "\n",
        "Now, I need write the `generate_example` function that can help me generate model inputs for training, validation and testing set. For different type of dataset, we will create different generator with the help of the `example_generator` method to create `tf.data.Dataset` object for our model.\n",
        "\n",
        "We can use `tf.data` API to create the input data pipeline for our model. I will use the `tf.data.Dataset` class to get the the examples from the `train_example_generator` function which uses `generate_example`, we can save the generator inside `example_gen` which we can iterate over later to get the examples. We can yield the examples according to the need of the problem.\n",
        "\n",
        "Remember, along with input article tokens and input summary tokens, we need the initial states as an input to the model. So, as we process the examples we can create this zero-value tensors and yield them along with 2 original inputs.\n",
        "\n",
        "For more about datasets from generator, refer to [here](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator)."
      ],
      "metadata": {
        "id": "usV8UchPA35e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `generate_example_v1` function creation\n",
        "Create a Geneator function that generates the source and target for training the model."
      ],
      "metadata": {
        "id": "ZUtzIfXm6UnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_example_v1(inputs, targets, input_tokenizer, target_tokenizer, input_len, target_len):\n",
        "  '''Generates examples for the model. Processes the `inputs` and `targets` with their respective\n",
        "  tokenizers and tokenize them to `input_len` and `target_len` length.\n",
        "\n",
        "  Arguments:\n",
        "    inputs: list of input sentences\n",
        "    targets: list of target sentences\n",
        "    input_tokenizer: Tokenizer class object, tokenizer for inputs\n",
        "    target_tokenizer: Tokenizer class object, tokenizer for targets\n",
        "    input_len: int, the length of the tokenization for inputs\n",
        "    target_len: int, the length of the tokenization for targets\n",
        "\n",
        "  Returns:\n",
        "    returns 2 values, a tuple containing 2 numpy arrays (input_tokens, target_tokens[:-1]) and\n",
        "    another numpy array target_tokens[1:]\n",
        "  '''\n",
        "\n",
        "  for inp, tar in zip(inputs, targets):\n",
        "    # Tokenizing article words\n",
        "    inp_tokens = tokenize_pad([inp],\n",
        "                              input_tokenizer,\n",
        "                              padding=\"post\",\n",
        "                              truncating=\"post\",\n",
        "                              maxlen=input_len)\n",
        "\n",
        "    # Tokenizing summary words\n",
        "    tar_tokens = tokenize_pad([tar],\n",
        "                 target_tokenizer,\n",
        "                 padding=\"post\",\n",
        "                 truncating=\"post\",\n",
        "                 maxlen=target_len)\n",
        "\n",
        "    yield (inp_tokens[0], tar_tokens[0][:-1]), tar_tokens[0][1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8647M-ey6n19",
        "outputId": "0783fcd2-3e99-45dc-cff0-102a8f9572f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Example with the generator function"
      ],
      "metadata": {
        "id": "-nytCw0dFO2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Example generated by the generator v1:\")\n",
        "\n",
        "# (inp_art_tokens, inp_sum_tokens), tar_sum_tokens = generate_example(list(train_dataset[:, 0]),\n",
        "example_gen = generate_example_v1(list(train_dataset[:, 0]),\n",
        "                               list(train_dataset[:, 1]),\n",
        "                               input_tokenizer=tokenizer,\n",
        "                               target_tokenizer=tokenizer,\n",
        "                               input_len=MAX_ARTICLE_TOKENS,\n",
        "                               target_len=MAX_SUMMARY_TOKENS)\n",
        "\n",
        "inps, tar = next(example_gen)\n",
        "print(f\"Inputs:\\n{inps[0]}\\n{inps[1]}\\n\\n\")\n",
        "print(f\"Target:\\n{tar}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "id": "BKKyIeVa5B20",
        "outputId": "f424eca8-5f29-4dd0-915b-7f5e362399ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example generated by the generator :\n",
            "Inputs:\n",
            "[   80    44    42    43    12    12   831   127  3951  3915   152    36\n",
            " 18545   821     5     9     1  1296    10  3733     4  1330  4243  1151\n",
            "     4    31  9579   812    50     2   258   173  7545    11    13  9225\n",
            "    15 17603     9   587  1606     3   831   127  3064     9   978     8\n",
            "  2466  1296    10  3733    19   233     3  3733    11    13  4038     1\n",
            "  6059   267    73   108   292    57    52   396  2268    15     9   227\n",
            "   591    10  1087     8    17    14   127    11    13  1029    12    12\n",
            "    66  5408  5142    32   201    79     3    13     3  3087   377  1582\n",
            "     3  1501     8  4316  2867    59     2  3546   150    20    10     2\n",
            "  1556   237 18546    12    12    99   112    27    55   135    10     2\n",
            "  1330   635     3     6   831   127    11    13  1029   280    38    27\n",
            "    55     1     8    18  2239   567    11    41     1    12  5157     3\n",
            "    31    22    71 13873     8     2   740     7    33     1    12   151\n",
            "     4    18  1214    20     2  3859     7     9    68  1828    15     9\n",
            "    68  1513    19   193  1388     7     2  2687     4     6     2  1104\n",
            "    17     3     6    61   314   399    99    27   550     5   163    76\n",
            "     2   794   212   100     7     2    79     3    13     3  2153    33\n",
            "   740     5     2    94    29   207    77     6   127   902    19    29\n",
            "  1087     5   741    19   230   111    21    20   841     5   887  1155\n",
            "    22   100  5382  5729     3    21    16    69  7619     5   891   506\n",
            "   586   347  4459   784     8   710   438   702  2908    10   464   236\n",
            "   230     3  1330  6944     1    17   127    52     1    26  1377     7\n",
            "     2   169  1569    12    12     2   735    14  1068    63   310     2\n",
            "    94    47     6  2521   941  1990     3   768     4    21   822     5\n",
            "    93    33    10  2731    22   295     4   698   746     3    14    11\n",
            "    13    26   740    29  3733    47   474    11    13   538    33   469\n",
            "   302     6    31     1  1525    14    36   127  2677    65   223  2082\n",
            "  2809    19  1532  2089   161    23  1087     4    66  1487    64    22\n",
            "   279    90     2   237    10   370     8    34  1649     5  4475  1894\n",
            "   618     5  1405  1093    10   532     3  2182     3   411    47  1003\n",
            "   971    29     2   906     3     6    21   238    11    41   141    61\n",
            "    21  4059     4    31    18    11    13    38   393     5  1311    18\n",
            "    64     3    21    11   372   379    15    54  1330  4656   152   199\n",
            "  7498   165    21    11]\n",
            "[  80 1330 3696 1835   14  831  127  265 3915   22 3733  821    3 4038\n",
            "    1   47  127   11   13  821    9    6 3859    7    9   68 1828   15\n",
            "    9   68 1513    6   31  603 3153 4711   90  258  173 7545   11   13\n",
            " 9225    3 3696  141  127   45 1628   54 1330  618   15  532    3   81\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0]\n",
            "\n",
            "\n",
            "Target:\n",
            "[1330 3696 1835   14  831  127  265 3915   22 3733  821    3 4038    1\n",
            "   47  127   11   13  821    9    6 3859    7    9   68 1828   15    9\n",
            "   68 1513    6   31  603 3153 4711   90  258  173 7545   11   13 9225\n",
            "    3 3696  141  127   45 1628   54 1330  618   15  532    3   81    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shapes of the Inputs:\\n{inps[0].shape}\\n{inps[1].shape}\\n\\n\")\n",
        "print(f\"Shape of the Target:\\n{tar.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "E-w0hmecDcho",
        "outputId": "dc67edf1-88c5-4f30-935e-e3ea04f8b0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of the Inputs:\n",
            "(400,)\n",
            "(99,)\n",
            "\n",
            "\n",
            "Shape of the Target:\n",
            "(99,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Data Type of the Inputs data:\\n{inps[0].dtype}\\n{inps[1].dtype}\\n\\n\")\n",
        "print(f\"Data Type of the Target data:\\n{tar.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "suZmEEhfDvcu",
        "outputId": "0e2da90a-79b0-4b89-a5da-5b28d899609c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Type of the Inputs data:\n",
            "int32\n",
            "int32\n",
            "\n",
            "\n",
            "Data Type of the Target data:\n",
            "int32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inps, tar = next(example_gen)\n",
        "print(f\"Second Inputs:\\n{inps[0]}\\n{inps[1]}\\n\\n\")\n",
        "print(f\"Second Target:\\n{tar}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "82m4io2PSyt3",
        "outputId": "d95bc6aa-4364-4c1f-c3de-8b0a11ce5f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second Inputs:\n",
            "[   80    44    42    43    12    12   222  6837     1     1     8     1\n",
            "    10   454   695    19   230  1234    60  7293    10  8812  1046  1015\n",
            "    49  5048   378    10     2   118     3  1450     1     8  3349    29\n",
            "     2   695   254     7  1881    48   145   321    10     2   308     4\n",
            "  9036  1031 12160     1    17     3     6  2072  1280     5  1046     8\n",
            "  1351  1274    72    25    62   476     4     6    46    17     3     6\n",
            "   344    15  1491     8  1450     3     6  8812  1046    52  9698   647\n",
            "     5  7643   549  6953     7  5879     1  7318     7     9     1  4173\n",
            "     7     2  5879    48  1231    10   193  7266    29  1675  8390     5\n",
            "  2537     1     4     1    17     3    58    48   282  4843     4   185\n",
            "     9   105   620    39    20   442    32     9   419   117   359     5\n",
            "   114     5   174  1479    19  5879     1     2   620    20  4267   233\n",
            "  1439    22  2781  1373     4    42  1260     1   234     3  1239  1450\n",
            "    69  1015     2  5048     7    79     3    13     3  2807     1   612\n",
            "     7  1675  8390     5     2    68   683   107   501     3     2   171\n",
            "   990   336  4705 10582    15   230   270     8   305    10  1675  8390\n",
            "     4  2537     1     8     1     4    22   426  6523    32   305   270\n",
            "     3    81     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n",
            "[   80   998     7     1     1     8     1    48  2158   102     7  1450\n",
            "     8  7293     3  1450     1     8  3349  1154  3089     3  6246  5327\n",
            " 10582   144   305     4   131   426  6523     3    81     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n",
            "\n",
            "\n",
            "Second Target:\n",
            "[  998     7     1     1     8     1    48  2158   102     7  1450     8\n",
            "  7293     3  1450     1     8  3349  1154  3089     3  6246  5327 10582\n",
            "   144   305     4   131   426  6523     3    81     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Making training, validation set examples for baseline model"
      ],
      "metadata": {
        "id": "9m3U7a0pFULD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_example_generetor_v1():\n",
        "  example_gen = generate_example_v1(list(train_dataset[:, 0]),\n",
        "                                list(train_dataset[:, 1]),\n",
        "                                input_tokenizer=tokenizer,\n",
        "                                target_tokenizer=tokenizer,\n",
        "                                input_len=MAX_ARTICLE_TOKENS,\n",
        "                                target_len=MAX_SUMMARY_TOKENS)\n",
        "\n",
        "  for example in example_gen:\n",
        "    s0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "    c0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "\n",
        "    (input_0, input_1), target = example\n",
        "    yield (input_0, input_1, s0, c0), target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "J_0r7ajRR8wk",
        "outputId": "367e274d-63e4-4e55-ae53-a7a96011f899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_signature = (\n",
        "    (tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32)),\n",
        "    tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32)\n",
        ")\n",
        "\n",
        "tf_train_dataset = tf.data.Dataset.from_generator(generator=train_example_generetor_v1,\n",
        "                                                  output_signature=output_signature)\n",
        "tf_train_dataset = tf_train_dataset.shuffle(BUFFER_SIZE)\n",
        "tf_train_dataset = tf_train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "tf_train_dataset = tf_train_dataset.prefetch(1)"
      ],
      "metadata": {
        "id": "Zj-H_fEh5Zu9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "524e02fb-448c-4b19-b09f-4d81b72f57a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def val_example_generetor_v1():\n",
        "  example_gen = generate_example_v1(list(val_dataset[:, 0]),\n",
        "                                list(val_dataset[:, 1]),\n",
        "                                input_tokenizer=tokenizer,\n",
        "                                target_tokenizer=tokenizer,\n",
        "                                input_len=MAX_ARTICLE_TOKENS,\n",
        "                                target_len=MAX_SUMMARY_TOKENS)\n",
        "\n",
        "  for example in example_gen:\n",
        "    s0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "    c0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "\n",
        "    (input_0, input_1), target = example\n",
        "    yield (input_0, input_1, s0, c0), target\n",
        "\n",
        "\n",
        "output_signature = (\n",
        "    (tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32)),\n",
        "    tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32)\n",
        ")\n",
        "\n",
        "tf_val_dataset = tf.data.Dataset.from_generator(generator=val_example_generetor_v1,\n",
        "                                                  output_signature=output_signature)\n",
        "tf_val_dataset = tf_val_dataset.shuffle(BUFFER_SIZE)\n",
        "tf_val_dataset = tf_val_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "-2qJcIbjRZXd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "89e83c15-798b-4136-818d-bac52016ad60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (art_inp, sum_inp, s0, c0), sum_tar in tf_train_dataset.take(1):\n",
        "  print(f\"Input tokenized article shape: {art_inp.shape}\")\n",
        "  print(f\"Input tokenized summary shape: {sum_inp.shape}\\n\")\n",
        "\n",
        "  print(f\"Target tokenized summary shape: {sum_tar.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "no4oMl22Fm6r",
        "outputId": "d3c68da1-cb08-4c1b-8e09-b769ccfcbb97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokenized article shape: (16, 400)\n",
            "Input tokenized summary shape: (16, 99)\n",
            "\n",
            "Target tokenized summary shape: (16, 99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A small demonstration of how Dot layer works"
      ],
      "metadata": {
        "id": "-2S_Jxhf25-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(10).reshape(1, 2, 5)\n",
        "res1 = tf.keras.layers.Dense(units=10)(x)\n",
        "res2 = tf.keras.layers.Dense(units=12)(res1)\n",
        "print(f\"After applying dense layer on x of shape:{x.shape}, res1 has{res1.shape} & res2 has {res2.shape} shape\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxBGPuOWKubc",
        "outputId": "125bcc6b-03c9-4c0e-e5aa-5920b47d29f0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After applying dense layer on x of shape:(1, 2, 5), res1 has(1, 2, 10) & res2 has (1, 2, 12) shape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = np.arange(10).reshape(1, 2, 5)\n",
        "x2 = np.arange(10, 22).reshape(1, 2, 6)\n",
        "print(f\"x1: {x1}\\nx2: {x2}\")\n",
        "\n",
        "Dot(axes=1)([x1, x2])"
      ],
      "metadata": {
        "id": "_WLTScTp1x-R",
        "outputId": "82c0a1d8-f90a-4d8c-8520-f25a9c06b0e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1: [[[0 1 2 3 4]\n",
            "  [5 6 7 8 9]]]\n",
            "x2: [[[10 11 12 13 14 15]\n",
            "  [16 17 18 19 20 21]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 5, 6), dtype=int64, numpy=\n",
              "array([[[ 80,  85,  90,  95, 100, 105],\n",
              "        [106, 113, 120, 127, 134, 141],\n",
              "        [132, 141, 150, 159, 168, 177],\n",
              "        [158, 169, 180, 191, 202, 213],\n",
              "        [184, 197, 210, 223, 236, 249]]])>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attention Mechanism"
      ],
      "metadata": {
        "id": "BVsZ_DeVmaie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_time_attention_v1(a, s_prev,\n",
        "                       repeater, concatenator, densor_1, densor_2, softmax_layer, dotter):\n",
        "  '''Calculates the attention score and returns the context for the current timestep in the decoder.\n",
        "  Attention mechanism uses encoder outputs `a` of shape `(batch, timesteps, features)` and decoder\n",
        "  previous hidden state `s_prev` of shape `(batch, features)`, then calculates alignment scores `alphas`\n",
        "  for each encoder timestep with the help of energies computed with 2 dense layers using `a` and `s_prev`.\n",
        "\n",
        "  Arguments:\n",
        "    a: tf.Tensor object, encoder output of shape `(batch, timesteps, features)` or `(batch, Tx, 2*n_a)`\n",
        "    s_prev: tf.Tensor object, decoder previous hidden state of shape `(batch, features)` or `(batch, n_s)`\n",
        "    repeater: RepeatVector layer, repeat the `s_prev` `Tx` times\n",
        "    concatenator: Concatenate layer, concatenates `a` and repeated `s_prev`, Concatenates along axis=-1\n",
        "    densor_1: Dense layer, calculates the pertial energies `e`, with `units=d1_units`\n",
        "    refer to `baseline_model` function for details about this variable\n",
        "    densor_2: Dense layer, calculated the energies `energies`, with `units=d2_units`\n",
        "    refer to `baseline_model` function for details about this variable\n",
        "    softmax_layer: Activation layer, computes softmax of the energies and calculates `alphas`, with\n",
        "    `units=article_vocab_size` refer to `baseline_model` function for details about this variable\n",
        "    dotter: Dot layer, Performs dot operation between `alphas` and `a` along axis=1\n",
        "\n",
        "  Returns:\n",
        "    returns the context of shape `(batch, features)`\n",
        "  '''\n",
        "\n",
        "  # Repeat the `s_prev` `Tx` times\n",
        "  s_prev = repeater(s_prev) # (batch, Tx, n_s)\n",
        "\n",
        "  # Concatenate `a` and `s_prev` along axis=-1\n",
        "  concat = concatenator([a, s_prev]) # (batch, Tx, n_a + n_s)\n",
        "\n",
        "  # Apply dense layer to get partial energies e\n",
        "  e = densor_1(concat) # (batch, Tx, d1_units)\n",
        "\n",
        "  # Apply dense layer again to get energies\n",
        "  energies = densor_2(e) # (batch, Tx, d2_units)\n",
        "\n",
        "  # Apply softmax over the energies\n",
        "  alphas = softmax_layer(energies) # (batch, Tx, d2_units)\n",
        "\n",
        "  # Dot the alphas and a along axes=1\n",
        "  context = dotter([alphas, a]) # (batch, d2_units, 2*n_a)\n",
        "\n",
        "  return context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "B_rPlnWardTC",
        "outputId": "2b856755-06a5-47b7-90fb-30f2001b4690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder-decoder Model using Attention mechanism"
      ],
      "metadata": {
        "id": "QxkE_-Ifn2k3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model(Tx, Ty,\n",
        "                   emb_dim, n_a, n_s, d1_units, d2_units, d_units,\n",
        "                   article_vocab_size, summary_vocab_size):\n",
        "  '''This implements the bas-line model archietecture for summarization.\n",
        "  It is a seq-seq model with attention mechanism implemented in it. The encoder take an input\n",
        "  with `Tx` time-steps and summarizes with the help of decoder into Ty words. The encoder and decoder\n",
        "  hidden states are `n_a` and `n_s` dimension respectively. The words are taken from the vocabulary of\n",
        "  article and summary `article_vocab` and `summary_vocab` with size `article_vocab_size` and\n",
        "  `summary_vocab_size` respectively.\n",
        "\n",
        "  Arguments:\n",
        "    Tx: int, length of the input article\n",
        "    Ty: int, length of the output summary\n",
        "    n_a: int, dimension of the encoder hidden states\n",
        "    n_s: int, dimension of the deocder hidden states\n",
        "    d1_units: int, units for the first dense layer in attention mechanism\n",
        "    d2_units: int, units for the second dense layer in attention mechanism\n",
        "    d_units: int, units for the dense layer before output layer\n",
        "    article_vocab_size: int, length of the article vocabulary\n",
        "    summary_vocab_size: int, length of the summary vocabulary\n",
        "\n",
        "  Returns:\n",
        "    returns the base line model\n",
        "  '''\n",
        "  # Defining the input for our model with shape (None, Tx) and (None, Ty) for encoder input and decoder input\n",
        "  X_inp = Input(shape=(Tx))\n",
        "  X_tar = Input(shape=(Ty))\n",
        "\n",
        "  # Initialize s0\n",
        "  s0 = Input(shape=(n_s, ), name=\"s0\")\n",
        "  # Initialize c0\n",
        "  c0 = Input(shape=(n_s, ), name=\"c0\")\n",
        "\n",
        "  # Initialize the a and s with a0 and s0\n",
        "  s = s0 # (batch, n_s)\n",
        "  c = c0 # (batch, n_s)\n",
        "\n",
        "  # Define the outputs as empty list\n",
        "  outputs = []\n",
        "\n",
        "  # First embedding layer for the article input\n",
        "  encoder_inp = Embedding(article_vocab_size, emb_dim)(X_inp) # (batch, Tx, emb_dim)\n",
        "\n",
        "  # Encoder: Bidirectional layer with LSTM cells\n",
        "  a = Bidirectional(LSTM(units=n_a, return_sequences=True))(encoder_inp) # (batch, Tx, n_a)\n",
        "\n",
        "  # Define the embedding for decoder\n",
        "  decoder_inp = Embedding(summary_vocab_size, emb_dim)(X_tar) # (batch, Ty, emb_dim)\n",
        "\n",
        "  # Define the layers for Attention so that we can use the same weights for all decoder timesteps\n",
        "  repeater = RepeatVector(Tx)\n",
        "  concatenator = Concatenate(axis=-1)\n",
        "  attn_densor1 = Dense(units=d1_units, activation='tanh')\n",
        "  attn_densor2 = Dense(units=d2_units, activation='linear', use_bias=False)\n",
        "  softmax_layer = Activation('softmax', name=\"attention_weights\")\n",
        "  dotter = Dot(axes=1)\n",
        "\n",
        "  # Define the Decoder unidirectional LSTM for shared weights\n",
        "  post_attention_lstm = LSTM(units=n_s, return_state=True)\n",
        "\n",
        "  # Define the last dense layer before output layer with linear activation\n",
        "  densor = Dense(units=d_units, activation='linear')\n",
        "\n",
        "  # Define the output layer so that it does not initalize again and again for shared weights\n",
        "  output_layer = Dense(units=summary_vocab_size, activation='softmax')\n",
        "\n",
        "  # Decoder: Appends outputs from the output layer in each timestep\n",
        "  for t in range(Ty):\n",
        "    # Get the decoder input for current timestep\n",
        "    curr_dec_in = decoder_inp[:, t:t+1, :] # (batch, 1, emb_dim)\n",
        "\n",
        "    # Get the context from the attention mechanism\n",
        "    context = one_time_attention_v1(a, s, # (batch, d2_units, 2*n_a)\n",
        "                                 repeater, concatenator, attn_densor1, attn_densor2, softmax_layer, dotter)\n",
        "\n",
        "    concat = Concatenate(axis=-1)([curr_dec_in, context]) # (batch, d2_units, emb_dim+2*n_a); d2_units=1 otherwise error\n",
        "    _, s, c = post_attention_lstm(concat, initial_state=[s, c]) # _, (batch, n_s), (batch, n_s)\n",
        "\n",
        "    # Calculate the output after using 2 linear dense layers\n",
        "    out = densor(s) # (batch, d_units)\n",
        "    out = densor(out) # (batch, d_units)\n",
        "    # Use the output_layer to get the output\n",
        "    out  = output_layer(out) # (batch, summary_vocab_size)\n",
        "\n",
        "    # Append the final output to the outputs list\n",
        "    outputs.append(out)\n",
        "\n",
        "  # Stack the list of each timesteps output along axis=1\n",
        "  outputs = tf.stack(outputs, axis=1) # (batch, Ty, summary_vocab_size)\n",
        "\n",
        "  model = Model(inputs=[X_inp, X_tar, s0, c0], outputs=outputs)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mudpzB78HDvZ",
        "outputId": "2fb0d213-077a-45c1-ada0-1648edd12e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset states generated by Keras\n",
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "APJAr_NwcRRj",
        "outputId": "d41ea3e1-367f-462a-f038-33ffdb99bc6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Baseline Model Creation and Training"
      ],
      "metadata": {
        "id": "moztj-HfDOls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tx = MAX_ARTICLE_TOKENS\n",
        "Ty = MAX_SUMMARY_TOKENS - 1\n",
        "emb_dim = EMB_OUT\n",
        "n_a = ENCODER_STATE_DIM\n",
        "n_s= DECODER_STATE_DIM\n",
        "d1_units = DENSE1_UNITS\n",
        "d2_units = DENSE2_UNITS\n",
        "d_units = DENSE_UNITS\n",
        "article_vocab_size = VOCAB_SIZE\n",
        "summary_vocab_size = VOCAB_SIZE\n",
        "\n",
        "base_model = baseline_model(Tx, Ty,\n",
        "                       emb_dim, n_a, n_s, d1_units, d2_units, d_units,\n",
        "                       article_vocab_size, summary_vocab_size)"
      ],
      "metadata": {
        "id": "V3ZAtG5I8mZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model has {base_model.count_params():,} parameters.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2eMakRHeZzrF",
        "outputId": "08d0700c-d496-412d-fff3-456f4d3e5dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model has 2,644,096 parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A look into how model will output on the above input."
      ],
      "metadata": {
        "id": "sN_nIO_-LdDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_model_out = base_model((art_inp, sum_inp, s0, c0))\n",
        "\n",
        "print(f\"Model output has a type: {type(sample_model_out)}\")\n",
        "print(f\"Model Output list for the Inputs above are of length: {len(sample_model_out)}\")\n",
        "print(f\"Model Output list has each output of shape: {sample_model_out[0].shape}\")"
      ],
      "metadata": {
        "id": "xzqmZfKoLcfJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "32287225-4fc5-4b3a-dc15-8b2c005978ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output has a type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Model Output list for the Inputs above are of length: 16\n",
            "Model Output list has each output of shape: (99, 20000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creating Custom Loss and Accuracy Version 1"
      ],
      "metadata": {
        "id": "C62CukniFhmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss_v1(y_true, y_pred):\n",
        "  '''Calculates the loss for the baseline model. The loss is calculated by taking the negative\n",
        "  log-likelihood of the target word(w*_t) in the current timestep. Then the overall loss\n",
        "  is the summation over all timesteps divided by T (not Ty because it would include paddings also).\n",
        "\n",
        "  Arguments:\n",
        "    y_true: tf.Tensor object, true values for the target\n",
        "    y_pred: list of tf.Tensor objects, predicted probablities of the summary words\n",
        "\n",
        "  Returns:\n",
        "    returns the loss on the predicted values for the model\n",
        "  '''\n",
        "  # Calculate the loss for each item in the batch.\n",
        "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "  # Remove the paddings from calculation of loss\n",
        "  mask = tf.cast(y_true != 0, loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  # Divide the total loss after masking out paddings divided by total words which are not paddings\n",
        "  return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def custom_accuracy_v1(y_true, y_pred):\n",
        "  '''Calculates accuracy of the baseline model. The accuracy is calculated by matching how many correct\n",
        "  words were predicted excluding the paddings. Then, just add those which are correct and you will get the\n",
        "  the accuracy and then just divide it by total words not including padding.\n",
        "\n",
        "  Arguments:\n",
        "    y_true: tf.Tensor object, expected target values\n",
        "    y_pred: list of tf.Tensor object, predicted target values by model\n",
        "\n",
        "  Returns:\n",
        "    returns the total accuracy over the batch of data\n",
        "  '''\n",
        "  # Find the word index with maximum probablity\n",
        "  y_pred = tf.argmax(y_pred, axis=-1)\n",
        "  y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "\n",
        "  # Count the words that matches with true values\n",
        "  match = tf.cast(y_pred == y_true, tf.float32)\n",
        "  mask = tf.cast(y_true != 0, tf.float32)\n",
        "\n",
        "  # Mask out the paddings\n",
        "  match *= mask\n",
        "\n",
        "  return tf.reduce_sum(match) / tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "dw-z3KccJdpj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "194cd324-9fd0-44e9-8aa1-e8a4f3b73e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Testing with loss and accuracy"
      ],
      "metadata": {
        "id": "BR02DedPFrDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sample y true values: {sum_tar}\")\n",
        "print(f\"Sample y pred values(first 10 values of first 2 timestep): {sample_model_out[:2]}\")\n",
        "\n",
        "sample_loss = custom_loss_v1(sum_tar, sample_model_out)\n",
        "print(f\"Loss of the sample y_true and y_pred: {sample_loss}\")\n",
        "\n",
        "sample_acc = custom_accuracy_v1(sum_tar, sample_model_out)\n",
        "print(f\"Accuracy of the sample y_true and y_pred: {sample_acc}\")"
      ],
      "metadata": {
        "id": "SR25pZHrACmA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "ee0770bc-19c8-4c74-d6cd-be5a51114c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample y true values: [[   2 1594 1589 ...    0    0    0]\n",
            " [  36 2526 7765 ...    0    0    0]\n",
            " [1024  358 5136 ...    0    0    0]\n",
            " ...\n",
            " [ 446  178    2 ...    0    0    0]\n",
            " [  68   47 1745 ...    0    0    0]\n",
            " [ 241 1043    1 ...    0    0    0]]\n",
            "Sample y pred values(first 10 values of first 2 timestep): [[[4.9766826e-05 4.9918344e-05 4.9897033e-05 ... 4.9849703e-05\n",
            "   5.0315728e-05 5.0180632e-05]\n",
            "  [4.9540908e-05 4.9899852e-05 4.9744962e-05 ... 4.9732076e-05\n",
            "   5.0619914e-05 5.0087474e-05]\n",
            "  [4.9342078e-05 4.9915510e-05 4.9560989e-05 ... 4.9633010e-05\n",
            "   5.0835100e-05 4.9942733e-05]\n",
            "  ...\n",
            "  [4.8487480e-05 5.0055794e-05 4.8468002e-05 ... 4.9327318e-05\n",
            "   5.1671042e-05 4.9163184e-05]\n",
            "  [4.8487480e-05 5.0055794e-05 4.8468002e-05 ... 4.9327318e-05\n",
            "   5.1671042e-05 4.9163184e-05]\n",
            "  [4.8487480e-05 5.0055794e-05 4.8468009e-05 ... 4.9327322e-05\n",
            "   5.1671042e-05 4.9163184e-05]]\n",
            "\n",
            " [[4.9986847e-05 4.9694067e-05 5.0172279e-05 ... 5.0206174e-05\n",
            "   5.0213788e-05 5.0044073e-05]\n",
            "  [5.0031969e-05 4.9539321e-05 5.0381001e-05 ... 5.0354411e-05\n",
            "   5.0285667e-05 5.0100505e-05]\n",
            "  [5.0090632e-05 4.9461749e-05 5.0534971e-05 ... 5.0449049e-05\n",
            "   5.0280312e-05 5.0154122e-05]\n",
            "  ...\n",
            "  [5.0358569e-05 4.9316510e-05 5.0878778e-05 ... 5.0763316e-05\n",
            "   5.0129740e-05 5.0536150e-05]\n",
            "  [5.0358594e-05 4.9316495e-05 5.0878807e-05 ... 5.0763316e-05\n",
            "   5.0129740e-05 5.0536142e-05]\n",
            "  [5.0358627e-05 4.9316488e-05 5.0878847e-05 ... 5.0763323e-05\n",
            "   5.0129747e-05 5.0536146e-05]]]\n",
            "Loss of the sample y_true and y_pred: 9.907593727111816\n",
            "Accuracy of the sample y_true and y_pred: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Compiling base line model"
      ],
      "metadata": {
        "id": "cs0e3XjqFwdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LEARNING_RATE\n",
        "initial_accumulator_value = INIT_ACC_VAL\n",
        "clipnorm = MAX_GRAD_NORM\n",
        "\n",
        "opt = Adagrad(learning_rate=lr,\n",
        "              initial_accumulator_value=initial_accumulator_value,\n",
        "              clipnorm=clipnorm)\n",
        "\n",
        "base_model.compile(loss=custom_loss_v1, optimizer=opt, metrics=[custom_loss_v1, custom_accuracy_v1])"
      ],
      "metadata": {
        "id": "bOTfC4BNnFgj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "48f21c46-7ca9-461a-c987-c53e1689dae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creating callbacks for model"
      ],
      "metadata": {
        "id": "_P1vbkDSF0T3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mention the checkpoint path and it's directory where you will save the model\n",
        "checkpoint_path = BASELINE_MODEL_CHECKPOINT\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Calculate no of batches, I am taking floor because when creating the training data I used drop_remainder\n",
        "n_batches = int(train_dataset.shape[0] / BATCH_SIZE)\n",
        "\n",
        "# Create the checkpoint for model saving, monitoring val_custom_accuracy_v1 and save only weights of the model\n",
        "saving_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                monitor='val_custom_accuracy_v1',\n",
        "                                                verbose=1,\n",
        "                                                save_weights_only=True,\n",
        "                                                save_freq=n_batches//2)\n",
        "\n",
        "# Create the checkpoint for stopping early after noticing that val_custom_accuracy_v1 is not increasing even after 5 consecutive epochs\n",
        "earlystop_cb = tf.keras.callbacks.EarlyStopping(monitor='val_custom_accuracy_v1',\n",
        "                                                    patience=PATIENCE,\n",
        "                                                    mode='max',\n",
        "                                                    )\n",
        "\n",
        "# Store the checkpoints in a list\n",
        "callbacks = [saving_cb, earlystop_cb]"
      ],
      "metadata": {
        "id": "_OFR6b5hD10E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training baseline model"
      ],
      "metadata": {
        "id": "tLyxWD4MF6W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = EPOCHS\n",
        "steps_per_epoch = STEPS_PER_EPOCHS\n",
        "\n",
        "history = base_model.fit(tf_train_dataset.repeat(),\n",
        "                    epochs=epochs,\n",
        "                    validation_data=tf_val_dataset,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    callbacks=callbacks\n",
        "                    )"
      ],
      "metadata": {
        "id": "OQE9gr_Bd9cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pointer Generetor model: Adding Pointer Generator to avoid getting OOV tokens in the summary"
      ],
      "metadata": {
        "id": "cDBfIISTS0j3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating `tf_train_dataset`, `tf_val_dataset` dataset using tf.data API\n",
        "\n",
        "I already have created to the `generate_example` function, I can use it again to generate examples for training and validation respectively.\n",
        "\n",
        "But this time I have to also consider the `<OOV>` with token value `1`. Instead of using `1`, I have to generate a new token value for each of the `<OOV>` words.\n",
        "\n",
        "How to do it?"
      ],
      "metadata": {
        "id": "0Y9oJUdnUM_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `find_oovs`, `map_oovs` & `tokenize_oovs` function"
      ],
      "metadata": {
        "id": "nJY4-VAaEfuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_oovs(sent, sent_token, sent_len):\n",
        "  '''Finds the out of vocabulary words from `sent` with the help of already tokenized `sent_tokens`.\n",
        "\n",
        "  Arguments:\n",
        "    sent: str, sentence to find the oov from\n",
        "    sent_token: 2D np.array, the tokenized form of the sentence with sent_len length\n",
        "    sent_len: int, length of the tokenized sentence\n",
        "\n",
        "  Returns:\n",
        "    Returns a list of all oov words in the `sent`\n",
        "  '''\n",
        "  analyzed_sent = custom_analyzer(sent)\n",
        "  oov_words = [w for i, w in enumerate(analyzed_sent[:sent_len]) if (sent_token[0][i] == 1)]\n",
        "  return oov_words\n",
        "\n",
        "def map_oovs(oovs, oov_start_token):\n",
        "  '''Stores the out of vocabulary words in a dictionary and sets the values of each oov key to\n",
        "  a temporary unique tokens.\n",
        "\n",
        "  Arguments:\n",
        "    oovs: list of oov words\n",
        "    oov_start_token: int, the first value to use as oov token then increase by 1\n",
        "\n",
        "  Returns:\n",
        "    dictionary of (oov, token) as (key, value) pairs\n",
        "  '''\n",
        "  unique_oovs = list(set(oovs))\n",
        "  oov_tokens = [oov_start_token+i for i in range(len(unique_oovs))]\n",
        "\n",
        "  oov_dict = dict(zip(unique_oovs, oov_tokens))\n",
        "\n",
        "  return oov_dict\n",
        "\n",
        "def tokenize_oovs(sent, sent_token, oov_dict, sent_len):\n",
        "  '''Tokenize the sent by replacing the oov tokens by new unique tokens from oov_dict.\n",
        "\n",
        "  Arguments:\n",
        "    sent: str, sentence to handle the oovs\n",
        "    sent_token: 2D np.array of tokens\n",
        "    oov_dict: dictionary, oov words and their tokens are stored here\n",
        "    sent_len: int, length of the sentence token array\n",
        "\n",
        "  Returns:\n",
        "    tokenized sentence with oov words tokenized to temporary oov tokens\n",
        "  '''\n",
        "  analyzed_sent = custom_analyzer(sent)\n",
        "\n",
        "  for i, w in enumerate(analyzed_sent[:sent_len]):\n",
        "    if w in oov_dict.keys():\n",
        "      sent_token[0, i] = oov_dict[w]\n",
        "\n",
        "  return sent_token"
      ],
      "metadata": {
        "id": "WkfC7nfwghMI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Applying functions on Examples"
      ],
      "metadata": {
        "id": "MygLMzLXEouR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Article:\\n{sample_article}\\n\\n\")\n",
        "\n",
        "sample_article_tokens = tokenize_pad([sample_article],\n",
        "                              tokenizer,\n",
        "                              padding=\"post\",\n",
        "                              truncating=\"post\",\n",
        "                              maxlen=MAX_ARTICLE_TOKENS)\n",
        "print(f\"sample article tokens:\\n{sample_article_tokens}\\n\\n\")\n",
        "\n",
        "sample_oovs = find_oovs(sample_article, sample_article_tokens, MAX_ARTICLE_TOKENS)\n",
        "print(f\"OOVs in the sample article:\\n{sample_oovs}\\n\\n\")\n",
        "\n",
        "sample_oov_dict = map_oovs(sample_oovs, VOCAB_SIZE)\n",
        "print(f\"OOV dictionary:\\n{sample_oov_dict}\\n\\n\")\n",
        "\n",
        "sample_article_tokens_with_oovs = tokenize_oovs(sample_article, sample_article_tokens, sample_oov_dict, MAX_ARTICLE_TOKENS)\n",
        "print(f\"sample article tokens with oov tokens:\\n{sample_article_tokens_with_oovs}\")"
      ],
      "metadata": {
        "id": "cqzj5WV-ihFC",
        "outputId": "8aa1fe75-fee5-4e4b-e7ed-48dab2dbd9bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article:\n",
            "new york (cnn) -- the u.s. population is expected to top out at close to 312.8 million people just around the time crowds gather to watch the ball drop on new year's eve, according to new census data released thursday. the figure represents a 0.7% increase from last year, adding 2,250,129 people to the u.s. population since the start of 2011, and a 1.3% increase since census day, april 1, 2010. the agency estimates that beginning in january, one american will be born every eight seconds and one will die every 12 seconds. u.s.-bound immigrants are also expected to add one person every 46 seconds. that combination of births, deaths and migration is expected to add a single person to the u.s. population every 17 seconds, the census bureau said. meanwhile, millions are set to ring in the new year. in new york, authorities are preparing for large crowds in manhattan's times square, where lady gaga is expected to join mayor michael bloomberg to push the button that drops the waterford crystal ball at 11:59 p.m. et on new year's eve. \"and i'm so looking forward to performing on nye+dropping the ball with mayor bloomberg!\" the pop star posted on twitter. \"what an honor as a new yorker.\" past guests have included muhammad ali, rudy giuliani, colin powell and bill and hillary clinton. on thursday, officials conducted new york's annual \"airworthiness test\" -- a process in which confetti is tossed by handfuls above times square -- in preparation for the annual city tradition of dumping one ton of confetti over revelers in the iconic square. the big apple this year edged out las vegas for the first time in seven years as the top travel u.s. destination for those celebrating the new year, according to a december travel booking website poll. seven new york neighborhoods made the top 10 list, with two districts in las vegas and one in new orleans making up the other three, according to the priceline poll. \"it appears that new york city will be helped this year by a weather forecast that calls for warmer than usual temperatures over the holiday weekend,\" said company spokesman brian ek.\n",
            "\n",
            "\n",
            "sample article tokens:\n",
            "[[   80    68   243    44    42    43    12    12     2    79     3    13\n",
            "      3   944    16   525     5   258    65    25   485     5     1   169\n",
            "     57    84   178     2    74  3295  4420     5   341     2  1581  1970\n",
            "     19    68    70    11    13  4480     4   104     5    68  5118   770\n",
            "    371   230     3     2  1329  2748     9     1  1092    29    96    70\n",
            "      4  1078     1    57     5     2    79     3    13     3   944   146\n",
            "      2   445     7     1     8     9     1  1092   146  5118   118     4\n",
            "    766     1     1     2   352  2401    14  1290    10   662     4    53\n",
            "    171    45    30   893   232   625  1991     8    53    45  1593   232\n",
            "      1  1991     3    79     3    13     3    12  3444  2006    28    69\n",
            "    525     5  1964    53   358   232     1  1991     3    14  3652     7\n",
            "  11243     4  1057     8  6969    16   525     5  1964     9   872   358\n",
            "      5     2    79     3    13     3   944   232     1  1991     4     2\n",
            "   5118  2382    17     3  1042     4  1084    28   257     5  3043    10\n",
            "      2    68    70     3    10    68   243     4   219    28  3300    15\n",
            "    563  3295    10  3082    11    13   280  1250     4   111  2109  7650\n",
            "     16   525     5  1366  1212   610  4185     5  1660     2  3609    14\n",
            "   7526     2 46852  5888  1581    25     1   758     3   133     3  2151\n",
            "     19    68    70    11    13  4480     3     6     8    24    11   133\n",
            "     73   468   698     5  3759    19 25108  3773  4697     2  1581    22\n",
            "   1212  4185   306     6     2  1981   597  1050    19   663     3     6\n",
            "     61    37  1590    23     9    68  9943     3     6   292  2444    27\n",
            "    937  6902  1982     4 10773 11878     4  8727  5316     8   480     8\n",
            "   1940   541     3    19   230     4   180  1767    68   243    11    13\n",
            "   1662     6 35834   932     6    12    12     9   510    10    66 24981\n",
            "     16  7823    32 45482  1201   280  1250    12    12    10  5726    15\n",
            "      2  1662   153  3000     7 11712    53  7327     7 24981    91 16814\n",
            "     10     2  3658  1250     3     2   286   981    33    70  9117    65\n",
            "   3109  2935    15     2    88    74    10   586    92    23     2   258\n",
            "    647    79     3    13     3  3541    15   110  4677     2    68    70\n",
            "      4   104     5     9   798   647  8679   568  1717     3   586    68\n",
            "    243  3951   138     2   258     1   737     4    22    75  4828    10\n",
            "   3109  2935     8    53    10    68  2808   334    67     2    83   123\n",
            "      4   104     5     2]]\n",
            "\n",
            "\n",
            "OOVs in the sample article:\n",
            "['312.8', '0.7%', '2,250,129', '2011,', '1.3%', '1,', '2010.', '12', '46', '17', '11:59', '10']\n",
            "\n",
            "\n",
            "OOV dictionary:\n",
            "{'11:59': 50000, '12': 50001, '17': 50002, '312.8': 50003, '1.3%': 50004, '0.7%': 50005, '2,250,129': 50006, '10': 50007, '46': 50008, '2011,': 50009, '2010.': 50010, '1,': 50011}\n",
            "\n",
            "\n",
            "sample article tokens with oov tokens:\n",
            "[[   80    68   243    44    42    43    12    12     2    79     3    13\n",
            "      3   944    16   525     5   258    65    25   485     5 50003   169\n",
            "     57    84   178     2    74  3295  4420     5   341     2  1581  1970\n",
            "     19    68    70    11    13  4480     4   104     5    68  5118   770\n",
            "    371   230     3     2  1329  2748     9 50005  1092    29    96    70\n",
            "      4  1078 50006    57     5     2    79     3    13     3   944   146\n",
            "      2   445     7 50009     8     9 50004  1092   146  5118   118     4\n",
            "    766 50011 50010     2   352  2401    14  1290    10   662     4    53\n",
            "    171    45    30   893   232   625  1991     8    53    45  1593   232\n",
            "  50001  1991     3    79     3    13     3    12  3444  2006    28    69\n",
            "    525     5  1964    53   358   232 50008  1991     3    14  3652     7\n",
            "  11243     4  1057     8  6969    16   525     5  1964     9   872   358\n",
            "      5     2    79     3    13     3   944   232 50002  1991     4     2\n",
            "   5118  2382    17     3  1042     4  1084    28   257     5  3043    10\n",
            "      2    68    70     3    10    68   243     4   219    28  3300    15\n",
            "    563  3295    10  3082    11    13   280  1250     4   111  2109  7650\n",
            "     16   525     5  1366  1212   610  4185     5  1660     2  3609    14\n",
            "   7526     2 46852  5888  1581    25 50000   758     3   133     3  2151\n",
            "     19    68    70    11    13  4480     3     6     8    24    11   133\n",
            "     73   468   698     5  3759    19 25108  3773  4697     2  1581    22\n",
            "   1212  4185   306     6     2  1981   597  1050    19   663     3     6\n",
            "     61    37  1590    23     9    68  9943     3     6   292  2444    27\n",
            "    937  6902  1982     4 10773 11878     4  8727  5316     8   480     8\n",
            "   1940   541     3    19   230     4   180  1767    68   243    11    13\n",
            "   1662     6 35834   932     6    12    12     9   510    10    66 24981\n",
            "     16  7823    32 45482  1201   280  1250    12    12    10  5726    15\n",
            "      2  1662   153  3000     7 11712    53  7327     7 24981    91 16814\n",
            "     10     2  3658  1250     3     2   286   981    33    70  9117    65\n",
            "   3109  2935    15     2    88    74    10   586    92    23     2   258\n",
            "    647    79     3    13     3  3541    15   110  4677     2    68    70\n",
            "      4   104     5     9   798   647  8679   568  1717     3   586    68\n",
            "    243  3951   138     2   258 50007   737     4    22    75  4828    10\n",
            "   3109  2935     8    53    10    68  2808   334    67     2    83   123\n",
            "      4   104     5     2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `generate_example_v2` function creation"
      ],
      "metadata": {
        "id": "b4U6JUL9ExLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_example_v2(inputs, targets,\n",
        "                        input_tokenizer, target_tokenizer,\n",
        "                        input_len, target_len,\n",
        "                        padding=\"post\", truncating=\"post\",\n",
        "                        vocab_size=VOCAB_SIZE):\n",
        "\n",
        "  '''Generates examples for the Pointer Generator model. Processes the `inputs` and `targets`\n",
        "  with their respective tokenizers and tokenize them to `input_len` and `target_len` length.\n",
        "  After tokenizing the article words, it looks for the out-of-vocabulary words and creates unique tokens\n",
        "  for each of those OOV words. Then, instead of keeping the oov word tokens as 1, it replaces them\n",
        "  with their respective newly generated tokens. This tokens are temporary\n",
        "\n",
        "  Arguments:\n",
        "    inputs: list of input sentences\n",
        "    targets: list of target sentences\n",
        "    input_tokenizer: Tokenizer class object, tokenizer for inputs\n",
        "    target_tokenizer: Tokenizer class object, tokenizer for targets\n",
        "    input_len: int, the length of the tokenization for inputs\n",
        "    target_len: int, the length of the tokenization for targets\n",
        "\n",
        "  Returns:\n",
        "    returns 2 values, a tuple containing 2 numpy arrays (input_tokens, target_tokens[:-1]) and\n",
        "    another numpy array target_tokens[1:]\n",
        "  '''\n",
        "\n",
        "  for inp, tar in zip(inputs, targets):\n",
        "    # Tokenizing article words\n",
        "    inp_token = tokenize_pad([inp],\n",
        "                              input_tokenizer,\n",
        "                              padding=padding,\n",
        "                              truncating=truncating,\n",
        "                              maxlen=input_len)\n",
        "\n",
        "    oov_words = find_oovs(inp, inp_token, input_len)\n",
        "    oov_dict = map_oovs(oov_words, oov_start_token=vocab_size)\n",
        "    inp_token = tokenize_oovs(inp, inp_token, oov_dict, input_len)\n",
        "\n",
        "    # Tokenizing summary words\n",
        "    tar_token = tokenize_pad([tar],\n",
        "                 target_tokenizer,\n",
        "                 padding=padding,\n",
        "                 truncating=truncating,\n",
        "                 maxlen=target_len)\n",
        "    tar_token = tokenize_oovs(tar, tar_token, oov_dict, target_len)\n",
        "\n",
        "    yield (inp_token[0], tar_token[0][:-1]), tar_token[0][1:]"
      ],
      "metadata": {
        "id": "bWzy1fmHTG_j"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Examples with the generator function"
      ],
      "metadata": {
        "id": "g66B6U8bE3jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Example generated by the generator v2:\")\n",
        "\n",
        "# (inp_art_tokens, inp_sum_tokens), tar_sum_tokens = generate_example(list(train_dataset[:, 0]),\n",
        "example_gen = generate_example_v2(list(train_dataset[:, 0]),\n",
        "                               list(train_dataset[:, 1]),\n",
        "                               input_tokenizer=tokenizer,\n",
        "                               target_tokenizer=tokenizer,\n",
        "                               input_len=MAX_ARTICLE_TOKENS,\n",
        "                               target_len=MAX_SUMMARY_TOKENS)\n",
        "\n",
        "inps, tar = next(example_gen)\n",
        "print(f\"Inputs:\\n{inps[0]}\\n{inps[1]}\\n\\n\")\n",
        "print(f\"Target:\\n{tar}\")"
      ],
      "metadata": {
        "id": "eA3joMNfbcjL",
        "outputId": "11093a09-a6a3-42c3-fa75-211940443a1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example generated by the generator v2:\n",
            "Inputs:\n",
            "[   80    44    42    43    12    12 12267  3609    16 27395   252    11\n",
            "    13  9873   832  3518     4    23     2  5456  1344  3958     5     2\n",
            "   422     7    26    88    12   394   778    15     2 50005   494     7\n",
            "    26  2746    53   733     3     2 50011    12   150  6683    29    96\n",
            "   802    11    13  1264   832  3518     4   272    32    26  4079  2793\n",
            "  3406     4    60 50002 10183    22 50009   640     4    31  3609    16\n",
            "  1869    15   315  4443    25     2  1169   111    21 16335   898    23\n",
            "     9  6879  1344    10 50012     6    18    11    13   333  1558   538\n",
            "   127     5  8050    23    33    16     2  1169    25    66    24   272\n",
            "    90    88   832  3518     4     6     2 50007  2292    11  1133    87\n",
            "  5456    11    13   839   422     3     6    60     9  8231   234     5\n",
            "    90   494    25     2 34868     4    24    11   372    30  1869    15\n",
            "   315  4443    25     2 42123     3     6    24    63    11    41   347\n",
            "    24    11   204   332  4376    67     9  1701    12  7327     7 50000\n",
            "  2950   103    24   136    11    41   418     9   118  1667    76    59\n",
            "    24   138    90  2929   127    10 50006     6 17691  3406 12797    10\n",
            "  1060     3  3609   138    26    88  1923    10     2  3549  2268     7\n",
            " 10046    25     2  1423   832  3518    10 50013    22  1229     4     8\n",
            "    34   146   961    19     5  2582 33809     4 10989     4  1907     4\n",
            "  6879     4 16261 13617     8   102  5456    10    37 50010   733     3\n",
            "     2  9559    34 19942    67 50008   832  3518 12797     8  4547    26\n",
            "   112    95  3565     5  1340    10 50003   116  2384    15 16261     3\n",
            "  3609    16  4258     7     9   658  1502    19   252     8    16   402\n",
            "  9664    29    26   466    12   220  1979    25     2  6312   832  3518\n",
            "    12    12     9  2913    21  2106  6197     9   131   788  1028     5\n",
            "     2 42123     3     6     2 50001   584  5456    11    13   430   583\n",
            "    20   131  3168    10  6312     9   727     7   288   317     8    24\n",
            "   497    18    45    30     9   788   546    33   802   103     2 42123\n",
            "    34   109     7     2   197  1233  6556     3   776 50000  7013    60\n",
            "     2  1264 13617     3     6  5171  2899  3044 10047 50004  2885     8\n",
            "    38    11   117   333  4308  2132    12   460    10     2   430   103\n",
            "    58    28    73   109  7881     3    18    11    13  1271     4    31\n",
            "    33    16  2191     9  2913    59    62     2   869  6271 16793     3\n",
            "     6  3406    16    69]\n",
            "[   80 12267  3609    16  3300    15     2 50005   494     7    26  2746\n",
            "    53   733     3     2  5456  1344   272    26    88   832  3518    10\n",
            "  8050   239    92   317     3    26  4079  2793  3406    16   468     5\n",
            "  1150    19    96   802    11    13  4175    10  1060     3    81     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n",
            "\n",
            "\n",
            "Target:\n",
            "[12267  3609    16  3300    15     2 50005   494     7    26  2746    53\n",
            "   733     3     2  5456  1344   272    26    88   832  3518    10  8050\n",
            "   239    92   317     3    26  4079  2793  3406    16   468     5  1150\n",
            "    19    96   802    11    13  4175    10  1060     3    81     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inps, tar = next(example_gen)\n",
        "print(f\"Inputs:\\n{inps[0]}\\n{inps[1]}\\n\\n\")\n",
        "print(f\"Target:\\n{tar}\")"
      ],
      "metadata": {
        "id": "hIuAkQbO7Bzz",
        "outputId": "c0b1e40c-0086-42af-abb8-2f37de6369f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "[   80    44    42    43    12    12    23  7594  4189 13831  2246   154\n",
            "   217   536    10   820  8974     4  1869     5  1377   848     7   965\n",
            "     4     9  6259  3724   415     5  5048    50   107     2  5147  7254\n",
            "     3    18   108   484  1389   248    10     2   327     4    17  1918\n",
            " 37957     4     9  2285    79     3    13     3   801  1256  1624     3\n",
            "     6     2  1653    22    66    33  5147   415     5   737     8   132\n",
            "  2426    91    19    71   381  2520  1055  1154     4   108   484  2601\n",
            "   404  2633    14    64   775     9  2896     7    33  1614    12    12\n",
            "   511 50001   900   181    12    12     5   952  2426  1679    71   381\n",
            "     3    14    11    13   131   484     2   746     7  1055  1154     4\n",
            "     6    21    17     3    82   965   231   912     9  3977  7452   113\n",
            "     2  1044   415  6936     3    14    98    30    29  3732  6838    56\n",
            "     6    82    83  2380  1154     4     6 37957    87    42    11    13\n",
            "     6    68   118     3     6     6    31    18   296  1536     4    29\n",
            "  1942   556     4    18    20    54   484    14   248    20  1389     3\n",
            "     6    59     2  1044   247  3786     4    18  2154   145  9893     4\n",
            "    66   134    27   265    18   154   531     4    17  2610 18519     4\n",
            "   201  4279   406    15     2   249     7  1776     3     6    73    72\n",
            "    35   443   248     4    14    64    27  1689    35    46    65     7\n",
            "     2  2914     4    66    16  1095  1085     5    93     4     6 18519\n",
            "    17     3    11    38    28    36   562   383    11   965 14755     3\n",
            "    31     2   217  1021  8160     8 12000   809    17   230    14     2\n",
            "  5147   144    36 21033  3519    29    71  2218  2259     3     2   352\n",
            "  1913     2  5147    11    13  2218  2259     4     8     6    58    20\n",
            "    77   994  1612   173    48   516     8     2  3083  1169  6970     4\n",
            "     6   355 20518 27396 50000    17     3 18519    17    83  6326   774\n",
            "  2715  1798    56    37  2404     4  1134    10     2  2715   594     3\n",
            "     6    31    14   804  1125  1187    11    41  1193    15     2  6936\n",
            "    33   952     3    18   804    20   248   950    14   549     4     6\n",
            "    47    17     3   334  2420  1674     4     2  5147  1310  1721     7\n",
            "  1791     3   339    37  4656  5724    16 11925     4     6    18    11\n",
            "    13  2634   343     5   131  1055  2633     4     6 37957    17     3\n",
            "    14    98  2088     6   246     2  5147    10    84     9   702     7\n",
            "   377   415     5  2426]\n",
            "[   80   217  1021  8160   809    49     2  1044   144    36 21033   161\n",
            "    29    71  2218  2259     3    82   965   231   912     9  7452   113\n",
            "     2  1044  7254     3     2  1044    51  2154   145  9893     4    31\n",
            "  1027    46   425    25     2    74     7     2  1499     3     2   108\n",
            "  1807  2182     5   965    16 17895     3    81     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n",
            "\n",
            "\n",
            "Target:\n",
            "[  217  1021  8160   809    49     2  1044   144    36 21033   161    29\n",
            "    71  2218  2259     3    82   965   231   912     9  7452   113     2\n",
            "  1044  7254     3     2  1044    51  2154   145  9893     4    31  1027\n",
            "    46   425    25     2    74     7     2  1499     3     2   108  1807\n",
            "  2182     5   965    16 17895     3    81     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Making training, validation set examples for pointer generator model"
      ],
      "metadata": {
        "id": "Ix6RsiveGSQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_example_generetor_v2():\n",
        "  example_gen = generate_example_v2(list(train_dataset[:, 0]),\n",
        "                                list(train_dataset[:, 1]),\n",
        "                                input_tokenizer=tokenizer,\n",
        "                                target_tokenizer=tokenizer,\n",
        "                                input_len=MAX_ARTICLE_TOKENS,\n",
        "                                target_len=MAX_SUMMARY_TOKENS)\n",
        "\n",
        "  for example in example_gen:\n",
        "    s0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "    c0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "\n",
        "    (input_0, input_1), target = example\n",
        "    yield (input_0, input_1, s0, c0), target"
      ],
      "metadata": {
        "id": "ZCRXKTLZGX_I"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_signature = (\n",
        "    (tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32)),\n",
        "    tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32)\n",
        ")\n",
        "\n",
        "tf_train_dataset = tf.data.Dataset.from_generator(generator=train_example_generetor_v2,\n",
        "                                                  output_signature=output_signature)\n",
        "tf_train_dataset = tf_train_dataset.shuffle(BUFFER_SIZE)\n",
        "tf_train_dataset = tf_train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "tf_train_dataset = tf_train_dataset.prefetch(1)"
      ],
      "metadata": {
        "id": "NBdNpR7rGw7m"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_example_generetor_v2():\n",
        "  example_gen = generate_example_v2(list(val_dataset[:, 0]),\n",
        "                                list(val_dataset[:, 1]),\n",
        "                                input_tokenizer=tokenizer,\n",
        "                                target_tokenizer=tokenizer,\n",
        "                                input_len=MAX_ARTICLE_TOKENS,\n",
        "                                target_len=MAX_SUMMARY_TOKENS)\n",
        "\n",
        "  for example in example_gen:\n",
        "    s0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "    c0 = np.zeros((DECODER_STATE_DIM, ), dtype=np.int32)\n",
        "\n",
        "    (input_0, input_1), target = example\n",
        "    yield (input_0, input_1, s0, c0), target\n",
        "\n",
        "\n",
        "output_signature = (\n",
        "    (tf.TensorSpec(shape=(MAX_ARTICLE_TOKENS, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32),\n",
        "     tf.TensorSpec(shape=(DECODER_STATE_DIM, ), dtype=tf.int32)),\n",
        "    tf.TensorSpec(shape=(MAX_SUMMARY_TOKENS-1, ), dtype=tf.int32)\n",
        ")\n",
        "\n",
        "tf_val_dataset = tf.data.Dataset.from_generator(generator=val_example_generetor_v2,\n",
        "                                                  output_signature=output_signature)\n",
        "tf_val_dataset = tf_val_dataset.shuffle(BUFFER_SIZE)\n",
        "tf_val_dataset = tf_val_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "byX6PXAKGw7y"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (art_inp, sum_inp, s0, c0), sum_tar in tf_train_dataset.take(1):\n",
        "  print(f\"Input tokenized article shape: {art_inp.shape}\")\n",
        "  print(f\"Input tokenized summary shape: {sum_inp.shape}\\n\")\n",
        "\n",
        "  print(f\"Target tokenized summary shape: {sum_tar.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac45f2a2-22db-4090-ce8b-e6a81cf77c11",
        "id": "2fZlevYZGw7y"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokenized article shape: (16, 400)\n",
            "Input tokenized summary shape: (16, 99)\n",
            "\n",
            "Target tokenized summary shape: (16, 99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attention Mechanism for Pointer Generator Model\n",
        "\n",
        "It now involves the attention weights also because they will be used to calculate the final distribution."
      ],
      "metadata": {
        "id": "bokn5sDnsnEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_time_attention_v2(a, s_prev,\n",
        "                       repeater, concatenator, densor_1, densor_2, softmax_layer, dotter):\n",
        "  '''Calculates the attention score and returns the context and attention distribution for the current\n",
        "  timestep in the decoder.\n",
        "  Attention mechanism uses encoder outputs `a` of shape `(batch, timesteps, features)` and decoder\n",
        "  previous hidden state `s_prev` of shape `(batch, features)`, then calculates alignment scores `alphas`\n",
        "  for each encoder timestep with the help of energies computed with 2 dense layers using `a` and `s_prev`.\n",
        "\n",
        "  Arguments:\n",
        "    a: tf.Tensor object, encoder output of shape `(batch, timesteps, features)` or `(batch, Tx, 2*n_a)`\n",
        "    s_prev: tf.Tensor object, decoder previous hidden state of shape `(batch, features)` or `(batch, n_s)`\n",
        "    repeater: RepeatVector layer, repeat the `s_prev` `Tx` times\n",
        "    concatenator: Concatenate layer, concatenates `a` and repeated `s_prev`, Concatenates along axis=-1\n",
        "    densor_1: Dense layer, calculates the pertial energies `e`, with `units=d1_units`\n",
        "    refer to `baseline_model` function for details about this variable\n",
        "    densor_2: Dense layer, calculated the energies `energies`, with `units=d2_units`\n",
        "    refer to `baseline_model` function for details about this variable\n",
        "    softmax_layer: Activation layer, computes softmax of the energies and calculates `alphas`, with\n",
        "    `units=article_vocab_size` refer to `baseline_model` function for details about this variable\n",
        "    dotter: Dot layer, Performs dot operation between `alphas` and `a` along axis=1\n",
        "\n",
        "  Returns:\n",
        "    returns the context of shape `(batch, 1, 2*n_a)` and\n",
        "    attention distribution of shape `(batch, Tx, d2_units)`\n",
        "  '''\n",
        "\n",
        "  # Repeat the `s_prev` `Tx` times\n",
        "  s_prev = repeater(s_prev) # (batch, Tx, n_s)\n",
        "\n",
        "  # Concatenate `a` and `s_prev` along axis=-1\n",
        "  concat = concatenator([a, s_prev]) # (batch, Tx, n_a + n_s)\n",
        "\n",
        "  # Apply dense layer to get partial energies e\n",
        "  e = densor_1(concat) # (batch, Tx, d1_units)\n",
        "\n",
        "  # Apply dense layer again to get energies\n",
        "  energies = densor_2(e) # (batch, Tx, d2_units)\n",
        "\n",
        "  # Apply softmax over the energies\n",
        "  alphas = softmax_layer(energies) # (batch, Tx, d2_units)\n",
        "\n",
        "  # Dot the alphas and a along axes=1\n",
        "  context = dotter([alphas, a]) # (batch, d2_units, 2*n_a)\n",
        "\n",
        "  return context, alphas"
      ],
      "metadata": {
        "id": "aDPDm6MJLIEz"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pointer Generator\n",
        "\n",
        "The function `generate_pointer` will return the $p_{gen}$. $p_{gen}$ will be used to decide whether the next word needs to be copied from the article or we should generate a new word from the vocabulary. This decision will be taken using the equation- $$P(w) = p_{gen}*P_{vocab}(w) + (1-p_{gen})*\\sum_{i:w_i=w}a^t_i$$\n",
        "\n",
        "Where\n",
        "- $P$ is the extended vocabulary containing words from vocabulary and article both.\n",
        "- $a^t_i$ is the attention $t^{th}$ time step need to give to $i^{th}$ article word.\n",
        "- $P_{vocab}$ is the previous vocabulary distribution without considering words from article."
      ],
      "metadata": {
        "id": "j7wikoNOuKsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Pointer Generator Network\n",
        "\n",
        "Pointer network takes the context vector ($h^{*(t)}$), decoder embedding input($x^{(t)}$) and decoder hidden state ($s^{(t)}$). The equation of the pointer network is - $$p_{gen} = \\sigma(W_h^Th^{*(t)}+W_x^Tx^{(t)}+W_s^Ts^{(t)}+b_{ptr})$$"
      ],
      "metadata": {
        "id": "PlMlegsIEbsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pointer_generator_v1(context_vector, decoder_state, decoder_inp):\n",
        "  '''Generates the p_gen needed to calculate the final vocabulary distribution.\n",
        "  It takes the context, decoder hidden state and decoder embedding input as it's input and then\n",
        "  passes them through a dense layer to get the pointer generator.\n",
        "\n",
        "  Arguments:\n",
        "    context_vector: Tensor of shape (batch, n_a)\n",
        "    decoder_state: Tensor of shape (batch, n_s)\n",
        "    decoder_inp: Tensor of shape (batch, emb_dim)\n",
        "\n",
        "  Returns:\n",
        "    returns the pointer generator p_gen\n",
        "  '''\n",
        "  concat = Concatenate(axis=-1)([context_vector, decoder_state, decoder_inp])\n",
        "  p_gen = tf.keras.layers.Dense(units=1, activation='sigmoid')(concat)\n",
        "\n",
        "  return p_gen"
      ],
      "metadata": {
        "id": "P7y1utw3mAZw"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Pointer Generator Model"
      ],
      "metadata": {
        "id": "AKSoa2YRENVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pointer_gen_model(Tx, Ty,\n",
        "                   emb_dim, n_a, n_s, d1_units, d2_units, d_units,\n",
        "                   article_vocab_size, summary_vocab_size):\n",
        "  '''This implements the bas-line model archietecture for summarization.\n",
        "  It is a seq-seq model with attention mechanism implemented in it. The encoder take an input\n",
        "  with `Tx` time-steps and summarizes with the help of decoder into Ty words. The encoder and decoder\n",
        "  hidden states are `n_a` and `n_s` dimension respectively. The words are taken from the vocabulary of\n",
        "  article and summary `article_vocab` and `summary_vocab` with size `article_vocab_size` and\n",
        "  `summary_vocab_size` respectively.\n",
        "\n",
        "  Arguments:\n",
        "    Tx: int, length of the input article\n",
        "    Ty: int, length of the output summary\n",
        "    n_a: int, dimension of the encoder hidden states\n",
        "    n_s: int, dimension of the deocder hidden states\n",
        "    d1_units: int, units for the first dense layer in attention mechanism\n",
        "    d2_units: int, units for the second dense layer in attention mechanism\n",
        "    d_units: int, units for the dense layer before output layer\n",
        "    article_vocab_size: int, length of the article vocabulary\n",
        "    summary_vocab_size: int, length of the summary vocabulary\n",
        "\n",
        "  Returns:\n",
        "    returns the base line model\n",
        "  '''\n",
        "  # Defining the input for our model with shape (None, Tx) and (None, Ty) for encoder input and decoder input\n",
        "  X_inp = Input(shape=(Tx))\n",
        "  X_tar = Input(shape=(Ty))\n",
        "\n",
        "  # Initialize s0\n",
        "  s0 = Input(shape=(n_s, ), name=\"s0\")\n",
        "  # Initialize c0\n",
        "  c0 = Input(shape=(n_s, ), name=\"c0\")\n",
        "\n",
        "  # Initialize the a and s with a0 and s0\n",
        "  s = s0 # (batch, n_s)\n",
        "  c = c0 # (batch, n_s)\n",
        "\n",
        "  # Define the outputs as empty list\n",
        "  outputs = []\n",
        "\n",
        "  # First embedding layer for the article input\n",
        "  encoder_inp = Embedding(article_vocab_size, emb_dim)(X_inp) # (batch, Tx, emb_dim)\n",
        "\n",
        "  # Encoder: Bidirectional layer with LSTM cells\n",
        "  a = Bidirectional(LSTM(units=n_a, return_sequences=True))(encoder_inp) # (batch, Tx, n_a)\n",
        "\n",
        "  # Define the embedding for decoder\n",
        "  decoder_inp = Embedding(summary_vocab_size, emb_dim)(X_tar) # (batch, Ty, emb_dim)\n",
        "\n",
        "  # Define the layers for Attention so that we can use the same weights for all decoder timesteps\n",
        "  repeater = RepeatVector(Tx)\n",
        "  concatenator = Concatenate(axis=-1)\n",
        "  attn_densor1 = Dense(units=d1_units, activation='tanh')\n",
        "  attn_densor2 = Dense(units=d2_units, activation='linear', use_bias=False)\n",
        "  softmax_layer = Activation('softmax', name=\"attention_weights\")\n",
        "  dotter = Dot(axes=1)\n",
        "\n",
        "  # Define the Decoder unidirectional LSTM for shared weights\n",
        "  post_attention_lstm = LSTM(units=n_s, return_state=True)\n",
        "\n",
        "  # Define the last dense layer before output layer with linear activation\n",
        "  densor = Dense(units=d_units, activation='linear')\n",
        "\n",
        "  # Define the output layer so that it does not initalize again and again for shared weights\n",
        "  output_layer = Dense(units=summary_vocab_size, activation='softmax')\n",
        "\n",
        "  # Initialize a tensor with zeros and with same shape as X_inp\n",
        "  extension = tf.zeros_like(X_inp)\n",
        "\n",
        "  # Decoder: Appends outputs from the output layer in each timestep\n",
        "  for t in range(Ty):\n",
        "    # Get the decoder input for current timestep\n",
        "    curr_dec_in = decoder_inp[:, t:t+1, :] # (batch, 1, emb_dim)\n",
        "\n",
        "    # Get the context from the attention mechanism\n",
        "    context, attn_dist = one_time_attention_v2(a, s, # (batch, d2_units, 2*n_a), (batch, Tx, d2_units)\n",
        "                                 repeater, concatenator, attn_densor1, attn_densor2, softmax_layer, dotter)\n",
        "\n",
        "    concat = Concatenate(axis=-1)([curr_dec_in, context]) # (batch, d2_units, emb_dim+2*n_a); d2_units=1 otherwise error\n",
        "    _, s, c = post_attention_lstm(concat, initial_state=[s, c]) # _, (batch, n_s), (batch, n_s)\n",
        "\n",
        "    # Calculate the output after using 2 linear dense layers\n",
        "    den1 = densor(s) # (batch, d_units)\n",
        "    den2 = densor(den1) # (batch, d_units)\n",
        "    # Use the output_layer to get the vocabulary distribution\n",
        "    p_vocab  = output_layer(den2) # (batch, summary_vocab_size)\n",
        "\n",
        "    # Generate pointer\n",
        "    p_gen = pointer_generator_v1(context[:, 0, :], s, curr_dec_in[:, 0, :])\n",
        "\n",
        "    # Calculate the total probablity of copying words from source text\n",
        "    p_copy = (1 - p_gen) * attn_dist[:, :, 0]\n",
        "\n",
        "    # Calculate the probablity to generate new word\n",
        "    p_final = p_gen * p_vocab\n",
        "\n",
        "    # Extend the final vocabulary to take new temporary words from source text\n",
        "    p_final = tf.concat([p_final, extension], axis=-1)\n",
        "\n",
        "    # Calculate the extended vocabulary distribution\n",
        "    p_final = # combine the p_copy with existing p_final\n",
        "\n",
        "    # Append the final output to the outputs list\n",
        "    outputs.append(p_final)\n",
        "\n",
        "  # Stack the list of each timesteps output along axis=1\n",
        "  outputs = tf.stack(outputs, axis=1) # (batch, Ty, summary_vocab_size)\n",
        "\n",
        "  model = Model(inputs=[X_inp, X_tar, s0, c0], outputs=outputs)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "hLrsABvkICua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pointer Generator Model Creation and Training"
      ],
      "metadata": {
        "id": "l5lRYuUrDih7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tx = MAX_ARTICLE_TOKENS\n",
        "Ty = MAX_SUMMARY_TOKENS - 1\n",
        "emb_dim = EMB_OUT\n",
        "n_a = ENCODER_STATE_DIM\n",
        "n_s= DECODER_STATE_DIM\n",
        "d1_units = DENSE1_UNITS\n",
        "d2_units = DENSE2_UNITS\n",
        "d_units = DENSE_UNITS\n",
        "article_vocab_size = VOCAB_SIZE\n",
        "summary_vocab_size = VOCAB_SIZE\n",
        "\n",
        "pointer_model = pointer_gen_model(Tx, Ty,\n",
        "                          emb_dim, n_a, n_s, d1_units, d2_units, d_units,\n",
        "                          article_vocab_size, summary_vocab_size)"
      ],
      "metadata": {
        "id": "n7-mN-LfD69k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model has {pointer_model.count_params():,} parameters.\")"
      ],
      "metadata": {
        "id": "AkrDZxHbIjFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A look into how model will output on the above input."
      ],
      "metadata": {
        "id": "4pJCgf-3IwUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_model_out = pointer_model((art_inp, sum_inp, s0, c0))\n",
        "\n",
        "print(f\"Model output has a type: {type(sample_model_out)}\")\n",
        "print(f\"Model Output list for the Inputs above are of length: {len(sample_model_out)}\")\n",
        "print(f\"Model Output list has each output of shape: {sample_model_out[0].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "32287225-4fc5-4b3a-dc15-8b2c005978ab",
        "id": "jl_ewDpoIwUi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output has a type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Model Output list for the Inputs above are of length: 16\n",
            "Model Output list has each output of shape: (99, 20000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Custom Loss and Accuracy Version 2"
      ],
      "metadata": {
        "id": "7Vgp0zJ0EDkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss_v2(y_true, y_pred):\n",
        "  '''Calculates the loss for the baseline model. The loss is calculated by taking the negative\n",
        "  log-likelihood of the target word(w*_t) in the current timestep. Then the overall loss\n",
        "  is the summation over all timesteps divided by T (not Ty because it would include paddings also).\n",
        "\n",
        "  Arguments:\n",
        "    y_true: tf.Tensor object, true values for the target\n",
        "    y_pred: list of tf.Tensor objects, predicted probablities of the summary words\n",
        "\n",
        "  Returns:\n",
        "    returns the loss on the predicted values for the model\n",
        "  '''\n",
        "  # Calculate the loss for each item in the batch.\n",
        "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "  # Remove the paddings from calculation of loss\n",
        "  mask = tf.cast(y_true != 0, loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  # Divide the total loss after masking out paddings divided by total words which are not paddings\n",
        "  return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def custom_accuracy_v2(y_true, y_pred):\n",
        "  '''Calculates accuracy of the baseline model. The accuracy is calculated by matching how many correct\n",
        "  words were predicted excluding the paddings. Then, just add those which are correct and you will get the\n",
        "  the accuracy and then just divide it by total words not including padding.\n",
        "\n",
        "  Arguments:\n",
        "    y_true: tf.Tensor object, expected target values\n",
        "    y_pred: list of tf.Tensor object, predicted target values by model\n",
        "\n",
        "  Returns:\n",
        "    returns the total accuracy over the batch of data\n",
        "  '''\n",
        "  # Find the word index with maximum probablity\n",
        "  y_pred = tf.argmax(y_pred, axis=-1)\n",
        "  y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "\n",
        "  # Count the words that matches with true values\n",
        "  match = tf.cast(y_pred == y_true, tf.float32)\n",
        "  mask = tf.cast(y_true != 0, tf.float32)\n",
        "\n",
        "  # Mask out the paddings\n",
        "  match *= mask\n",
        "\n",
        "  return tf.reduce_sum(match) / tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "E_SW6SzNDH1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Testing with loss and accuracy"
      ],
      "metadata": {
        "id": "ShbQdiQqILXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sample y true values: {sum_tar}\")\n",
        "print(f\"Sample y pred values(first 10 values of first 2 timestep): {sample_model_out[:2]}\")\n",
        "\n",
        "sample_loss = custom_loss_v2(sum_tar, sample_model_out)\n",
        "print(f\"Loss of the sample y_true and y_pred: {sample_loss}\")\n",
        "\n",
        "sample_acc = custom_accuracy_v2(sum_tar, sample_model_out)\n",
        "print(f\"Accuracy of the sample y_true and y_pred: {sample_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "ee0770bc-19c8-4c74-d6cd-be5a51114c64",
        "id": "NOapo56oILX5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample y true values: [[   2 1594 1589 ...    0    0    0]\n",
            " [  36 2526 7765 ...    0    0    0]\n",
            " [1024  358 5136 ...    0    0    0]\n",
            " ...\n",
            " [ 446  178    2 ...    0    0    0]\n",
            " [  68   47 1745 ...    0    0    0]\n",
            " [ 241 1043    1 ...    0    0    0]]\n",
            "Sample y pred values(first 10 values of first 2 timestep): [[[4.9766826e-05 4.9918344e-05 4.9897033e-05 ... 4.9849703e-05\n",
            "   5.0315728e-05 5.0180632e-05]\n",
            "  [4.9540908e-05 4.9899852e-05 4.9744962e-05 ... 4.9732076e-05\n",
            "   5.0619914e-05 5.0087474e-05]\n",
            "  [4.9342078e-05 4.9915510e-05 4.9560989e-05 ... 4.9633010e-05\n",
            "   5.0835100e-05 4.9942733e-05]\n",
            "  ...\n",
            "  [4.8487480e-05 5.0055794e-05 4.8468002e-05 ... 4.9327318e-05\n",
            "   5.1671042e-05 4.9163184e-05]\n",
            "  [4.8487480e-05 5.0055794e-05 4.8468002e-05 ... 4.9327318e-05\n",
            "   5.1671042e-05 4.9163184e-05]\n",
            "  [4.8487480e-05 5.0055794e-05 4.8468009e-05 ... 4.9327322e-05\n",
            "   5.1671042e-05 4.9163184e-05]]\n",
            "\n",
            " [[4.9986847e-05 4.9694067e-05 5.0172279e-05 ... 5.0206174e-05\n",
            "   5.0213788e-05 5.0044073e-05]\n",
            "  [5.0031969e-05 4.9539321e-05 5.0381001e-05 ... 5.0354411e-05\n",
            "   5.0285667e-05 5.0100505e-05]\n",
            "  [5.0090632e-05 4.9461749e-05 5.0534971e-05 ... 5.0449049e-05\n",
            "   5.0280312e-05 5.0154122e-05]\n",
            "  ...\n",
            "  [5.0358569e-05 4.9316510e-05 5.0878778e-05 ... 5.0763316e-05\n",
            "   5.0129740e-05 5.0536150e-05]\n",
            "  [5.0358594e-05 4.9316495e-05 5.0878807e-05 ... 5.0763316e-05\n",
            "   5.0129740e-05 5.0536142e-05]\n",
            "  [5.0358627e-05 4.9316488e-05 5.0878847e-05 ... 5.0763323e-05\n",
            "   5.0129747e-05 5.0536146e-05]]]\n",
            "Loss of the sample y_true and y_pred: 9.907593727111816\n",
            "Accuracy of the sample y_true and y_pred: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Compiling pointer generator model"
      ],
      "metadata": {
        "id": "nT2RqhLFMlHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LEARNING_RATE\n",
        "initial_accumulator_value = INIT_ACC_VAL\n",
        "clipnorm = MAX_GRAD_NORM\n",
        "\n",
        "opt = Adagrad(learning_rate=lr,\n",
        "              initial_accumulator_value=initial_accumulator_value,\n",
        "              clipnorm=clipnorm)\n",
        "\n",
        "pointer_model.compile(loss=custom_loss_v2, optimizer=opt, metrics=[custom_loss_v2, custom_accuracy_v2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "48f21c46-7ca9-461a-c987-c53e1689dae8",
        "id": "WTayhfQFMlH0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creating callbacks for model"
      ],
      "metadata": {
        "id": "pQSFBBfYMlH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mention the checkpoint path and it's directory where you will save the model\n",
        "checkpoint_path = POINTER_MODEL_CHECKPOINT\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Calculate no of batches, I am taking floor because when creating the training data I used drop_remainder\n",
        "n_batches = int(train_dataset.shape[0] / BATCH_SIZE)\n",
        "\n",
        "# Create the checkpoint for model saving, monitoring val_custom_accuracy_v1 and save only weights of the model\n",
        "saving_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                monitor='val_custom_accuracy_v2',\n",
        "                                                verbose=1,\n",
        "                                                save_weights_only=True,\n",
        "                                                save_freq=n_batches//2)\n",
        "\n",
        "# Create the checkpoint for stopping early after noticing that val_custom_accuracy_v1 is not increasing even after 5 consecutive epochs\n",
        "earlystop_cb = tf.keras.callbacks.EarlyStopping(monitor='val_custom_accuracy_v2',\n",
        "                                                    patience=PATIENCE,\n",
        "                                                    mode='max',\n",
        "                                                    )\n",
        "\n",
        "# Store the checkpoints in a list\n",
        "callbacks = [saving_cb, earlystop_cb]"
      ],
      "metadata": {
        "id": "BXuC_RPbMlH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training pointer generator model"
      ],
      "metadata": {
        "id": "S4iHgb8KMlH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = EPOCHS\n",
        "steps_per_epoch = STEPS_PER_EPOCHS\n",
        "\n",
        "history = pointer_model.fit(tf_train_dataset.repeat(),\n",
        "                    epochs=epochs,\n",
        "                    validation_data=tf_val_dataset,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    callbacks=callbacks\n",
        "                    )"
      ],
      "metadata": {
        "id": "z0ZekuBoMlH0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}