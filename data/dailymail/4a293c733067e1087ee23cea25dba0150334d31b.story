Smartphones today react to touch, shakes and even our voices, but phones of the future could respond to these motions with touches of their own.

A Microsoft researcher from Beijing is working to develop screens that create a variety of different responsive sensations.

Examples include a clicking sensation when pressing an on-screen button, and sensing the weight of folders as they’re dragged across a display. 

Scroll down for video 

A Microsoft researcher from Beijing is working to develop touchscreens (prototype pictured) that create different, responsive sensations. The examples include a clicking sensation when pressing an on-screen button, and sensing the weight of folders as they’re dragged across a display

Some of the sensations are based on stimulating the skin, while others stimulate muscles, and recent research also found such sensations can help people type faster.

Prototype tablet devices, including those developed by Microsoft and Fujitsu, use ultrasound vibrations to mimic a variety of textures.

These
 vibrations change the friction between the finger and the screen to 
trick the brain into thinking it’s plucking a harp, touching the skin of
 an alligator, and more.

It can also give the sensation of a slippery liquid.

Other, similar technologies change the 
friction between the finger and the screen using static electricity. 

Disney Research developed a similar 
system in October that uses an algorithm for 2D touchscreens that 
modifies the friction between a user's finger and the screen to add 
physical sensations to what a viewer is looking at.

Fujitsu claims its technology can reproduce edges, ridges, protrusions and bumps as well as other sensations using its technology.

‘The way we design computers today,’ Microsoft researcher Hong Tan said, ‘It would seem that people only use their eyes.’

‘Sure, we tap on our device screens, slide our fingertips across the glass, and type on on-screen keyboards.

‘Sometimes, we give voice commands and listen back. 

'Our phones vibrate when a text arrives, and we feel a rumble from a joystick when we play a video game.

‘But still, it’s almost entirely about the eyes.’

Microsoft researcher Hong Tan believes users ‘have barely begun to engage our other senses, particularly touch’, and she has been working to develop hardware and software to add tactile sensations smartphones and tablets - known as haptic feedback.

‘With sight alone, most people are perfectly fine interacting with computing devices today, but how much more efficiently, how much more enjoyably, can we interact with computers? 

'How much more accessible can we make them? We won’t know until this becomes taken for granted.’

Tan previously worked with researchers from Purdue University to develop haptic keyboards. 

Some of the sensations being developed are based on stimulating the skin, while others stimulate muscles. Recent research also found such sensations can help people type faster. Researchers suggest mimicking the feeling of keys improves the positioning of the fingers and makes typing feel more natural

In the case of vibration feedback, for example, it involves electronic engineering and mechanics, as well as knowledge about human sensitivity to create various vibration frequencies.

In the case of haptic keyboards, the key-click feedback actually simulates the feeling of pressing a key.

One method being researched includes putting a layer of material under the glass that bends under electric voltage, which, in turn, bends the glass ever so slightly to simulate a key click.

Tan’s Human-Computer Interaction group has developed a number of prototypes that produce haptic keyboard feedback.

In a recent research paper, Tan and Jin Ryong Kim, a graduate student at Purdue, revealed that haptic keyboards can boost typing speed and accuracy.

Fujitsu unveiled a prototype tablet at this year’s Mobile World Congress that uses similar technology. It uses ultrasound vibrations to mimic a variety of textures. These vibrations change the friction between the finger and the screen to trick the brain into thinking it’s touching the skin of an alligator (pictured) and more

Disney Research developed a similar system in October that uses an algorithm for 2D touchscreens that modifies the friction between a user's finger and the screen to add physical sensations to what a viewer is looking at (pictured)

More research needs to be done into why this occurs, but Tan suggests that by mimicking keys it improves the positioning of the fingers and makes typing feel more natural.

Tan’s group is also working on haptic tablets that simulate sticky and smooth sensations.

Fujitsu unveiled a prototype tablet at this year’s Mobile World Congress that uses similar technology.

The Japanese firm's prototype uses ultrasound vibrations to mimic a variety of textures. 

These vibrations change the friction between the finger and the screen to trick the brain into thinking it’s plucking a harp, touching the skin of an alligator and more.

Disney Research developed a similarsystem in October that uses an algorithm for 2D touchscreens that modifies the friction between a user's finger and the screen to add physical sensations to what a viewer is looking at. 

However, the technology is still in its infancy and there are no immediate plans to release devices with these features. 

 

 

@highlight

Microsoft researcher Hong Tan is an expert in haptic feedback

@highlight

She is developing touchscreens that create different, responsive sensations

@highlight

Examples include a clicking sensation when pressing an on-screen button, and sensing the weight of folders as they’re dragged across a display

@highlight

Some are based on stimulating the skin, while others stimulate muscles

@highlight

Recent research also found the sensations can help people type faster

@highlight

Fujitsu has developed a prototype tablet that works in a similar way