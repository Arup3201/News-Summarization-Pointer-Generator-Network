Swiping through the air to control items on a screen conjure up images of the sci-fi technology seen in Minority Report.

But a Norwegian firm has not only designed the system using an everyday smartphone, it has designed it to work from up to seven feet (2 metres) away.

The system tracks a user’s hands movements using ultrasound to skip through images, play and pause videos and music, take selfies and control characters in online games.

Scroll down for video 

During MailOnline’s demonstration, Elliptic Labs’ vice president of product development, Guenael Strutt showcased how the technology can be used to show or hide the controls on YouTube videos (pictured)

Dubbed Ultra-Fast Ultra-Far Interaction, the system was built by experts at Norway-based Elliptic Labs.

Ultrasound signals sent through the air from speakers in smartphones and tablets bounce against a user’s hand and are recorded by standard microphones.

Elliptic Labs’ technology uses these signals to recognises hand gestures and uses them to move objects on a screen. The company compared it to the way bats use echolocation to navigate.

Gestures can be recognised from all sides of the device at 180 degrees.

During MailOnline’s demonstration, Elliptic Labs’ vice president of product development, Guenael Strutt showcased how the technology can be used to show or hide the controls on YouTube videos.

Dubbed Ultra-Fast Ultra-Far Interaction, the system was built by experts at Norway-based Elliptic Labs.

Ultrasound signals sent through the air from speakers in smartphones and tablets bounce against a user’s hand and are recorded by standard microphones.

Elliptic Labs’ technology uses these signals to recognises hand gestures and uses them to move objects on a screen.

The company compared it to the way bats use echolocation to navigate.

Gestures can be recognised from all sides of the device at 180 degrees.

He revealed how photos can be moved and managed using slow or fast swipes left and right, how an on-screen octopus could be controlled on a mobile game by moving his hand up and down, and taking selfies by virtually tapping a shutter button.

And on a tablet, a music app and playback was controlled by virtually pressing the play button.

A previous version, which measured gestures from 19 inches (50cm) away, was showcased at this year’s Consumer Electronics Show in Las Vegas in January.

This demo introduced Multi Layer Interaction (MLI) which lets mobiles and tablets display different content depending on the location and distance a user’s hand is from the device.

By using technology that is already inside smartphones along with software that can sit on top of existing operating systems, Elliptic Labs hopes to launch the technology in handsets later this year.

Science fiction to reality: The technology that involves swiping through the air to control items on a screen conjures up images of the futuristic world seen in Minority Report (scene pictured)

Elliptic Labs’ technology uses these signals to recognises hand gestures and uses them to move objects on a screen. The company compared it to the way bats use echolocation to navigate (demo handset pictured)

Mr Strutt said the company had already partnered with two manufacturers but didn’t reveal which ones.

‘With Elliptic Labs’ gesture recognition technology the entire zone above and around a mobile device becomes interactive and responsive to the smallest gesture,’ said the firm.

‘The active area is 180 degrees around the device made possible by ultrasound [and] Elliptic Labs delivers the largest interaction space for consumer electronic devices while using very low power.’

Mr Strutt added that the interaction space can also be customised by device manufacturers or software developers depending on how they want it to be used. 

@highlight

The system tracks a users hands movements using ultrasound

@highlight

Gestures can skip through images, play videos and take selfies

@highlight

It can also control characters in online games or control music 

@highlight

Ultrasound signals sent through the air from speakers in smartphones and tablets bounce against a user’s hand and are recorded by microphones

@highlight

Elliptic Labs uses these signals to recognise hand gestures

@highlight

The company compared it to the way bats use echolocation to navigate 