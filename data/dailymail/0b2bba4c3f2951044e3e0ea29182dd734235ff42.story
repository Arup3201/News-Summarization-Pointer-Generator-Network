PUBLISHED:

18:18 EST, 24 February 2013


| 

UPDATED:

18:58 EST, 24 February 2013

'If a robot goes wrong, who is accountable?': Professor Noel Sharkey called for a pre-emptive ban on killer robots

Killer robots were once confined to Hollywood films or the pages of science-fiction novels.

But with growing advances in technology, scientists warn that warfare could be conducted by autonomous weapons within a generation.

Noel Sharkey, a professor of artificial intelligence and robotics at Sheffield University, said global action was needed to control their development.

The technology is being developed in an unregulated environment, while the machines would struggle to distinguish between a child holding an ice-cream cone and a man with a gun, leading to the indiscriminate loss of civilian life, said Dr Sharkey.

'There is no transparency, no legal process. The laws of war allow for rights of surrender, for prisoner of war rights, for a human face to take judgments on collateral damage.

'Humans are thinking, sentient beings. If a robot goes wrong, who is accountable? Certainly not the robot,' said Dr Sharkey.

Unmanned drones fitted with missiles, controlled from military bases by a human operator, have already been extensively used in Afghanistan and Pakistan to target militants.

But they have proved controversial, with claims they are also responsible for large numbers of civilian casualties.

Joined by other activists, including Nobel peace prize winners, Dr Sharkey is set to launch the 'Stop the Killer Robots' campaign at the House of Commons in April, calling for a pre-emptive ban on autonomous weapons.

Many of the campaigners have already lobbied for international action on cluster bombs and landmines.

'These things are not science fiction; 
they are well into development,' Dr Sharkey said in an interview with 
the Observer. 'The research wing of the Pentagon in the US is working on
the X47B [unmanned plane] which has supersonic twists and turns with a 
G-force that no human being could manage, a craft which would take 
autonomous armed combat anywhere in the planet.

Call of Duty: Experts say the U.S. is already courting young gamers to operate autonomous weapons

The U.S. is already training more drone pilots than real aircraft pilots, according to Professor Noel Sharkey

'In America they are already training more drone pilots than real aircraft pilots, looking for young men who are very good at computer games.

'They are looking at swarms of robots, with perhaps one person watching what they do.'

He added: 'Autonomous robotic weapons won't get tired, they won't seek revenge if their colleague is killed, but neither will my washing machine. No one on your side might get killed, but what effect will you be having on the other side, not just in lives but in attitudes and anger?'

Despite huge advancements in programming, scientists have been unable to get a robot to distinguish between friend or foe, 'We are struggling to get them to distinguish between a human being and a car.

The U.S. is said to be courting youngsters who are gaming wizards to operate autonomous weapons

'We have already seen utter incompetence in the use of drones, operators making a lot of mistakes and not being properly supervised,' he said.

Last year, campaign group Human Rights Watch (HRW) produced a 50-page report 'Losing Humanity: The Case Against Killer Robots' outlining their concerns about fully automated weapons.

'Giving machines the power to decide who lives and dies on the battlefield would take technology too far,' said Steve Goose from HRW. 'Human control of robotic warfare is essential to minimizing civilian deaths and injuries.'

@highlight

Professor Noel Sharkey warns againstÂ  autonomous weapons development

@highlight

Robots won't distinguish between child with ice cream and man with gun