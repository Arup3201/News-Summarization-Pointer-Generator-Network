Facebook has come under fire for its election plans to try to encourage voting - and mine its users data for political preferences.

The firm announced plans to mine data of millions of American voters, just as an experiment which tried to encourage people to vote was disclosed.

The data mining is likely to prove controversial as it adds to the amount Facebook knows about its users - although the company itself says that the data is anonymized before being processed. 

The move was announced as a controversial 2010 study has been revealed called 'A 61-Million-Person Experiment in Social Influence and Political Mobilization,'.

It found that around 20 percent of the users who saw that their friends had voted also clicked on an 'I Voted' button Facebook is set to make available.

User data: Facebook says it's mining its users' posts to analyze sentiment regarding candidates and issues for the 2014 and 2016 elections

Earlier this year Facebook issued tough new guidelines on research using its system following outrage from users over experiments on the social network.

The firm tightened its research guidelines following uproar over its disclosure this summer that it allowed researchers to manipulate users' feeds to see if their moods could be changed.

At issue was study in which Facebook allowed researchers to manipulate the content that appeared in the main section, or 'news feed,' of small fraction of the social network's users. 

As part of the study, Facebook put different forms of an 'I'm Voting' button on the pages of about 60 million of its American users.

Company researchers were testing them to understand the effect of each and to determine how to optimize the tool's impact, according to Mother Jones.

Two groups of 600,000 users were left out to serve as a control group—one which saw the 'I'm Voting' button but didn't get any information about their friends' behavior, and one which saw nothing related to voting at all. 

However, experts have warned the feature could be misused.

Jonathan Zittrain, a professor of law and computer science at Harvard University, believes the search giant could even influence the outcome of an election.

'Consider a hypothetical, hotly contested future election,' he wrote in New Republic. 

'Suppose that Mark Zuckerberg personally favors whichever candidate you don't like. 

'He arranges for a voting prompt to appear within the newsfeeds of tens of millions of active Facebook users, but unlike in the 2010 experiment, the group that will not receive the message is not chosen at random. 

Facebook founder Mark Zuckerberg declines to declare how he votes – but he has allied himself with immigration reform, one of the key causes of liberals in America.

It is probably the biggest clue to how he thinks politically.

He founded an action group which aims to give legal status to 11 million immigrants who do not have official permission to be in the US, an amnesty which is fiercely opposed by conservatives.

FWD.us is also supported by Steve Ballmer of Microsoft, Tim Armstrong of AOL and Eric Schmidt of Google.

The group aims to mirror the success of Silicon Valley’s new technology with lobbying and activism but has itself been hit by controversy when some liberal supporters quit it over it offering support for a controversial oil pipeline.

And he has also criticized surveillance by the NSA and other spy agencies, which resulted in him meeting President Obama to discuss his concerns in March this year. A company spokesman praised the president for his ‘engagement’.

Conservatives have also claimed Zuckerberg as one of their own. He has raised money for charter schools in New Jersey alongside its Republic governor Chris Christie.

The schools are opposed by liberals who object to teaching unions not being recognized.

Zuckerberg himself claims to be ‘post left and right’ and interested in a ‘knowledge economy’.

'Rather, Zuckerberg makes use of the fact that Facebook 'likes' can predict political views and party affiliation, even beyond the many users who proudly advertise those affiliations directly. 

'With that knowledge, our hypothetical Zuck chooses not to spice the feeds of users unsympathetic to his views. 

'Such machinations then flip the outcome of our hypothetical election. Should the law constrain this kind of behavior?

The firm will also collect data on its users in upcoming elections, it revealed today.

'Given the volume of conversation around politics on Facebook, we believe this data truly represents what the American people think about the potential candidates,' said Andy Mitchell Facebook's Director of News and Global Media Partnerships in a statement. 

Coverage: ABC News, whose 2012 Election Day coverage with Diane Sawyer is pictured here, will use the data in their coverage of the 2014 midterm elections with an eye on contenders for 2016

The data will be collected and shared with ABC News and BuzzFeed, to be used in 2014 and 2016 Election Day coverage.

However, experts have warned the social network could eventually use it to sell targeted advertising - and even influence the outcome of an election. 

Sociologist Zeynep Tufekci told MailOnline 'Of all the online platforms, Facebook probably has most information about its users. 

'Recent research shows that even a slice of Facebook data can reveal a person's political leanings, gender, sexual orientation, race, personality characteristics by datamining their acts on Facebook--in other words, without ever asking the user and even if you have never identified them. 

The California-based firm carried out its most controversial experiment during a week in 2012.

During that time, negative posts were deprioritised in the data feeds of 689,003 users, to see if it generated a more positive response.

Posts were determined by the experiment to be positive or negative if they contained at least one positive or negative word.

The experiment affected around 0.04 per cent of users - or 1 in 2500.

According to Facebook, nobody's posts were 'hidden,' they just didn't show up on some feeds.

It found that negative posts elicited a swell of positive responses, but also that a reduction in positive news led to more negative posts.

‘When positive expressions were reduced, people produced fewer positive posts and more negative posts; when negative expressions were reduced, the opposite pattern occurred,’ said the researchers.

During the weeklong study in January 2012, data-scientists were trying to collect evidence to prove their thesis that people's moods could spread like an 'emotional contagion' depending on what they were reading.

'Although this subject matter was important to research, we were unprepared for the reaction the paper received when it was published and have taken to heart the comments and criticism,' Mike Schroepfer, Facebook's chief technology officer, wrote in a blog post.

'While this particular program is slated as one that anonymizes user data, Facebook has this information and could in the future potentially sell it to political campaigns as a targeting tool.

'Hence, a political campaign could potentially target people of a particular political leaning, personality type, gender, or sexual orientation with targeted ads that would not be visible to anyone else, or nudge to motivate or demotivate a person to vote.'

Politico reports that Facebook will glean the data from posts by users in the United States 18 or older and will use sentiment analysis about specific politicians.

Sentiment analysis gauges whether a person's opinion about another person or subject is positive, negative or neutral, often by tracking keywords.

The analysis looks to be more sophisticated than how media outlets have used Facebook and other social media platforms in the past. 

The data will be searchable by gender and location, allowing analysis to be done on a state-by-state basis and giving the ability to isolate sentiment about specific issues in primary states like Iowa. 

Politico reports that Facebook will glean the data from posts by users in the United States 18 or older and will use sentiment analysis about specific politicians.Sentiment analysis gauges whether a person's opinion about another person or subject is positive, negative or neutral, often by tracking keywords.

An unnamed Facebook representative said the data 'is gathered in an aggregated and depersonalized manner in a privacy safe way.' 

ABC News plans to begin using Facebook data next week as part of its 2014 Election Day coverage, paying attention to the potential 2016 candidates.

The data will help 'identify the most important trends and the most stimulating conversations happening around the 2016 election cycle,' said ABC News president James Goldston in a statement.

Buzzfeed will integrate the data into election stories and use it in their news app, with editor in chief Ben Smith enthusiastic about the Facebook partnership.

'Facebook is going to be a central -- maybe the central -- arena in which political conversation happens in 2016,' he said in a statement.

A Pew Research Center poll released last week showed that 48 percent of web users said they consumed news on Facebook while 14 percent got news from YouTube.

Twitter came in at 9 percent while Google Plus only had 6 percent of web users reading news on the platform. 

@highlight

The social media site will mine data from users 18 and older, using sentiment analysis and will allow  outlets to sort by categories like gender and location

@highlight

Controversial 2010 study called 'A 61-Million-Person Experiment in Social Influence and Political Mobilization' under fire

@highlight

A recently release Pew study found that an large amount of web users get news from Facebook