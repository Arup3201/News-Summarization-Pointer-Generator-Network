People play down the amount they consume

It could be the struggling slimmer's best friend - or an irritating nightmare.

Clothing fitted with multiple 3D cameras that track everything you put in your mouth is being hailed as the future of dieting

The tiny cameras, embedded in clothes, could help abolish one of the main reasons for failed diets: underestimating the amount of calories we consume

People frequently calculate calories inaccurately when dieting, most likely playing down the amount they consume.

And there's no doubt that this 'guestimation' has a detrimental effect to dieters' waistlines.Â 

Now though scientists have developed special cameras that can be worn throughout the day - and will document exactly how much the wearer is eating.

The 3D cameras keep track of food intake by taking multiple images of the food and calculating how many calories it contains.

It works by taking information on the volume of food, using the plate as a scale reference, and by looking at the shape of the food to ascertain what it is.

It runs the information through a database to provide an accurate assessment of the number of calories in the dish.

The researchers tested the 'eButton' camera device on 17 foods, including burgers, broccoli, fish, ketchup and peanut butter. Ketchup, haddock and ice cream gave researchers problems. Their geometric properties resulted in the largest estimation errors. In the case of the ketchup, it was too small, whereas the ice cream and haddock had concave surfaces, which led to an overestimation of their volumes.

The University of Pittsburgh scientists including Hsin-Chen Chen et al, who devised the gadget, say that better understanding of intake - thanks to more accurate information - could lead to better overall health and help tackle chronic conditions such as obesity, diabetes and cardiovascular disease.

a) The eButton contains an (b) electronic circuit board and takes automatic photos of food while (c) attached to the wearer's shirt

They maintain that the current lack of convenient methods for measuring the portion sizes day-to-day calls for technology that can calculate calories without emotional investment.

The scientists say that their research, published in Journal of Measurement Science and 
Technology, will allow dieters to stop using rough 
approximations to gauge how much they are eating - and make better decisions about portion control.

The fascinating gadget is still in primitive stages of development.

Femail emailed the team at Pittsburgh with queries about how the cameras would compute salad dressings and sandwich fillings, and how they would calculate the calories, but they had not got back to us at the time of publishing.

More accurate information could lead to better overall health and help tackle chronic conditions

The technology combines cutting-edge 
artificial intelligence and camera technology to create a garment 
helping dieters avoid underestimating the number of calories they are 
consuming - a leading reason that diets fail.

An 'eButton' calculates the three dimensional shape and size of food on the plate to work out the portion sizes of your food.

This image is then compared with a built-in library of foods, with just a 3.7 per cent margin of error.

(a) original image with user-drawn points (green); (b) dissimilarity map Md; (c) segmentation result

Cameras estimate volume from a photographic image of food 
contained on a typical dining plate.

Then, the food is segmented automatically from the background in the image. Next, adaptive
 thresholding and snake modelling get to work, based on several image 
features like colour contrast, regional colour homogeneity and curve 
bending degree.

Next, a
 3D model representing the general shape of the food (e.g. cylinder or
 sphere) is selected from a pre-constructed shape model library.

The
 position, orientation and scale of the selected shape model are 
determined by registering the projected 3D model and the food contour in
 the image, where the properties of the reference are used as 
constraints. The volume is estimated 
from the size of the shape model after registering the 3D shape model to
 the 2D food contour (3D/2D model-to-image 
registration).

Estimation of food portion size in real eating activity using the eButton

SOURCE: Model-based measurement of food portion size for image-based dietary assessment using 3D/2D registration

@highlight

University of Pittsburgh researchers present method to estimate calories

@highlight

Tiny 3D cameras embedded into clothing take pictures and create model

@highlight

Proposal in latest Journal of Measurement Science and Technology

@highlight

eButton camera was incorrect 3.7% of the time

@highlight

Visual estimation is wrong 20% of the time