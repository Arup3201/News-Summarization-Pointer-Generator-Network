We like to think of ourselves as the superior species.

But robots are learning to cook like humans - by watching YouTube videos.

In a sign of the times, researchers have found a way to teach robots how to use cooking tools.

Scroll down for video 

Robots were taught to cook as part of an impressive use of artificial intelligence called 'deep learning'

Tutorials: Researchers used a video by YouTube cook 'Laura in the Kitchen' to teach the robots how to cook

Actions: Researchers used convolutional neural networks to help the robots identify the way a hand grasps an item, like a spatula, seen here, 

 

The researchers from the University of Maryland and the Australian research center NICTA, have published a paper on their findings.

Their work is part of an impressive use of artificial intelligence called 'deep learning.'

Deep learning involves researchers using training systems called artificial neural networks on lots of information derived from audio, images, and other inputs.  

In order to train the robots, researchers selected data from 88 YouTube videos of people cooking, according to Venture Beat.

A 'special' robot chef cuts noodles in a restaurant's kitchen in Jilin, China, the sight of a robot cooking a meal could soon become a common occurence

From there, the researchers generated commands that a robot could then execute.

The researchers employed 'convolutional neural networks' which are now in use at Facebook, among other companies.

They used these networks to identify the way a hand is grasping an item, and to recognize specific objects. 

Their system was also able to anticipate the action involving an object and a hand. 

According to technology experts, they presented the systems with new information and received inferences about it in response.

The results from the study will be revealed later this month at the 29th annual conference of the Association for the Advancement of Artificial Intelligence. 

Ultimately, researchers hope their results may signal the start of a training program which will allow robots to be able to seek their own sources of information.

A spokesman for the researchers said: 'We believe this preliminary integrated system raises hope towards a fully intelligent robot for manipulation tasks that can automatically enrich its own knowledge resource by 'watching' recordings from the World Wide Web.' 

Convolutional neural networks were introduced in a 1980 paper by Kunihiko Fukushima.

The design of convolutional neural networks follows the discovery of visual mechanisms in living organisms. 

In our brain, the visual cortex contains lots of cells and it is these cells which are responsible for detecting light in small, overlapping sub-regions of the visual field, called receptive fields. 

These cells act as local filters over the input space and the more complex cells have larger receptive fields. 

A convolution operator is created to mimic and perform the same function by all of these cells. 

The networks were inspired by biological processes and are widely used models for image and video recognition, being a power tool for different vision problems.

@highlight

Research was carried out by the University of Maryland and NICTA

@highlight

It used an impressive type of artificial intelligence called 'deep learning'

@highlight

Researchers selected data from 88 YouTube videos to train the robots 