By
Victoria Woollaston

When you search Google or use Amazon, you might assume the results you see are the same as those viewed by your friends, family and other internet users. But you’d be wrong.

Websites and social networks track your location and search history and make assumptions about your age, race, gender and political views to create a profile of who they think you are.

They then show adverts they believe to be the most relevant, in order to maximise clicks, and personalise which results you see by filtering out what they think is irrelevant.

This is sold to the public as positive - making each
 web session relevant and interesting - yet is leading researchers to 
fear the so-called ‘filter bubble’ could widen divides between the North
 and South, rich and poor, and young and old.

Websites track users to create a personal profile of who they think they are. Princeton University has created bots with fake ages and genders, virtually based in various locations, to map the extent at which this personalisation effects how people move around the web. An example map is pictured

For example, in terms of wealth, if users are 
only ever shown particular products and job advertisements  based on how much they earn or where the live, these users will 
never be given the opportunities to increase how their wealth, or how much they spend on items.

To assess the extent to which personalisation is having an effect on our society, Princeton University has created bots, each with their own fake profiles.

These bots have different fake ages and genders, each of them earn a different level of money, are virtually based in various locations around the world and have different interests.

By using these bots to scan and search the web, the researchers hope to create a picture of not only what each of them sees, but also what sites they are missing out on.

The filter bubble is when a website 
guesses what information a particular user wants to see. It uses 
information it knows, from a person’s search history and location, and 
attempts to guess what it doesn’t.

It makes assumptions about a person’s 
wealth, based on where they live and work, for example, or looks at 
their credit score. It guesses a person’s age by comparing what they’ve 
searched for with what people of the same age are searching for.

Some algorithms can also scan personal
 social network profiles, for example, to fill in the knowledge gaps. Political 
views and opinions can then be garnered from various sources.

This tracking is all done using cookies installed on websites and browsers.

For example, if two different people 
search for the word ‘apple’ they could get different results.
 If their age and search history suggests they like tech and gadgets, a
 search for ‘apple’ will show results for Apple iPhones, iPads and 
Apple-related news stories (pictured left).

If the person searching regularly checks in at the 
gym, or is a keen baker, or does grocery shopping online, the algorithm 
might decide they are instead looking for the fruit (pictured right). This means they push Apple 
products down the list and in some cases the irrelevant results aren’t shown at all.

When it comes to wealth, if users are 
only ever shown particular products, job adverts and so on, they will 
never increase how much money they earn or how much they spend on items; widening the 
rich and poor divide.

In terms of politics, if a user has 
previously searched for details about a particular political party or 
policy, or live in a Labour stronghold as an example, when they search 
for news they may be shown more left-leaning publications or links.

This means alternative policies are 
hidden, meaning their beliefs are constantly reaffirmed and they only 
deal with like-minded sites and people.

Researchers fear this can 
prevent change as well as widen the gaps between political groups and 
lead to a state of isolation.

According to lead researcher, Arvind Narayanan: ‘Our goal is a web privacy census which will be a comprehensive map of which entities are collecting what information, what they are inferring from it, and who they are sharing it with. It is an important step in our ultimate goal of figuring out how users are treated based on that information.’

Personalisation also has its benefits. 
Shopping sites such as Amazon, for example, can scan a user's search and
 purchase history to offer suggestions. This can help find similar, 
cheaper items or items that are more suited to their needs at a glance, 
without having to perform additional searches.

It's also possible to disable personalised adverts and results. Google's search engine lets you switch off personalisation, for example. While all web users can enable the Do Not 
Track features built into the major browsers.

Researchers from the Universitat Pompeu Fabra in Barcelona and Yahoo Labs felt the issue was so potentially damaging, they have also created a way to ‘burst the filter bubble.’

Personalisation does have its benefits. Shopping sites such as Amazon, for example, can scan a user's search and purchase history to offer suggestions. This can help find similar, cheaper items or items that are more suited to their needs at a glance, without having to perform additional searches

They believe that just because people have opposing views on certain topics, doesn't mean they won't share interests in others.

To this end, they created a recommendation engine that makes filter bubble-style assumptions to create a profile, but then widens the results to show opposing views that a user may also be interested in.

Google lets users switch off personalisation. Users can also enable the Do Not Track features built into all of the major browsers including Firefox, pictured

'We nudge users to read content from people who may have opposite views, or high view gaps, in those issues, while still being relevant according to their preferences,” Graells-Garrido told MIT Technology Review.

The team scanned thousands of tweets to establish a wordcloud.They looked at people who tweeted about a certain topic and then looked at what other interests they had tweeted about previously.

Graells-Carrido was then able to create a list of interests for each topic along the lines of ‘if you like that, you’ve love this.’

When a user searched for a particular topic, the recommendation engine would not only show similar links, it would also show interests that may overlap, but may not share the same view.

Their results discovered that people can be more open to ideas that are different from their own and people who are opinionated, appreciate the opinions of others more.

@highlight

Sites such as Google, Amazon and Facebook personalise what users see

@highlight

This personalisation depends on the user’s location, age, or search history

@highlight

These
 sites make assumptions about what they think a user will find 
interesting and repeatedly serves similar results

@highlight

Researchers fear this could create a two-tier web and widen 
social divides as people are never shown opposing views