{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27545,"status":"ok","timestamp":1687339181461,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"F3fh9Mru9Txd","outputId":"e647bffe-b42a-4069-9aa1-fa446138a065"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"qobuwS7N6mpZ"},"source":["## Libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"qsSZykoojfwL","executionInfo":{"status":"ok","timestamp":1687339193934,"user_tz":-330,"elapsed":3610,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["import os\n","import pathlib\n","from collections import Counter\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.layers import TextVectorization, Embedding, LSTM, Bidirectional, Dense, \\\n"," AdditiveAttention, LayerNormalization, Add\n","\n","from math import inf\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"ZBVqadIrP22p"},"source":["## Define all paths relevant for this project"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"IhazYkvLjEJ-","executionInfo":{"status":"ok","timestamp":1687339197785,"user_tz":-330,"elapsed":524,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["project_dir = \"/content/drive/MyDrive/Projects/Suvidha-Foundation-Internship-Project\""]},{"cell_type":"code","execution_count":4,"metadata":{"id":"nD1-ER-3NJSk","executionInfo":{"status":"ok","timestamp":1687339197786,"user_tz":-330,"elapsed":4,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["train_file_path = os.path.join(project_dir, 'data/preprocessed/finished_files/final_train.csv')\n","val_file_path = os.path.join(project_dir, 'data/preprocessed/finished_files/final_val.csv')\n","test_file_path = os.path.join(project_dir, 'data/preprocessed/finished_files/final_test.csv')"]},{"cell_type":"markdown","metadata":{"id":"nA-A5lJdY410"},"source":["## Preparing Data for Model Experiement and for Actual Training"]},{"cell_type":"markdown","metadata":{"id":"iMHo8KwghWg_"},"source":["### Load the data from CSV file and according save it inside contexts and targets"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Meu3gn_KY9if","executionInfo":{"status":"ok","timestamp":1687339201048,"user_tz":-330,"elapsed":481,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["def load_data(path):\n","  data = pd.read_csv(path)\n","  articles, summaries = data['article'].to_numpy(), data['highlights'].to_numpy()\n","\n","  return articles, summaries"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"-EXVHtEjoPhl","executionInfo":{"status":"ok","timestamp":1687339231488,"user_tz":-330,"elapsed":29676,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["train_articles_raw, train_summaries_raw = load_data(train_file_path)\n","val_articles_raw, val_summaries_raw = load_data(val_file_path)\n","test_articles_raw, test_summaries_raw = load_data(test_file_path)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1687339231489,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"1JGFOx4fEIvm","outputId":"9161a481-6326-4ec7-b888-c6a7658d5d0b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["287113"]},"metadata":{},"execution_count":7}],"source":["len(train_articles_raw)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1687339231490,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"3dagsGETF6ro","outputId":"bd525fa5-3c11-494f-cdc7-57ad0a89a928"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"by . associated press . published : . 14:11 est , 25 october 2013 . | . updated : . 15:36 est , 25 october 2013 . the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo , grand forks and jamestown to the hepatitis a virus in late september and early october . the state health department has issued an advisory of exposure for anyone who attended five churches and took communion . bishop john folda ( pictured ) of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo , grand forks and jamestown to the hepatitis a . state immunization program manager molly howell says the risk is low , but officials feel it 's important to alert people to the possible exposure . the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a . the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month . symptoms of hepatitis a include fever , tiredness , loss of appetite , nausea and abdominal discomfort . fargo catholic diocese in north dakota ( pictured ) is where the bishop is located .\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}],"source":["train_articles_raw[0]"]},{"cell_type":"markdown","metadata":{"id":"Wo9PYHLAhcjI"},"source":["### Create experimental tf dataset"]},{"cell_type":"markdown","metadata":{"id":"s_8U2yIeZA4G"},"source":["Using tf.data with csv files - [Tensorflow Tutorial Link](https://www.tensorflow.org/tutorials/load_data/csv#using_tfdata).\n","\n","Creating train_ds, val_ds and test_ds using tf.data.Dataset - [Tensorflow Tutorial Link](https://www.tensorflow.org/text/tutorials/nmt_with_attention#create_a_tfdata_dataset)."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Y5x-m_uCmM_s","executionInfo":{"status":"ok","timestamp":1687339240139,"user_tz":-330,"elapsed":5785,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["train_raw = tf.data.Dataset \\\n","            .from_tensor_slices((train_articles_raw, train_summaries_raw))\n","\n","val_raw = tf.data.Dataset \\\n","          .from_tensor_slices((val_articles_raw, val_summaries_raw))\n","\n","test_raw = tf.data.Dataset \\\n","          .from_tensor_slices((test_articles_raw, test_summaries_raw))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1687339240140,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"ExLQIGrxb0XA","outputId":"df8b78b9-56cc-4f11-f0f0-68204f0c9a40"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(b\"by . associated press . published : . 14:11 est , 25 october 2013 . | . updated : . 15:36 est , 25 october 2013 . the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo , grand forks and jamestown to the hepatitis a virus in late september and early october . the state health department has issued an advisory of exposure for anyone who attended five churches and took communion . bishop john folda ( pictured ) of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo , grand forks and jamestown to the hepatitis a . state immunization program manager molly howell says the risk is low , but officials feel it 's important to alert people to the possible exposure . the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a . the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month . symptoms of hepatitis a include fever , tiredness , loss of appetite , nausea and abdominal discomfort . fargo catholic diocese in north dakota ( pictured ) is where the bishop is located .\", shape=(), dtype=string)\n","\n","tf.Tensor(b'[START] bishop john folda , of north dakota , is taking time off after being diagnosed . he contracted the infection through contaminated food in italy . church members in fargo , grand forks and jamestown could have been exposed . [END]', shape=(), dtype=string)\n"]}],"source":["for example_article_string, example_summary_string in train_raw.take(1):\n","  print(example_article_string)\n","  print()\n","  print(example_summary_string)\n","  break"]},{"cell_type":"markdown","metadata":{"id":"UWxDk1TqiMGM"},"source":["### Vocabulary Loading"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"wJTCAtd3h3hB","executionInfo":{"status":"ok","timestamp":1687339240141,"user_tz":-330,"elapsed":24,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["# Retrieve the vocabularies using the vocab file\n","with open(os.path.join(project_dir, 'data/preprocessed/finished_files/vocab'), 'r') as reader:\n","  vocab = reader.read()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1687339240142,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"TiLiOX4NpaF_","outputId":"6c654f52-6526-4471-db45-620e8037c703"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'. 12012810\\nthe 11803'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}],"source":["vocab[:20]"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1687339240142,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"CN1GQSYJpge-","outputId":"e378482a-86ec-4cb9-cf9f-bd2f2ee10ddb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.', 'the', ',', 'to', 'a']"]},"metadata":{},"execution_count":13}],"source":["[v.split(' ')[0] for v in vocab.split('\\n')[:5]]"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"moJRwKjyp0nN","executionInfo":{"status":"ok","timestamp":1687339240978,"user_tz":-330,"elapsed":858,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["vocab_data = [v.split(' ')[0] for v in vocab.split('\\n')]"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1687339240978,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"Fd98e5G3rfOC","outputId":"fb3b7762-f2d5-49ce-d2cb-7751cdae2029"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["200000"]},"metadata":{},"execution_count":15}],"source":["# In the vocabolary we already have the masked token, so we need to remove it\n","# otherwise TextVectorization would give ValuesError\n","vocab_data.index('')"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"mEtQ-TMPr7bR","executionInfo":{"status":"ok","timestamp":1687339240979,"user_tz":-330,"elapsed":7,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["vocab_data.remove('')"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"4_ZcVZFgyQP3","executionInfo":{"status":"ok","timestamp":1687339240979,"user_tz":-330,"elapsed":6,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["# Add it to the vocab_data as well as to all the texts\n","vocab_data.insert(0, '[START]')\n","vocab_data.insert(1, '[END]')"]},{"cell_type":"markdown","metadata":{"id":"612fTKqGQ5gH"},"source":["### Text Tokenizer"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Bozji4clsV14","executionInfo":{"status":"ok","timestamp":1687339240980,"user_tz":-330,"elapsed":7,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["# As we do not have [START] and [END] included in our context or target,\n","# let's include them in a function and pass it to the TextVectorization\n","def add_start_end(text):\n","  # If already any [START] or [END] token is present, remove them\n","  text = tf.strings.regex_replace(text, '[START]', '')\n","  text = tf.strings.regex_replace(text, '[END]', '')\n","\n","  text = tf.strings.strip(text)\n","  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n","\n","  return text"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1687339240980,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"Nfhe-UzAwCH2","outputId":"7d50c15c-bd95-467d-9208-aad89dcb7999"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(b'how are you ?', shape=(), dtype=string)\n","how are you ?\n","[START] how are you ? [END]\n"]}],"source":["example_text = tf.constant('how are you ?')\n","print(example_text)\n","print(example_text.numpy().decode())\n","print(add_start_end(example_text).numpy().decode())"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1687339240980,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"VYJ8MUvEQSmt","outputId":"4249c93e-83b7-43a9-8840-e3f945f5d7fd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[START]', '[END]', '.', 'the', ',', 'to', 'a', 'and', 'of', 'in']"]},"metadata":{},"execution_count":20}],"source":["vocab_data[:10]"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"kZ6xpyBzp98Q","executionInfo":{"status":"ok","timestamp":1687339242530,"user_tz":-330,"elapsed":1555,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["max_article_tokens = 400 # From the paper\n","max_summary_tokens = 100 # From the paper\n","\n","article_vocab_size = 50000\n","summary_vocab_size = 50000\n","\n","article_processor = TextVectorization(max_tokens=article_vocab_size+2, # 2 extra for '', [UNK]\n","                                   standardize=add_start_end,\n","                                   vocabulary=vocab_data[:article_vocab_size],\n","                                   output_sequence_length = max_article_tokens)\n","\n","summary_processor = TextVectorization(max_tokens=summary_vocab_size+2, # 2 extra for '', [UNK]\n","                                   standardize=add_start_end,\n","                                   vocabulary=vocab_data[:summary_vocab_size],\n","                                   output_sequence_length = max_summary_tokens)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1687339242531,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"zaEItS58ucmo","outputId":"de6d3654-5e24-4c50-97f9-5825f26449f2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['', '[UNK]', '[START]', '[END]', '.', 'the', ',', 'to', 'a', 'and']"]},"metadata":{},"execution_count":22}],"source":["article_processor.get_vocabulary()[:10]"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1687339242531,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"DJoWn4a54bpJ","outputId":"3dbc68a9-0da2-4dce-d119-19c92a09e610"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=string, numpy=b\"by . associated press . published : . 14:11 est , 25 october 2013 . | . updated : . 15:36 est , 25 october 2013 . the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo , grand forks and jamestown to the hepatitis a virus in late september and early october . the state health department has issued an advisory of exposure for anyone who attended five churches and took communion . bishop john folda ( pictured ) of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo , grand forks and jamestown to the hepatitis a . state immunization program manager molly howell says the risk is low , but officials feel it 's important to alert people to the possible exposure . the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a . the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month . symptoms of hepatitis a include fever , tiredness , loss of appetite , nausea and abdominal discomfort . fargo catholic diocese in north dakota ( pictured ) is where the bishop is located .\">"]},"metadata":{},"execution_count":23}],"source":["example_article_string"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1687339242532,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"H4XUZx0d0Z0B","outputId":"e8a0eefb-66ec-4bb4-9c28-aed2ebbed4e0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(400,), dtype=int64, numpy=\n","array([    2,    28,     4,  1579,   673,     4,   263,    23,     4,\n","       48259,   179,     6,   712,   519,   202,     4,   393,     4,\n","         331,    23,     4,     1,   179,     6,   712,   519,   202,\n","           4,     5,  4273,    10,     5, 15991,  3060, 14346,    11,\n","         294,  6146,    32,  2727,  2367,   919,    10,   833,   342,\n","          11, 15991,     6,  1028, 28440,     9, 36041,     7,     5,\n","       13753,     8,  2080,    11,   554,   491,     9,   365,   519,\n","           4,     5,   164,   259,   409,    32,  1250,    41,  7558,\n","          10,  4374,    13,   713,    44,  1634,   218,  6880,     9,\n","         195, 21741,     4,  4273,   364,     1,    54,   205,    53,\n","          10,     5, 15991,  3060, 14346,    11,   294,  6146,    32,\n","        2727,  2367,   919,    10,   833,   342,    11, 15991,     6,\n","        1028, 28440,     9, 36041,     7,     5, 13753,     8,     4,\n","         164, 32830,   913,   544,  9407, 14201,   106,     5,   655,\n","          17,  1103,     6,    36,   287,   468,    19,    16,   581,\n","           7,  3292,    68,     7,     5,   589,  4374,     4,     5,\n","       14346,   662,    15,   306,    14,  4273,   364,     1,    17,\n","         345,    82,   129,    46,   101,  1781,    20, 13753,     8,\n","           4,     5, 14346,   106,    18,  6119,     5,  2678,   144,\n","        6719,   424,   108,  3245,     8,   987,    13,  4175, 26887,\n","       10070,    11,  1296,    77,   248,     4,  2075,    10, 13753,\n","           8,   729,  5213,     6, 19081,     6,  1017,    10,  8441,\n","           6, 11991,     9, 11408, 11853,     4, 15991,  3060, 14346,\n","          11,   294,  6146,    54,   205,    53,    17,   111,     5,\n","        4273,    17,  2283,     4,     3,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0])>"]},"metadata":{},"execution_count":24}],"source":["example_article_token = article_processor(example_article_string)\n","example_article_token"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":848,"status":"ok","timestamp":1687339243374,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"zexEbNJV41te","outputId":"0fbd5853-f4ed-43ff-f074-e1c2c46fa379"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['', '[UNK]', '[START]', '[END]', '.', 'the', ',', 'to', 'a', 'and']"]},"metadata":{},"execution_count":25}],"source":["summary_processor.get_vocabulary()[:10]"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1687339243374,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"K_XifvBz4GR1","outputId":"287db89e-79ac-4a7d-9fed-93b39e7d121b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=string, numpy=b'[START] bishop john folda , of north dakota , is taking time off after being diagnosed . he contracted the infection through contaminated food in italy . church members in fargo , grand forks and jamestown could have been exposed . [END]'>"]},"metadata":{},"execution_count":26}],"source":["example_summary_string"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":745,"status":"ok","timestamp":1687339244117,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"VcX26Sry3LWq","outputId":"c9def340-de5a-4d1e-d101-8030314152b4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(100,), dtype=int64, numpy=\n","array([    2,     1,  4273,   364,     1,     6,    10,   294,  6146,\n","           6,    17,   345,    82,   129,    46,   101,  1781,     4,\n","          18,  6119,     5,  2678,   144,  6719,   424,    11,  1296,\n","           4,   833,   342,    11, 15991,     6,  1028, 28440,     9,\n","       36041,    87,    30,    48,  2727,     4,     1,     3,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0])>"]},"metadata":{},"execution_count":27}],"source":["example_summary_token = summary_processor(example_summary_string)\n","example_summary_token"]},{"cell_type":"markdown","metadata":{"id":"Ep8QmSUB8FVv"},"source":["### OOV (Out of Vocabulary) tokens"]},{"cell_type":"markdown","metadata":{"id":"vvpDFe6qJfJB"},"source":["#### Finding OOVs from articles and maximum oovs in a batch"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":545,"status":"ok","timestamp":1687342493859,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"d2pXG3_BeJvY","outputId":"a3ebab2d-c487-4d96-8218-397749d47702"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(219,), dtype=string, numpy=\n","array([b'by', b'.', b'associated', b'press', b'.', b'published', b':',\n","       b'.', b'14:11', b'est', b',', b'25', b'october', b'2013', b'.',\n","       b'|', b'.', b'updated', b':', b'.', b'15:36', b'est', b',', b'25',\n","       b'october', b'2013', b'.', b'the', b'bishop', b'of', b'the',\n","       b'fargo', b'catholic', b'diocese', b'in', b'north', b'dakota',\n","       b'has', b'exposed', b'potentially', b'hundreds', b'of', b'church',\n","       b'members', b'in', b'fargo', b',', b'grand', b'forks', b'and',\n","       b'jamestown', b'to', b'the', b'hepatitis', b'a', b'virus', b'in',\n","       b'late', b'september', b'and', b'early', b'october', b'.', b'the',\n","       b'state', b'health', b'department', b'has', b'issued', b'an',\n","       b'advisory', b'of', b'exposure', b'for', b'anyone', b'who',\n","       b'attended', b'five', b'churches', b'and', b'took', b'communion',\n","       b'.', b'bishop', b'john', b'folda', b'(', b'pictured', b')', b'of',\n","       b'the', b'fargo', b'catholic', b'diocese', b'in', b'north',\n","       b'dakota', b'has', b'exposed', b'potentially', b'hundreds', b'of',\n","       b'church', b'members', b'in', b'fargo', b',', b'grand', b'forks',\n","       b'and', b'jamestown', b'to', b'the', b'hepatitis', b'a', b'.',\n","       b'state', b'immunization', b'program', b'manager', b'molly',\n","       b'howell', b'says', b'the', b'risk', b'is', b'low', b',', b'but',\n","       b'officials', b'feel', b'it', b\"'s\", b'important', b'to', b'alert',\n","       b'people', b'to', b'the', b'possible', b'exposure', b'.', b'the',\n","       b'diocese', b'announced', b'on', b'monday', b'that', b'bishop',\n","       b'john', b'folda', b'is', b'taking', b'time', b'off', b'after',\n","       b'being', b'diagnosed', b'with', b'hepatitis', b'a', b'.', b'the',\n","       b'diocese', b'says', b'he', b'contracted', b'the', b'infection',\n","       b'through', b'contaminated', b'food', b'while', b'attending', b'a',\n","       b'conference', b'for', b'newly', b'ordained', b'bishops', b'in',\n","       b'italy', b'last', b'month', b'.', b'symptoms', b'of',\n","       b'hepatitis', b'a', b'include', b'fever', b',', b'tiredness', b',',\n","       b'loss', b'of', b'appetite', b',', b'nausea', b'and', b'abdominal',\n","       b'discomfort', b'.', b'fargo', b'catholic', b'diocese', b'in',\n","       b'north', b'dakota', b'(', b'pictured', b')', b'is', b'where',\n","       b'the', b'bishop', b'is', b'located', b'.'], dtype=object)>"]},"metadata":{},"execution_count":42}],"source":["words = tf.strings.split(example_article_string, sep=' ')\n","\n","words"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1687342494794,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"rY_8pNLZkr3k","outputId":"a73784d1-2d08-4d1d-d2b2-a3a14854eada"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(398,), dtype=string, numpy=\n","array([b'by', b'.', b'associated', b'press', b'.', b'published', b':',\n","       b'.', b'14:11', b'est', b',', b'25', b'october', b'2013', b'.',\n","       b'|', b'.', b'updated', b':', b'.', b'15:36', b'est', b',', b'25',\n","       b'october', b'2013', b'.', b'the', b'bishop', b'of', b'the',\n","       b'fargo', b'catholic', b'diocese', b'in', b'north', b'dakota',\n","       b'has', b'exposed', b'potentially', b'hundreds', b'of', b'church',\n","       b'members', b'in', b'fargo', b',', b'grand', b'forks', b'and',\n","       b'jamestown', b'to', b'the', b'hepatitis', b'a', b'virus', b'in',\n","       b'late', b'september', b'and', b'early', b'october', b'.', b'the',\n","       b'state', b'health', b'department', b'has', b'issued', b'an',\n","       b'advisory', b'of', b'exposure', b'for', b'anyone', b'who',\n","       b'attended', b'five', b'churches', b'and', b'took', b'communion',\n","       b'.', b'bishop', b'john', b'folda', b'(', b'pictured', b')', b'of',\n","       b'the', b'fargo', b'catholic', b'diocese', b'in', b'north',\n","       b'dakota', b'has', b'exposed', b'potentially', b'hundreds', b'of',\n","       b'church', b'members', b'in', b'fargo', b',', b'grand', b'forks',\n","       b'and', b'jamestown', b'to', b'the', b'hepatitis', b'a', b'.',\n","       b'state', b'immunization', b'program', b'manager', b'molly',\n","       b'howell', b'says', b'the', b'risk', b'is', b'low', b',', b'but',\n","       b'officials', b'feel', b'it', b\"'s\", b'important', b'to', b'alert',\n","       b'people', b'to', b'the', b'possible', b'exposure', b'.', b'the',\n","       b'diocese', b'announced', b'on', b'monday', b'that', b'bishop',\n","       b'john', b'folda', b'is', b'taking', b'time', b'off', b'after',\n","       b'being', b'diagnosed', b'with', b'hepatitis', b'a', b'.', b'the',\n","       b'diocese', b'says', b'he', b'contracted', b'the', b'infection',\n","       b'through', b'contaminated', b'food', b'while', b'attending', b'a',\n","       b'conference', b'for', b'newly', b'ordained', b'bishops', b'in',\n","       b'italy', b'last', b'month', b'.', b'symptoms', b'of',\n","       b'hepatitis', b'a', b'include', b'fever', b',', b'tiredness', b',',\n","       b'loss', b'of', b'appetite', b',', b'nausea', b'and', b'abdominal',\n","       b'discomfort', b'.', b'fargo', b'catholic', b'diocese', b'in',\n","       b'north', b'dakota', b'(', b'pictured', b')', b'is', b'where',\n","       b'the', b'bishop', b'is', b'located', b'.', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b''], dtype=object)>"]},"metadata":{},"execution_count":43}],"source":["if words.shape[0] > max_article_tokens-2:\n","  words = tf.slice(words, [0], [max_article_tokens-2])\n","else:\n","  paddings = [[0, (max_article_tokens - 2) - tf.shape(words)[0]]]\n","  words = tf.pad(words, paddings, constant_values='')\n","\n","words"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"ZWjCUhJfwTIA","executionInfo":{"status":"ok","timestamp":1687342495721,"user_tz":-330,"elapsed":933,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["word2id = tf.keras.layers.StringLookup(mask_token='',\n","                                      oov_token=\"[UNK]\",\n","                                      vocabulary=summary_processor.get_vocabulary())"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"ftZGDs7vpGkI","executionInfo":{"status":"ok","timestamp":1687342495722,"user_tz":-330,"elapsed":16,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["tokens = word2id(words)"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1687342495722,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"zqLFCW8fpVAA","outputId":"57560a3e-d350-4a75-85bb-9e51406552e4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(398,), dtype=int64, numpy=\n","array([   28,     4,  1579,   673,     4,   263,    23,     4, 48259,\n","         179,     6,   712,   519,   202,     4,   393,     4,   331,\n","          23,     4,     1,   179,     6,   712,   519,   202,     4,\n","           5,  4273,    10,     5, 15991,  3060, 14346,    11,   294,\n","        6146,    32,  2727,  2367,   919,    10,   833,   342,    11,\n","       15991,     6,  1028, 28440,     9, 36041,     7,     5, 13753,\n","           8,  2080,    11,   554,   491,     9,   365,   519,     4,\n","           5,   164,   259,   409,    32,  1250,    41,  7558,    10,\n","        4374,    13,   713,    44,  1634,   218,  6880,     9,   195,\n","       21741,     4,  4273,   364,     1,    54,   205,    53,    10,\n","           5, 15991,  3060, 14346,    11,   294,  6146,    32,  2727,\n","        2367,   919,    10,   833,   342,    11, 15991,     6,  1028,\n","       28440,     9, 36041,     7,     5, 13753,     8,     4,   164,\n","       32830,   913,   544,  9407, 14201,   106,     5,   655,    17,\n","        1103,     6,    36,   287,   468,    19,    16,   581,     7,\n","        3292,    68,     7,     5,   589,  4374,     4,     5, 14346,\n","         662,    15,   306,    14,  4273,   364,     1,    17,   345,\n","          82,   129,    46,   101,  1781,    20, 13753,     8,     4,\n","           5, 14346,   106,    18,  6119,     5,  2678,   144,  6719,\n","         424,   108,  3245,     8,   987,    13,  4175, 26887, 10070,\n","          11,  1296,    77,   248,     4,  2075,    10, 13753,     8,\n","         729,  5213,     6, 19081,     6,  1017,    10,  8441,     6,\n","       11991,     9, 11408, 11853,     4, 15991,  3060, 14346,    11,\n","         294,  6146,    54,   205,    53,    17,   111,     5,  4273,\n","          17,  2283,     4,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0])>"]},"metadata":{},"execution_count":46}],"source":["tokens"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1687342495723,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"IBY4Uukpp9dl","outputId":"d4a86d02-8532-4e85-e6cb-7a980ee9a021"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(398,), dtype=string, numpy=\n","array([b'by', b'.', b'associated', b'press', b'.', b'published', b':',\n","       b'.', b'14:11', b'est', b',', b'25', b'october', b'2013', b'.',\n","       b'|', b'.', b'updated', b':', b'.', b'15:36', b'est', b',', b'25',\n","       b'october', b'2013', b'.', b'the', b'bishop', b'of', b'the',\n","       b'fargo', b'catholic', b'diocese', b'in', b'north', b'dakota',\n","       b'has', b'exposed', b'potentially', b'hundreds', b'of', b'church',\n","       b'members', b'in', b'fargo', b',', b'grand', b'forks', b'and',\n","       b'jamestown', b'to', b'the', b'hepatitis', b'a', b'virus', b'in',\n","       b'late', b'september', b'and', b'early', b'october', b'.', b'the',\n","       b'state', b'health', b'department', b'has', b'issued', b'an',\n","       b'advisory', b'of', b'exposure', b'for', b'anyone', b'who',\n","       b'attended', b'five', b'churches', b'and', b'took', b'communion',\n","       b'.', b'bishop', b'john', b'folda', b'(', b'pictured', b')', b'of',\n","       b'the', b'fargo', b'catholic', b'diocese', b'in', b'north',\n","       b'dakota', b'has', b'exposed', b'potentially', b'hundreds', b'of',\n","       b'church', b'members', b'in', b'fargo', b',', b'grand', b'forks',\n","       b'and', b'jamestown', b'to', b'the', b'hepatitis', b'a', b'.',\n","       b'state', b'immunization', b'program', b'manager', b'molly',\n","       b'howell', b'says', b'the', b'risk', b'is', b'low', b',', b'but',\n","       b'officials', b'feel', b'it', b\"'s\", b'important', b'to', b'alert',\n","       b'people', b'to', b'the', b'possible', b'exposure', b'.', b'the',\n","       b'diocese', b'announced', b'on', b'monday', b'that', b'bishop',\n","       b'john', b'folda', b'is', b'taking', b'time', b'off', b'after',\n","       b'being', b'diagnosed', b'with', b'hepatitis', b'a', b'.', b'the',\n","       b'diocese', b'says', b'he', b'contracted', b'the', b'infection',\n","       b'through', b'contaminated', b'food', b'while', b'attending', b'a',\n","       b'conference', b'for', b'newly', b'ordained', b'bishops', b'in',\n","       b'italy', b'last', b'month', b'.', b'symptoms', b'of',\n","       b'hepatitis', b'a', b'include', b'fever', b',', b'tiredness', b',',\n","       b'loss', b'of', b'appetite', b',', b'nausea', b'and', b'abdominal',\n","       b'discomfort', b'.', b'fargo', b'catholic', b'diocese', b'in',\n","       b'north', b'dakota', b'(', b'pictured', b')', b'is', b'where',\n","       b'the', b'bishop', b'is', b'located', b'.', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b''], dtype=object)>"]},"metadata":{},"execution_count":47}],"source":["words"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1687342495723,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"2LQac9ppp6mi","outputId":"68058a59-34e8-497d-d645-c25918c0660d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(398,), dtype=bool, numpy=\n","array([False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False,  True, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False,  True, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False,  True, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False])>"]},"metadata":{},"execution_count":48}],"source":["tokens == 1"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1687342495724,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"8ffCspm-TShq","outputId":"d762e92d-6fb5-41d4-80be-d96e77475b75"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'15:36', b'folda', b'folda'], dtype=object)>"]},"metadata":{},"execution_count":49}],"source":["oovs = tf.boolean_mask(words, tf.equal(tokens, 1))\n","\n","oovs"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1687342495724,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"bDhA7UW1QDfV","outputId":"aa3ce395-adf4-49f7-b641-4b13f0429f46"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'15:36', b'folda'], dtype=object)>"]},"metadata":{},"execution_count":50}],"source":["tf.unique(oovs).y"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1687342495724,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"kELMY1OsxoMu","outputId":"b537bf50-15e0-473d-ae79-ac1d4d32f495"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":51}],"source":["oovs = tf.unique_with_counts(oovs).y\n","oovs_count = tf.unique_with_counts(oovs).y.shape[0]\n","\n","oovs_count"]},{"cell_type":"markdown","metadata":{"id":"Iad-kg5uJz7T"},"source":["#### Mapping article OOV words to indices and vice versa"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1687342501028,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"vrfYEQTGp_Nk","outputId":"86527cd8-4ba8-4fc2-93be-a7eec4b1541a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 1], dtype=int32)>"]},"metadata":{},"execution_count":52}],"source":["tf.range(oovs_count, dtype=tf.int32)"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1687342503385,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"zz6jBNR50doY","outputId":"33cdd168-e705-4d21-f0a3-ac6c4cefd846"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["50002"]},"metadata":{},"execution_count":53}],"source":["vocab_size = summary_processor.vocabulary_size()\n","\n","vocab_size"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1687342505554,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"gAOgJAV40nov","outputId":"7b1272c0-8477-4c88-cac0-86b959e2e8d0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=int32, numpy=50002>"]},"metadata":{},"execution_count":54}],"source":["vocab_size = tf.constant(vocab_size)\n","\n","vocab_size"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1687342507041,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"dqSAu1-s0sLc","outputId":"5ef6b923-542f-4d60-917f-832fb429f605"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2,), dtype=int32, numpy=array([50002, 50003], dtype=int32)>"]},"metadata":{},"execution_count":55}],"source":["values = tf.add(tf.range(oovs_count, dtype=tf.int32), vocab_size)\n","\n","values"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1687342509323,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"BQx_93niqDo3","outputId":"34e33023-a028-426f-80d2-c3f93e8e8567"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'15:36', b'folda'], dtype=object)>"]},"metadata":{},"execution_count":56}],"source":["keys = oovs\n","\n","keys"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gr0-feMyqPOl"},"outputs":[],"source":["init = tf.lookup.KeyValueTensorInitializer(keys, values)\n","oov_w2i = tf.lookup.StaticHashTable(init, default_value=1)\n","oov_w2i.lookup(tf.constant(b'folda'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":483,"status":"ok","timestamp":1686988324510,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"ciLkHobRVk3F","outputId":"05591778-cc94-4e4d-cf43-958d003bcc69"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(), dtype=string, numpy=b'folda'>"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["init = tf.lookup.KeyValueTensorInitializer(values, keys)\n","oov_i2w = tf.lookup.StaticHashTable(init, default_value='[UNK]')\n","oov_i2w.lookup(tf.constant(50003))"]},{"cell_type":"code","source":["oov_start_idx = vocab_size\n","\n","oov_words = oovs\n","oov_ids = tf.add(tf.range(oovs_count, dtype=tf.int32), vocab_size)\n","\n","init = tf.lookup.KeyValueTensorInitializer(oov_words, oov_ids)\n","oov_word2id = tf.lookup.StaticHashTable(init, default_value=1)\n","\n","init = tf.lookup.KeyValueTensorInitializer(oov_ids, oov_words)\n","oov_id2word = tf.lookup.StaticHashTable(init, default_value='[UNK]')"],"metadata":{"id":"MV45WCt-c2Ju"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["oov_word2id.lookup(tf.constant(b'folda'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tSneJculdKHH","executionInfo":{"status":"ok","timestamp":1687090944980,"user_tz":-330,"elapsed":5,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}},"outputId":"a0087779-fb06-47e9-cbdc-8e349df86fa4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=int32, numpy=50003>"]},"metadata":{},"execution_count":69}]},{"cell_type":"markdown","metadata":{"id":"Erk64K_RKr2Q"},"source":["#### Extend encoder vocab by updating UNK tokens with new OOV ids"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":669,"status":"ok","timestamp":1686993516460,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"BKwvPn2GzmQ4","outputId":"ca43fc3b-d79e-4b48-d1b5-5be6824ac383"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(219,), dtype=int64, numpy=\n","array([   28,     4,  1579,   673,     4,   263,    23,     4, 48259,\n","         179,     6,   712,   519,   202,     4,   393,     4,   331,\n","          23,     4,     1,   179,     6,   712,   519,   202,     4,\n","           5,  4273,    10,     5, 15991,  3060, 14346,    11,   294,\n","        6146,    32,  2727,  2367,   919,    10,   833,   342,    11,\n","       15991,     6,  1028, 28440,     9, 36041,     7,     5, 13753,\n","           8,  2080,    11,   554,   491,     9,   365,   519,     4,\n","           5,   164,   259,   409,    32,  1250,    41,  7558,    10,\n","        4374,    13,   713,    44,  1634,   218,  6880,     9,   195,\n","       21741,     4,  4273,   364,     1,    54,   205,    53,    10,\n","           5, 15991,  3060, 14346,    11,   294,  6146,    32,  2727,\n","        2367,   919,    10,   833,   342,    11, 15991,     6,  1028,\n","       28440,     9, 36041,     7,     5, 13753,     8,     4,   164,\n","       32830,   913,   544,  9407, 14201,   106,     5,   655,    17,\n","        1103,     6,    36,   287,   468,    19,    16,   581,     7,\n","        3292,    68,     7,     5,   589,  4374,     4,     5, 14346,\n","         662,    15,   306,    14,  4273,   364,     1,    17,   345,\n","          82,   129,    46,   101,  1781,    20, 13753,     8,     4,\n","           5, 14346,   106,    18,  6119,     5,  2678,   144,  6719,\n","         424,   108,  3245,     8,   987,    13,  4175, 26887, 10070,\n","          11,  1296,    77,   248,     4,  2075,    10, 13753,     8,\n","         729,  5213,     6, 19081,     6,  1017,    10,  8441,     6,\n","       11991,     9, 11408, 11853,     4, 15991,  3060, 14346,    11,\n","         294,  6146,    54,   205,    53,    17,   111,     5,  4273,\n","          17,  2283,     4])>"]},"execution_count":109,"metadata":{},"output_type":"execute_result"}],"source":["words = tf.strings.split(example_article_string, sep=' ')\n","word2id(words)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1686993517244,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"8RMLhrziXA-5","outputId":"e4e3fd8a-fdf3-4d98-a749-0afdd36b31de"},"outputs":[{"data":{"text/plain":["array([[b'by', b'.', b'associated', b'press', b'.', b'published', b':',\n","        b'.', b'14:11', b'est', b',', b'25', b'october', b'2013', b'.',\n","        b'|', b'.', b'updated', b':', b'.', b'15:36', b'est', b',',\n","        b'25', b'october', b'2013', b'.', b'the', b'bishop', b'of',\n","        b'the', b'fargo', b'catholic', b'diocese', b'in', b'north',\n","        b'dakota', b'has', b'exposed', b'potentially', b'hundreds',\n","        b'of', b'church', b'members', b'in', b'fargo', b',', b'grand',\n","        b'forks', b'and', b'jamestown', b'to', b'the', b'hepatitis',\n","        b'a', b'virus', b'in', b'late', b'september', b'and', b'early',\n","        b'october', b'.', b'the', b'state', b'health', b'department',\n","        b'has', b'issued', b'an', b'advisory', b'of', b'exposure',\n","        b'for', b'anyone', b'who', b'attended', b'five', b'churches',\n","        b'and', b'took', b'communion', b'.', b'bishop', b'john',\n","        b'folda', b'(', b'pictured', b')', b'of', b'the', b'fargo',\n","        b'catholic', b'diocese', b'in', b'north', b'dakota', b'has',\n","        b'exposed', b'potentially', b'hundreds', b'of', b'church',\n","        b'members', b'in', b'fargo', b',', b'grand', b'forks', b'and',\n","        b'jamestown', b'to', b'the', b'hepatitis', b'a', b'.', b'state',\n","        b'immunization', b'program', b'manager', b'molly', b'howell',\n","        b'says', b'the', b'risk', b'is', b'low', b',', b'but',\n","        b'officials', b'feel', b'it', b\"'s\", b'important', b'to',\n","        b'alert', b'people', b'to', b'the', b'possible', b'exposure',\n","        b'.', b'the', b'diocese', b'announced', b'on', b'monday',\n","        b'that', b'bishop', b'john', b'folda', b'is', b'taking', b'time',\n","        b'off', b'after', b'being', b'diagnosed', b'with', b'hepatitis',\n","        b'a', b'.', b'the', b'diocese', b'says', b'he', b'contracted',\n","        b'the', b'infection', b'through', b'contaminated', b'food',\n","        b'while', b'attending', b'a', b'conference', b'for', b'newly',\n","        b'ordained', b'bishops', b'in', b'italy', b'last', b'month',\n","        b'.', b'symptoms', b'of', b'hepatitis', b'a', b'include',\n","        b'fever', b',', b'tiredness', b',', b'loss', b'of', b'appetite',\n","        b',', b'nausea', b'and', b'abdominal', b'discomfort', b'.',\n","        b'fargo', b'catholic', b'diocese', b'in', b'north', b'dakota',\n","        b'(', b'pictured', b')', b'is', b'where', b'the', b'bishop',\n","        b'is', b'located', b'.', '', '', '', '', '', '', '', '', '', '',\n","        '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","        '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","        '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","        '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","        '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","        '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","        '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","        '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","        '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","        '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","        '', '', '', '', '', '', '', '', '']], dtype=object)"]},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["words = tf.keras.utils.pad_sequences([words],\n","                                     maxlen=max_article_tokens-2,\n","                                     padding=\"post\",\n","                                     truncating=\"post\",\n","                                     dtype=object,\n","                                     value='')\n","\n","words"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686993517244,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"n5yNk3xY0rR6","outputId":"7ab146bf-e67f-41d2-8df7-600a1cf71302"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 2), dtype=int64, numpy=\n","array([[  0,  20],\n","       [  0,  85],\n","       [  0, 150]])>"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["tf.where(word2id(words)==1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686993517755,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"m4FDpKnOZA34","outputId":"321d1a06-3108-4f92-bd3f-ae6a2c1f4613"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(398,), dtype=string, numpy=\n","array([b'by', b'.', b'associated', b'press', b'.', b'published', b':',\n","       b'.', b'14:11', b'est', b',', b'25', b'october', b'2013', b'.',\n","       b'|', b'.', b'updated', b':', b'.', b'15:36', b'est', b',', b'25',\n","       b'october', b'2013', b'.', b'the', b'bishop', b'of', b'the',\n","       b'fargo', b'catholic', b'diocese', b'in', b'north', b'dakota',\n","       b'has', b'exposed', b'potentially', b'hundreds', b'of', b'church',\n","       b'members', b'in', b'fargo', b',', b'grand', b'forks', b'and',\n","       b'jamestown', b'to', b'the', b'hepatitis', b'a', b'virus', b'in',\n","       b'late', b'september', b'and', b'early', b'october', b'.', b'the',\n","       b'state', b'health', b'department', b'has', b'issued', b'an',\n","       b'advisory', b'of', b'exposure', b'for', b'anyone', b'who',\n","       b'attended', b'five', b'churches', b'and', b'took', b'communion',\n","       b'.', b'bishop', b'john', b'folda', b'(', b'pictured', b')', b'of',\n","       b'the', b'fargo', b'catholic', b'diocese', b'in', b'north',\n","       b'dakota', b'has', b'exposed', b'potentially', b'hundreds', b'of',\n","       b'church', b'members', b'in', b'fargo', b',', b'grand', b'forks',\n","       b'and', b'jamestown', b'to', b'the', b'hepatitis', b'a', b'.',\n","       b'state', b'immunization', b'program', b'manager', b'molly',\n","       b'howell', b'says', b'the', b'risk', b'is', b'low', b',', b'but',\n","       b'officials', b'feel', b'it', b\"'s\", b'important', b'to', b'alert',\n","       b'people', b'to', b'the', b'possible', b'exposure', b'.', b'the',\n","       b'diocese', b'announced', b'on', b'monday', b'that', b'bishop',\n","       b'john', b'folda', b'is', b'taking', b'time', b'off', b'after',\n","       b'being', b'diagnosed', b'with', b'hepatitis', b'a', b'.', b'the',\n","       b'diocese', b'says', b'he', b'contracted', b'the', b'infection',\n","       b'through', b'contaminated', b'food', b'while', b'attending', b'a',\n","       b'conference', b'for', b'newly', b'ordained', b'bishops', b'in',\n","       b'italy', b'last', b'month', b'.', b'symptoms', b'of',\n","       b'hepatitis', b'a', b'include', b'fever', b',', b'tiredness', b',',\n","       b'loss', b'of', b'appetite', b',', b'nausea', b'and', b'abdominal',\n","       b'discomfort', b'.', b'fargo', b'catholic', b'diocese', b'in',\n","       b'north', b'dakota', b'(', b'pictured', b')', b'is', b'where',\n","       b'the', b'bishop', b'is', b'located', b'.', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b''], dtype=object)>"]},"execution_count":112,"metadata":{},"output_type":"execute_result"}],"source":["words = tf.reshape(words, [-1])\n","words"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686993523206,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"vFUlv9QL1NaE","outputId":"3307ee67-6762-4862-910f-00701ad6be43"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 1), dtype=int64, numpy=\n","array([[ 20],\n","       [ 85],\n","       [150]])>"]},"execution_count":113,"metadata":{},"output_type":"execute_result"}],"source":["unk_ids = tf.where(word2id(words)==1)\n","unk_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":444,"status":"ok","timestamp":1686993546215,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"-BT9hP_K21zm","outputId":"0012f321-8544-470e-d452-01084a2010ad"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'15:36', b'folda', b'folda'], dtype=object)>"]},"execution_count":116,"metadata":{},"output_type":"execute_result"}],"source":["unk_words = tf.gather(words, unk_ids[:, 0])\n","unk_words"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":526,"status":"ok","timestamp":1686993561182,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"B9BHxW2r9mkj","outputId":"6b9d4727-87fd-4ff3-f9f3-a99758786ca7"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3,), dtype=int32, numpy=array([50002, 50003, 50003], dtype=int32)>"]},"execution_count":117,"metadata":{},"output_type":"execute_result"}],"source":["unk_tokens = oov_w2i.lookup(unk_words)\n","unk_tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686993561979,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"thVCEXuTBv2A","outputId":"d28dee34-652c-4e1f-938a-4346362d8041"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(398,), dtype=int64, numpy=\n","array([   28,     4,  1579,   673,     4,   263,    23,     4, 48259,\n","         179,     6,   712,   519,   202,     4,   393,     4,   331,\n","          23,     4,     1,   179,     6,   712,   519,   202,     4,\n","           5,  4273,    10,     5, 15991,  3060, 14346,    11,   294,\n","        6146,    32,  2727,  2367,   919,    10,   833,   342,    11,\n","       15991,     6,  1028, 28440,     9, 36041,     7,     5, 13753,\n","           8,  2080,    11,   554,   491,     9,   365,   519,     4,\n","           5,   164,   259,   409,    32,  1250,    41,  7558,    10,\n","        4374,    13,   713,    44,  1634,   218,  6880,     9,   195,\n","       21741,     4,  4273,   364,     1,    54,   205,    53,    10,\n","           5, 15991,  3060, 14346,    11,   294,  6146,    32,  2727,\n","        2367,   919,    10,   833,   342,    11, 15991,     6,  1028,\n","       28440,     9, 36041,     7,     5, 13753,     8,     4,   164,\n","       32830,   913,   544,  9407, 14201,   106,     5,   655,    17,\n","        1103,     6,    36,   287,   468,    19,    16,   581,     7,\n","        3292,    68,     7,     5,   589,  4374,     4,     5, 14346,\n","         662,    15,   306,    14,  4273,   364,     1,    17,   345,\n","          82,   129,    46,   101,  1781,    20, 13753,     8,     4,\n","           5, 14346,   106,    18,  6119,     5,  2678,   144,  6719,\n","         424,   108,  3245,     8,   987,    13,  4175, 26887, 10070,\n","          11,  1296,    77,   248,     4,  2075,    10, 13753,     8,\n","         729,  5213,     6, 19081,     6,  1017,    10,  8441,     6,\n","       11991,     9, 11408, 11853,     4, 15991,  3060, 14346,    11,\n","         294,  6146,    54,   205,    53,    17,   111,     5,  4273,\n","          17,  2283,     4,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0])>"]},"execution_count":118,"metadata":{},"output_type":"execute_result"}],"source":["tokens = word2id(words)\n","tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_zcGn_JhcjFJ"},"outputs":[],"source":["unk_tokens = tf.cast(unk_tokens, tf.int64)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686993570133,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"5cKMK7j7oXe3","outputId":"68c816dc-1fb7-4143-bfe0-5948b62e4a85"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 1), dtype=int64, numpy=\n","array([[ 20],\n","       [ 85],\n","       [150]])>"]},"execution_count":120,"metadata":{},"output_type":"execute_result"}],"source":["unk_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":461,"status":"ok","timestamp":1686993575161,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"kRDjiCfgnhV2","outputId":"0a539640-084f-4a2a-bdbc-635863aa8f75"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3,), dtype=int64, numpy=array([50002, 50003, 50003])>"]},"execution_count":121,"metadata":{},"output_type":"execute_result"}],"source":["unk_tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":465,"status":"ok","timestamp":1686993578077,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"oWzzCY8fZ9s6","outputId":"0d70a8f3-c785-4448-d296-100c18ea9fb3"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(398,), dtype=int64, numpy=\n","array([   28,     4,  1579,   673,     4,   263,    23,     4, 48259,\n","         179,     6,   712,   519,   202,     4,   393,     4,   331,\n","          23,     4, 50002,   179,     6,   712,   519,   202,     4,\n","           5,  4273,    10,     5, 15991,  3060, 14346,    11,   294,\n","        6146,    32,  2727,  2367,   919,    10,   833,   342,    11,\n","       15991,     6,  1028, 28440,     9, 36041,     7,     5, 13753,\n","           8,  2080,    11,   554,   491,     9,   365,   519,     4,\n","           5,   164,   259,   409,    32,  1250,    41,  7558,    10,\n","        4374,    13,   713,    44,  1634,   218,  6880,     9,   195,\n","       21741,     4,  4273,   364, 50003,    54,   205,    53,    10,\n","           5, 15991,  3060, 14346,    11,   294,  6146,    32,  2727,\n","        2367,   919,    10,   833,   342,    11, 15991,     6,  1028,\n","       28440,     9, 36041,     7,     5, 13753,     8,     4,   164,\n","       32830,   913,   544,  9407, 14201,   106,     5,   655,    17,\n","        1103,     6,    36,   287,   468,    19,    16,   581,     7,\n","        3292,    68,     7,     5,   589,  4374,     4,     5, 14346,\n","         662,    15,   306,    14,  4273,   364, 50003,    17,   345,\n","          82,   129,    46,   101,  1781,    20, 13753,     8,     4,\n","           5, 14346,   106,    18,  6119,     5,  2678,   144,  6719,\n","         424,   108,  3245,     8,   987,    13,  4175, 26887, 10070,\n","          11,  1296,    77,   248,     4,  2075,    10, 13753,     8,\n","         729,  5213,     6, 19081,     6,  1017,    10,  8441,     6,\n","       11991,     9, 11408, 11853,     4, 15991,  3060, 14346,    11,\n","         294,  6146,    54,   205,    53,    17,   111,     5,  4273,\n","          17,  2283,     4,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0])>"]},"execution_count":122,"metadata":{},"output_type":"execute_result"}],"source":["oov_extended_encoder_in = tf.tensor_scatter_nd_update(tokens, unk_ids, unk_tokens)\n","oov_extended_encoder_in"]},{"cell_type":"markdown","metadata":{"id":"RZwn6wTmJIvP"},"source":["#### Finding the final distributions combining p_gen part and 1-p_gen part"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1686590799011,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"dclx3bKuSgXt","outputId":"f5a6dd29-536c-45b2-f8d5-ee14ff7bcc8b"},"outputs":[{"data":{"text/plain":["TensorShape([16, 17])"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["batch_size = example_tokens.shape[0]\n","extended_zeros = tf.zeros((batch_size, max_art_oov))\n","\n","extended_zeros.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g5B59BVgUr4l"},"outputs":[],"source":["# Dummy output value from the decoder which can be thought of Pvocab\n","P_vocab = tf.random.normal([batch_size, vocab_size])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1686590799012,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"RbnsxdGFToGM","outputId":"88f7f6f5-184f-4b24-9c71-a656b634e6ae"},"outputs":[{"data":{"text/plain":["TensorShape([16, 50019])"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["extended_vocab = tf.concat([P_vocab, extended_zeros], axis=1)\n","\n","extended_vocab.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1686590799012,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"UNqNc60aVe-N","outputId":"b6209900-ae55-443b-b6fb-32230342a528"},"outputs":[{"data":{"text/plain":["TensorShape([16, 400])"]},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["dummy_attention = tf.random.normal([batch_size, max_article_tokens])\n","\n","dummy_attention.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1686590799012,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"nO7IMJueW6Pg","outputId":"798ad86d-4129-468c-84ee-116d15553987"},"outputs":[{"data":{"text/plain":["TensorShape([16, 1])"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["dummy_p_gen = tf.random.normal([batch_size, 1])\n","\n","dummy_p_gen.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1686590799012,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"WaQ8qtDMgYCE","outputId":"b6beb54a-0fff-4c0c-fb30-c012d0cbbab4"},"outputs":[{"data":{"text/plain":["TensorShape([16, 50019])"]},"execution_count":97,"metadata":{},"output_type":"execute_result"}],"source":["generate_word_prob = dummy_p_gen * extended_vocab\n","\n","generate_word_prob.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1686590799012,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"Gj4mhpqOltjx","outputId":"787ac45a-9eb6-4fdf-a182-329ca5a62e5d"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(50019,), dtype=float32, numpy=\n","array([-0.19701234,  0.49117807,  1.9465048 , ...,  0.        ,\n","        0.        ,  0.        ], dtype=float32)>"]},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["extended_vocab[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1686590799012,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"s6h_UU7MtTMS","outputId":"693e066d-dd4e-4d5d-daf4-007aa8b37dc0"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 16, 400], dtype=int32)>"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["tf.shape(enc_extended_vocab)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":847,"status":"ok","timestamp":1686590799855,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"rdQG7QBSyM4X","outputId":"7ad37264-d355-4ef0-e9e6-f896e9f67c24"},"outputs":[{"data":{"text/plain":["[(0,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2,    28,     4,  8504,  4611,     4,     8,  1529,    32,\n","           379,     5,   113, 11606, 50002,    11,   416,   349,    25,\n","            56,    10,   113,    74,  3150,  3750,     7,   150,   383,\n","            10,     5,   967,    31,    67,  2176,   619, 14913,     4,\n","           748,  6002,     6,   835,     6,    32,    48,  2308,    24,\n","          1663,    25,  1773, 20137, 50003,     9, 50004,   140,   491,\n","             4,    26,   191,    10,    24,  7056,   601,  2329,    25,\n","             5,  2310,     9, 50005, 10791,    11, 50006,     6,  4135,\n","             6,    18,    32,    98,  2008,    41,  2139,  4616,  7500,\n","            13,     8,   717,   692,    29,     5,  3818,    10,     5,\n","         50007,   276,    10, 50003,     4,  2350,    23,   748,  6002,\n","            54,   114,    53,    32,   379,    41, 11606, 50002,    25,\n","            56,    10,   113,    74,  3150,  3750,     7,   150,   383,\n","            10,     5,   967,    16,  2176,   619, 14913,     4,    18,\n","            32,    48,  2308,     5,  1663,    25,  1773, 20137, 50003,\n","             4,     5,  4238,     6,    44,    70,  2197, 50008,    25,\n","          7882,   921,     6,    32,  3764,     5,   378,   823,    25,\n","             5,   472,    66,    57,    12,  3149,    11,  7509,    36,\n","            72,    34,  8456,   110,   144,     5,   115,    26,   368,\n","            26, 50009,     4,  4037, 20137,     6,  3203,     6,    44,\n","            32,    98,   223,    85,     5,   472,    29,    24, 19987,\n","           262,  1773,    22,   748,    31,    67,  1651,    12,   524,\n","            26,     8,   157,   775,   530,  1174,   517,     4,   615,\n","          1553,     7,    30,     8,   290,   824,    60,    62,    75,\n","            79,     5,  3978,  3262,    44,  2375,  1474,   513,    81,\n","            27, 10444,    75,    41, 50010,  1620,    10, 24414,    13,\n","             8, 17926,  3913,  7159,     9,    18, 20567,    90,    82,\n","            15,     5, 50011,     6,    21,    22,    99, 20137,     4,\n","           232,   200,   540,    27,    43,  7882,   921,  4463,   130,\n","             7,  1215,     8, 50012,   228,    66,    19,  1125,    18,\n","            43,    84,    95,    18,   336,    43,     8,   225,     4,\n","           349,    13, 10675,    23,   748,  6002,  1174,   835,    32,\n","             8,  2079,   469,    66,    18,    17,     5,   113, 50002,\n","         11606,    11,     5,   171,   349,    13,     5,   967,     4,\n","            21,    27,   104,    14,  4053,     4,    91,    58,   199,\n","           318,   168,    13,    19,     4,    51,   808,  2705,     9,\n","            18, 15373,    19,    80,   132,     4,    21,    27,   104,\n","            24,  7836,     6,     5,   151,    18,   112,    19,    73,\n","           450,     6,    42,   476,    24,  2513,     7,    86,    19,\n","            36,    80, 13593,    19,    61,     4,    21,     8, 50002,\n","            17,     8,   433,    44, 11017,    63,  8099,  4616,  5659,\n","             9, 15692,  1843,     4,     5, 17441,   461,  1117,   475,\n","             5, 15030, 50002,     4,     5,  1000,     6,    57,    17,\n","           810,     7,  1705,     5,   619,  4578,    10,  1600,   471,\n","            20,     5, 16210,     3], dtype=int32)>),\n"," (1,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2,    28,     4,   496,   677,   991,     4,     8,   198,\n","            17,   950,    13,    33, 11544,   270,    16,   132,     7,\n","            41,  1057,    46,   209,   177,   287,   532,     7,  5396,\n","            33,   129,    20,     8,  3505,  1654,     7,   421,    75,\n","           214,    29,  3531,     6,    19,    32,    48,   455,   196,\n","             4,  6170,  2876,   801,    33,   270,   329,     6,   983,\n","             6,    44,    17, 25148,     9,    32,  4234,     6,     7,\n","          1964,   177,    11,   663,   273,    18,    17,  1008,    57,\n","            17,    24,   613,   132,     4,   390,  2876,    22,    14,\n","           355,    30,   743,     7,  1387,    33,   270,    16,  1678,\n","          1057,   721,     9,   223,  2326,  1789,     7,   421,    75,\n","            61,    10,   177,     6,   141,  2058,    33,   138, 48334,\n","            77,   153,     4,     5,   132,     7,  1641,    23,   329,\n","         22425,     6,   983,     6,    44,    32,  6175,     9,  4234,\n","             6,    32,    48, 16793,   125,    28,    24, 13290,   177,\n","             6,    24,   198,    32,   447,     4,    39,   558,     5,\n","             4,   608,  1654,    46,    33,   270,    12,   603,   214,\n","            29,     5,    90,   127,    10,     5,     4,   177,    93,\n","            15,   552,   517,     4,   329,    17,   680,   101, 36191,\n","             4,    45,  1080,    41,  1024,    10,   138,  4687,    11,\n","           528,     7,   421,   329,    61,    10,   177,     6,    57,\n","             5,   198,  2414,     4,   390,  2876,    32,    48,  7956,\n","            20, 50002,   148, 12910,   177,   959,     9, 19386,   534,\n","          5612,    10,  1131,   140,    77,    93,    46, 19130,  1081,\n","           518,  2277,    14,    33,   270,    12, 38695,     9,   114,\n","            61,    10,   177,  2241,     4,   390,  2876,    84,  2406,\n","            23,   232,   347,   106,    18,    16,   810,  1013,     7,\n","             4,  1057,     4,    27,    86,    65,   199,    49,   271,\n","             4,    27,   207,     4,   388,    49,   271,     4,    21,\n","             5,   115,   558,    41, 40632,   981,     4,    15,   552,\n","          1191,    57,  1108,   138, 48334,    13,   329,     7,    34,\n","           899,   214,    29,     4,   209,   177,     4,    18,    17,\n","           680,  3794,     7,   168,     7,   177,   273,    24, 14980,\n","             4,  1672,   200,  2262,     4,  6160,     7,  1641,    23,\n","           329,     6,   983,     6,    17, 25148,    36,   338,     7,\n","          5389,    20,   422,   359,    24,  3423,     4,    91,   390,\n","          2876,  9460,     5,   271,     6,    39,   444,  1934,   139,\n","           613,  2277,   125,     5,   177,     6,     5,   981,   272,\n","             4,   390,  2876,    84, 50003,  1272,    23,  1369,    87,\n","          1024,   130,     8,   222,     4,    27,   308,    42,   159,\n","             7,   150,   139,   271,     7,   944,   214,    96,   270,\n","            16,   518,     7,    41,  1057,     4,    21,     5, 11544,\n","           708,    16,  1057,   721,  1348,  2308,   123,     7,  2555,\n","           105,    24,   461,     9,   502,   260, 50004,    18,  1351,\n","           382,     6, 11256,     3], dtype=int32)>),\n"," (2,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2,    28,     4,   496,   677,   991,     4,   263,    23,\n","             4, 41381,   179,     6,   503,   491,   235,     4,   393,\n","             4,   331,    23,     4, 42694,   179,     6,   503,   491,\n","           235,     4,   396,    23, 17146,  4289,  3618,     6,   894,\n","             6,    12,   396,    15,  5037,   515,    10,  1610,  1407,\n","             9,  6638,     7,    33,  4465,   270,  1563,     4,     8,\n","           198,   688,  4465,   270,  1555,  1407,    17,   479,    10,\n","           862,    75,     7,   150,    24,   213,   146,   109,    18,\n","          1064,    11,  3867,  1252,    14,    33,   647,  4509,    64,\n","           592,    33,     7,     8,  2616,  7256,     6,   134,  1349,\n","           164,     4, 17146,  9582,  3618,     6,   894,     6,    10,\n","         50002,     6,  4409,     6,    12,   396,    15,   306,    15,\n","          5037,   515,    10,  1610,  1407,     9,  6638,    11,     5,\n","           187,    10,    33,   270,     6,  1563,     6,    44,   240,\n","            10,    41,  7256,    10,  5507,  3700,     4,   147,     7,\n","             8,  9526,   773,  5509,     6,  3618,   118,    33,   270,\n","             6,  1563,     6, 11309,    15,     8,  7907,    11,    49,\n","           103,    15,   561,   292,    46, 33314,    18,    43,  2102,\n","            33,  5507,  8332,     4,    39,   112,    42,  2180,   510,\n","           192,     4,    18,   240,     5,   200,   127,     6,     9,\n","            24,   187,    12,  1561,     8,  1407,  7628,     7,   242,\n","          1317,    10,  5507,  8628,     4,    39,    32,    42,   463,\n","            48,  5202,   543,    36,    12,   101,   443,   275,  2029,\n","           314,    25,     5,  8008,   534,   924,     4,  1989,     4,\n","            84,    83,    14,  3618,    12,     8, 14677,  8961,     9,\n","            33,   270,  8261,    11,   319,     4, 28152,    21,    29,\n","         12241,    33,    85,    33,  4509,     9,    24,  1252,    14,\n","            39,     4,   403,  7256,     6,     5,  5509,   106,     4,\n","          1563,     4,  3618,  1784,     7,  1194,   450,    11,   435,\n","             6,     5,  5509,   272,     6,    36,     4,  3618,    84,\n","           377,    39,  4290,   510,  1897,     7,   944,    75,    76,\n","             8,     4,   650,   607,   109,    18,  9201,    65,   199,\n","             7,   168,     4,    21,   402,   105,    13,   161,     4,\n","           250,    23,  1563,  3618,     6,   716,     6,   240,    15,\n","            24,   198,    16,  7907,   283,    41,  7256,    10,    33,\n","          5507,  3700,     6,   297,    46,    39,  4632,    75,    62,\n","           345,    33,  5821,     4,  4409,    32,    43,     8,  1610,\n","          1407,   347,    15,     5,  1884,   140,  6959,     6,    36,\n","            19,    32,    48,   176,  4066,     6,    91,    25,    73,\n","             4, 18352,  1343,  2752,     6,    41,  4409,   326,   347,\n","          1164,     6,    22,    39,   668,    65,  4563,   139, 11049,\n","            13,  1610,  1407,    11,    33,    60,    79,   486,    88,\n","            10, 10283,   347,    11,  4409,     4,    26,  1324,     6,\n","             5,   347,  9279,     7,    21,     8,   433,    44,  8829,\n","          2288,   165,   542,     3], dtype=int32)>),\n"," (3,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2,    54,   126,    53,    78,    91,   413,    71,    12,\n","             8,   329,  8191, 31447,  2182,    11,   298,   487,    45,\n","            12,    19,     4,  1230,     6,     5,  9996,   107,     9,\n","           675,   994,   345,    15, 32210,     6,  5086, 50002,    28,\n","             5,   264,    16,  5532,   288,  2478,     6,    56,   225,\n","          1559,   781,     4,   466,    73,    10, 32210,    16,  1297,\n","            38,  5559,   401,    78,   825,    38,  6093,    78,     9,\n","            49,  1021, 21018, 50003,   141,   630,    97,     5,  1712,\n","           453,    23,    35,    51,    38,    42,   244,     7,   360,\n","             4,    37,    46,     8,  1449,  1513,    11,    49,  1110,\n","         21785,   335,   264,   125,  3061,     6, 50003,  2039,    49,\n","          1796,    43,   221,  1251,    78,  3114,   109,    40,   118,\n","             5,  2641,    11,     8,  8207,  6016,     4,    71,    12,\n","             7,    34,    92,   620,    45,    82,   968,    26,    40,\n","            47,   224,     7,     5,  8575,    28,  1230,    44,  2121,\n","             8, 49365,   889,     7, 50004,  2137,     8, 10267, 22492,\n","             4,    14,  3920,     5,   964,    11,     5,   566,    10,\n","             5,  1339,    14, 14033,     5,   994,    10,   278,  2478,\n","         17445,   125,   278,   100,     9,  2504,    26,     8, 21942,\n","             7,   200,    93,    16,   107,   335,    11,  1221,     4,\n","            36, 32210,    16,  1297,    47, 14057,     8,  1514, 13346,\n","            29,     5, 50005,  1430,     6,    44,  2708,    95,  1265,\n","             5,   573,     4,    97,     5,   264,    71,    12,     8,\n","          1449,    83,  2285,   348,     5,   642,    11,  3032,    11,\n","          1005,     7,     5,  2340,  1708,    11,  1221,     4,    35,\n","         32210,   217,    41,  1279,    11,  1283,    10,  1777,   370,\n","             9,   227,   626,  5774,    40,    43,     5,  1247,     6,\n","            37,  1230,  1021, 14379,  4254, 15716,    22,     4,    35,\n","            51,   112,    65,  2003,    60,   995,   109,    40,   112,\n","            65,   590,   167,     4,    45,   264,    32,    65,  2229,\n","           487,    11,   139,   151,     4,    11,   102,  1521,    19,\n","            16,   120,    19,   141,  3574,     4,    37,    46,  6221,\n","            85, 50006,     7,    49,  3300,  2354,     7, 26228,     6,\n","         32210,  4497, 27576,    13,   470,    79,   218,   440,    26,\n","           661,  1163,  4664,  5674,  1050,  2656, 28782, 19030,    25,\n","            24,   343,   682,     7,   224,     5,    35,  1551, 49434,\n","            37,   606,     4,   139, 32210, 17967,    76,  1230,    16,\n","           446,    12, 17501,    28,     5,  1430,    36,  4254, 15716,\n","            16,   293,   705,  1396,    74,   995,    11,     5,   702,\n","            10,    74,   440,    26,   329,  5003,     9,  5674,   118,\n","             5,  2641,     4,   329,  2142,  3678,     8,   620,  1065,\n","           293,    10,     5,   929,    97,  5674,  5363,    24,  7588,\n","            80,    97,     5,  1105,   617,    78,   374,    75,     5,\n","            90,   604,     7,    86,    19,  1258,    11,     5,  1712,\n","           283,    24,   117,     3], dtype=int32)>),\n"," (4,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2,    28,     4, 16556, 16456,     4,     8,  4695,   330,\n","            32,  1523,     8, 12237,   187,  1982,   125,     8,   782,\n","         24653,   640,    40,    43,   176,     7,  5853,     8,  7317,\n","           479,    10,   799,    49,  5591,   316,     4,     8,  1982,\n","          1523,    28,  5364,     9, 50002, 50003,    11, 50004,   534,\n","          4222,   134,  1599,   193,     5,   276,     6, 50005,     6,\n","             9,  7317,  1840, 50006,    26,  4538,     4, 50006,     6,\n","          1861,     6,    17,  1227,    11,  1737,   534,     6,  3434,\n","             6,   111,    39,    17,   543,    20,  5575,   489,    11,\n","             5,   235,   187,    10, 45703, 33976, 50003,     4, 24653,\n","            23,  7317,  1840, 50006,     6,  1861,    54,   114,    53,\n","             6,    32,    48,   737,    11,     8, 12237,   187,  1982,\n","           108,  5008,   535,    15,     8,  5575,   489,   819,    11,\n","             5,   235,  2331,   187,    10, 45703, 33976, 50003,    54,\n","           132,    53,  4316,    10,  2343,    23,     5,   334,    21,\n","          1982,  5943,    14, 50005,   743,     7,  2030,    14, 50006,\n","            43,     8,   595,     6,   180,    74, 28232,    13,  6964,\n","           862,     9,     8,  3287,   441,     4,     5,   238,  1912,\n","           479,    10,  1610,     8,   281,   947,    14,  3660,    11,\n","             5,   522,    16,   187,    25,    33,   103,    11, 50007,\n","             6,  3434,     4,     5, 50003,  6937, 50005,     6,   774,\n","            61,    10, 24525,     6,  2472,     6,   743,     7,  2030,\n","            14, 50006,    43,     8,   134,   595,     6,   180,    74,\n","         28232,    13,  6964,   862,     9,     8,  3287,   441,    66,\n","           141,   467,    40,   726,    13,     5,  1565,   849,    10,\n","          2441,  1654,   867,    15,     5,   498,     4, 50005,  1250,\n","             8,   325,    11,  1005,     7,     8,  1791,    13,   970,\n","             4,    52,   108,    51,   971,  2660,  7040,    28,   174,\n","          1063,     6,    51,    72,    42,   970,    15,  3093,    10,\n","          2340, 11012,     6,    31,     5,   276,    22,     4,   280,\n","             6,     8,  3610,    10,     5,   516,   472,    32,  4754,\n","             5, 50008,    21,   745,    14,    40,    43,  1228,     8,\n","          2441,  1654,    15, 50006,     6,  1311, 50009,    14,     5,\n","           330,   112,    42,   150,  2405,    10,     5,   351,     4,\n","             5, 12237,   187,  1982,  5943, 50006,    12,  2996,    55,\n","             5,   522,    16,   281,   947,  1670,     4,     5,   289,\n","           711,     8,  4210, 12607,     9, 37802, 41825,     9,   240,\n","           561,  1191,     6,   235,     6,    29,  7465,   585,  4598,\n","             6,   147,     7,    41,  4891,     4,   723,   546,    23,\n","         50006,    12,   412,    46,     5, 21892,   425,    25,    33,\n","           103,    11,     5, 46787,  1936,    10, 44742,  2589,    11,\n","         50007,    15,   561,  1191,     6,   235,     4, 50004,   230,\n","           295,    14,     5,   115,    38,  1758,  8202,  4481,    13,\n","           510,     9,  1899,  4748,     6,  1236,     9,  1270,     6,\n","             9,  1017,    10,     3], dtype=int32)>),\n"," (5,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2,    28,     4,  1033, 17755,     4,     8,  8335,  1735,\n","             9,   602,  3084,    32,    48,   396,    46,   671,   408,\n","             7, 13418,     8,  1129,    76,   990,    33,     8,   531,\n","         17704,   469,     4, 50002, 50003,     6,   894,     6,    43,\n","           336,   726,    13,   539,  2434,  1571,    29,   684, 32787,\n","         50004,    25,    24,  2959,    11, 19234,     6,  6581,     6,\n","            36,   475,  2148,    46,    39,   302,    18,    12, 32529,\n","            33,     4,    39,   671,   453,  9228,     5,  1129,     6,\n","          3237, 18625,     9,   165,   976,    13,   531,     6,    46,\n","          1482,  3526,    18,    43,   176,  5694,   271,  1438,    13,\n","          4589,   637,     7,  1747,    33,   928,     4, 50002, 50003,\n","             6,   894,     6,   671,   532,     7, 13418,    33,  2293,\n","          4384,     6,   684, 32787, 50004,     6,    76,   990,    33,\n","           531,  2434,  7575,     9, 18625,   340,   336,   274,   539,\n","          1571,     4, 50003,    43,   336,  7299,   539,  7253,    25,\n","             5,  2959,     6,    36,    46,  1482,  5495,    20,     5,\n","          1093,    10,     5,   718,   928,     6,   453,   374,  2134,\n","             4, 50003,    70,   555,    14,   684, 50004,    43,   176,\n","           164,   215,  3077,    13,    33,   976,     6,   124,  9749,\n","            33,    13,     5,   700,     4,   133,  8335,  6060,   157,\n","            11,   193,   685,     9,   209,   259,     6,     9,    71,\n","            38,   533,  1090,    14,  6060,   256,   164,  2496,  2433,\n","             9,  2935,     7,  2238,   685,   794,     6,   124,   646,\n","           685,  3368,    13,    49,   256,     4,   463,   681,    10,\n","          3125,    19,     7,    83,     6,    39,  2351,     5,  1129,\n","          2068,     9,  3209,    14,    18,   449,    33,   271,     7,\n","           421,  2717,     9,  1289,    61,   165, 17704,   469,     4,\n","            18,    11,   863,   295,    14,    39,    12,   408,     7,\n","         13418,    75,     7,    83,     9,   377,   217,    59,     8,\n","          7991,   928,    14,  3660,    11,    33,   101,   396,    26,\n","             5,  1292,    12,  1680,    85,     4,  1197, 10670,    75,\n","             7,   142,    14,    39,    12,  5495,    20,    33,    77,\n","         17704,   469,     6,    21,    22,     8,    83,   400,     4,\n","           232,   832,    12,   914,  2803,     6,  1377,    13,   165,\n","          2434, 10005,   469,     9,  1292,     7,  5584,     4,    39,\n","          1784,     7,  2030,    35, 17422,   430,    37,    62,    75,\n","            91,    18,   112,    42,   449,    59,     4,    83,   142,\n","         50003,  1784,     7,  2030,   684, 50004,    12,   359,   271,\n","            13,  4589,   637,     7,  1747,  2293,   976,     4,   684,\n","         50004,  5527,   129,     5,    83,     9,    55, 50003,   603,\n","            59,     7,  3838,     5,  1292,    39,    12,   396,     4,\n","          1197,   447,    14,     5,  2959,    12,   359,  2482,  1438,\n","            13,  3401,   637,    36,    51,    30,    92,   473,    10,\n","            45,     4,  1197,    22,    39,    87,  2014,    24,  3055,\n","            11,    41,  1456,     3], dtype=int32)>),\n"," (6,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2,   161,    32,  1246,    10,     5,   697,     8,  9274,\n","            12,   366,    11,     5, 13457,    20,     8,  2132,   299,\n","            34,     8,  1300,  1385,    25,     8,   235,  2132, 10392,\n","          8910,    28,     5,  1355,     4,  2383, 12627,     6,  1182,\n","             6,    17,  5183,  9274, 16413,     9,  1300,  1385,  1997,\n","          8599,    13,   138,  6137,  2473, 15995,  4481,    46,    18,\n","         41027,    33,    11,     5,   371,    20,     8,  2132,   299,\n","           108,   408,     7,   366,     8,   870,   129,     8, 12000,\n","          1455,   172,     5, 12420,    10,    33, 13457,   116,    41,\n","          5559,  2132,  1712,    11,   663,     4,     5,   943,   385,\n","            11,     8,  4407,    10,     5,  1982,  6379,    28,  1457,\n","            14,    39,   569,    92,  5366,    13,     5,   870,     7,\n","           829,    34,   366,     9,    14,    39,    32,   711,  1236,\n","             6,  5753,     9,  4804,    26,     8,   734,    10,     5,\n","           441,    66,    36,    39,  1162,    11,     5,   161,     7,\n","            30,     8,   404,  1282,    10,  8216,  1029,    46,   101,\n","           366,     4,   402,   105,    13,   161,     4,    42,     5,\n","           257,   840,    23,  6905, 12627,  2386,   105,    20,     5,\n","         12000,  1455,    11,    33,  8343, 12420,    97,     5,   369,\n","            54,   114,    53,     9,    20,     8,  1556, 43950,    15,\n","            33, 13457,    46,     5,  7351,  2978,  5807,    54,   132,\n","            53,   404,   241,    23,  5164, 12627,    54,   132,    53,\n","          4444,   108,    61,    25,     8,  1469, 10392,    20,   315,\n","             4, 12627,    12,  3008,     7,     5,  9274,  2132,  4810,\n","           443,   480,   486,     6,   235,    25,     5,  1066,  3459,\n","             6,   147,     7,     5,  2274,     4,  8599,    17,     8,\n","         13111,    10,     5,  9274,   410,   185,     4,    39, 16332,\n","            20,     8,  1791,   365,    11,     5,   127,     7,  3489,\n","            52,  1925,    15,    33,  3021,    20,    33, 13457,  6521,\n","          2727,    13,     8,  2490,    31,    20,  8599,     6,     5,\n","          1893,    90,   295,    28,  6370,  5943,     4,    52,     8,\n","          2132, 12000,    12,   124,  1455,   172,     5, 12420,    10,\n","            33, 13457,     9,     8,  2132,   870,    12,  8523,    15,\n","           254,    10,     5, 12000,     6,    31,     5,  1893,  1527,\n","             6,     9,     5,   161,   411,     4, 22097,   304,    23,\n","          8599, 23632,   129,     6,    36, 12333,   466,    26,   184,\n","            10, 12627,    26,    18,   239,     5,   870,     4, 12627,\n","            12,   568,     7,   357,    14,     5,     4,  3010,    64,\n","           729,   113,     8, 16470,    10,  8599,  2894,     5,   870,\n","            10,     5, 12000,     4,    13,     8,   683,     6,     9,\n","            42,    75,   829, 11203,     5,  2132,   299,   189,    36,\n","            18,   112,     4,  5807,     5,   299,     6,     9,    18,\n","          1724,  3028,     4,     5,   161,   411,  8599,   586,    59,\n","             5,   369,     9,    90,   373,    19,     6,  1610,   582,\n","             7,   225,    19,     3], dtype=int32)>),\n"," (7,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2,    28,     4,  4456, 24413,     4,   263,    23,     4,\n","         40138,   179,     6,  1161,   570,   202,     4,   393,     4,\n","           331,    23,     4, 45447,   179,     6,  1161,   570,   202,\n","             4,     5,  1718,  1435,    32,  1392,   328,    26,     5,\n","         12655,  1345,    39,  2186,   196,  1015,   475,     8,  1525,\n","            61,     4,     5,  1345,    12,   867,     7,  1113,    29,\n","             5,   242,   436,  2664,    16,   516,   982,    45,   410,\n","             6,    36,   541,    41,  1105,    10,     5,  2199,    10,\n","          2027,  5727,    61,    11,     5, 26343, 11207, 11947,    19,\n","            12,    61,    10,  2491,     4,  7734,  3804, 26814,  2333,\n","             7,  1113,     5, 40649,  1345,    14,  7986,  1718,   141,\n","           467,    39,    16,   680,   277,   212,  1598,     4,   402,\n","           105,    13,   161,     4,   254,  1569,    23,     5,  2199,\n","          2186,    45, 26343, 11207,  1345,    29,     5,   279,  1698,\n","             7,     5,  5525, 26650,   571,  6732,     4,   522,    15,\n","           813,    23,    25,   277,   212,  1598,     6,  1718,    16,\n","           522,  8106,    17,  3728,    36,    39,   239,    65,    30,\n","             7,  1643,  8187,  1862,   463,     4,     5,  2199,  8331,\n","             5,   439,     9,   310,  1345,    20,     8,   439,  7904,\n","          4487,  4213,    26,    39, 10715,     5,  5525, 26650,   571,\n","          6732,    20, 11032,  1185,     9,  1357,     4,  1718,     6,\n","          1543,     6,    32,   249,    48,     8,  1596,    10, 12655,\n","             9,    32,    48,   211,    11,  1862,    29,     5,   279,\n","          1698,    15,  2471,   922,  3545,     4,     5,  1718,  1435,\n","            23,     5, 40649,  1345,   904,    61,    41,  1105,    46,\n","          1718,    12,   211,    11,    19,     4, 15464,   127,    61,\n","            23,     5,  2199,  1666,     5,  1357,  5773,  6732,    20,\n","           399,  1185,     9,   869,  1357,     4,    80,    77,   248,\n","             6,  1718,  2186,     8, 50002,   439,  3248,  1345,    29,\n","             5,   982,    20,     8,   310,  1166,  7205,  9265,    26,\n","            39,  1634,     5,  3239,    10,   289, 23061,   320,    20,\n","            33,   399,     4,     5,  2199,     6,    44,    17,   497,\n","             7,   384,  1112,    11,   561,     6,    12,  1587, 15526,\n","             5, 16115,    10,    56,    10,     5,   982,    16,   208,\n","          7152,    25,     5,  1786,    10,   480,     4,    15,    14,\n","          3311,     6,    39,    12,  9280,     7,     4,    30,  1202,\n","             8,   917,  7764,  4937,  1345,   197, 50003,    21,    14,\n","            39,    32,   463,     4,     7,    34,   211,   880,    11,\n","           209,     4,  1596,    10,     5,  1698,    23,  1718,  2186,\n","            45,   439, 12655,  3248,  1345,    77,   248,    15,    41,\n","          4399,    20,   869,  1185,     4,   196,    17,    65,     5,\n","            90,    82,  1718,    32,   678,     8,  8157,    11,  1442,\n","            25, 12655,     4,   110,    11,  1046,     6,   249,    97,\n","            39,    12,     5,  2199,     6,    39,    12,   152,   374,\n","            33,   617,    26,     3], dtype=int32)>),\n"," (8,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2,     5,   238,    44,   720,   105,    69,   266, 15125,\n","          1957,  1870,  7440,    17,  4007,    11,  1931,    13,  4448,\n","             4,  1473, 21977,   455,    11,    41,  3268,   754,    20,\n","          1457,    14,    39,    32,  2408,   117,    69, 16117, 23442,\n","          1842,    45,   609,    66,   180,    56,   197,  1816,  1928,\n","            16,  1548,  1368,    21,    66,     9,   106,    39,  1328,\n","             7,   145,     8,   740,    11,     5,  2265,  1066,     4,\n","            39,    16,   680, 50002,  4448,     9,   177,     6,    21,\n","            39,   106,     4,    39,  1403,   488,  1813,    26,     8,\n","           567,   109, 50003,   119,   130,    11,  1962,     4,    21,\n","            39,   801,     7,  1955,    33,  7979,  2510,    11,  1300,\n","             9,   602,  7154,     7,   429,  5141,    11,     5,  4448,\n","          1066,     4,   402,   105,    13,   161,     4,   110,    11,\n","          4448,    23,  1473, 21977,    32,  2408,   117,    69,  4448,\n","          2680,     9,  1328,     7,   379,     8,  5141,  4448,   418,\n","            55,    39,  1823,   921,     6,    39,   106,     4, 50003,\n","           119,   130,    11,  1962,    21,    23,  1870,  7440,    12,\n","           872,    11,     5,  3790,    13,    69,   266,  1363,    55,\n","         21977,  7583,    24,   438,    20,    33, 16709, 16282,  5087,\n","             4,     5,  4473,  4409,  2554,   106,    39,    32,    65,\n","           387,    29,     5,  7440,   140,    39,  1403,     8, 16709,\n","            15,     5,   795,   155,  2771,     4,  6633,    16,   438,\n","            13,    69,   266,  1363,    11,   528,   202,    66,  4443,\n","            14,    39,  6956,  5059,   892,    20,    75,     6,   141,\n","            46,    18,  2536,   447,     7,    30,  9434,    59,    24,\n","           714,     4,    36,     6, 21977,    22,    39,  2342,     7,\n","           173,    14,  7440,    17,   152,  1453,    33,     4,    18,\n","          1754,   474,   315,    20,    33,   273,   508,     9,   152,\n","            32,    65,  3676,    33,    15,   588,     6,    39,   385,\n","             4,    21,    27,   173,    18,  2342,    19,    55,    27,\n","           882,    62,    75,     6,   141,    55,    27,    31,   848,\n","           374,  1633,    10,    75,     6,    19,    31,    67,    80,\n","            14,    18,  2342,     5,  1053,     6,    21,    39,  8643,\n","             4,    21,    27,   173,    18,    31,    67,   211,    73,\n","            96,    69,  4448,  2680,     6,   246,     4,    21, 21977,\n","            32,  4534,    42,     7,    86,  4448,   328,     6,    36,\n","           106,    39,   356,    48,    41, 50004,     9,    87,    65,\n","           732,   214,    29,     5,  4990,     4,    46, 21977, 10670,\n","            33,   151,    76,     5,  4990,    77,   609,     6,    39,\n","           628,    11,     8, 16117,  4448,   161,   197, 50005,     9,\n","           130,     6,    21,    11,    57,    39,   563,    61,   102,\n","            10,     5, 26132,   546,    39,     9,  7440,    43, 10670,\n","            62,     4,    39,  1080,    59,     5,  2265,  1273,  2345,\n","            20,   976,    66,     8, 17704,   469,     7,  1130,    33,\n","           335,  1224,     7,     3], dtype=int32)>),\n"," (9,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2,    28,     4,  2687,   920,     4,   263,    23,     4,\n","         50002,   179,     6,   927,   528,   235,     4,   393,     4,\n","           331,    23,     4, 49453,   179,     6,   376,   528,   235,\n","             4,   869,  1185,   196,   197,    68,   556,    11,     5,\n","          1456,  1663,    10, 10432,  8336, 12079, 16285,     6, 12207,\n","             9,  7924,   854,    21,     4,   439, 14783,    38,  7416,\n","          6113,    11,     5,  2147,   109,    10,     5,  7971,   901,\n","            10, 10432,  8336,     6,    57,    17,   908,    60,    79,\n","          1151,   497,     7,  1900,    11,   102,   653,     4, 10432,\n","          8336,    17,  6463,     7, 12281, 20894,  3124,     9,    11,\n","           102,  3251,   653,    19,    17,   555,    14,    19,  2272,\n","             8,  5204,    13,   623,     9,  2504,    26,    41, 39306,\n","             4,     5,   869,     6,    44,    17,   619,  9433,    10,\n","             5,  1190, 22635,  1102,     6,    17,   283,    11,     5,\n","          8225,    10,    24,  3074,  3725,   262,  1563,     4,    18,\n","            12,   888,    25,  2540, 50003,  2824,   417,    11,  2502,\n","           344,    45,   248,     4,   117,  1413,   439, 10432,   838,\n","            11,  7486,     9,  1052,    71,    38,    45,   153,   101,\n","           873,     7,     5,  2147,    11,  9871,     4,   402,   105,\n","            13,   161,     4,   619,  9433,    23,   869,  1185, 10391,\n","             8,  6595,   439, 10432,   197, 50004,   116,     8,   692,\n","             7,  2540, 50003,  2147,  1115,   417,    11, 50005,    45,\n","           248,     4,    18,    32,   197,    68,   556,    11,     5,\n","          1456,  1663,    10, 10432,  8336, 12079, 16285,     6, 12207,\n","             9,  7924,   854,    21,   869,  1185,  1432,    20,  9097,\n","         35433,     6,     5,  2614,    10,  5119,  1190,     5, 35433,\n","          1753,     6,    57,    17,  2038,   117,  1413,   439, 10432,\n","           838,    11,  7486,     9,  1052,    11,  2502,     7,     5,\n","          2147,    11,  9871,     4,  5812,    23,   869,  1185,     6,\n","            44,    17,     5,   619,  9433,    10,  2824,  1190,     5,\n","         22635,  1102,     6, 10391, 14458,   116,    24,   692,     7,\n","             5,  1115,   417,     4,    11,    41,   754,    14,  5029,\n","            15,   893,  3298,   196,    18,    12,   282,    89,    18,\n","           302,    10,    68,    44,   701,    10,     5, 10432,    31,\n","            67,  7483,    36,   979,     7, 50006,    63,  1113,    49,\n","         11863,     4,     5,  2594,    10,  2027,  3006,    23,    21,\n","            27,   173,    40,    38,  1639, 16285,     4,    27,   173,\n","            40,    38, 12207,     4,    27,   173,    40,    38,   854,\n","             6,  3068,     9,  7924,   854,     4,   268,   761,   130,\n","           135,  1859,     6,    19,    31,    67,     8,  2947,     4,\n","            21, 14036,    32,    43,     8,  2360,  1107,    15,    73,\n","         10432,  6697,    11,     5,  2147,     9,    19,    17,   555,\n","            40,    87,   705,    34, 11865,    91,    40,   657,     7,\n","            34,   250,     4,  1185,    22,    23, 50007,    20,  6169,\n","             6,    40,   245,     3], dtype=int32)>),\n"," (10,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2,     5,  1380,    10,    45,    93,    16,  3451,  2646,\n","            50,    34,  7479,    15,   296,    46,   466,   181,   212,\n","            10, 22109,     9,   420,   411,     4, 21941,    38, 12032,\n","         34522,   583,    13,     5,  1077,     6,    36,   386,    82,\n","          1136,   923,  2177,     5,  1948,    50,   829,   168,     7,\n","          5654, 50002,     4,    11,     5,   352,   153,     6,  5104,\n","            13,     5,  1534,  9753,    30,    48,  2168,  4812,     9,\n","             5,   763,  2767,    17, 10411,     8,   889,    13,     5,\n","          4507,  1635,     4,   402,   105,    13,   161,     4, 21941,\n","            38, 12032, 34522,   583,    54,   114,    53,    13,     5,\n","          1077,     6,    36, 12457,  1136,   923,  2177,     5,  1948,\n","            50,   829,   168,     7,  5654, 50002,    54,   132,    53,\n","             4,  1229, 13707,  1845, 50003,    17,   205,   580,     4,\n","            11,     5,   352,   153,     6,  5104,    13,     5,  1534,\n","          9753,    30,    48,  2168,  4812,     9,     5,   763,  2767,\n","            17, 10411,     8,   889,    13,     5,  4507,  1635,     4,\n","           344,    45,   153,     6,     5,   923,  1434,   220,   225,\n","            64,   168,     7,  1845, 50003,     9, 34522,   583,    64,\n","          1983,    11,   523,     4,    36,  3220,     6,   390,   583,\n","         20194,     5,   698,   844,    29, 10453,     4,    45,  2177,\n","           390,   583,    87,   145,     8,  9990,  4963,    13,     5,\n","          1077,     4,  5104,    13,  3451,  2646, 11943,    23,     4,\n","           527,     4,  5654,     4,   659,     4,  1845,     4,   856,\n","             4, 34522,     4,  5104,    13,  3451,  2646,  2864,    23,\n","             4,   527,     4,  1973,     4,   659,     4,  9382,  2568,\n","             4,   856,     4,  6843,     4,   798,     4,  1714,     4,\n","             5,  6590,    38,   774,    15, 12457,  5104,     9,  2168,\n","          6590,  3388,    28,  1136,     9,    38,    60,  5505,     9,\n","         22327,    79,     5, 50004,  8034,     4,   147,     7,  4547,\n","           923,   223,    29,  1136,    16,   209, 13147,  4303,     6,\n","           280,     6,   390,   583,    32,    48,  6490,     5,   128,\n","         50005,  9753,    10,     5,   352,   486,   204,     6,  2515,\n","             4,   283,    33,  4194,    15,     5,   517,     9,  1008,\n","           506,     6,  5104,    13,     5,  4731,  2798,   943,    47,\n","          1287,    79,     5,   100,    74, 11943,     4,    36,     6,\n","          1845, 50003,    16,  1237,    10,     5,  7689,    21,   221,\n","           427,    15,  1346,   506,   120,    75,     5,   128,  3671,\n","            13,  9753,    14,   153,     4,   273,    45,   153,     6,\n","            99, 50003,    12,  1531,   642,     7,    99, 50002,     6,\n","            36,    60,   666,     5,   751,    30,   558,     8,    60,\n","           141,  2275,    10,  1136,  5104,     4,  2213,     6,   467,\n","             6,     5,   128,   782,  1237,  1265,     5,   898,   600,\n","            32,    48,   390,   583,    16, 35546, 31641,    66,     8,\n","          1288,    10,    41,  4278,   617, 38957,   966,  3378,  9114,\n","          2927,     4,    45,     3], dtype=int32)>),\n"," (11,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2, 50002,     6, 50003,     9, 20783,   254,     5,   837,\n","             4, 23921,     9, 16790,    21,  4425,    70,  2683,  6711,\n","           128,  8220,  3594,     4,    28,     4,  8286,   208,     4,\n","           263,    23,     4, 45398,   179,     6,   835,   552,   235,\n","             4,   393,     4,   331,    23,     4, 50004,   179,     6,\n","           835,   552,   235,     4,   362,    19,    16,  4736, 17903,\n","            63,   439, 12656,     6,  7217,    30,    48,   455,    26,\n","             5,   128,   505,     7,   548,   424,    15,    49,  6691,\n","             4,     9,   574,    40,    31,  1262, 18126,    26,    41,\n","           298,     4, 20448,     9,  1275,    11,  3314,   311,     5,\n","           107,     6, 22200,  5903,     5,   837,    26,   128,  8220,\n","           424,     4, 50003,     6, 20783,     6, 20005,     9,     4,\n","         50005,    70,   120,    59,     5,   254,   258,    10,     5,\n","            52, 50006,    31,   837,     4,  7217,    30,    48,  2683,\n","             5, 50007,   424,   790,    54,   683,  2897,    28,  2230,\n","            53,     5, 28826,   424,   790,   228,    70,   118,    14,\n","          6711,     5,   254,   376,   128,  8220,  3594,    47,  4753,\n","             6,     4, 31231,     6,   439, 12656,     6, 50008,     6,\n","          1238,  4425,     6, 27822,     6, 31983,     6,     9,     4,\n","          4736, 17903,     6,    57,   131,    42,  2006,   133,     4,\n","            89,   131,   221,    26,     8,  1767,     7, 33539,    17,\n","             4,     5,   633,    14, 28699,   170,    26, 23921,     6,\n","         16790,    31,  4425,     6, 39341,     6, 30779,     4,     9,\n","         14623,    30,   120,     5,   254,   894,   128, 22737,  3594,\n","             6,    57,   411,    14,     4,   391,     9,    13,    73,\n","            51,    31,  1262,     8,   790,    10, 28826, 23864,     4,\n","             9,    19,    16,   137,    14,    38,     5,   964, 16187,\n","             4,    55,    19,   494,     7,  4567,     7,  1585,  1404,\n","          3594,    20,  3144,   557,   101, 28826, 23864,     6,   108,\n","           845,   557,    10,  6853,    38, 28826,  1080,  7200,    28,\n","          2784,    25,  1095,   557,     4, 50009,    12,  2683,     5,\n","           128,  8220,   424,   733, 50003,     9, 20783,     4,     8,\n","          5077,  4029,   557,    10,    68,    11,  3576,   142,    49,\n","          1160,    17,     8, 50010, 25558,    79,    40,    38,     6,\n","            20,     8, 10657,    10,  7217,     4,   141, 27124,    49,\n","          1160,  1295,   109,    40,   769,    31,   188,   104,     8,\n","           424,    14,     4,    40,  1801,  1630,    54,   292,   557,\n","            53,     4,     8,  2371,    10,     5,  3199,    68,  4195,\n","             4,   468,    49,   213,  2100,  4591,   109,    49,   198,\n","             6,   262,    63,  9919,     4,  7705,     7,  1585,  1874,\n","          3594,     4,    19,    16,    42,    80,  2854,    14,     4,\n","          2014, 28826,    66, 15652,   190,   233,    10,   334,  4476,\n","            40,   736,   820,     7,   744,     4, 50011,     7,   119,\n","            49,   973,  1630, 10632,    28, 30719,    49,   137,     7,\n","          1585,     4,     5,     3], dtype=int32)>),\n"," (12,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2,  2189,    23,   364,  2552, 43317,  2378,    25,   392,\n","          2336,  2527,  1147,   116,     5,  3803,     4,   140,   364,\n","          2552, 43317,    12,  4212,    13,  8924,    25,   392,  2336,\n","          2527,  1147,    11, 50002,  1683,    11,     5,  3803,     6,\n","          1128,    30,   249,   140,  8222,    91,     5,  2189,   195,\n","          6073,    62,   100,  4256,     7,    24,  3484,     4,    98,\n","             8,   154,  1721,    16,   332,    32,   783,    41,  7145,\n","           151,     7,  5199,  1485,   760,    66,    28,  1214,     5,\n","          2267,    10, 50003,  6202,  6105,    76,     8,   243,  6713,\n","             4,   377,    25,     5,  1721,    16,   409,    11,  2070,\n","           534,     6,  3434,     6,    30,   911,  2267,  9585,    10,\n","         43317,     9,   100,  6202,  6105,     6,     9,   118,     8,\n","           613,  4649,    10,   476,     5,  4212,  6105,    21,  4660,\n","          2066,    76, 19643,  1492,    20,   100,   347,  1691,  2633,\n","             4,    40,    72,    86,    81,   109,     5, 12712,    38,\n","          8960,  2789,    26,  4553,   637,   802,    66,   391,    40,\n","            30,    48,   224,     7,   187,    28,     5,   164,     4,\n","             5,   409,    98,  1328,     7,   323,     4,  1921,    10,\n","          2267,   473,    29,   792,     6, 20362,    63, 20634,    10,\n","          1019,     6,    63,  1309,     4,   183,     5, 25141,    10,\n","           637,    14,  2743,     5, 50003,  6105,     7,     5,     4,\n","         15341,    10,  1485,   760,     4,     9,     4,    40,   245,\n","          1732,     7, 11110,   355,    11,   100,   272,     7,  7534,\n","             5,  2267,     4,    10,    49,   213,  4212,  3951,    63,\n","            29, 24870,   723,  2680,     4,  1369,     4,    80,   178,\n","           102,    10,   174,  2675,   112,   100,  4256,    21,     6,\n","            22,  2704, 11997,     6,     5,  2666,   872,     5,  1263,\n","             6,  5766,    14,   102,    10,     5,  4212,     4,  6105,\n","         13155,    73,    85,     5,   171,    97,     5,  4634,    14,\n","           224,     4,    95,   371,  2409,    13,     5,    77,    82,\n","             4,     5,     4,  3434,  2459,     6,    57,   453,   116,\n","             5,   609,     6,    17,     5,   718,  6120,     4,    11,\n","             8,   611,    14,   453,    55,  1721,  1524, 16250, 19330,\n","             5,   749,    10,     4,  2833,   637,    10, 43317,     7,\n","          1060,  2267,  9585,     4,   792,    10,     8,  6202,  2189,\n","            23,   117, 27101,    10,  6202,  7083,   364,  2552, 43317,\n","            16,   792,    66,   666,   783,     9,  8701,    28,  2070,\n","           534,  1721,    16,  2666,  2704, 11997,     4,   174,    87,\n","            34,  1462,    20,     5,  2267,    10,    68,   688,  1278,\n","          1717,   227,   725,    11,     5,  3803,     6,    55, 43317,\n","            12,   799,   237,   231,     4,    14,  1263,     6,    57,\n","           568,     7,     5,  6325,    10,    56, 43317,   624,     6,\n","           678, 16250,     7,  3373,    91,     5,   934,    87,   192,\n","          1738,     8,   985,    14,    32,    48,    61,    71,    13,\n","          1466,    23,   112,     3], dtype=int32)>),\n"," (13,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2, 12366,  1739, 11010,    28,  4197,  1495,    17,   274,\n","             8,    52,   744,  1107,    31,    15,   259,   694,     6,\n","             5,   281,    10,     5,  1326,   957,   483,     4,   484,\n","           909,  1973,  4896,    22,     5,   156,   808,     7,   482,\n","            20,     5,    52, 36608,    31,    10,  1495, 10475,    26,\n","            19,    17,  2320,   693,    13, 50002,     8,   747,  3407,\n","          3801,     4,    18,  5148,  1094,  1183,    14,     5,   939,\n","           901,    10,  1495,  3980,     7,  4998,    32,  1403,    28,\n","           466,   446,   140,     5,  3745,     4,     5,   281,    10,\n","             5,  1326,   957,     5,   156,   808,     7,   482,    20,\n","             5,    52, 36608,    31,    10,  1495, 10475,    26,    19,\n","            17,  2320,   693,    13, 50002,     8,   747,  3407,  3801,\n","            54,  1960,   683,    53,   574,    99,  4896,   112,    42,\n","          2068,   458,    13,     8,  3035,   901,    13,  1495,     6,\n","            18,    22,  2390,   162,    52,   150,     8,   284,    31,\n","            25,    89,   808,     7,    34,   495,     4,     5,   128,\n","           490,  1326,  1094,   185,    14,    60,    79,    56,   222,\n","           794,    38,   101,   630,     7,   215,    13, 21503,  2200,\n","             9,   850,   253,    93, 50003,    26,   133,    26,     8,\n","          1752,   303,     4,    36,   340,     5, 31339,  3605,    15,\n","           259,   694,     6,     5,   156,    32,    81,   368,  1036,\n","             7,  5347,  3035, 11967,     4,  2390,   745,    19,    64,\n","           366,  1344, 12778,    36,  1959,  7593,    95,    10,    52,\n","          3216,     7,     5,  7263,    31,    10,     5,  1495,  1066,\n","             4,    99,  4896,  1036,     7,    34,  2892,    15,   362,\n","            18,  4903,     8,  3035,   901,   190,  1694,     4,    36,\n","            25,     8,   987,    25,     5,   796,    31,    67,  1747,\n","         14168,    11,   208,     6,    18,    22,     5,   686,    10,\n","          1495,   843,   871,     7,    34,  4869, 33528,     4,    52,\n","          1495,     6,   427,    20,  3067,     6,    17,    56,    10,\n","             5,  7548,    51,   247,   261,     5,    69,   156,     7,\n","          1389,   135,   365,     6,    31,    18,    22,     4,    52,\n","             5,  3980,   901,    10,  1495,    32,   221,   105,    28,\n","          2695,   190,   233,   172,  5841,     9,   565,     4,    81,\n","            14,    17,   318,    51,    50,   199,     5,   200,   156,\n","             7,   284,    25,     4,    52,    51,   199,     5,   259,\n","           351,     7,   980,    59,     9,    34,  8505,    11,    45,\n","          1499,     6, 18202,     5,   744,  1107, 16933,     9, 50004,\n","         13647,    30,    73,   311,     5,  1326,     4,    52,    19,\n","            17,    41,   327,    10,  1657,   312,     5,  1107,    14,\n","         36608,    10,  1495,    17,   274,    15,     8,   747,  3407,\n","          6210,     9,   937, 50005,    31,     5,  2103,    43,  2426,\n","          2185,     8,  3035,   901,    13,  1495,    10, 23070,     8,\n","          1694,    11,   235,    36, 19269,     5,   645,     5,   283,\n","            93,     4,     5,     3], dtype=int32)>),\n"," (14,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2,    54,   126,    53,    78,  1524,  2917,   162,    30,\n","            48,     8,  1609,   418,     4,  1428,    75, 17138,    24,\n","           432,  7682,    11,    42,   184,    60,    79,     8,  2452,\n","             9,  6766,    11,    35,  7773,   472,    37,   122,    18,\n","           603,     8,  1937,  1420,    76,     8,  4045,   984,     6,\n","         29497,    24,  2578,    11,    35,     5,  4597,    10,   271,\n","             6,    37,  7064,    24, 50002,   183,  7542,    10, 21292,\n","            25,     5,   258,    10,    35, 50003, 11609,    37,     9,\n","           195,     8,   730,     6,  4209,    11,    24,   213,  1719,\n","            11,    35,   254,   874,    37,     9,    35, 34488,     4,\n","            37,    18,   356,    43,     5,  2982,     6,     9,    60,\n","           581,     6,    18,    43,     5, 37714,     4,    18,  3042,\n","           450,    15,     4,   152,     6,     5,  1092,    10,     8,\n","         21451,  4550,    32,  1547,    42,    48,   318,    18,    16,\n","            48,    11,     8, 13866,     7,  2936,     6,  1501,  9790,\n","            10, 50004,    24, 50005,  9292,     4,  3042,    61,     6,\n","           102,   398,    38,   908,  1334,    13,     4,    50,  6562,\n","           185,    59,    13, 33076,    10,  3648,    21,   122,    27,\n","            86,    65,   178,   123,   184,    40,   131,    30, 50006,\n","            24,  6947,  3759,     6,     9,    19,   239,    65,   926,\n","             4,    18,  3805,    35,  1609,    10,  3648,     6,    37,\n","            41, 50007,  2126,     7, 16362,  1019,  2583,     6,    29,\n","             5,   135,  1397,    18,  1162,     4,    18, 11938, 50008,\n","            29,  5517,  7542,    10, 11022, 50009,    11,     8, 22501,\n","           644,  6057,     6,  2905, 50010,   288,  1264,     9,  7438,\n","         26287,  8491,     6, 32023, 17400, 12499,     6,  2660, 10090,\n","         21742, 21715,    97, 14681,    76,     5,  8642, 23325,     4,\n","          4951,     9, 44653,     6,   949, 50011, 50012,     6,  1628,\n","            10,  1609,     4,     8, 27692,    10,   336, 31056, 11043,\n","         50013,  1807,     9,  2138,  5586,     6, 50011,    17,   135,\n","           184,     8,  2698,  1638,    11,  1033, 50014,    16, 50015,\n","           707,  4550,     4,    36,    18,    16,    70,     5,   418,\n","            10,     5,   185,     6,     5,    56,  2369,  1155,    17,\n","          2934,     7,   163,     6,     7,   145,    63,     7, 11962,\n","             4,  2917,    32,     5, 21101,     7,  1525,    73,    14,\n","           141,    26,    18,   411,   167,     8, 50016,  7295,     7,\n","          2125,     6,   584,     9, 14496,     4,    55,    18,   239,\n","          2549,     6,    18,    16,  3543,     4,   280,     6,  2917,\n","            17,    80,    26,   206,    11,     5,  5758,  2680,     6,\n","           362,    19,    16, 19159,    20,   299,   963, 13345,  8573,\n","            16,  2609,  1086,    63, 31752,   129,    41,  2250, 50017,\n","            35,  3501,  1689,    37,  1503,  3193,    54, 40999, 50018,\n","            53,     4,     8, 20002,  4550,    11,    57,   466,  2369,\n","         13700,    76, 17958, 32920,    25,     5,  1934,    10,     8,\n","          4010,    54,  1895,     3], dtype=int32)>),\n"," (15,\n","  <tf.Tensor: shape=(400,), dtype=int32, numpy=\n","  array([    2,    28,     4, 16371,  3459,     4,   263,    23,     4,\n","         43793,   179,     6,   486,   131,   235,     4,   393,     4,\n","           331,    23,     4, 40144,   179,     6,   486,   131,   235,\n","             4,  5190,    23,   912,  7950,  7390,    20,    24,  3661,\n","            16,   107,   354,    56,  2553,    14,  5088,   486,    88,\n","           303,     4,     8,   107,   354,    56,  2553,    14,  5088,\n","           486,    88,   303,    32,    48,  5190,    20,     5,  2081,\n","            16,  5965,    46,    18,  1587,    19,    15,  5983,     4,\n","           912,  7950,  7390,     6,  2019,     6,    22,    18,    12,\n","           114, 50002,    21,    55,    18,   229,   311,     5,   889,\n","          2553,  2734,     7,    24,  3661,    11, 22075,     4,     5,\n","          2553,     6,     9,    56,   100,  5879,     7,   685,  2522,\n","          7390,     6,    43,  2657,    29,     5,   115,   103,    11,\n","         50003,     6,  2107,     6,    36,     5,   889,  2553,  1117,\n","           118,    94,   151,     7,     8,  6180,    11,  3649,    44,\n","           224,    19,    59,    13,  2575,     4,    99,  7390,     6,\n","            29, 50004,     6, 50005,     6,     4,  1235,     6,   106,\n","            19,    12, 50006,   730,    21,    14,    18,   118,     5,\n","          2553,    15,     5,   516,     4,  2575,   498,    20,     8,\n","          1463,   901,    10,    80, 31253,     4,    99,     4,  7390,\n","             6,    44,  1049,    25,     5,   243,  3932,    10,  1235,\n","             6,    22,    23,    21,    27,  3044,    31,   188,     4,\n","           357,    96,  1241,    55,    27,   406,    96,  3661,    31,\n","            67,   461,     9, 32759,   260,     4,   221,    59,    26,\n","           191,    10,     5,  5791,    13,     5,  2553,     4,    21,\n","            27,     4,  8324,    31,   188,    48,  6814,   412,    13,\n","            19,     6,    36,    27,    31,  1461,  6375,  1706,    96,\n","             4,  3661,    31,    67,   461,     9,     5,  1538, 50007,\n","            21,    76,   763,  5547,     7,   163,    89,     4,   529,\n","             9,    61,    10,  6539,   730,    55,    27,   703,    77,\n","           153,     6,    71,    19,    12,     4,    21,    27,     4,\n","         11089,     5, 11066,     7,  2346,    44,    96,  3661,    12,\n","             9,    18,   485,   130,     4,     5,  2553,    13,   531,\n","             6,   300,    27,    43,    60,    10,     8,   745,     7,\n","            19,    79,   713,     4,    27,    72,    31,   188,  2341,\n","            75,   478,    13,    24,  9819,     4,    21,   685,     4,\n","          7390,  1275,    20,     5,  2594,    10,  3649,    31,    67,\n","           784, 12840,    15,     5,  1310,     4,   459,    29, 15956,\n","             6,  1819,    11,     5,   992,    10, 50008,    11, 15548,\n","            97,   101,     4, 33236,    28,     5,  6593,     4,    18,\n","           873,     7,     5,   815,     9,  1275,    20,     5,   279,\n","           636,    44,  6477,     5, 41551,    46,     5,   354,  1114,\n","            11, 13509,     4,  9316,    23,   685,  2522,  7390,     6,\n","           205,    15,    24,  1137,   127,    11, 17878,     6,    12,\n","          2734,     5,   107,     3], dtype=int32)>)]"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["# Make the pair [0, 28] and like this for all 16X400 elements\n","list(enumerate(enc_extended_vocab))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1937,"status":"ok","timestamp":1686590801788,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"f69lSxrczHNk","outputId":"d2bbda9d-3d66-4d7d-88b9-49364455de49"},"outputs":[{"data":{"text/plain":["[[0, 2],\n"," [0, 28],\n"," [0, 4],\n"," [0, 8504],\n"," [0, 4611],\n"," [0, 4],\n"," [0, 8],\n"," [0, 1529],\n"," [0, 32],\n"," [0, 379],\n"," [0, 5],\n"," [0, 113],\n"," [0, 11606],\n"," [0, 50002],\n"," [0, 11],\n"," [0, 416],\n"," [0, 349],\n"," [0, 25],\n"," [0, 56],\n"," [0, 10],\n"," [0, 113],\n"," [0, 74],\n"," [0, 3150],\n"," [0, 3750],\n"," [0, 7],\n"," [0, 150],\n"," [0, 383],\n"," [0, 10],\n"," [0, 5],\n"," [0, 967],\n"," [0, 31],\n"," [0, 67],\n"," [0, 2176],\n"," [0, 619],\n"," [0, 14913],\n"," [0, 4],\n"," [0, 748],\n"," [0, 6002],\n"," [0, 6],\n"," [0, 835],\n"," [0, 6],\n"," [0, 32],\n"," [0, 48],\n"," [0, 2308],\n"," [0, 24],\n"," [0, 1663],\n"," [0, 25],\n"," [0, 1773],\n"," [0, 20137],\n"," [0, 50003],\n"," [0, 9],\n"," [0, 50004],\n"," [0, 140],\n"," [0, 491],\n"," [0, 4],\n"," [0, 26],\n"," [0, 191],\n"," [0, 10],\n"," [0, 24],\n"," [0, 7056],\n"," [0, 601],\n"," [0, 2329],\n"," [0, 25],\n"," [0, 5],\n"," [0, 2310],\n"," [0, 9],\n"," [0, 50005],\n"," [0, 10791],\n"," [0, 11],\n"," [0, 50006],\n"," [0, 6],\n"," [0, 4135],\n"," [0, 6],\n"," [0, 18],\n"," [0, 32],\n"," [0, 98],\n"," [0, 2008],\n"," [0, 41],\n"," [0, 2139],\n"," [0, 4616],\n"," [0, 7500],\n"," [0, 13],\n"," [0, 8],\n"," [0, 717],\n"," [0, 692],\n"," [0, 29],\n"," [0, 5],\n"," [0, 3818],\n"," [0, 10],\n"," [0, 5],\n"," [0, 50007],\n"," [0, 276],\n"," [0, 10],\n"," [0, 50003],\n"," [0, 4],\n"," [0, 2350],\n"," [0, 23],\n"," [0, 748],\n"," [0, 6002],\n"," [0, 54],\n"," [0, 114],\n"," [0, 53],\n"," [0, 32],\n"," [0, 379],\n"," [0, 41],\n"," [0, 11606],\n"," [0, 50002],\n"," [0, 25],\n"," [0, 56],\n"," [0, 10],\n"," [0, 113],\n"," [0, 74],\n"," [0, 3150],\n"," [0, 3750],\n"," [0, 7],\n"," [0, 150],\n"," [0, 383],\n"," [0, 10],\n"," [0, 5],\n"," [0, 967],\n"," [0, 16],\n"," [0, 2176],\n"," [0, 619],\n"," [0, 14913],\n"," [0, 4],\n"," [0, 18],\n"," [0, 32],\n"," [0, 48],\n"," [0, 2308],\n"," [0, 5],\n"," [0, 1663],\n"," [0, 25],\n"," [0, 1773],\n"," [0, 20137],\n"," [0, 50003],\n"," [0, 4],\n"," [0, 5],\n"," [0, 4238],\n"," [0, 6],\n"," [0, 44],\n"," [0, 70],\n"," [0, 2197],\n"," [0, 50008],\n"," [0, 25],\n"," [0, 7882],\n"," [0, 921],\n"," [0, 6],\n"," [0, 32],\n"," [0, 3764],\n"," [0, 5],\n"," [0, 378],\n"," [0, 823],\n"," [0, 25],\n"," [0, 5],\n"," [0, 472],\n"," [0, 66],\n"," [0, 57],\n"," [0, 12],\n"," [0, 3149],\n"," [0, 11],\n"," [0, 7509],\n"," [0, 36],\n"," [0, 72],\n"," [0, 34],\n"," [0, 8456],\n"," [0, 110],\n"," [0, 144],\n"," [0, 5],\n"," [0, 115],\n"," [0, 26],\n"," [0, 368],\n"," [0, 26],\n"," [0, 50009],\n"," [0, 4],\n"," [0, 4037],\n"," [0, 20137],\n"," [0, 6],\n"," [0, 3203],\n"," [0, 6],\n"," [0, 44],\n"," [0, 32],\n"," [0, 98],\n"," [0, 223],\n"," [0, 85],\n"," [0, 5],\n"," [0, 472],\n"," [0, 29],\n"," [0, 24],\n"," [0, 19987],\n"," [0, 262],\n"," [0, 1773],\n"," [0, 22],\n"," [0, 748],\n"," [0, 31],\n"," [0, 67],\n"," [0, 1651],\n"," [0, 12],\n"," [0, 524],\n"," [0, 26],\n"," [0, 8],\n"," [0, 157],\n"," [0, 775],\n"," [0, 530],\n"," [0, 1174],\n"," [0, 517],\n"," [0, 4],\n"," [0, 615],\n"," [0, 1553],\n"," [0, 7],\n"," [0, 30],\n"," [0, 8],\n"," [0, 290],\n"," [0, 824],\n"," [0, 60],\n"," [0, 62],\n"," [0, 75],\n"," [0, 79],\n"," [0, 5],\n"," [0, 3978],\n"," [0, 3262],\n"," [0, 44],\n"," [0, 2375],\n"," [0, 1474],\n"," [0, 513],\n"," [0, 81],\n"," [0, 27],\n"," [0, 10444],\n"," [0, 75],\n"," [0, 41],\n"," [0, 50010],\n"," [0, 1620],\n"," [0, 10],\n"," [0, 24414],\n"," [0, 13],\n"," [0, 8],\n"," [0, 17926],\n"," [0, 3913],\n"," [0, 7159],\n"," [0, 9],\n"," [0, 18],\n"," [0, 20567],\n"," [0, 90],\n"," [0, 82],\n"," [0, 15],\n"," [0, 5],\n"," [0, 50011],\n"," [0, 6],\n"," [0, 21],\n"," [0, 22],\n"," [0, 99],\n"," [0, 20137],\n"," [0, 4],\n"," [0, 232],\n"," [0, 200],\n"," [0, 540],\n"," [0, 27],\n"," [0, 43],\n"," [0, 7882],\n"," [0, 921],\n"," [0, 4463],\n"," [0, 130],\n"," [0, 7],\n"," [0, 1215],\n"," [0, 8],\n"," [0, 50012],\n"," [0, 228],\n"," [0, 66],\n"," [0, 19],\n"," [0, 1125],\n"," [0, 18],\n"," [0, 43],\n"," [0, 84],\n"," [0, 95],\n"," [0, 18],\n"," [0, 336],\n"," [0, 43],\n"," [0, 8],\n"," [0, 225],\n"," [0, 4],\n"," [0, 349],\n"," [0, 13],\n"," [0, 10675],\n"," [0, 23],\n"," [0, 748],\n"," [0, 6002],\n"," [0, 1174],\n"," [0, 835],\n"," [0, 32],\n"," [0, 8],\n"," [0, 2079],\n"," [0, 469],\n"," [0, 66],\n"," [0, 18],\n"," [0, 17],\n"," [0, 5],\n"," [0, 113],\n"," [0, 50002],\n"," [0, 11606],\n"," [0, 11],\n"," [0, 5],\n"," [0, 171],\n"," [0, 349],\n"," [0, 13],\n"," [0, 5],\n"," [0, 967],\n"," [0, 4],\n"," [0, 21],\n"," [0, 27],\n"," [0, 104],\n"," [0, 14],\n"," [0, 4053],\n"," [0, 4],\n"," [0, 91],\n"," [0, 58],\n"," [0, 199],\n"," [0, 318],\n"," [0, 168],\n"," [0, 13],\n"," [0, 19],\n"," [0, 4],\n"," [0, 51],\n"," [0, 808],\n"," [0, 2705],\n"," [0, 9],\n"," [0, 18],\n"," [0, 15373],\n"," [0, 19],\n"," [0, 80],\n"," [0, 132],\n"," [0, 4],\n"," [0, 21],\n"," [0, 27],\n"," [0, 104],\n"," [0, 24],\n"," [0, 7836],\n"," [0, 6],\n"," [0, 5],\n"," [0, 151],\n"," [0, 18],\n"," [0, 112],\n"," [0, 19],\n"," [0, 73],\n"," [0, 450],\n"," [0, 6],\n"," [0, 42],\n"," [0, 476],\n"," [0, 24],\n"," [0, 2513],\n"," [0, 7],\n"," [0, 86],\n"," [0, 19],\n"," [0, 36],\n"," [0, 80],\n"," [0, 13593],\n"," [0, 19],\n"," [0, 61],\n"," [0, 4],\n"," [0, 21],\n"," [0, 8],\n"," [0, 50002],\n"," [0, 17],\n"," [0, 8],\n"," [0, 433],\n"," [0, 44],\n"," [0, 11017],\n"," [0, 63],\n"," [0, 8099],\n"," [0, 4616],\n"," [0, 5659],\n"," [0, 9],\n"," [0, 15692],\n"," [0, 1843],\n"," [0, 4],\n"," [0, 5],\n"," [0, 17441],\n"," [0, 461],\n"," [0, 1117],\n"," [0, 475],\n"," [0, 5],\n"," [0, 15030],\n"," [0, 50002],\n"," [0, 4],\n"," [0, 5],\n"," [0, 1000],\n"," [0, 6],\n"," [0, 57],\n"," [0, 17],\n"," [0, 810],\n"," [0, 7],\n"," [0, 1705],\n"," [0, 5],\n"," [0, 619],\n"," [0, 4578],\n"," [0, 10],\n"," [0, 1600],\n"," [0, 471],\n"," [0, 20],\n"," [0, 5],\n"," [0, 16210],\n"," [0, 3],\n"," [1, 2],\n"," [1, 28],\n"," [1, 4],\n"," [1, 496],\n"," [1, 677],\n"," [1, 991],\n"," [1, 4],\n"," [1, 8],\n"," [1, 198],\n"," [1, 17],\n"," [1, 950],\n"," [1, 13],\n"," [1, 33],\n"," [1, 11544],\n"," [1, 270],\n"," [1, 16],\n"," [1, 132],\n"," [1, 7],\n"," [1, 41],\n"," [1, 1057],\n"," [1, 46],\n"," [1, 209],\n"," [1, 177],\n"," [1, 287],\n"," [1, 532],\n"," [1, 7],\n"," [1, 5396],\n"," [1, 33],\n"," [1, 129],\n"," [1, 20],\n"," [1, 8],\n"," [1, 3505],\n"," [1, 1654],\n"," [1, 7],\n"," [1, 421],\n"," [1, 75],\n"," [1, 214],\n"," [1, 29],\n"," [1, 3531],\n"," [1, 6],\n"," [1, 19],\n"," [1, 32],\n"," [1, 48],\n"," [1, 455],\n"," [1, 196],\n"," [1, 4],\n"," [1, 6170],\n"," [1, 2876],\n"," [1, 801],\n"," [1, 33],\n"," [1, 270],\n"," [1, 329],\n"," [1, 6],\n"," [1, 983],\n"," [1, 6],\n"," [1, 44],\n"," [1, 17],\n"," [1, 25148],\n"," [1, 9],\n"," [1, 32],\n"," [1, 4234],\n"," [1, 6],\n"," [1, 7],\n"," [1, 1964],\n"," [1, 177],\n"," [1, 11],\n"," [1, 663],\n"," [1, 273],\n"," [1, 18],\n"," [1, 17],\n"," [1, 1008],\n"," [1, 57],\n"," [1, 17],\n"," [1, 24],\n"," [1, 613],\n"," [1, 132],\n"," [1, 4],\n"," [1, 390],\n"," [1, 2876],\n"," [1, 22],\n"," [1, 14],\n"," [1, 355],\n"," [1, 30],\n"," [1, 743],\n"," [1, 7],\n"," [1, 1387],\n"," [1, 33],\n"," [1, 270],\n"," [1, 16],\n"," [1, 1678],\n"," [1, 1057],\n"," [1, 721],\n"," [1, 9],\n"," [1, 223],\n"," [1, 2326],\n"," [1, 1789],\n"," [1, 7],\n"," [1, 421],\n"," [1, 75],\n"," [1, 61],\n"," [1, 10],\n"," [1, 177],\n"," [1, 6],\n"," [1, 141],\n"," [1, 2058],\n"," [1, 33],\n"," [1, 138],\n"," [1, 48334],\n"," [1, 77],\n"," [1, 153],\n"," [1, 4],\n"," [1, 5],\n"," [1, 132],\n"," [1, 7],\n"," [1, 1641],\n"," [1, 23],\n"," [1, 329],\n"," [1, 22425],\n"," [1, 6],\n"," [1, 983],\n"," [1, 6],\n"," [1, 44],\n"," [1, 32],\n"," [1, 6175],\n"," [1, 9],\n"," [1, 4234],\n"," [1, 6],\n"," [1, 32],\n"," [1, 48],\n"," [1, 16793],\n"," [1, 125],\n"," [1, 28],\n"," [1, 24],\n"," [1, 13290],\n"," [1, 177],\n"," [1, 6],\n"," [1, 24],\n"," [1, 198],\n"," [1, 32],\n"," [1, 447],\n"," [1, 4],\n"," [1, 39],\n"," [1, 558],\n"," [1, 5],\n"," [1, 4],\n"," [1, 608],\n"," [1, 1654],\n"," [1, 46],\n"," [1, 33],\n"," [1, 270],\n"," [1, 12],\n"," [1, 603],\n"," [1, 214],\n"," [1, 29],\n"," [1, 5],\n"," [1, 90],\n"," [1, 127],\n"," [1, 10],\n"," [1, 5],\n"," [1, 4],\n"," [1, 177],\n"," [1, 93],\n"," [1, 15],\n"," [1, 552],\n"," [1, 517],\n"," [1, 4],\n"," [1, 329],\n"," [1, 17],\n"," [1, 680],\n"," [1, 101],\n"," [1, 36191],\n"," [1, 4],\n"," [1, 45],\n"," [1, 1080],\n"," [1, 41],\n"," [1, 1024],\n"," [1, 10],\n"," [1, 138],\n"," [1, 4687],\n"," [1, 11],\n"," [1, 528],\n"," [1, 7],\n"," [1, 421],\n"," [1, 329],\n"," [1, 61],\n"," [1, 10],\n"," [1, 177],\n"," [1, 6],\n"," [1, 57],\n"," [1, 5],\n"," [1, 198],\n"," [1, 2414],\n"," [1, 4],\n"," [1, 390],\n"," [1, 2876],\n"," [1, 32],\n"," [1, 48],\n"," [1, 7956],\n"," [1, 20],\n"," [1, 50002],\n"," [1, 148],\n"," [1, 12910],\n"," [1, 177],\n"," [1, 959],\n"," [1, 9],\n"," [1, 19386],\n"," [1, 534],\n"," [1, 5612],\n"," [1, 10],\n"," [1, 1131],\n"," [1, 140],\n"," [1, 77],\n"," [1, 93],\n"," [1, 46],\n"," [1, 19130],\n"," [1, 1081],\n"," [1, 518],\n"," [1, 2277],\n"," [1, 14],\n"," [1, 33],\n"," [1, 270],\n"," [1, 12],\n"," [1, 38695],\n"," [1, 9],\n"," [1, 114],\n"," [1, 61],\n"," [1, 10],\n"," [1, 177],\n"," [1, 2241],\n"," [1, 4],\n"," [1, 390],\n"," [1, 2876],\n"," [1, 84],\n"," [1, 2406],\n"," [1, 23],\n"," [1, 232],\n"," [1, 347],\n"," [1, 106],\n"," [1, 18],\n"," [1, 16],\n"," [1, 810],\n"," [1, 1013],\n"," [1, 7],\n"," [1, 4],\n"," [1, 1057],\n"," [1, 4],\n"," [1, 27],\n"," [1, 86],\n"," [1, 65],\n"," [1, 199],\n"," [1, 49],\n"," [1, 271],\n"," [1, 4],\n"," [1, 27],\n"," [1, 207],\n"," [1, 4],\n"," [1, 388],\n"," [1, 49],\n"," [1, 271],\n"," [1, 4],\n"," [1, 21],\n"," [1, 5],\n"," [1, 115],\n"," [1, 558],\n"," [1, 41],\n"," [1, 40632],\n"," [1, 981],\n"," [1, 4],\n"," [1, 15],\n"," [1, 552],\n"," [1, 1191],\n"," [1, 57],\n"," [1, 1108],\n"," [1, 138],\n"," [1, 48334],\n"," [1, 13],\n"," [1, 329],\n"," [1, 7],\n"," [1, 34],\n"," [1, 899],\n"," [1, 214],\n"," [1, 29],\n"," [1, 4],\n"," [1, 209],\n"," [1, 177],\n"," [1, 4],\n"," [1, 18],\n"," [1, 17],\n"," [1, 680],\n"," [1, 3794],\n"," [1, 7],\n"," [1, 168],\n"," [1, 7],\n"," [1, 177],\n"," [1, 273],\n"," [1, 24],\n"," [1, 14980],\n"," [1, 4],\n"," [1, 1672],\n"," [1, 200],\n"," [1, 2262],\n"," [1, 4],\n"," [1, 6160],\n"," [1, 7],\n"," [1, 1641],\n"," [1, 23],\n"," [1, 329],\n"," [1, 6],\n"," [1, 983],\n"," [1, 6],\n"," [1, 17],\n"," [1, 25148],\n"," [1, 36],\n"," [1, 338],\n"," [1, 7],\n"," [1, 5389],\n"," [1, 20],\n"," [1, 422],\n"," [1, 359],\n"," [1, 24],\n"," [1, 3423],\n"," [1, 4],\n"," [1, 91],\n"," [1, 390],\n"," [1, 2876],\n"," [1, 9460],\n"," [1, 5],\n"," [1, 271],\n"," [1, 6],\n"," [1, 39],\n"," [1, 444],\n"," [1, 1934],\n"," [1, 139],\n"," [1, 613],\n"," [1, 2277],\n"," [1, 125],\n"," [1, 5],\n"," [1, 177],\n"," [1, 6],\n"," [1, 5],\n"," [1, 981],\n"," [1, 272],\n"," [1, 4],\n"," [1, 390],\n"," [1, 2876],\n"," [1, 84],\n"," [1, 50003],\n"," [1, 1272],\n"," [1, 23],\n"," [1, 1369],\n"," [1, 87],\n"," [1, 1024],\n"," [1, 130],\n"," [1, 8],\n"," [1, 222],\n"," [1, 4],\n"," [1, 27],\n"," [1, 308],\n"," [1, 42],\n"," [1, 159],\n"," [1, 7],\n"," [1, 150],\n"," [1, 139],\n"," [1, 271],\n"," [1, 7],\n"," [1, 944],\n"," [1, 214],\n"," [1, 96],\n"," [1, 270],\n"," [1, 16],\n"," [1, 518],\n"," [1, 7],\n"," [1, 41],\n"," [1, 1057],\n"," [1, 4],\n"," [1, 21],\n"," [1, 5],\n"," [1, 11544],\n"," [1, 708],\n"," [1, 16],\n"," [1, 1057],\n"," [1, 721],\n"," [1, 1348],\n"," [1, 2308],\n"," [1, 123],\n"," [1, 7],\n"," [1, 2555],\n"," [1, 105],\n"," [1, 24],\n"," [1, 461],\n"," [1, 9],\n"," [1, 502],\n"," [1, 260],\n"," [1, 50004],\n"," [1, 18],\n"," [1, 1351],\n"," [1, 382],\n"," [1, 6],\n"," [1, 11256],\n"," [1, 3],\n"," [2, 2],\n"," [2, 28],\n"," [2, 4],\n"," [2, 496],\n"," [2, 677],\n"," [2, 991],\n"," [2, 4],\n"," [2, 263],\n"," [2, 23],\n"," [2, 4],\n"," [2, 41381],\n"," [2, 179],\n"," [2, 6],\n"," [2, 503],\n"," [2, 491],\n"," [2, 235],\n"," [2, 4],\n"," [2, 393],\n"," [2, 4],\n"," [2, 331],\n"," [2, 23],\n"," [2, 4],\n"," [2, 42694],\n"," [2, 179],\n"," [2, 6],\n"," [2, 503],\n"," [2, 491],\n"," [2, 235],\n"," [2, 4],\n"," [2, 396],\n"," [2, 23],\n"," [2, 17146],\n"," [2, 4289],\n"," [2, 3618],\n"," [2, 6],\n"," [2, 894],\n"," [2, 6],\n"," [2, 12],\n"," [2, 396],\n"," [2, 15],\n"," [2, 5037],\n"," [2, 515],\n"," [2, 10],\n"," [2, 1610],\n"," [2, 1407],\n"," [2, 9],\n"," [2, 6638],\n"," [2, 7],\n"," [2, 33],\n"," [2, 4465],\n"," [2, 270],\n"," [2, 1563],\n"," [2, 4],\n"," [2, 8],\n"," [2, 198],\n"," [2, 688],\n"," [2, 4465],\n"," [2, 270],\n"," [2, 1555],\n"," [2, 1407],\n"," [2, 17],\n"," [2, 479],\n"," [2, 10],\n"," [2, 862],\n"," [2, 75],\n"," [2, 7],\n"," [2, 150],\n"," [2, 24],\n"," [2, 213],\n"," [2, 146],\n"," [2, 109],\n"," [2, 18],\n"," [2, 1064],\n"," [2, 11],\n"," [2, 3867],\n"," [2, 1252],\n"," [2, 14],\n"," [2, 33],\n"," [2, 647],\n"," [2, 4509],\n"," [2, 64],\n"," [2, 592],\n"," [2, 33],\n"," [2, 7],\n"," [2, 8],\n"," [2, 2616],\n"," [2, 7256],\n"," [2, 6],\n"," [2, 134],\n"," [2, 1349],\n"," [2, 164],\n"," [2, 4],\n"," [2, 17146],\n"," [2, 9582],\n"," [2, 3618],\n"," [2, 6],\n"," [2, 894],\n"," [2, 6],\n"," [2, 10],\n"," [2, 50002],\n"," [2, 6],\n"," [2, 4409],\n"," [2, 6],\n"," [2, 12],\n"," [2, 396],\n"," [2, 15],\n"," [2, 306],\n"," [2, 15],\n"," [2, 5037],\n"," [2, 515],\n"," [2, 10],\n"," [2, 1610],\n"," [2, 1407],\n"," [2, 9],\n"," [2, 6638],\n"," [2, 11],\n"," [2, 5],\n"," [2, 187],\n"," [2, 10],\n"," [2, 33],\n"," [2, 270],\n"," [2, 6],\n"," [2, 1563],\n"," [2, 6],\n"," [2, 44],\n"," [2, 240],\n"," [2, 10],\n"," [2, 41],\n"," [2, 7256],\n"," [2, 10],\n"," [2, 5507],\n"," [2, 3700],\n"," [2, 4],\n"," [2, 147],\n"," [2, 7],\n"," [2, 8],\n"," [2, 9526],\n"," [2, 773],\n"," [2, 5509],\n"," [2, 6],\n"," [2, 3618],\n"," [2, 118],\n"," [2, 33],\n"," [2, 270],\n"," [2, 6],\n"," [2, 1563],\n"," [2, 6],\n"," [2, 11309],\n"," [2, 15],\n"," [2, 8],\n"," [2, 7907],\n"," [2, 11],\n"," [2, 49],\n"," [2, 103],\n"," [2, 15],\n"," [2, 561],\n"," [2, 292],\n"," [2, 46],\n"," [2, 33314],\n"," [2, 18],\n"," [2, 43],\n"," [2, 2102],\n"," [2, 33],\n"," [2, 5507],\n"," [2, 8332],\n"," [2, 4],\n"," [2, 39],\n"," [2, 112],\n"," [2, 42],\n"," [2, 2180],\n"," [2, 510],\n"," [2, 192],\n"," [2, 4],\n"," [2, 18],\n"," [2, 240],\n"," [2, 5],\n"," [2, 200],\n"," [2, 127],\n"," [2, 6],\n"," [2, 9],\n"," [2, 24],\n"," [2, 187],\n"," [2, 12],\n"," [2, 1561],\n"," [2, 8],\n"," [2, 1407],\n"," [2, 7628],\n"," [2, 7],\n"," [2, 242],\n"," [2, 1317],\n"," [2, 10],\n"," [2, 5507],\n"," [2, 8628],\n"," [2, 4],\n"," [2, 39],\n"," [2, 32],\n"," [2, 42],\n"," [2, 463],\n"," [2, 48],\n"," [2, 5202],\n"," ...]"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["[[batch_no, elm.numpy()] for batch_no, batch in list(enumerate(enc_extended_vocab)) for elm in batch]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y14Q3lHhzlrI"},"outputs":[],"source":["indices = tf.constant([[batch_no, elm.numpy()]\n","                       for batch_no, batch in list(enumerate(enc_extended_vocab))\n","                       for elm in batch], dtype=tf.int64)\n","\n","values = tf.ones(shape=(indices.shape[0]))\n","\n","dense_shape = extended_vocab.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1686590804037,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"WDmaM6VX0o1F","outputId":"5f90d4d3-fcdc-4ab4-8b3c-1cb88de75cbb"},"outputs":[{"data":{"text/plain":["SparseTensor(indices=tf.Tensor(\n","[[  0   2]\n"," [  0  28]\n"," [  0   4]\n"," ...\n"," [ 15   5]\n"," [ 15 107]\n"," [ 15   3]], shape=(6400, 2), dtype=int64), values=tf.Tensor([1. 1. 1. ... 1. 1. 1.], shape=(6400,), dtype=float32), dense_shape=tf.Tensor([   16 50019], shape=(2,), dtype=int64))"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["sparse_unk = tf.SparseTensor(indices, values, dense_shape)\n","sparse_unk"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1686590804037,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"2NoLrwOB3FyA","outputId":"5a21946a-4827-4498-b8f7-35e15050ee18"},"outputs":[{"data":{"text/plain":["TensorShape([16, 400])"]},"execution_count":104,"metadata":{},"output_type":"execute_result"}],"source":["copy_word_prob = (1-dummy_p_gen)@tf.ones((1, dummy_attention.shape[1]))*dummy_attention\n","\n","copy_word_prob.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1686590804037,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"fHO6PTCx48RJ","outputId":"a65e6a64-7f42-40f8-b59d-4aafb1322515"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=-1.4672438>"]},"execution_count":105,"metadata":{},"output_type":"execute_result"}],"source":["copy_word_prob[0, 3]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1686590804037,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"6DCwYkmN4-aM","outputId":"16d084b2-7d57-4b86-fa77-5a1454affe18"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=1.6601427>"]},"execution_count":106,"metadata":{},"output_type":"execute_result"}],"source":["1 - dummy_p_gen[0, 0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1686590804037,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"X7G1Zk6U5GHp","outputId":"f52c3548-4708-4759-9f61-667ee6cc3fce"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=-1.4672438>"]},"execution_count":107,"metadata":{},"output_type":"execute_result"}],"source":["(1 - dummy_p_gen[0, 0]) * dummy_attention[0, 3]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1686590804037,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"HSm73TI17lFr","outputId":"a73e901a-87f0-4451-82cd-7f92ce2b357a"},"outputs":[{"data":{"text/plain":["TensorShape([6400])"]},"execution_count":108,"metadata":{},"output_type":"execute_result"}],"source":["sparse_unk.values.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1466,"status":"ok","timestamp":1686590805498,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"fMElvxDQ8vff","outputId":"1cbb9a09-2f76-493a-9bff-46910bfe6c05"},"outputs":[{"data":{"text/plain":["SparseTensor(indices=tf.Tensor(\n","[[  0   2]\n"," [  0  28]\n"," [  0   4]\n"," ...\n"," [ 15   5]\n"," [ 15 107]\n"," [ 15   3]], shape=(6400, 2), dtype=int64), values=tf.Tensor(\n","[-0.5758334   2.3832648   1.844269   ...  0.08851024 -0.40647966\n","  0.04801887], shape=(6400,), dtype=float32), dense_shape=tf.Tensor([   16 50019], shape=(2,), dtype=int64))"]},"execution_count":109,"metadata":{},"output_type":"execute_result"}],"source":["indices = tf.constant([[batch_no, elm.numpy()]\n","                       for batch_no, batch in list(enumerate(enc_extended_vocab))\n","                       for elm in batch], dtype=tf.int64)\n","\n","values = tf.reshape(copy_word_prob, [-1])\n","dense_shape = extended_vocab.shape\n","\n","sparse_unk = tf.SparseTensor(indices, values, dense_shape)\n","sparse_unk"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1686590805499,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"HvDpkykD_gpO","outputId":"0faf2b42-e777-4026-ab14-5cec8764b6ad"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(16, 50019), dtype=float32, numpy=\n","array([[ 0.        ,  0.        , -0.5758334 , ...,  0.        ,\n","         0.        ,  0.        ],\n","       [ 0.        ,  0.        , -1.4551897 , ...,  0.        ,\n","         0.        ,  0.        ],\n","       [ 0.        ,  0.        , -0.86349815, ...,  0.        ,\n","         0.        ,  0.        ],\n","       ...,\n","       [ 0.        ,  0.        , -0.04558611, ...,  0.        ,\n","         0.        ,  0.        ],\n","       [ 0.        ,  0.        , -1.7585374 , ...,  1.2480762 ,\n","        -1.1533684 ,  2.144622  ],\n","       [ 0.        ,  0.        , -0.15936618, ...,  0.        ,\n","         0.        ,  0.        ]], dtype=float32)>"]},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["dense_unk = tf.sparse.to_dense(sparse_unk, validate_indices=False)\n","\n","dense_unk"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1160,"status":"ok","timestamp":1686590806654,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"3Tp34w7j9cSL","outputId":"3cc8f380-2ccb-4174-bcef-0550a6c7f895"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=0.55988365>"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["copy_word_prob[3, 16]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1686590806655,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"ejx8glUA-1aG","outputId":"2fe058ec-fb97-413d-fe18-f86aed231d01"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(), dtype=int32, numpy=487>"]},"execution_count":112,"metadata":{},"output_type":"execute_result"}],"source":["enc_extended_vocab[3, 16]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1686590806655,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"qSrOU-cX9mwA","outputId":"3d443162-9188-4cbf-c90c-28470551dc98"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=0.22178374>"]},"execution_count":113,"metadata":{},"output_type":"execute_result"}],"source":["dense_unk[3, 45]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1686590806655,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"NcPdpSjSvzox","outputId":"70ead2ae-5fb9-4c87-a576-ffa585578073"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(16, 100), dtype=float32, numpy=\n","array([[-0.74156123,  0.56941223, -0.9034836 , ...,  1.7447785 ,\n","         0.08023512,  2.1157024 ],\n","       [-1.1822935 ,  1.1088858 ,  1.5788027 , ..., -0.4146117 ,\n","        -1.7387275 ,  0.40882516],\n","       [-0.7363009 , -1.2251134 ,  0.17634897, ..., -2.2362814 ,\n","         0.02384201, -1.0045148 ],\n","       ...,\n","       [-0.56834644, -2.5515718 , -0.23059589, ...,  1.3981578 ,\n","        -0.04787099, -0.44183278],\n","       [-0.8972602 ,  0.33710226,  1.1216476 , ...,  0.9076844 ,\n","        -0.84655833, -0.8770524 ],\n","       [ 0.21172185,  0.36680886,  0.15578592, ...,  0.40860587,\n","         1.7032349 ,  0.99210364]], dtype=float32)>"]},"execution_count":114,"metadata":{},"output_type":"execute_result"}],"source":["tensor1 = tf.random.normal(shape=[16, 100], dtype=tf.float32)\n","tensor2 = tf.random.normal(shape=[16, 100], dtype=tf.float64)\n","\n","# tensor1 + tensor2 # Error as 2 are of different data types\n","tensor1 + tf.cast(tensor2, tf.float32) # Use tf.cast to first cast the values of 2nd tensor to float32"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1686590806655,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"dsHIKGVg8A9e","outputId":"0edaedec-8740-4d3a-d37e-af91ee2357ba"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(16, 50019), dtype=float32, numpy=\n","array([[ 0.13005626, -0.32424763, -1.8608043 , ...,  0.        ,\n","         0.        ,  0.        ],\n","       [-0.14785765,  0.6501635 , -0.35145938, ...,  0.        ,\n","         0.        ,  0.        ],\n","       [-0.18460785,  0.18151662, -0.89514816, ...,  0.        ,\n","         0.        ,  0.        ],\n","       ...,\n","       [ 1.5748049 ,  0.57108235, -0.07488305, ...,  0.        ,\n","         0.        ,  0.        ],\n","       [ 0.23433426,  0.5141154 , -1.611971  , ...,  1.2480762 ,\n","        -1.1533684 ,  2.144622  ],\n","       [-0.12962072,  0.05396838, -1.6464111 , ...,  0.        ,\n","         0.        ,  0.        ]], dtype=float32)>"]},"execution_count":115,"metadata":{},"output_type":"execute_result"}],"source":["tf.cast(generate_word_prob, tf.float32) + tf.cast(dense_unk, tf.float32)"]},{"cell_type":"markdown","metadata":{"id":"enGgXln6Izhh"},"source":["#### Summary vocab extention using article OOVs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":504,"status":"ok","timestamp":1686994615542,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"xB1joSi4zPWH","outputId":"c18e29c1-f708-4002-d115-dfe8b4f57d6c"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(), dtype=string, numpy=b'[START] bishop john folda , of north dakota , is taking time off after being diagnosed . he contracted the infection through contaminated food in italy . church members in fargo , grand forks and jamestown could have been exposed . [END]'>"]},"execution_count":123,"metadata":{},"output_type":"execute_result"}],"source":["example_summary_string"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":776,"status":"ok","timestamp":1686994630411,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"_QkQ7ME86TjM","outputId":"e07d6ea4-dccf-40f7-85b4-d73d9fd69273"},"outputs":[{"data":{"text/plain":["array([[b'[START]', b'bishop', b'john', b'folda', b',', b'of', b'north',\n","        b'dakota', b',', b'is', b'taking', b'time', b'off', b'after',\n","        b'being', b'diagnosed', b'.', b'he', b'contracted', b'the',\n","        b'infection', b'through', b'contaminated', b'food', b'in',\n","        b'italy', b'.', b'church', b'members', b'in', b'fargo', b',',\n","        b'grand', b'forks', b'and', b'jamestown', b'could', b'have',\n","        b'been', b'exposed', b'.', b'[END]', '', '', '', '', '', '', '',\n","        '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","        '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","        '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","        '', '', '']], dtype=object)"]},"execution_count":124,"metadata":{},"output_type":"execute_result"}],"source":["words = tf.strings.split(example_summary_string, sep=' ')\n","words = tf.keras.utils.pad_sequences(tf.reshape(words, [1, -1]),\n","                                     maxlen=max_summary_tokens,\n","                                     padding=\"post\",\n","                                     truncating=\"post\",\n","                                     dtype=object,\n","                                     value='')\n","words"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1686994647007,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"m-7g3kTmnsan","outputId":"ef427655-a187-473e-a3ae-c2da2d5b9768"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(100,), dtype=string, numpy=\n","array([b'[START]', b'bishop', b'john', b'folda', b',', b'of', b'north',\n","       b'dakota', b',', b'is', b'taking', b'time', b'off', b'after',\n","       b'being', b'diagnosed', b'.', b'he', b'contracted', b'the',\n","       b'infection', b'through', b'contaminated', b'food', b'in',\n","       b'italy', b'.', b'church', b'members', b'in', b'fargo', b',',\n","       b'grand', b'forks', b'and', b'jamestown', b'could', b'have',\n","       b'been', b'exposed', b'.', b'[END]', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n","       b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n","      dtype=object)>"]},"execution_count":125,"metadata":{},"output_type":"execute_result"}],"source":["words = tf.reshape(words, [-1])\n","words"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":575,"status":"ok","timestamp":1686994704134,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"qYwHVuZo6uAE","outputId":"b16a6506-3944-4ae0-ac0e-7b6aa899730f"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(100,), dtype=int64, numpy=\n","array([    2,  4273,   364,     1,     6,    10,   294,  6146,     6,\n","          17,   345,    82,   129,    46,   101,  1781,     4,    18,\n","        6119,     5,  2678,   144,  6719,   424,    11,  1296,     4,\n","         833,   342,    11, 15991,     6,  1028, 28440,     9, 36041,\n","          87,    30,    48,  2727,     4,     3,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0])>"]},"execution_count":126,"metadata":{},"output_type":"execute_result"}],"source":["tokens = word2id(words)\n","tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":520,"status":"ok","timestamp":1686994730940,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"Sy34LFD9H7o-","outputId":"e6b7b77b-031c-44a0-f3c2-2fb141698937"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[3]])>"]},"execution_count":128,"metadata":{},"output_type":"execute_result"}],"source":["unk_ids = tf.where(word2id(words)==1)\n","unk_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":484,"status":"ok","timestamp":1686994789479,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"v8MolkqwH4cV","outputId":"c29ae8b0-e2f3-4cb1-e45b-edcf2539637e"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'folda'], dtype=object)>"]},"execution_count":131,"metadata":{},"output_type":"execute_result"}],"source":["unk_words = tf.gather(words, tf.where(word2id(words)==1)[:, 0])\n","unk_words"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686994867634,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"0_NtBw86Gwhd","outputId":"cf78532c-f6b3-44f4-d95c-bc0830bd53f6"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1,), dtype=int32, numpy=array([50003], dtype=int32)>"]},"execution_count":134,"metadata":{},"output_type":"execute_result"}],"source":["unk_tokens = oov_w2i.lookup(unk_words)\n","unk_tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cinI2yRvEaM"},"outputs":[],"source":["unk_tokens = tf.cast(unk_tokens, tf.int64)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1686994981722,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"fL3Hw6Sxu5_y","outputId":"0af31582-2706-4e4f-d75c-e89beabd6407"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(100,), dtype=int64, numpy=\n","array([    2,  4273,   364, 50003,     6,    10,   294,  6146,     6,\n","          17,   345,    82,   129,    46,   101,  1781,     4,    18,\n","        6119,     5,  2678,   144,  6719,   424,    11,  1296,     4,\n","         833,   342,    11, 15991,     6,  1028, 28440,     9, 36041,\n","          87,    30,    48,  2727,     4,     3,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0])>"]},"execution_count":137,"metadata":{},"output_type":"execute_result"}],"source":["tf.tensor_scatter_nd_update(tokens, unk_ids, unk_tokens)"]},{"cell_type":"markdown","metadata":{"id":"cxcnl02e7d03"},"source":["#### Decoder extended vocabulary to words"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dZEHTbbg7j3j"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"LahUcxcHA6hD"},"source":["### OOV Utils Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IlxgluRRA-Yv"},"outputs":[],"source":["class OOV_Utils():\n","  def __init__(self,\n","               word2id, id2word,\n","               vocab_size=50002,\n","               max_article_tokens=400, max_summary_tokens=100):\n","    self.vocab_size = vocab_size\n","    self.word2id = word2id\n","    self.id2word = id2word\n","    self.max_article_tokens = max_article_tokens\n","    self.max_summary_tokens = max_summary_tokens\n","\n","\n","  def max_oovs(self, article):\n","    words = tf.strings.split(article)\n","\n","    # Truncate sequence if it exceeds the maximum length\n","    words = words[:self.max_article_tokens]\n","\n","    # Pad the sequence if it is shorter than the maximum length\n","    num_padding = self.max_article_tokens - tf.shape(words, out_type=tf.int32)[0]\n","    padding = tf.repeat([''], num_padding)\n","    words = tf.concat([words, padding], axis=0)\n","\n","    tokens = self.word2id(words)\n","    oovs = tf.boolean_mask(words, tf.equal(tokens, 1))\n","    oovs = tf.unique_with_counts(oovs).y\n","    oovs_count = tf.shape(tf.unique_with_counts(oovs).y, out_type=tf.int32)[0]\n","\n","    self.oovs = oovs\n","    self.oovs_count = oovs_count\n","\n","\n","  def map_oovs(self):\n","\n","    oov_start_idx = self.vocab_size\n","\n","    self.oov_word2id = None\n","    self.oov_id2word = None\n","\n","    if self.oovs_count != 0:\n","      oov_words = self.oovs\n","      oov_ids = tf.add(tf.range(self.oovs_count, dtype=tf.int32), oov_start_idx)\n","\n","      init = tf.lookup.KeyValueTensorInitializer(oov_words, oov_ids)\n","      self.oov_word2id = tf.lookup.StaticHashTable(init, default_value=1)\n","\n","      init = tf.lookup.KeyValueTensorInitializer(oov_ids, oov_words)\n","      self.oov_id2word = tf.lookup.StaticHashTable(init, default_value='[UNK]')\n","\n","\n","  def extended_encoder_vocab(self, article):\n","    oov_w2i = self.oov_word2id\n","\n","    words = tf.strings.split(article)\n","\n","    # Truncate sequence if it exceeds the maximum length\n","    words = words[:self.max_article_tokens]\n","\n","    # Pad the sequence if it is shorter than the maximum length\n","    num_padding = self.max_article_tokens - tf.shape(words, out_type=tf.int32)[0]\n","    padding = tf.repeat([''], num_padding)\n","    words = tf.concat([words, padding], axis=0)\n","\n","    words = tf.pad(words, paddings=[[1, 0]], constant_values=\"[START]\")\n","    words = tf.pad(words, paddings=[[0, 1]], constant_values=\"[END]\")\n","\n","    unk_ids = tf.where(self.word2id(words)==1)\n","    unk_words = tf.gather(words, unk_ids[:, 0])\n","\n","    oov_extended_encoder_in = self.word2id(words)\n","\n","    if self.oovs_count != 0:\n","      unk_tokens = oov_w2i.lookup(unk_words)\n","      unk_tokens = tf.cast(unk_tokens, tf.int64)\n","      oov_extended_encoder_in = tf.tensor_scatter_nd_update(oov_extended_encoder_in, unk_ids, unk_tokens)\n","\n","    return oov_extended_encoder_in\n","\n","\n","  def extended_decoder_vocab(self, summary):\n","\n","    oov_w2i = self.oov_word2id\n","\n","    words = tf.strings.split(summary)\n","\n","    # Truncate sequence if it exceeds the maximum length\n","    words = words[:self.max_summary_tokens]\n","\n","    # Pad the sequence if it is shorter than the maximum length\n","    num_padding = self.max_summary_tokens - tf.shape(words, out_type=tf.int32)[0]\n","    padding = tf.repeat([''], num_padding)\n","    words = tf.concat([words, padding], axis=0)\n","\n","    unk_ids = tf.where(self.word2id(words)==1)\n","    unk_words = tf.gather(words, unk_ids[:, 0])\n","\n","    oov_extended_decoder = self.word2id(words)\n","\n","    if self.oovs_count != 0:\n","      unk_tokens = oov_w2i.lookup(unk_words)\n","      unk_tokens = tf.cast(unk_tokens, tf.int64)\n","      oov_extended_decoder = tf.tensor_scatter_nd_update(oov_extended_decoder, unk_ids, unk_tokens)\n","\n","    return oov_extended_decoder"]},{"cell_type":"markdown","source":["## Dataset For Model Training and Evaluation"],"metadata":{"id":"6vh3wZ255iuO"}},{"cell_type":"markdown","source":["### Train, Val and Test Dataset"],"metadata":{"id":"-gOstX3M5qr0"}},{"cell_type":"code","source":["word2id = tf.keras.layers.StringLookup(mask_token='',\n","                                      oov_token=\"[UNK]\",\n","                                      vocabulary=summary_processor.get_vocabulary())\n","id2word = tf.keras.layers.StringLookup(mask_token='',\n","                                      oov_token=\"[UNK]\",\n","                                      vocabulary=summary_processor.get_vocabulary(),\n","                                      invert=True)\n","\n","vocab_size = summary_processor.vocabulary_size()\n","max_article_tokens = 400\n","max_summary_tokens = 100\n","\n","oov_utils = OOV_Utils(word2id, id2word,\n","                        vocab_size, max_article_tokens, max_summary_tokens)\n","\n","def process_each_example(article, summary):\n","  oov_utils.max_oovs(article)\n","  oov_utils.map_oovs()\n","\n","  encoder_in = oov_utils.extended_encoder_vocab(article)\n","  target = oov_utils.extended_decoder_vocab(summary)\n","  target_in = target[:-1]\n","  target_out = target[1:]\n","\n","  oovs_count = tf.cast(oov_utils.oovs_count, tf.int64)\n","\n","  return (oovs_count, encoder_in, target_in), target_out\n","\n","def process_examples(articles, summaries):\n","  processed_data = []\n","\n","  for article, summary in zip(articles, summaries):\n","    (oovs_count, encoder_in, decoder_in), target = process_each_example(article, summary)\n","    processed_data.append([(oovs_count, encoder_in, decoder_in), target])\n","\n","  return processed_data\n","\n","train_ds = process_examples(train_articles_raw, train_summaries_raw)\n","train_ds = tf.data.Dataset.from_tensor_slices(train_ds)"],"metadata":{"id":"OHxmTPgN0586"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word2id = tf.keras.layers.StringLookup(mask_token='',\n","                                      oov_token=\"[UNK]\",\n","                                      vocabulary=summary_processor.get_vocabulary())\n","id2word = tf.keras.layers.StringLookup(mask_token='',\n","                                      oov_token=\"[UNK]\",\n","                                      vocabulary=summary_processor.get_vocabulary(),\n","                                      invert=True)\n","\n","vocab_size = summary_processor.vocabulary_size()\n","max_article_tokens = 400\n","max_summary_tokens = 100\n","\n","oov_utils = OOV_Utils(word2id, id2word,\n","                        vocab_size, max_article_tokens, max_summary_tokens)\n","\n","def process_example(article, summary):\n","  oov_utils.max_oovs(article)\n","  oov_utils.map_oovs()\n","\n","  encoder_in = oov_utils.extended_encoder_vocab(article)\n","  target = oov_utils.extended_decoder_vocab(summary)\n","  target_in = target[:-1]\n","  target_out = target[1:]\n","\n","  oovs_count = tf.cast(oov_utils.oovs_count, tf.int64)\n","\n","  return oovs_count, encoder_in, target_in, target_out\n","\n","def prepare_inp_target(oovs_count, encoder_in, target_in, target_out):\n","  oovs_count.set_shape([None, ])\n","  encoder_in.set_shape([None, max_article_tokens])\n","  target_in.set_shape([None, max_summary_tokens-1])\n","  target_out.set_shape([None, max_summary_tokens-1])\n","\n","  return (oovs_count, encoder_in, target_in), target_out\n","\n","BUFFER_SIZE = 1000\n","BATCH_SIZE = 16"],"metadata":{"id":"Nfonz_9p5wwQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ids = list(range(len(train_articles_raw)))\n","train_ds = tf.data.Dataset.from_generator(lambda: train_ids, tf.uint8)\n","train_ds = train_ds.shuffle(buffer_size=BUFFER_SIZE, seed=0, reshuffle_each_iteration=True)\n","\n","def func(i):\n","  i = i.numpy()\n","  oovs_count, encoder_in, target_in, target_out = process_example(train_articles_raw[i],\n","                                                                  train_summaries_raw[i])\n","\n","  return oovs_count, encoder_in, target_in, target_out\n","\n","train_ds = train_ds.map(map_func=lambda i: tf.py_function(func=func,\n","                                               inp=[i],\n","                                               Tout=[tf.int64, tf.int64, tf.int64, tf.int64]),\n","                        num_parallel_calls=tf.data.AUTOTUNE)\n","train_ds = train_ds.batch(BATCH_SIZE).map(prepare_inp_target)\n","train_ds = train_ds.prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"v_hCO5nF6E7G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for (ex_oovs_count, ex_encoder_in, ex_decoder_in), ex_decoder_out in train_ds.take(1):\n","  print(ex_oovs_count)\n","  print()\n","  print(ex_encoder_in)\n","  print(ex_decoder_in)\n","  print()\n","  print(ex_decoder_out)"],"metadata":{"id":"pvzLJ50ZFozc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_ids = list(range(len(val_articles_raw)))\n","val_ds = tf.data.Dataset.from_generator(lambda: val_ids, tf.uint8)\n","val_ds = val_ds.shuffle(buffer_size=BUFFER_SIZE, seed=0, reshuffle_each_iteration=True)\n","\n","def func(i):\n","  i = i.numpy()\n","  oovs_count, encoder_in, target_in, target_out = process_example(val_articles_raw[i],\n","                                                                  val_summaries_raw[i])\n","\n","  return oovs_count, encoder_in, target_in, target_out\n","\n","val_ds = val_ds.map(map_func=lambda i: tf.py_function(func=func,\n","                                               inp=[i],\n","                                               Tout=[tf.int64, tf.int64, tf.int64, tf.int64]),\n","                    num_parallel_calls=tf.data.AUTOTUNE)\n","val_ds = val_ds.batch(BATCH_SIZE).map(prepare_inp_target)\n","val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"5QykYfRR6ML6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_ids = list(range(len(test_articles_raw)))\n","test_ds = tf.data.Dataset.from_generator(lambda: test_ids, tf.uint8)\n","\n","def func(i):\n","  i = i.numpy()\n","  oovs_count, encoder_in, target_in, target_out = process_example(test_articles_raw[i],\n","                                                                  test_summaries_raw[i])\n","\n","  return oovs_count, encoder_in, target_in, target_out\n","\n","test_ds = test_ds.map(map_func=lambda i: tf.py_function(func=func,\n","                                               inp=[i],\n","                                               Tout=[tf.int64, tf.int64, tf.int64, tf.int64]),\n","                      num_parallel_calls=tf.data.AUTOTUNE)\n","test_ds = test_ds.batch(BATCH_SIZE).map(prepare_inp_target)\n","test_ds = test_ds.prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"2FW3b_vM6nvM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AdcyHm9ulxYs"},"source":["## Encoder, Decoder, Pointer Generator & Summarizer"]},{"cell_type":"markdown","metadata":{"id":"q9dHhoI1-Puy"},"source":["### Encoder Class"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"hR983wQomsbf","executionInfo":{"status":"ok","timestamp":1687347504177,"user_tz":-330,"elapsed":492,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, emb_out, lstm_units, text_processor):\n","    super(Encoder, self).__init__()\n","    self.emb_out = emb_out\n","    self.lstm_units = lstm_units\n","    self.text_processor = text_processor\n","    self.vocab_size = text_processor.vocabulary_size()\n","\n","    # Embedding layer will convert the tokens into vectors\n","    self.embedding = Embedding(self.vocab_size, self.emb_out)\n","\n","    # Using Bidirectional layer with lstm cells\n","    self.rnn = Bidirectional(\n","        layer= LSTM(self.lstm_units,\n","                    # Return all output sequences\n","                    return_sequences=True),\n","        merge_mode='sum')\n","\n","\n","  def call(self, x):\n","    x = self.embedding(x)\n","\n","    x = self.rnn(x)\n","\n","    return x\n","\n","  def convert_inputs(self, texts):\n","    texts = tf.convert_to_tensor(texts)\n","\n","    if(len(texts.shape) == 0):\n","      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n","\n","    articles = self.text_processor(texts)\n","    enc_articles = self(articles)\n","\n","    return enc_articles"]},{"cell_type":"markdown","metadata":{"id":"HVQIT-iVNbUY"},"source":["### Bahdanu's Attention with Coverage"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"Y73teQTwpXPy","executionInfo":{"status":"ok","timestamp":1687347525424,"user_tz":-330,"elapsed":576,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["class CrossAttention(tf.keras.layers.Layer):\n","  def __init__(self, use_scale=True, **kwargs):\n","    super(CrossAttention, self).__init__()\n","\n","    self.additive_attention = AdditiveAttention(use_scale=use_scale, **kwargs)\n","    self.layernorm = LayerNormalization()\n","    self.add = Add()\n","\n","\n","  def call(self, x, context):\n","    attn_output, attn_scores = self.additive_attention(\n","        [x, context],\n","        return_attention_scores=True\n","    )\n","\n","    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n","    self.last_attention_weights = attn_scores\n","\n","    x = self.add([x, attn_output])\n","    x = self.layernorm(x)\n","\n","    return x, attn_output"]},{"cell_type":"code","source":["ex_attention_layer = CustomAttention()\n","\n","EMB_OUT = 256\n","emb = Embedding(summary_processor.vocabulary_size(), EMB_OUT)\n","ex_decoder_emb = emb(ex_decoder_in[:, 0:1])\n","ex_coverage = tf.zeros(ex_encoder_out.shape)\n","ex_decoder_attention, attn_output = ex_attention_layer(ex_decoder_emb, ex_encoder_out, ex_coverage)\n","\n","print(f\"ex_decoder_emb, shape = {ex_decoder_emb.shape}\")\n","print(f\"ex_encoder_out, shape = {ex_encoder_out.shape}\")\n","print(f\"ex_coverage, shape = {ex_coverage.shape}\")\n","print(f\"ex_decoder_attention, shape = {ex_decoder_attention.shape}\")\n","print(f\"attn_output, shape = {attn_output.shape}\")"],"metadata":{"id":"7hN3gzNhx__L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AdditiveAttentionWithCoverage(tf.keras.layers.attention.base_dense_attention.BaseDenseAttention):\n","  '''Calculates the Additive Attention by adding coverage with it\n","\n","    Args:\n","          use_scale : Boolean if True scale value will be initialized with shape [dim] otherwise it will be 1.0\n","\n","    Call Args:\n","      inputs: list of the following tensors:\n","        * `coverage`: It is of same shape as the attention distribution means `[batch, Tv, dim]`. For the first decoder\n","            input it is zero valued tensor.\n","        * `query`: Query tensor of shape `[batch, Tq, dim]`.\n","        * `value`: Value tensor of shape `[batch, Tv, dim]`.\n","        * `key`: Optional Key tensor of shape `[batch, Tv, dim]`.\n","\n","      mask: List of the following tensors:\n","        * `query_mask`: Boolean tensor of shape [batch_size, Tq]. If given then the query will be taken as zero where\n","          mask == False.\n","        * `key_mask`: Boolean tensor of shape [batch_size, Tv]. If given then the key will be taken as zero where\n","          mask == False.\n","\n","      training: Python boolean indicating whether the layer should behave in\n","          training mode (adding dropout) or in inference mode (no dropout).\n","\n","      return_attention_scores: bool, if `True`, returns the attention scores\n","          (after masking and softmax) as an additional output argument.\n","\n","\n","    Outputs:\n","\n","      Attention outputs of shape `[batch_size, Tq, dim]`.\n","      [Optional] Attention scores after masking and softmax with shape\n","        `[batch_size, Tq, Tv]`.\n","  '''\n","\n","  def __init__(self, use_scale=True, **kwargs):\n","    super().__init__(**kwargs)\n","    self.use_scale = use_scale\n","\n","  def build(self, input_shape):\n","    v_shape = tf.TensorShape(input_shape[1])\n","    dim = v_shape[-1]\n","    dim = tf.compat.dimension_value(dim)\n","\n","    if self.use_scale:\n","      self.scale = self.add_weight(shape=[dim],\n","                                   initializer=\"glorot_uniform\",\n","                                   dtype=self.dtype,\n","                                   trainable=True)\n","    else:\n","      self.scale = 1.0\n","\n","    self.wh = self.add_weight(shape=[1, 1, dim],\n","                              initializer=\"glorot_uniform\",\n","                              dtype=self.dtype,\n","                              trainable=True)\n","    self.ws = self.add_weight(shape=[1, 1, dim], initializer=\"glorot_uniform\",\n","                              dtype=self.dtype,\n","                              trainable=True)\n","    self.wc = self.add_weight(shape=[1, 1, dim],\n","                              initializer=\"glorot_uniform\",\n","                              dtype=self.dtype,\n","                              trainable=True)\n","    self.b = self.add_weight(shape=[1],\n","                             initializer=\"glorot_uniform\",\n","                             dtype=self.dtype,\n","                             trainable=True)\n","\n","  def _calculate_scores(self, coverage, query, key):\n","    \"\"\"Calculates attention scores as a nonlinear sum of query and key.\n","\n","    Args:\n","      coverage: Coverage tensor of shape `[batch_size, Tv, dim]`\n","      query: Query tensor of shape `[batch_size, Tq, dim]`.\n","      key: Key tensor of shape `[batch_size, Tv, dim]`.\n","    Returns:\n","      Tensor of shape `[batch_size, Tq, Tv]`.\n","    \"\"\"\n","    # Reshape tensors to enable broadcasting.\n","    # Reshape into [batch_size, Tq, 1, dim].\n","    q_reshaped = tf.expand_dims(query, axis=-2)\n","    # Reshape into [batch_size, 1, Tv, dim].\n","    k_reshaped = tf.expand_dims(key, axis=-3)\n","    c_reshaped = tf.expand_dims(coverage, axis=-3)\n","\n","    return tf.reduce_sum(self.scale * tf.tanh(self.wh * k_reshaped +\n","                                              self.ws * q_reshaped +\n","                                              self.wc * c_reshaped +\n","                                              self.b),\n","                         axis=-1)\n","\n","\n","  def call(self,\n","           inputs,\n","           mask=None,\n","           training=None,\n","           return_attention_scores=False,\n","           use_causal_mask=False):\n","    self._validate_call_args(input)\n","    c = inputs[0]\n","    q = inputs[1]\n","    v = inputs[2]\n","    k = inputs[3] if len(inputs)>3 else v\n","\n","    q_mask = mask[0] if mask else None\n","    v_mask = mask[1] if mask else None\n","    scores = self._calculate_scores(coverage=c, query=q, key=k)\n","\n","    if v_mask is not None:\n","      # Mask of shape [batch_size, 1, Tv].\n","      v_mask = tf.expand_dims(v_mask, axis=-2)\n","      if self.causal or use_causal_mask:\n","          # Creates a lower triangular mask, so position i cannot attend to\n","          # positions j>i. This prevents the flow of information from the\n","          # future into the past.\n","          scores_shape = tf.shape(scores)\n","          # causal_mask_shape = [1, Tq, Tv].\n","          causal_mask_shape = tf.concat(\n","              [tf.ones_like(scores_shape[:-2]), scores_shape[-2:]], axis=0\n","          )\n","          causal_mask = _lower_triangular_mask(causal_mask_shape)\n","      else:\n","          causal_mask = None\n","\n","      scores_mask = _merge_masks(v_mask, causal_mask)\n","      result, attention_scores = self._apply_scores(\n","          scores=scores, value=v, scores_mask=scores_mask, training=training\n","      )\n","      if q_mask is not None:\n","          # Mask of shape [batch_size, Tq, 1].\n","          q_mask = tf.expand_dims(q_mask, axis=-1)\n","          result *= tf.cast(q_mask, dtype=result.dtype)\n","      if return_attention_scores:\n","          return result, attention_scores\n","      return result\n","\n","\n","\n","  def _validate_call_args(self, inputs, mask):\n","    \"\"\"Validates arguments of the call method.\"\"\"\n","    class_name = self.__class__.__name__\n","    if not isinstance(inputs, list):\n","        raise ValueError(\n","            f\"{class_name} layer must be called on a list of inputs, \"\n","            \"namely [coverage, query, value] or [coverage, query, value, key]. \"\n","            f\"Received: {inputs}.\"\n","        )\n","    if len(inputs) < 3 or len(inputs) > 4:\n","        raise ValueError(\n","            f\"{class_name} layer accepts inputs list of length 3 or 4, \"\n","            \"namely [coverage, query, value] or [coverage, query, value, key]. \"\n","            f\"Received length: {len(inputs)}.\"\n","        )\n","    if mask:\n","        if not isinstance(mask, list):\n","            raise ValueError(\n","                f\"{class_name} layer mask must be a list, \"\n","                f\"namely [query_mask, value_mask]. Received: {mask}.\"\n","            )\n","        if len(mask) < 2 or len(mask) > len(inputs):\n","            raise ValueError(\n","                f\"{class_name} layer mask must be a list of length 2, \"\n","                \"namely [query_mask, value_mask]. \"\n","                f\"Received length: {len(mask)}.\"\n","            )\n","\n","\n","\n","# From tensorflow GitHub Source Code\n","def _lower_triangular_mask(shape):\n","    \"\"\"Creates a lower-triangular boolean mask over the last 2 dimensions.\"\"\"\n","    row_index = tf.cumsum(tf.ones(shape=shape, dtype=tf.int32), axis=-2)\n","    col_index = tf.cumsum(tf.ones(shape=shape, dtype=tf.int32), axis=-1)\n","    return tf.greater_equal(row_index, col_index)\n","\n","\n","def _merge_masks(x, y):\n","    if x is None:\n","        return y\n","    if y is None:\n","        return x\n","    return tf.logical_and(x, y)"],"metadata":{"id":"uOg6fhehPJoG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomAttention(tf.keras.layers.Layer):\n","  def __init__(self, use_scale=True, **kwargs):\n","    super(CustomAttention, self).__init__()\n","\n","    self.coverage_attention = AdditiveAttentionWithCoverage(use_scale=use_scale, **kwargs)\n","    self.layernorm = LayerNormalization()\n","    self.add = Add()\n","\n","\n","  def call(self, query, value, coverage):\n","    attn_output, attn_scores = self.coverage_attention(\n","        [coverage, query, value],\n","        return_attention_scores=True\n","    )\n","\n","    coverage = tf.add(coverage, attn_scores)\n","    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n","    self.last_attention_weights = attn_scores\n","\n","    query = self.add([query, attn_output])\n","    query = self.layernorm(query)\n","\n","    return query, attn_output"],"metadata":{"id":"TrpxqA1-xNJR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ex_attention_layer = CrossAttention()\n","\n","EMB_OUT = 256\n","emb = Embedding(summary_processor.vocabulary_size(), EMB_OUT)\n","ex_decoder_emb = emb(ex_decoder_in[:, 0:1])\n","ex_decoder_attention, attn_output = ex_attention_layer(ex_decoder_emb, ex_encoder_out)\n","\n","print(f\"ex_decoder_emb, shape = {ex_decoder_emb.shape}\")\n","print(f\"ex_encoder_out, shape = {ex_encoder_out.shape}\")\n","print(f\"ex_decoder_attention, shape = {ex_decoder_attention.shape}\")\n","print(f\"attn_output, shape = {attn_output.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ChYjPOTDG2bB","executionInfo":{"status":"ok","timestamp":1687153497565,"user_tz":-330,"elapsed":19,"user":{"displayName":"Arup Jana","userId":"14810629413154081064"}},"outputId":"029a8f97-4407-4797-fbdd-1744a4097bab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ex_decoder_emb, shape = (16, 1, 256)\n","ex_encoder_out, shape = (16, 400, 256)\n","ex_decoder_attention, shape = (16, 1, 256)\n","attn_output, shape = (16, 1, 256)\n"]}]},{"cell_type":"markdown","metadata":{"id":"MGwv7L8eJ1KH"},"source":["### Decoder"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"OHzf_bETCcsr","executionInfo":{"status":"ok","timestamp":1687347568312,"user_tz":-330,"elapsed":515,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["class Decoder(tf.keras.layers.Layer):\n","  @classmethod\n","  def add_method(cls, fun):\n","    setattr(cls, fun.__name__, fun)\n","    return fun\n","\n","  def __init__(self, units, text_processor):\n","    super(Decoder, self).__init__()\n","\n","    self.text_processor = text_processor\n","    self.vocab_size = text_processor.vocabulary_size()\n","    self.word_to_id = tf.keras.layers.StringLookup(vocabulary=text_processor.get_vocabulary(),\n","                                                   mask_token='',\n","                                                   oov_token='[UNK]')\n","    self.id_to_word = tf.keras.layers.StringLookup(vocabulary=text_processor.get_vocabulary(),\n","                                                   mask_token='',\n","                                                   oov_token='[UNK]',\n","                                                   invert=True)\n","    self.start_token = self.word_to_id('[START]')\n","    self.end_token = self.word_to_id('[END]')\n","\n","    self.units = units\n","\n","    self.embedding = Embedding(self.vocab_size, self.units, mask_zero=True)\n","    self.rnn = LSTM(self.units, return_sequences=True, return_state=True)\n","    self.attention = CrossAttention()\n","    self.output_layer = Dense(self.vocab_size, activation='softmax')\n","\n","\n","  def call(self, x, enc_article, state=None, return_state=False, return_attn=False):\n","    dec_in = self.embedding(x)\n","\n","    x, h_state, m_state = self.rnn(dec_in, initial_state=state)\n","    x, context_vector = self.attention(x, enc_article)\n","    self.last_attention_weights = self.attention.last_attention_weights\n","\n","\n","    logits = self.output_layer(x)\n","\n","    if return_state and return_attn:\n","      out = (logits, context_vector, [h_state, m_state])\n","\n","    elif return_attn:\n","      out = (logits, context_vector)\n","\n","    elif return_state:\n","      out = (logits, [h_state, m_state])\n","\n","    else:\n","      out = logits\n","\n","\n","    return out"]},{"cell_type":"markdown","metadata":{"id":"xdvFnzQDwZH9"},"source":["### Decoder add methods for inference"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"cO_cXcP7W5M_","executionInfo":{"status":"ok","timestamp":1687347570220,"user_tz":-330,"elapsed":7,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["@Decoder.add_method\n","def get_initial_state(self, articles):\n","  batch_size = tf.shape(articles)[0]\n","  start_tokens = tf.fill([batch_size, 1], self.start_token)\n","  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n","  embedded = self.embedding(start_tokens)\n","  return start_tokens, done, self.rnn.get_initial_state(embedded)"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"5Sm1P9GBXDtd","executionInfo":{"status":"ok","timestamp":1687347570223,"user_tz":-330,"elapsed":9,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["@Decoder.add_method\n","def tokens_to_text(self, tokens):\n","  words = self.id_to_word(tokens)\n","  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n","  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n","  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n","  return result"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"8kEiFZ3BXL-S","executionInfo":{"status":"ok","timestamp":1687347570225,"user_tz":-330,"elapsed":9,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["@Decoder.add_method\n","def get_next_token(self, article, next_token, done, state):\n","  logits, state = self(\n","    next_token, article,\n","    state = state,\n","    return_state=True)\n","\n","  next_token = tf.argmax(logits, axis=-1)\n","\n","  # If a sequence produces an `end_token`, set it `done`\n","  done = done | (next_token == self.end_token)\n","  # Once a sequence is done it only produces 0-padding.\n","  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n","\n","  return next_token, done, state"]},{"cell_type":"markdown","metadata":{"id":"EaBpoQxpHjkY"},"source":["### Pointer Generator"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"IoMmtzILHi9A","executionInfo":{"status":"ok","timestamp":1687347571996,"user_tz":-330,"elapsed":11,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["class PointerGenerator(tf.keras.layers.Layer):\n","  def __init__(self, units, vocab_size):\n","    super(PointerGenerator, self).__init__()\n","\n","    w_init = tf.random_normal_initializer()\n","    b_init = tf.zeros_initializer()\n","\n","    self.w_context = tf.Variable(initial_value=w_init(shape=(units, 1), dtype=\"float32\"),\n","        trainable=True)\n","    self.w_decoder_in = tf.Variable(initial_value=w_init(shape=(units, 1), dtype=\"float32\"),\n","        trainable=True)\n","    self.w_decoder_st = tf.Variable(initial_value=w_init(shape=(units, 1), dtype=\"float32\"),\n","        trainable=True)\n","    self.b_ptr = tf.Variable(initial_value=b_init(shape=(1,), dtype=\"float32\"),\n","                             trainable=True)\n","\n","    self.embedding = Embedding(vocab_size, units, mask_zero=True)\n","\n","  def call(self, inputs):\n","    context, dec_in, dec_st = inputs\n","    batch_size = tf.shape(context)[0]\n","\n","    dec_in = self.embedding(dec_in)\n","    dec_in = tf.reshape(dec_in, [batch_size, -1])\n","\n","    ptr_gen = tf.sigmoid(tf.matmul(context, self.w_context)\n","        + tf.matmul(dec_in, self.w_decoder_in)\n","        + tf.matmul(dec_st, self.w_decoder_st)\n","        + self.b_ptr)\n","\n","    return ptr_gen"]},{"cell_type":"markdown","metadata":{"id":"tjhs-ZwsXSwd"},"source":["### Summarizer"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"c0fYjckpA4S5","executionInfo":{"status":"ok","timestamp":1687347573587,"user_tz":-330,"elapsed":3,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"}}},"outputs":[],"source":["class Summarizer(tf.keras.Model):\n","\n","  @classmethod\n","  def add_method(cls, fun):\n","    setattr(cls, fun.__name__, fun)\n","    return fun\n","\n","  def __init__(self, enc_emb_dim, units,\n","               vocab_size,\n","               article_processor, summary_processor,\n","               max_article_tokens, max_summary_tokens):\n","\n","    super().__init__()\n","\n","    self.units = units\n","    self.vocab_size = vocab_size\n","    self.max_article_tokens = max_article_tokens\n","    self.max_summary_tokens = max_summary_tokens\n","\n","    self.encoder = Encoder(enc_emb_dim, units, article_processor)\n","    self.decoder = Decoder(units, summary_processor)\n","    self.pointer_generator = PointerGenerator(units, vocab_size)\n","\n","  def call(self, inputs):\n","    count_oovs, article_in, summary_in = inputs\n","    max_art_oov = tf.reduce_max(count_oovs)\n","\n","    logits = []\n","    extended_zeros = tf.zeros((BATCH_SIZE, max_art_oov))\n","\n","    encoder_flat = tf.reshape(article_in, [-1])\n","    batch_indices = tf.tile(tf.range(BATCH_SIZE)[:, tf.newaxis], [1, self.max_article_tokens])\n","    batch_indices = tf.reshape(batch_indices, [-1])\n","    batch_indices = tf.cast(batch_indices, tf.int64)\n","\n","    indices = tf.stack([batch_indices, encoder_flat], axis=1)\n","\n","    enc_article = self.encoder(article_in)\n","\n","    for t in range(self.max_summary_tokens-1): # We have to go till 98 as x has 98 entries for each batch\n","      dec_in = summary_in[:, t:t+1]\n","\n","      P_vocab, context_vector, [h_state, _] = self.decoder(dec_in, enc_article,\n","                                                          return_state=True, return_attn=True)\n","      P_vocab = tf.reshape(P_vocab, [BATCH_SIZE, -1])\n","      context_vector = tf.reshape(context_vector, [BATCH_SIZE, -1])\n","\n","      P_vocab = tf.concat([P_vocab, extended_zeros], axis=1)\n","\n","      p_gen = self.pointer_generator([context_vector, dec_in, h_state])\n","      P_vocab = p_gen * P_vocab\n","\n","      attention = self.decoder.attention.last_attention_weights\n","      attn_dist = (1-p_gen)@tf.ones((1, attention.shape[1]))*attention\n","\n","      values = tf.reshape(attn_dist, [-1])\n","      P_extended = tf.zeros((BATCH_SIZE, self.vocab_size+max_art_oov))\n","      attn_dist = tf.tensor_scatter_nd_update(P_extended, indices, values)\n","\n","      P = tf.cast(P_vocab, tf.float32) + tf.cast(attn_dist, tf.float32)\n","      P = tf.expand_dims(P, axis=1)\n","      logits.append(P)\n","\n","    logits = tf.concat(logits, axis=1)\n","    return logits"]},{"cell_type":"markdown","source":["## Evaluate and Train Model on Dataset"],"metadata":{"id":"NBdb4Ax04gPb"}},{"cell_type":"code","source":["UNITS = 256\n","EMB_DIM = 128\n","max_article_tokens = 400\n","vocab_size = summary_processor.vocabulary_size()\n","\n","model = Summarizer(EMB_DIM, UNITS, vocab_size,\n","                   article_processor, summary_processor,\n","                   max_article_tokens, max_summary_tokens)"],"metadata":{"id":"hGi_AqnW4oIq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def masked_loss(y_true, y_pred):\n","    # Calculate the loss for each item in the batch.\n","    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction='none')\n","    loss = loss_fn(y_true, y_pred)\n","\n","    # Mask off the losses on padding.\n","    mask = tf.cast(y_true != 0, loss.dtype)\n","    loss *= mask\n","\n","    # Return the total.\n","    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"],"metadata":{"id":"ujGaindj4-ar"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def masked_acc(y_true, y_pred):\n","  # Find the index with max logits value\n","  y_pred = tf.argmax(y_pred, axis=-1)\n","  y_pred = tf.cast(y_pred, y_true.dtype)\n","\n","  match = tf.cast(y_true == y_pred, tf.float32)\n","  # Mask off the padding.\n","  mask = tf.cast(y_true != 0, tf.float32)\n","\n","  return tf.reduce_sum(match) / tf.reduce_sum(mask)"],"metadata":{"id":"aF5WvAAy5Bvw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["adagrad_opt = tf.keras.optimizers.experimental.Adagrad(\n","    learning_rate=0.15,\n","    initial_accumulator_value=0.1,\n","    clipnorm=2,\n",")\n","\n","model.compile(adagrad_opt, loss=masked_loss, metrics=[masked_loss, masked_acc])"],"metadata":{"id":"jQd6ksYJ4sRf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.evaluate(val_ds)"],"metadata":{"id":"3FXTb9qt5Lse"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Apdyas1qCaMJ"},"source":["## Model Training and Evaluation loop"]},{"cell_type":"code","source":["word2id = tf.keras.layers.StringLookup(mask_token='',\n","                                      oov_token=\"[UNK]\",\n","                                      vocabulary=summary_processor.get_vocabulary())\n","id2word = tf.keras.layers.StringLookup(mask_token='',\n","                                      oov_token=\"[UNK]\",\n","                                      vocabulary=summary_processor.get_vocabulary(),\n","                                      invert=True)\n","\n","vocab_size = summary_processor.vocabulary_size()\n","max_article_tokens = 400\n","max_summary_tokens = 100"],"metadata":{"id":"U_vgIkl6Uvk0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encode_oov(article, summary):\n","  ## 1. Find the OOV words and Count of them\n","  # Split the article into words\n","  article_words = tf.strings.split(article)\n","\n","  # Truncate sequence if it exceeds the maximum length\n","  article_words = article_words[:max_article_tokens]\n","  # Pad the sequence if it is shorter than the maximum length\n","  num_padding = (max_article_tokens-2) - tf.shape(article_words, out_type=tf.int32)[0]\n","  padding = tf.repeat([''], num_padding)\n","  article_words = tf.concat([article_words, padding], axis=0)\n","\n","  # Find the tokens for article words\n","  article_tokens = word2id(article_words)\n","\n","  # Find the OOV words by comparing the article_tokens to 1\n","  oovs = tf.boolean_mask(article_words, tf.equal(article_tokens, 1))\n","  oovs = tf.unique_with_counts(oovs).y\n","\n","  # Count of the OOVs in the article\n","  oovs_count = tf.shape(tf.unique_with_counts(oovs).y, out_type=tf.int32)[0]\n","\n","  ## 2. Encode article and Summary with OOVs\n","  # For encoder\n","  # Add [START] and [END] tokens to article\n","  article_words = tf.pad(article_words, paddings=[[1, 0]], constant_values=\"[START]\")\n","  article_words = tf.pad(article_words, paddings=[[0, 1]], constant_values=\"[END]\")\n","  # Find the unknown words indices\n","  article_unk_ids = tf.where(word2id(article_words)==1)\n","  # Gather the unknown words using their indices\n","  article_unk_words = tf.gather(article_words, article_unk_ids[:, 0])\n","  # Tokenize the article words (UNK words included)\n","  encoder_in = word2id(article_words)\n","\n","  # For decoder\n","  summary_words = tf.strings.split(summary)\n","  # Truncate sequence if it exceeds the maximum length\n","  summary_words = summary_words[:max_summary_tokens]\n","  # Pad the sequence if it is shorter than the maximum length\n","  num_padding = max_summary_tokens - tf.shape(summary_words, out_type=tf.int32)[0]\n","  padding = tf.repeat([''], num_padding)\n","  summary_words = tf.concat([summary_words, padding], axis=0)\n","  # Find the article OOVs indices in the summary\n","  summary_unk_ids = tf.where(word2id(summary_words)==1)\n","  # Gather the words in those indices\n","  summary_unk_words = tf.gather(summary_words, summary_unk_ids[:, 0])\n","  # Tokenize the summary words along with Known OOVs\n","  decoder_in_out = word2id(summary_words)\n","\n","  # If any UNK word is present in the article\n","  if tf.not_equal(oovs_count, 0):\n","    ## 3. Find the mapping and then use to map from OOVs to their IDs\n","    # Calculate the IDs according to no of OOVs e.g. 50002, 50003, 50004, ...\n","    oov_ids = tf.add(tf.range(oovs_count, dtype=tf.int32), vocab_size)\n","    # Create the mapping table for oov word to id\n","    init = tf.lookup.KeyValueTensorInitializer(oovs, oov_ids)\n","    oov_word2id = tf.lookup.StaticHashTable(init, default_value=1)\n","\n","    # Map the article's UNK words to their IDs\n","    article_unk_tokens = oov_word2id.lookup(article_unk_words)\n","    article_unk_tokens = tf.cast(article_unk_tokens, tf.int64)\n","    # Place the OOV IDs at the right indices where UNK words were found\n","    encoder_in = tf.tensor_scatter_nd_update(encoder_in, article_unk_ids, article_unk_tokens)\n","\n","    # Map the summary's UNK words to their IDs\n","    summary_unk_tokens = oov_word2id.lookup(summary_unk_words)\n","    summary_unk_tokens = tf.cast(summary_unk_tokens, tf.int64)\n","    decoder_in_out = tf.tensor_scatter_nd_update(decoder_in_out, summary_unk_ids, summary_unk_tokens)\n","\n","  return (oovs_count, encoder_in, decoder_in_out[:-1]), decoder_in_out[1:]"],"metadata":{"id":"DnHmJF1GJbD2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = train_raw.map(encode_oov)\n","val_ds = val_raw.map(encode_oov)"],"metadata":{"id":"Jb_U4qsxvnMG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Loiqh6nefTT0"},"outputs":[],"source":["def masked_loss(y_true, y_pred):\n","    # Calculate the loss for each item in the batch.\n","    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction='none')\n","    loss = loss_fn(y_true, y_pred)\n","\n","    # Mask off the losses on padding.\n","    mask = tf.cast(y_true != 0, loss.dtype)\n","    loss *= mask\n","\n","    # Return the total.\n","    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aaVycGPOUJp7"},"outputs":[],"source":["class SummaryLossMetric(tf.keras.metrics.Metric):\n","  def __init__(self, name=\"summary_loss\", **kwargs):\n","    super(SummaryLossMetric, self).__init__(name, **kwargs)\n","    self.loss = self.add_weight(name=\"loss\", initializer='zero')\n","\n","  def update_state(self, y_true, y_pred, sample_weight=None):\n","    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n","    loss = loss_fn(y_true, y_pred)\n","\n","    mask = tf.cast(y_true != 0, loss.dtype)\n","    loss *= mask\n","\n","    self.loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)\n","\n","  def result(self):\n","    return self.loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iMDpkUfFXSof"},"outputs":[],"source":["class SummaryAccuracyMetric(tf.keras.metrics.Metric):\n","  def __init__(self, name=\"SummaryAccuracyMetric\", **kwargs):\n","    super(SummaryAccuracyMetric, self).__init__(name, **kwargs)\n","\n","    self.accuracy = self.add_weight(name=\"acc\", initializer='zero')\n","\n","  def update_state(self, y_true, y_pred, sample_weight=None):\n","    y_pred = tf.argmax(y_pred, axis=-1)\n","    y_pred = tf.cast(y_pred, y_true.dtype)\n","\n","    match = tf.cast(y_true == y_pred, tf.float32)\n","    mask = tf.cast(y_true != 0, tf.float32)\n","\n","    self.accuracy = tf.reduce_sum(match) / tf.reduce_sum(mask)\n","\n","  def result(self):\n","    return self.accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r07c7xxcDUXI"},"outputs":[],"source":["UNITS = 256\n","EMB_DIM = 128\n","max_article_tokens = 400\n","vocab_size = summary_processor.vocabulary_size()\n","\n","model = Summarizer(EMB_DIM, UNITS, vocab_size,\n","                   article_processor, summary_processor,\n","                   max_article_tokens, max_summary_tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"628BB3GzhmHh"},"outputs":[],"source":["adagrad_opt = tf.keras.optimizers.experimental.Adagrad(\n","    learning_rate=0.15,\n","    initial_accumulator_value=0.1,\n","    clipnorm=2,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3DY-LE2mxQA"},"outputs":[],"source":["loss_metric = SummaryLossMetric()\n","acc_metric = SummaryAccuracyMetric()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o11QDTHpmEDG"},"outputs":[],"source":["@tf.function\n","def train_step(x, y):\n","  with tf.GradientTape() as tape:\n","    logits = model(x, training=True)\n","\n","    loss = masked_loss(y, logits)\n","\n","  grad = tape.gradient(loss, model.trainable_weights)\n","  adagrad_opt.apply_gradients(zip(grad, model.trainable_weights))\n","\n","  return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EesNAz8CmgOX"},"outputs":[],"source":["@tf.function\n","def test_step(x, y):\n","  logits = model(x, training=False)\n","\n","  loss_metric.update_state(y, logits)\n","  acc_metric.update_state(y, logits)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BNgcm0avsFzL"},"outputs":[],"source":["def training_loop(model, epochs=5,\n","                  steps_per_epoch=10, validation_steps=5,\n","                  save_point='/checkpoint.ckpt',\n","                  patience=3):\n","  history = {'train_loss':[], 'validation_loss': []}\n","\n","  prev_acc = -inf\n","  curr_acc = 0\n","\n","  # For shuffle\n","  BUFFER_SIZE = len(train_raw)\n","\n","  # For taking care of the OOV words in article\n","  word2id = tf.keras.layers.StringLookup(mask_token='',\n","                                      oov_token=\"[UNK]\",\n","                                      vocabulary=summary_processor.get_vocabulary())\n","  id2word = tf.keras.layers.StringLookup(mask_token='',\n","                                        oov_token=\"[UNK]\",\n","                                        vocabulary=summary_processor.get_vocabulary(),\n","                                        invert=True)\n","  vocab_size = summary_processor.vocabulary_size()\n","  max_article_tokens = 400\n","  max_summary_tokens = 100\n","  oov_utils = OOV_Utils(word2id, id2word,\n","                            vocab_size, max_article_tokens, max_summary_tokens)\n","\n","  # For the EarlyStopping\n","  patience_array = []\n","  stop_training = False\n","\n","  for epoch in range(epochs):\n","    # Start of the new progress bar\n","    train_pbar = tqdm(total=100, ncols=100, desc=f\"Training Epoch {epoch+1}\", position=0, leave=True)\n","\n","    count = 0\n","    # Train the model using new train data\n","    for articles, summaries in train_raw.shuffle(BUFFER_SIZE).repeat():\n","\n","      train_batch_size = articles.shape[0]\n","      oov_utils.max_oovs(articles)\n","\n","      train_encoder_in = oov_utils.extended_encoder_vocab(articles)\n","\n","      summaries_tokens = oov_utils.extended_decoder_vocab(summaries)\n","\n","      train_decoder_in = summaries_tokens[:, :-1]\n","      train_decoder_out = summaries_tokens[:, 1:]\n","\n","      max_oovs = oov_utils.max_art_oov\n","      train_max_oov = tf.ones([train_batch_size, 1], dtype=tf.int32) * max_oovs\n","\n","      loss = train_step((train_max_oov, train_encoder_in, train_decoder_in), train_decoder_out)\n","\n","      count += 1\n","\n","      # Calculate the progress and update the progress bar\n","      progress = int((100 / steps_per_epoch) * count)\n","      train_pbar.update(progress)\n","      # Update the progess bar information\n","      train_pbar.set_postfix_str(f\"loss: {loss : .3f}\")\n","\n","      # Making sure it runs for exactly steps_per_epoch times\n","      if count >= steps_per_epoch:\n","        break\n","\n","    # New progress bar for validation set\n","    val_pbar = tqdm(total=50, ncols=50, desc=f\"Validation Epoch {epoch+1}\", position=1, leave=True)\n","\n","    count = 0\n","    # Take validatoion batch and evaluate the model with it\n","    for (val_max_oov, val_encoder_in, val_decoder_in), val_decoder_out in val_raw.shuffle(BUFFER_SIZE).repeat():\n","      val_batch_size = articles.shape[0]\n","      oov_utils.max_oovs(articles)\n","\n","      val_encoder_in = oov_utils.extended_encoder_vocab(articles)\n","\n","      summaries_tokens = oov_utils.extended_decoder_vocab(summaries)\n","\n","      val_decoder_in = summaries_tokens[:, :-1]\n","      val_decoder_out = summaries_tokens[:, 1:]\n","\n","      max_oovs = oov_utils.max_art_oov\n","      val_max_oov = tf.ones([val_batch_size, 1], dtype=tf.int32) * max_oovs\n","\n","      test_step((val_max_oov, val_encoder_in, val_decoder_in), val_decoder_out)\n","\n","      count += 1\n","\n","      # Update the progress bar\n","      progress = int((50 / validation_steps) * count)\n","      val_pbar.update(progress)\n","      # Update bar showing validation performance\n","      val_pbar.set_postfix_str(f\"val loss: {float(loss_metric.result()): .3f} - \\\n","       val acc: {float(acc_metric.result()): .3f}\")\n","\n","      if count >= validation_steps:\n","        break\n","\n","\n","    # Add new train and validation losses in the history dictionary\n","    history['train_loss'].append(float(loss))\n","    history['validation_loss'].append(float(loss_metric.result()))\n","\n","\n","\n","    # Whether to save the current model comparing it's previous and current performance on validation\n","    curr_acc = float(acc_metric.result())\n","    if prev_acc < curr_acc:\n","      print(f\"Accuracy improved from {prev_acc} to {curr_acc}. Saving model weights at {save_point}\")\n","      model.save_weights(save_point)\n","    else:\n","      print(f\"Accuracy did not improve.\")\n","\n","    # EarlyStopping Mechanism\n","    patience_array.append(curr_acc)\n","\n","    if len(patience_array) == patience+1:\n","\n","      count = 0\n","\n","      for p in patience_array[1:]:\n","        if p < patience_array[0]:\n","          count += 1\n","\n","      if count == len(patience_array)-1:\n","        stop_training = True\n","        break\n","\n","      if len(patience_array) == patience+1:\n","        patience_array.pop(0)\n","\n","\n","    # Update the previous accuracy with new for the next epoch\n","    prev_acc = curr_acc\n","\n","    # Reset the metrics for further analysis on new epoch\n","    loss_metric.reset_state()\n","    acc_metric.reset_state()\n","\n","  return model, history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":40843,"status":"error","timestamp":1686980202815,"user":{"displayName":"ARUP JANA","userId":"15117592170041517372"},"user_tz":-330},"id":"0ev6wSqjClUX","outputId":"80f211a5-cb43-49a3-afcc-1404bbd0c681"},"outputs":[{"name":"stderr","output_type":"stream","text":["\rTraining Epoch 1:   0%|                                                     | 0/100 [00:00<?, ?it/s]"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-e8cdb493fdca>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_point\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-44-ce8dfb6de3c0>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, epochs, steps_per_epoch, validation_steps, save_point, patience)\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0mtrain_max_oov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_oovs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_max_oov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_encoder_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_decoder_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_decoder_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_variable_creation_fn = (\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m    \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m         ._get_concrete_function_internal_garbage_collected(\n\u001b[1;32m    765\u001b[0m             *args, **kwds))\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;34m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_concrete_function_internal_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaceholder_bound_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           concrete_function = self._create_concrete_function(\n\u001b[0m\u001b[1;32m    397\u001b[0m               args, kwargs, func_graph)\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     concrete_function = monomorphic_function.ConcreteFunction(\n\u001b[0;32m--> 300\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1212\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m   1190\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/__autograph_generated_fileszma4x5t.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 ):\n\u001b[0;32m-> 1145\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/__autograph_generated_fileyof076ky.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mattn_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attn_dist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdec_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dec_in'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_summary_tokens\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m't'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mfor_stmt\u001b[0;34m(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0mfor_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tf_distributed_iterable_for_stmt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m   \u001b[0mfor_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36m_py_for_stmt\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    500\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m       \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mprotected_body\u001b[0;34m(protected_iter)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0moriginal_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprotected_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotected_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m       \u001b[0moriginal_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotected_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m       \u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m       \u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/__autograph_generated_fileyof076ky.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mdec_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0mP_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_article\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_attn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                     \u001b[0mP_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mcontext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 ):\n\u001b[0;32m-> 1145\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/__autograph_generated_file8em8c3up.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, x, enc_article, state, return_state, return_attn, training)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mdec_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_vector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_article\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attention_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/base_rnn.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 ):\n\u001b[0;32m-> 1145\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/lstm.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    746\u001b[0m                         \u001b[0mnew_c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m                         \u001b[0mruntime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m                     ) = lstm_with_backend_selection(**normal_lstm_kwargs)\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/lstm.py\u001b[0m in \u001b[0;36mlstm_with_backend_selection\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[1;32m   1339\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m         )\n\u001b[0;32m-> 1341\u001b[0;31m         \u001b[0mgru_lstm_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_gpu_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/gru_lstm_utils.py\u001b[0m in \u001b[0;36mfunction_register\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mconcrete_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_gradient_functions_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36madd_gradient_functions_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m   2010\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m     forward_function, backward_function = (\n\u001b[0;32m-> 2012\u001b[0;31m         self._delayed_rewrite_functions.forward_backward())\n\u001b[0m\u001b[1;32m   2013\u001b[0m     \u001b[0mforward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m     \u001b[0mbackward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    524\u001b[0m       backwards_graph = func_graph_module.FuncGraph(\n\u001b[1;32m    525\u001b[0m           _backward_name(self._func_graph.name))\n\u001b[0;32m--> 526\u001b[0;31m       func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    527\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackwards_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m           \u001b[0mpython_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_backprop_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1212\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[0;34m(*grad_ys)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backprop_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         return gradients_util._GradientsHelper(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mtrainable_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 \u001b[0;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[1;32m    696\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n\u001b[1;32m    697\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m   \u001b[0;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 696\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    697\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_IfGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0;31m# graphs. These functions will capture tensors from the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   true_grad_graph = _create_grad_func(\n\u001b[0m\u001b[1;32m    122\u001b[0m       true_graph, grads, util.unique_grad_fn_name(true_graph.name))\n\u001b[1;32m    123\u001b[0m   false_grad_graph = _create_grad_func(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_create_grad_func\u001b[0;34m(func_graph, grads, name)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_create_grad_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m   \u001b[0;34m\"\"\"Returns the FuncGraph representation of _grad_fn.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m   return func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    431\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m       \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1212\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    430\u001b[0m   return func_graph_module.func_graph_from_py_func(\n\u001b[1;32m    431\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m       \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m       func_graph=_CondGradFuncGraph(name, func_graph))\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_grad_fn\u001b[0;34m(func_graph, grads)\u001b[0m\n\u001b[1;32m    419\u001b[0m   \u001b[0;31m# func_graph. The captured func_graph tensors are resolved to external tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m   \u001b[0;31m# in _resolve_grad_inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m   result = gradients_util._GradientsHelper(\n\u001b[0m\u001b[1;32m    422\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m       src_graph=func_graph)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 \u001b[0;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[1;32m    696\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n\u001b[1;32m    697\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m   \u001b[0;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 696\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    697\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_ConcatGradV2\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ConcatV2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_ConcatGradV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m   return _ConcatGradHelper(\n\u001b[0m\u001b[1;32m    228\u001b[0m       op, grad, start_value_index=0, end_value_index=-1, dim_index=-1)\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_ConcatGradHelper\u001b[0;34m(op, grad, start_value_index, end_value_index, dim_index)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       \u001b[0;31m# Get the inputs' tensor shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m       \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ExtractInputShapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0;31m# The magic number of 16 was found through benchmarking a range of sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0;31m# on CPUs and a Maxwell TitanX.  A speedup was seen in a large majority of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_ExtractInputShapes\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     90\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m       if not isinstance(input_shape,\n\u001b[0;32m---> 92\u001b[0;31m                         ops.Tensor) or input_shape.op.type != \"Const\":\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mfully_known\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2583\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m     \u001b[0;34m\"\"\"The type of the op (e.g. `\"MatMul\"`).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["epochs = 1\n","steps = 5\n","\n","model_dir = os.path.join(project_dir, \"models\")\n","model_path = os.path.join(model_dir,\"weights_best.ckpt\")\n","\n","\n","model, history = training_loop(model, epochs, steps, save_point=model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"executionInfo":{"elapsed":649,"status":"ok","timestamp":1685805098820,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"-YQ3sU6ln52o","outputId":"91edc13e-f549-4898-f4c6-5ebef079f4eb"},"outputs":[{"data":{"text/plain":["<matplotlib.legend.Legend at 0x7ff8bf50e7a0>"]},"execution_count":62,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.plot(history.history['loss'], label='loss')\n","plt.plot(history.history['val_loss'], label='val_loss')\n","plt.ylim([0, max(plt.ylim())])\n","plt.xlabel('Epoch #')\n","plt.ylabel('CE/token')\n","plt.legend()"]},{"cell_type":"markdown","metadata":{"id":"gWij0ZAKovXW"},"source":["## Test the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ROIgJghVrGNs"},"outputs":[],"source":["@Summarizer.add_method\n","def summarize(self,\n","              texts, *,\n","              max_length=120):\n","  # Process the input texts\n","  context = self.encoder.convert_inputs(texts, mode=\"encode\")\n","  batch_size = tf.shape(texts)[0]\n","\n","  # Setup the loop inputs\n","  tokens = []\n","  attention_weights = []\n","  next_token, done, state = self.decoder.get_initial_state(context)\n","\n","  for _ in range(max_length):\n","    # Generate the next token\n","    next_token, done, state = self.decoder.get_next_token(\n","        context, next_token, done,  state)\n","\n","    # Collect the generated tokens\n","    tokens.append(next_token)\n","    attention_weights.append(self.decoder.last_attention_weights)\n","\n","    if tf.executing_eagerly() and tf.reduce_all(done):\n","      break\n","\n","  # Stack the lists of tokens and attention weights.\n","  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n","  self.last_attention_weights = tf.concat(tf.reshape(attention_weights, [batch_size, -1, 1]), axis=2)  # t*[(batch s, 1)] -> (batch, s, t)\n","\n","  result = self.decoder.tokens_to_text(tokens)\n","  return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XMtNEYFsoxyZ"},"outputs":[],"source":["UNITS = 256\n","EMB_DIM = 128\n","\n","model_dir = os.path.join(project_dir, \"models\")\n","model_path = os.path.join(model_dir,\"weights.best.hdf5\")\n","\n","summarizer = Summarizer(EMB_DIM, UNITS, article_processor, summary_processor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NrpYnMySqSDR"},"outputs":[],"source":["adagrad_opt = tf.keras.optimizers.experimental.Adagrad(\n","    learning_rate=0.15,\n","    initial_accumulator_value=0.1,\n","    clipnorm=2,\n",")\n","\n","summarizer.compile(optimizer=adagrad_opt,\n","              loss=masked_loss,\n","              metrics=[masked_acc, masked_loss])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6kB-RzzlptUt"},"outputs":[],"source":["summarizer.load_weights(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115519,"status":"ok","timestamp":1686222240770,"user":{"displayName":"Arup Jana","userId":"08424695991937250832"},"user_tz":-330},"id":"YRhw35Xaq45i","outputId":"97870c40-8428-4650-bffa-089e5b887702"},"outputs":[{"name":"stdout","output_type":"stream","text":["20/20 [==============================] - 115s 5s/step - loss: 5.2256 - masked_acc: 0.2306 - masked_loss: 5.2277\n"]},{"data":{"text/plain":["{'loss': 5.225553035736084,\n"," 'masked_acc': 0.23058421909809113,\n"," 'masked_loss': 5.227725982666016}"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["summarizer.evaluate(val_ds, steps=20, return_dict=True)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["qobuwS7N6mpZ","ZBVqadIrP22p","iMHo8KwghWg_","Wo9PYHLAhcjI","UWxDk1TqiMGM","612fTKqGQ5gH","Ep8QmSUB8FVv","vvpDFe6qJfJB","Iad-kg5uJz7T","Erk64K_RKr2Q","RZwn6wTmJIvP","enGgXln6Izhh","cxcnl02e7d03","LahUcxcHA6hD","-gOstX3M5qr0","q9dHhoI1-Puy","HVQIT-iVNbUY","MGwv7L8eJ1KH","xdvFnzQDwZH9","EaBpoQxpHjkY","tjhs-ZwsXSwd","NBdb4Ax04gPb","gWij0ZAKovXW"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}